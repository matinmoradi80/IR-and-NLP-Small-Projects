ID,Title,Abstract,Publication Year,Authors,Related_Topics,Citation Count,Reference Count
231732518,The Eighth Visual Object Tracking VOT2020 Challenge Results,,2020,"M. Kristan,A. Leonardis,Jiri Matas,M. Felsberg,R. Pflugfelder,Joni-Kristian Kämäräinen,Martin Danelljan,L. Č. Zajc,A. Lukežič,O. Drbohlav,Linbo He,Yushan Zhang,Song Yan,Jinyu Yang,G. Fernandez,A. Hauptmann,Alireza Memarmoghadam,Álvaro García-Martín,Andreas Robinson,A. Varfolomieiev,Awet Haileslassie Gebrehiwot,Bedirhan Uzun,Bin Yan,Bing Li,C. Qian,Chi-Yi Tsai,C. Micheloni,Dong Wang,Fei Wang,Fei Xie,Felix Järemo Lawin,F. Gustafsson,G. Foresti,Goutam Bhat,Guang-Gui Chen,Haibin Ling,Haitao Zhang,Hakan Cevikalp,Haojie Zhao,Haoran Bai,Hari Chandana Kuchibhotla,Hasan Saribas,Heng Fan,Hossein Ghanei-Yakhdan,Houqiang Li,Houwen Peng,Huchuan Lu,Hui Li,Javad Khaghani,Jesús Bescós,Jianhua Li,Jianlong Fu,Jiaqian Yu,Jingtao Xu,J. Kittler,Jun Yin,Junhyun Lee,Kaicheng Yu,Kaiwen Liu,Kang Yang,Kenan Dai,Li Cheng,Li Zhang,Lijun Wang,Linyuan Wang,L. Gool,Luca Bertinetto,Matteo Dunnhofer,Miao Cheng,Mohana Murali Dasari,Ning Wang,Pengyu Zhang,Philip H. S. Torr,Qiang Wang,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Seokeon Choi,S. M. Marvasti-Zadeh,Shaochuan Zhao,S. Kasaei,Shoumeng Qiu,Shuhao Chen,Thomas Bo Schön,Tianyang Xu,W. Lu,Weiming Hu,Wen-gang Zhou,Xi Qiu,Xiao Ke,Xiaojun Wu,Xiaolin Zhang,Xiaoyun Yang,Xuefeng Zhu,Yingjie Jiang,Yingming Wang,Yiwei Chen,Yu Ye,Yuezhou Li,Yuncon Yao,Yunsung Lee,Yuzhang Gu,Zezhou Wang,Zhangyong Tang,Zhenhua Feng,Zhijun Mai,Zhipeng Zhang,Zhirong Wu,Ziang Ma",Computer Science,187,87
39119547,Benign and malignant breast tumors classification based on region growing and CNN segmentation,,2015,"R. Rouhi,M. Jafari,S. Kasaei,P. Keshavarzian",Computer Science,352,58
206661629,Event Detection and Summarization in Soccer Videos Using Bayesian Network and Copula,"Semantic video analysis and automatic concept extraction play an important role in several applications; including content-based search engines, video indexing, and video summarization. As the Bayesian network is a powerful tool for learning complex patterns, a novel Bayesian network-based method is proposed for automatic event detection and summarization in soccer videos. The proposed method includes efficient algorithms for shot boundary detection, shot view classification, mid-level visual feature extraction, and construction of the related Bayesian network. The method contains of three main stages. In the first stage, the shot boundaries are detected. Using the hidden Markov model, the video is segmented into large and meaningful semantic units, called play-break sequences. In the next stage, several features are extracted from each of these units. Finally, in the last stage, in order to achieve high level semantic features (events and concepts), the Bayesian network is used. The basic part of the method is constructing the Bayesian network, for which the structure is estimated using the Chow-Liu tree. The joint distributions of random variables of the network are modeled by applying the Farlie-Gumbel-Morgenstern family of Copulas. The performance of the proposed method is evaluated on a dataset with about 9 h of soccer videos. The method is capable of detecting seven different events in soccer videos; namely, goal, card, goal attempt, corner, foul, offside, and nonhighlights. Experimental results show the effectiveness and robustness of the proposed method on detecting these events.",2014,"Mostafa Tavassolipour,Mahmood Karimian,S. Kasaei",Computer Science,98,40
5253113,An efficient PCA-based color transfer method,,2007,"A. Abadpour,S. Kasaei","Mathematics,Computer Science",67,45
208527176,Deep Learning for Visual Tracking: A Comprehensive Survey,"Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years – predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.",2019,"S. M. Marvasti-Zadeh,Li Cheng,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",205,272
9281781,Spatial-Aware Dictionary Learning for Hyperspectral Image Classification,"This paper presents a structured dictionary-based model for hyperspectral data that incorporates both spectral and contextual characteristics of spectral samples. The idea is to partition the pixels of a hyperspectral image into a number of spatial neighborhoods called contextual groups and to model the pixels inside a group as members of a common subspace. That is, each pixel is represented using a linear combination of a few dictionary elements learned from the data, but since pixels inside a contextual group are often made up of the same materials, their linear combinations are constrained to use common elements from the dictionary. To this end, dictionary learning is carried out with a joint sparse regularizer to induce a common sparsity pattern in the sparse coefficients of a contextual group. The sparse coefficients are then used for classification using a linear support vector machine. Experimental results on a number of real hyperspectral images confirm the effectiveness of the proposed representation for hyperspectral image classification. Moreover, experiments with simulated multispectral data show that the proposed model is capable of finding representations that may effectively be used for classification of multispectral resolution samples.",2013,"A. Soltani-Farani,H. Rabiee,Seyyed Abbas Hosseini",Computer Science,122,67
227126845,Multiresolution Knowledge Distillation for Anomaly Detection,"Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the ""distillation"" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.",2020,"Mohammadreza Salehi,Niousha Sadjadi,Soroosh Baselizadeh,M. Rohban,H. Rabiee",Computer Science,217,62
4909695,A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics,"Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user’s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.",2017,"Seyed Ali Osia,Ali Shahin Shamsabadi,Sina Sajadmanesh,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,204,70
34979781,Novel dataset for fine-grained abnormal behavior understanding in crowd,"Despite the huge research on crowd on behavior understanding in visual surveillance community, lack of publicly available realistic datasets for evaluating crowd behavioral interaction led not to have a fair common test bed for researchers to compare the strength of their methods in the real scenarios. This work presents a novel crowd dataset contains around 45,000 video clips which annotated by one of the five different fine-grained abnormal behavior categories. We also evaluated two state-of-the-art methods on our dataset, showing that our dataset can be effectively used as a benchmark for fine-grained abnormality detection. The details of the dataset and the results of the baseline methods are presented in the paper.",2016,"H. Rabiee,J. Haddadnia,Hossein Mousavi,M. Kalantarzadeh,Moin Nabi,Vittorio Murino",Computer Science,50,26
11527748,Deep Private-Feature Extraction,"We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints. Using the selective exchange of information between a user's device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model. We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency trade-offs. Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive information.",2018,"S. A. Ossia,A. Taheri,A. Shamsabadi,Kleomenis Katevas,H. Haddadi,H. Rabiee","Mathematics,Computer Science",78,63
204812415,Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl,,2019,"Juan C. Caicedo,A. Goodman,Kyle W. Karhohs,B. Cimini,Jeanelle Ackerman,Marzieh Haghighi,Cherkeng Heng,Tim Becker,M. Doan,C. McQuin,M. Rohban,Shantanu Singh,Anne E Carpenter","Medicine,Computer Science",427,53
227126845,Multiresolution Knowledge Distillation for Anomaly Detection,"Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the ""distillation"" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.",2020,"Mohammadreza Salehi,Niousha Sadjadi,Soroosh Baselizadeh,M. Rohban,H. Rabiee",Computer Science,217,62
10706307,Data-analysis strategies for image-based cell profiling,,2017,"Juan C. Caicedo,Sam Cooper,Florian Heigwer,Scott Warchal,P. Qiu,Csaba Molnar,A. Vasilevich,Joseph D Barry,Harmanjit Singh Bansal,Oren Z. Kraus,Mathias Wawer,L. Paavolainen,M. Herrmann,M. Rohban,Jane Hung,H. Hennig,J. Concannon,Ian Smith,P. Clemons,Shantanu Singh,P. Rees,P. Horváth,Roger G. Linington,Anne E Carpenter","Medicine,Computer Science",483,154
14176792,Minimax Optimal Sparse Signal Recovery With Poisson Statistics,"We are motivated by problems that arise in a number of applications such as Online Marketing and Explosives detection, where the observations are usually modeled using Poisson statistics. We model each observation as a Poisson random variable whose mean is a sparse linear superposition of known patterns. Unlike many conventional problems observations here are not identically distributed since they are associated with different sensing modalities. We analyze the performance of a maximum likelihood (ML) decoder, which for our Poisson setting involves a non-linear optimization but yet is computationally tractable. We derive fundamental sample complexity bounds for sparse recovery when the measurements are contaminated with Poisson noise. In contrast to the least-squares linear regression setting with Gaussian noise, we observe that in addition to sparsity, the scale of the parameters also fundamentally impacts l2 error in the Poisson setting. We show that our upper bounds are tight under suitable regularity conditions. Specifically, we derive a minimax matching lower bound on the mean-squared error and show that our constrained ML decoder is minimax optimal for this regime.",2015,"M. Rohban,Venkatesh Saligrama,Delaram Motamed Vaziri","Computer Science,Mathematics",14,25
212675673,ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection,,2020,"Mohammadreza Salehi,Atrin Arya,Barbod Pajoum,Mohammad Otoofi,Amirreza Shaeiri,M. Rohban,H. Rabiee","Computer Science,Medicine",42,49
8959730,Inhibition of TGFβ Signaling Promotes Ground State Pluripotency,,2013,"Seyedeh-Nafiseh Hassani,M. Totonchi,A. Sharifi-Zarchi,Sepideh Mollamohammadi,Mohammad Pakzad,S. Moradi,A. Samadian,N. Masoudi,Shahab Mirshahvaladi,A. Farrokhi,B. Greber,M. Araúzo-Bravo,D. Sabour,M. Sadeghi,G. Salekdeh,H. Gourabi,H. Schöler,H. Baharvand","Biology,Medicine",63,40
206250519,Treatment of human embryonic stem cells with different combinations of priming and inducing factors toward definitive endoderm.,"Despite the enormous progress in studying definitive endoderm (DE) differentiation from human embryonic stem cells (hESCs), none of the reported protocols have produced a universal, cost-effective, and competent DE with the capability to further differentiate into endodermal derivatives. In this study, by using a 2-step differentiation strategy, we have treated hESCs for 1 day with ""priming"" small molecules (SM), [stauprimide, NSC-308848, rapamycin (Rapa), and/or CHIR] and for the next 3 days with ""inducing"" SM (LY294002, cymarin, IDE1, and/or IDE2) in conjunction with activin A. In the positive control group, we treated hESCs with Wnt3a (25 ng/mL) for 1 day and activin A (100 ng/mL; W/A100-A100) for the next 3 days. Gene expression analysis showed that treatment of hESCs with 100 nM Rapa and 50 ng/mL activin A (Rapa-A50) out of 25 combinations of factors gave rise to higher expressions of 2 DE-specific genes, SOX17 and FOXA2. Similar results were obtained after treating 2 other hESC lines with this regimen. To investigate the competency of Rapa-A50-induced DE for further differentiation into endodermal derivatives, these cells and W/A100-A100-induced DE cells (positive control) were further differentiated into pancreatic progenitors (PP), then into pancreatic endocrine (PE) cells using 5 previously described differentiation protocols. Gene analysis of differentiated cells showed that the established protocols were insufficient to enable universal differentiation into PE, whereas Rapa-A50-induced DE cells were more competent for PP differentiation in a protocol-dependent manner. Additionally, Rapa-A50-induced DE had the capability to differentiate into hepatocyte-like cells (HLCs) as efficiently as W/A100-A100-induced DE. These data have indicated that hESCs primed with Rapa, and induced by a lower concentration of activin A, could lead to DE that had the capability to further differentiate into HLCs and PP cells, but not PE cells. Thus, current protocols for the differentiation of DE into PE still need additional study.",2013,"Y. Tahamtani,M. Azarnia,A. Farrokhi,A. Sharifi-Zarchi,N. Aghdami,H. Baharvand","Biology,Medicine",37,53
211122907,Graph Traversal Edit Distance and Extensions,"Many problems in applied machine learning deal with graphs (also called networks), including social networks, security, web data mining, protein function prediction, and genome informatics. The kernel paradigm beautifully decouples the learning algorithm from the underlying geometric space, which renders graph kernels important for the aforementioned applications. In this article, we give a new graph kernel, which we call graph traversal edit distance (GTED). We introduce the GTED problem and give the first polynomial time algorithm for it. Informally, the GTED is the minimum edit distance between two strings formed by the edge labels of respective Eulerian traversals of the two graphs. Also, GTED is motivated by and provides the first mathematical formalism for sequence co-assembly and de novo variation detection in bioinformatics. We demonstrate that GTED admits a polynomial time algorithm using a linear program in the graph product space that is guaranteed to yield an integer solution. To the best of our knowledge, this is the first approach to this problem. We also give a linear programming relaxation algorithm for a lower bound on GTED. We use GTED as a graph kernel and evaluate it by computing the accuracy of a support vector machine (SVM) classifier on a few data sets in the literature. Our results suggest that our kernel outperforms many of the common graph kernels in the tested data sets. As a second set of experiments, we successfully cluster viral genomes using GTED on their assembly graphs obtained from de novo assembly of next-generation sequencing reads.",2020,"A. Boroojeny,Akash Shrestha,A. Sharifi-Zarchi,S. Gallagher,S. C. Sahinalp,H. Chitsaz","Computer Science,Medicine",4,46
8324116,DNA methylation regulates discrimination of enhancers from promoters through a H3K4me1-H3K4me3 seesaw mechanism,,2017,"A. Sharifi-Zarchi,Daniela Gerovska,Kenjiro Adachi,M. Totonchi,H. Pezeshk,R. Taft,H. Schöler,H. Chitsaz,M. Sadeghi,H. Baharvand,M. Araúzo-Bravo","Medicine,Biology",79,112
54584061,Downregulation of Extracellular Matrix and Cell Adhesion Molecules in Cumulus Cells of Infertile Polycystic Ovary Syndrome Women With and Without Insulin Resistance,"Objective The extracellular matrix (ECM) of the cumulus oocyte complex (COC) is composed of several molecules that have different roles during follicle development. This study aims to explore gene expression profiles for ECM and cell adhesion molecules in the cumulus cells of polycystic ovary syndrome (PCOS) patients based on their insulin sensitivity following controlled ovarian stimulation (COS). Materials and Methods In this prospective case-control study enrolled 23 women less than 36 years of age who participated in an intracytoplasmic sperm injection (ICSI) program. Patients were subdivided into 3 groups: control (n=8, fertile women with male infertility history), insulin resistant (IR) PCOS (n=7), and insulin sensitive (IS) PCOS (n=8). We compared 84 ECM component and adhesion molecule gene expressions by quantitative real-time polymerase chain reaction array (qPCR-array) among the groups. Results We noted that 21 of the 84 studied genes differentially expressed among the groups, from which 18 of these genes downregulated. Overall, comparison of PCOS cases with controls showed downregulation of extracellular matrix protein 1 (ECM1); catenin (cadherin-associated protein), alpha 1 (CTNNA1); integrin, alpha 5 (ITGA5); laminin, alpha 3 (LAMA3); laminin, beta 1 (LAMB1); fibronectin 1 (FN1); and integrin, alpha 7 (ITGA7). In the IS group, there was upregulation of ADAM metallopeptidase with thrombospondin type 1 motif, 8 (ADAMTS8) and neural cell adhesion molecule 1 (NCAM1) compared with the controls (P<0.05). Conclusion Downregulation of ECM and cell adhesion molecules seem to be related to PCOS. Gene expression profile alterations in cumulus cells from both the IS and IR groups of PCOS patients seems to be involved in the composition and regulation of ECM during the ovulation process. This study highlights the association of ECM gene alteration as a viewpoint for additional understanding of the etiology of PCOS.",2018,"F. Hassani,S. Oryan,P. Eftekhari-Yazdi,M. Bazrgar,A. Moini,N. Nasiri,A. Sharifi-Zarchi","Medicine,Biology",24,41
232145932,Transformer-based deep neural network language models for Alzheimer’s disease risk assessment from targeted speech,,2021,"A. Roshanzamir,H. Aghajan,Mahdieh Soleymani Baghshah","Computer Science,Medicine",50,55
235097481,MG-BERT: Multi-Graph Augmented BERT for Masked Language Modeling,"Pre-trained models like Bidirectional Encoder Representations from Transformers (BERT), have recently made a big leap forward in Natural Language Processing (NLP) tasks. However, there are still some shortcomings in the Masked Language Modeling (MLM) task performed by these models. In this paper, we first introduce a multi-graph including different types of relations between words. Then, we propose Multi-Graph augmented BERT (MG-BERT) model that is based on BERT. MG-BERT embeds tokens while taking advantage of a static multi-graph containing global word co-occurrences in the text corpus beside global real-world facts about words in knowledge graphs. The proposed model also employs a dynamic sentence graph to capture local context effectively. Experimental results demonstrate that our model can considerably enhance the performance in the MLM task.",2021,"Parishad BehnamGhader,Hossein Zakerinia,Mahdieh Soleymani Baghshah",Computer Science,2,29
196551931,Deep Learning-Based Proarrhythmia Analysis Using Field Potentials Recorded From Human Pluripotent Stem Cells Derived Cardiomyocytes,"An early characterization of drug-induced cardiotoxicity may be possible by combining comprehensive in vitro proarrhythmia assay and deep learning techniques. We aimed to develop a method to automatically detect irregular beating rhythm of field potentials recorded from human pluripotent stem cells (hPSC) derived cardiomyocytes (hPSC-CM) by multi-electrode array (MEA) system. We included field potentials from 380 experiments, which were labeled as normal or arrhythmic by electrophysiology experts. Convolutional and recurrent neural networks (CNN and RNN) were employed for automatic classification of field potential recordings. A preparation phase was initially applied to split 60-s long recordings into a series of 5-s windows. Subsequently, the classification phase comprising of two main steps was designed and applied. The first step included the classification of 5-s windows by using a designated CNN. While, the results of 5-s window assessments were used as the input sequence to an RNN that aggregates these results in the second step. The output was then compared to electrophysiologist-level arrhythmia detection, resulting in 0.83 accuracy, 0.93 sensitivity, 0.70 specificity, and 0.80 precision. In summary, this paper introduces a novel method for automated analysis of “irregularity” in an in vitro model of cardiotoxicity experiments. Thus, our method may overcome the drawbacks of using predesigned features that restricts the classification performance to the comprehensiveness and the quality of the designed features. Furthermore, automated analysis may facilitate the quality control experiments through the procedure of drug development with respect to cardiotoxicity and avoid late drug attrition from market.",2019,"Zeinab Golgooni,Sara Mirsadeghi,Mahdieh Soleymani Baghshah,P. Ataee,H. Baharvand,S. Pahlavan,H. Rabiee",Computer Science,7,46
9801881,An attribute learning method for zero-shot recognition,"Recently, the problem of integrating side information about classes has emerged in the learning settings like zero-shot learning. Although using multiple sources of information about the input space has been investigated in the last decade and many multi-view and multi-modal learning methods have already been introduced, the attribute learning for classes (output space) is a new problem that has been attended in the last few years. In this paper, we propose an attribute learning method that can use different sources of descriptions for classes to find new attributes that are more proper to be used as class signatures. Experimental results show that the learned attributes by the proposed method can improve the accuracy of the state-of-the-art zero-shot learning methods.",2017,"Ramtin Yazdanian,Seyed Mohsen Shojaee,Mahdieh Soleymani Baghshah",Computer Science,0,29
220403407,A Distilled Model for Tracking and Tracker Fusion,"Visual object tracking was generally tackled by reasoning independently on fast processing algorithms, accurate online adaptation methods, and fusion of trackers. In this paper, we unify such goals by proposing a novel tracking methodology that takes advantage of other visual trackers, offline and online. A compact student model is trained via the marriage of knowledge distillation and reinforcement learning. The first allows to transfer and compress tracking knowledge of other trackers. The second enables the learning of evaluation measures which are then exploited online. After learning, the student can be ultimately used to build (i) a very fast single-shot tracker, (ii) a tracker with a simple and effective online adaptation mechanism, (iii) a tracker that performs fusion of other trackers. Extensive validation shows that the proposed algorithms compete with state-of-the-art trackers while running in real-time.",2020,"Matteo Dunnhofer,N. Martinel,C. Micheloni",Computer Science,4,88
220364434,Jointly Modeling Motion and Appearance Cues for Robust RGB-T Tracking,"In this study, we propose a novel RGB-T tracking framework by jointly modeling both appearance and motion cues. First, to obtain a robust appearance model, we develop a novel late fusion method to infer the fusion weight maps of both RGB and thermal (T) modalities. The fusion weights are determined by using offline-trained global and local multimodal fusion networks, and then adopted to linearly combine the response maps of RGB and T modalities. Second, when the appearance cue is unreliable, we comprehensively take motion cues, i.e., target and camera motions, into account to make the tracker robust. We further propose a tracker switcher to switch the appearance and motion trackers flexibly. Numerous results on three recent RGB-T tracking datasets show that the proposed tracker performs significantly better than other state-of-the-art algorithms.",2020,"Pengyu Zhang,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu,Xiaoyun Yang","Medicine,Computer Science",78,70
220363592,Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation,"Visual object tracking aims to precisely estimate the bounding box for the given target, which is a challenging problem due to factors such as deformation and occlusion. Many recent trackers adopt the multiple-stage strategy to improve bounding box estimation. These methods first coarsely locate the target and then refine the initial prediction in the following stages. However, existing approaches still suffer from limited precision, and the coupling of different stages severely restricts the method’s transferability. This work proposes a novel, flexible, and accurate refinement module called Alpha-Refine (AR), which can significantly improve the base trackers’ box estimation quality. By exploring a series of design options, we conclude that the key to successful refinement is extracting and maintaining detailed spatial information as much as possible. Following this principle, Alpha-Refine adopts a pixel-wise correlation, a corner prediction head, and an auxiliary mask head as the core components. Comprehensive experiments on TrackingNet, LaSOT, GOT-10K, and VOT2020 benchmarks with multiple base trackers show that our approach significantly improves the base tracker’s performance with little extra latency. The proposed Alpha-Refine method leads to a series of strengthened trackers, among which the ARSiamRPN (AR strengthened SiamRPNpp) and the ARDiMP50 (AR strengthened DiMP50) achieve good efficiency-precision trade-off, while the ARDiMPsuper (AR strengthened DiMPsuper) achieves very competitive performance at a realtime speed. Code and pretrained models are available at https://github.com/MasterBin-IIAU/AlphaRefine.",2020,"B. Yan,Dong Wang,Huchuan Lu,Xiaoyun Yang",Computer Science,129,74
219793067,Ocean: Object-aware Anchor-free Tracking,,2020,"Zhipeng Zhang,Houwen Peng",Computer Science,439,50
218487341,How to Train Your Energy-Based Model for Regression,"Energy-based models (EBMs) have become increasingly popular within computer vision in recent years. While they are commonly employed for generative image modeling, recent work has applied EBMs also for regression tasks, achieving state-of-the-art performance on object detection and visual tracking. Training EBMs is however known to be challenging. While a variety of different techniques have been explored for generative modeling, the application of EBMs to regression is not a well-studied problem. How EBMs should be trained for best possible regression performance is thus currently unclear. We therefore accept the task of providing the first detailed study of this problem. To that end, we propose a simple yet highly effective extension of noise contrastive estimation, and carefully compare its performance to six popular methods from literature on the tasks of 1D regression and object detection. The results of this comparison suggest that our training method should be considered the go-to approach. We also apply our method to the visual tracking task, achieving state-of-the-art performance on five datasets. Notably, our tracker achieves 63.7% AUC on LaSOT and 78.7% Success on TrackingNet. Code is available at this https URL.",2020,"F. Gustafsson,Martin Danelljan,R. Timofte,Thomas Bo Schön","Computer Science,Mathematics",32,62
215769027,A Transductive Approach for Video Object Segmentation,"Semi-supervised video object segmentation aims to separate a target object from a video sequence, given the mask in the first frame. Most of current prevailing methods utilize information from additional modules trained in other domains like optical flow and instance segmentation, and as a result they do not compete with other methods on common ground. To address this issue, we propose a simple yet strong transductive method, in which additional modules, datasets, and dedicated architectural designs are not needed. Our method takes a label propagation approach where pixel labels are passed forward based on feature similarity in an embedding space. Different from other propagation methods, ours diffuses temporal information in a holistic manner which take accounts of long-term object appearance. In addition, our method requires few additional computational overhead, and runs at a fast ~37 fps speed. Our single model with a vanilla ResNet50 backbone achieves an overall score of 72.3% on the DAVIS 2017 validation set and 63.1% on the test set. This simple yet high performing and efficient method can serve as a solid baseline that facilitates future research. Code and models are available at https://github.com/ microsoft/transductive-vos.pytorch.",2020,"Yizhuo Zhang,Zhirong Wu,Houwen Peng,Stephen Lin",Computer Science,93,53
214808684,Performance Evaluation Methodology for Long-Term Single-Object Tracking,"A long-term visual object tracking performance evaluation methodology and a benchmark are proposed. Performance measures are designed by following a long-term tracking definition to maximize the analysis probing strength. The new measures outperform existing ones in interpretation potential and in better distinguishing between different tracking behaviors. We show that these measures generalize the short-term performance measures, thus linking the two tracking problems. Furthermore, the new measures are highly robust to temporal annotation sparsity and allow annotation of sequences hundreds of times longer than in the current datasets without increasing manual annotation labor. A new challenging dataset of carefully selected sequences with many target disappearances is proposed. A new tracking taxonomy is proposed to position trackers on the short-term/long-term spectrum. The benchmark contains an extensive evaluation of the largest number of long-term trackers and comparison to state-of-the-art short-term trackers. We analyze the influence of tracking architecture implementations to long-term performance and explore various redetection strategies as well as the influence of visual model update strategies to long-term tracking drift. The methodology is integrated in the VOT toolkit to automate experimental analysis and benchmarking and to facilitate the future development of long-term trackers.",2020,"A. Lukežič,L. Č. Zajc,Tomás Vojír,Jiri Matas,M. Kristan","Medicine,Computer Science",20,0
214743010,High-Performance Long-Term Tracking With Meta-Updater,"Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we propose a novel offline-trained Meta-Updater to address an important but unsolved problem: Is the tracker ready for updating in the current frame? The proposed meta-updater can effectively integrate geometric, discriminative, and appearance cues in a sequential manner, and then mine the sequential information with a designed cascaded LSTM module. Our meta-updater learns a binary output to guide the tracker’s update and can be easily embedded into different trackers. This work also introduces a long-term tracking framework consisting of an online local tracker, an online verifier, a SiamRPN-based re-detector, and our meta-updater. Numerous experimental results on the VOT2018LT,VOT2019LT, OxUvALT, TLP, and LaSOT benchmarks show that our tracker performs remarkably better than other competing algorithms. Our project is available on the website: https://github.com/Daikenan/LTMU.",2020,"Kenan Dai,Yunhua Zhang,Dong Wang,Jianhua Li,Huchuan Lu,Xiaoyun Yang",Computer Science,141,57
214693026,Probabilistic Regression for Visual Tracking,"Visual tracking is fundamentally the problem of regressing the state of the target in each video frame. While significant progress has been achieved, trackers are still prone to failures and inaccuracies. It is therefore crucial to represent the uncertainty in the target estimation. Although current prominent paradigms rely on estimating a state-dependent confidence score, this value lacks a clear probabilistic interpretation, complicating its use. In this work, we therefore propose a probabilistic regression formulation and apply it to tracking. Our network predicts the conditional probability density of the target state given an input image. Crucially, our formulation is capable of modeling label noise stemming from inaccurate annotations and ambiguities in the task. The regression network is trained by minimizing the Kullback-Leibler divergence. When applied for tracking, our formulation not only allows a probabilistic representation of the output, but also substantially improves the performance. Our tracker sets a new state-of-the-art on six datasets, achieving 59.8% AUC on LaSOT and 75.8% Success on TrackingNet. The code and models are available at https://github.com/visionml/pytracking.",2020,"Martin Danelljan,L. Gool,R. Timofte",Computer Science,350,53
214640989,Learning What to Learn for Video Object Segmentation,,2020,"Goutam Bhat,Felix Järemo Lawin,Martin Danelljan,Andreas Robinson,M. Felsberg,L. Gool,R. Timofte",Computer Science,115,42
29420979,Latent feature mining of spatial and marginal characteristics for mammographic mass classification,,2014,"Ying Wang,Jie Li,Xinbo Gao",Computer Science,43,40
25255951,"Mass Classification in Mammograms Using Selected Geometry and Texture Features, and a New SVM-Based Feature Selection Method","Masses are the primary indications of breast cancer in mammograms, and it is important to classify them as benign or malignant. Benign and malignant masses differ in geometry and texture characteristics. However, not every geometry and texture feature that is extracted contributes to the improvement of classification accuracy; thus, to select the best features from a set is important. In this paper, we examine the feature selection methods for mass classification. We integrate a support vector machine (SVM)-based recursive feature elimination (SVM-RFE) procedure with a normalized mutual information feature selection (NMIFS) to avoid their singular disadvantages (the redundancy in the selected features of the SVM-RFE and the unoptimized classifier for the NMIFS) while retaining their advantages, and we propose a new feature selection method, which is called the SVM-RFE with an NMIFS filter (SRN). In addition to feature selection, we also study the initialization of mass segmentation. Different initialization methods are investigated, and we propose a fuzzy c-means (FCM) clustering, with spatial constraints as the initialization step. In the experiments, 826 regions of interest (ROIs) from the Digital Database for Screening Mammography were used. All 826 were used in the classification experiments, and 413 ROIs were used in the feature selection experiments. Different feature selection methods, including F-score, Relief, SVM-RFE, SVM-RFE with a minimum redundancy-maximum relevance (mRMR) filter [SVM-RFE (mRMR)], and SRN, were used to select features and to compare mass classification results using the selected features. In the classification experiments, the linear discriminant analysis and the SVM classifiers were investigated. The accuracy that is obtained with the SVM classifier using the selected features obtained by the F-score, Relief, SVM-RFE, SVM-RFE (mRMR), and SRN methods are 88%, 88%, 90%, 91%, and 93%, respectively, with a tenfold cross-validation procedure, and 91%, 89%, 92%, 92%, and 94%, respectively, with a leave-one-out (LOO) scheme. We also compared the performance of the different feature selection methods using the receiver operating characteristic analysis and the areas under the curve (AUCs). The AUCs for the F-score, Relief, SVM-RFE, SVM-RFE (mRMR), and SRN methods are 0.9014, 0.8916, 0.9121, 0.9236, and 0.9439, respectively, with a tenfold cross-validation procedure, and are 0.9312, 0.9178, 0.9324, 0.9413, and 0.9615, respectively, with a LOO scheme. Both the accuracy and AUC values show that the proposed SRN feature selection method has the best performance. In addition to the accuracy and the AUC, we also measured the significance between the two best feature selection methods, i.e., the SVM-RFE (mRMR) and the proposed SRN method. Experimental results show that the proposed SRN method is significantly more accurate than the SVM-RFE (mRMR) (p = 0.011).",2014,"Xiaoming Liu,Jinshan Tang","Mathematics,Computer Science",157,42
29026398,Mammographical mass detection and classification using Local Seed Region Growing-Spherical Wavelet Transform (LSRG-SWT) hybrid scheme,,2013,"P. Gorgel,A. Sertbas,O. Ucan","Computer Science,Medicine",77,24
17223461,Breast mass contour segmentation algorithm in digital mammograms,,2013,"Tolga Berber,A. Alpkocak,P. Balcı,O. Dicle","Computer Science,Medicine",70,31
7202576,A novel image mining technique for classification of mammograms using hybrid feature selection,,2013,"A. K. Mohanty,M. Senapati,S. Lenka","Mathematics,Computer Science",44,49
11770931,Mammogram retrieval on similar mass lesions,,2012,"Chia-Hung Wei,Sherry Y. Chen,Xiaohui Liu","Medicine,Computer Science",67,33
62493876,Pattern Recognition System using MLP Neural Networks,"Pattern recognition can be used to recognize and/or locate specific objects in an image. The pattern recognition approaches are based on analysis of statistical parameters computed using image processing tools. The parameters may be compared with the standard pattern parameters to identify the pattern or a neural network may be trained using the statistical parameters to identify a given pattern. In the presented work, a neural network approach has been worked out in identifying a pattern. The neural approach applies biological concepts to machines to recognize patterns. A neural network is an information processing system. It consists of massive simple processing units with a high degree of interconnection between each unit. The processing units work cooperatively with each other and achieve massive parallel distributed processing. The design and function of neural networks simulate some functionality of biological brains and neural systems. The advantages of neural networks are their adaptive-learning, self-organization and fault-tolerance capabilities. For these outstanding capabilities, neural networks are used for pattern recognition applications. In the presented work, multi-layer perceptron (MLP) neural network is used for pattern recognition. Here, each neuron computes a so called “net input” from the outputs of previous neurons and from the weights of the connections. Typically, such a net input is a weighted sum, and a numerical value, called “bias”, is added to the net input. In MLPs, a function called “activation function”, is applied to the net input. In our experiments, we used a sigmoid function.",2012,"Sarvda Chauhan,V. Goel,Shalini Dhingra",Computer Science,13,21
11572102,Building an ensemble system for diagnosing masses in mammograms,,2012,"Yu Zhang,Noriko Tomuro,J. Furst,D. Raicu","Medicine,Computer Science",47,29
37779049,Hypergraphs as a mean of discovering the dependence structure of a discrete multivariate probability distribution,,2012,"T. Szántai,E. Kovács","Mathematics,Computer Science",26,17
10196911,Knowledge-Discounted Event Detection in Sports Video,"Automatic events annotation is an essential requirement for constructing an effective sports video summary. Researchers worldwide have actively been seeking the most robust and powerful solutions to detect and classify key events (or highlights) in different sports. Most of the current and widely used approaches have employed rules that model the typical pattern of audiovisual features within particular sport events. These rules are mainly based on manual observation and heuristic knowledge; therefore, machine learning can be used as an alternative. To bridge the gap between the two alternatives, we propose a hybrid approach, which integrates statistics into logical rule-based models during highlight detection. We have also successfully pioneered the use of play-break segment as a universal scope of detection and a standard set of features that can be applied for different sports, including soccer, basketball, and Australian football. The proposed method uses a limited amount of domain knowledge, making this method less subjective and more robust for different sports. An experiment using a large data set of sports video has demonstrated the effectiveness and robustness of the algorithms.",2010,"D. Tjondronegoro,Yi-Ping Phoebe Chen",Computer Science,90,37
15050518,An Investigation Into the Feasibility of Real-Time Soccer Offside Detection From a Multiple Camera System,"In this paper, we investigate on the feasibility of multiple camera system for automatic offside detection. We propose six fixed cameras, properly placed on the two sides of the soccer field (three for each side) to reduce perspective and occlusion errors. The images acquired by the synchronized cameras are processed to detect the players' position and the ball position in real-time; a multiple view analysis is carried out to evaluate the offside event, considering the position of all the players in the field, determining the players who passed the ball, and determining if active offside condition occurred. The whole system has been validated using real-time images acquired during official soccer matches, and quantitative results on the system accuracy were obtained comparing the system responses with the ground truth data generated manually on a number of extracted significant sequences.",2009,"T. D’orazio,Marco Leo,P. Spagnolo,P. Mazzeo,N. Mosca,M. Nitti,A. Distante",Computer Science,65,33
2171158,Detecting video events based on action recognition in complex scenes using spatio-temporal descriptor,"Event detection plays an essential role in video content analysis and remains a challenging open problem. In particular, the study on detecting human-related video events in complex scenes with both a crowd of people and dynamic motion is still limited. In this paper, we investigate detecting video events that involve elementary human actions, e.g. making cellphone call, putting an object down, and pointing to something, in complex scenes using a novel spatio-temporal descriptor based approach. A new spatio-temporal descriptor, which temporally integrates the statistics of a set of response maps of low-level features, e.g. image gradients and optical flows, in a space-time cube, is proposed to capture the characteristics of actions in terms of their appearance and motion patterns. Based on this kind of descriptors, the bag-of-words method is utilized to describe a human figure as a concise feature vector. Then, these features are employed to train SVM classifiers at multiple spatial pyramid levels to distinguish different actions. Finally, a Gaussian kernel based temporal filtering is conducted to segment the sequences of events from a video stream taking account of the temporal consistency of actions. The proposed approach is capable of tolerating spatial layout variations and local deformations of human actions due to diverse view angles and rough human figure alignment in complex scenes. Extensive experiments on the 50-hour video dataset of TRECVid 2008 event detection task demonstrate that our approach outperforms the well-known SIFT descriptor based methods and effectively detects video events in challenging real-world conditions.",2009,"Guangyu Zhu,Ming Yang,Kai Yu,W. Xu,Yihong Gong",Computer Science,59,36
13342984,A visual system for real time detection of goal events during soccer matches,,2009,"T. D’orazio,Marco Leo,P. Spagnolo,M. Nitti,N. Mosca,A. Distante",Computer Science,47,26
6303108,"Automatic player detection, labeling and tracking in broadcast soccer video",,2009,"Jia Liu,Xiaofeng Tong,Wenlong Li,Tao Wang,Yimin Zhang,Hongqi Wang",Computer Science,177,24
8669557,Event Detection of Broadcast Baseball Videos,"This paper presents an effective and efficient event detection system for broadcast baseball videos. It integrates midlevel cues including scoreboard information and shot transition patterns into event classification rules. First, a simple scoreboard detection and recognition scheme is developed to extract the game status from videos. Then, a shot transition classifier is designed to obtain the shot transition patterns, which contains several novel schemes including adaptive playfield segmentation, pitch shot detection, field shot detection, as well as infield/outfield classification. The extracted midlevel cues are used to develop an event classifier based on a Bayesian Belief Network. The network is with low complexity because the number of these cues used is small, which not only improves the generalization performance of the event classifier but also reduces system complexity as well as training efforts. Using the inference results of the network, we further derive a set of classification rules to identify baseball events. The set of rules is stored in a look-up table such that the classification is only a simple table look-up operation. The proposed approach is very simple and computational efficient. More importantly, the simulation results indicate that it identifies ten significant baseball events with 95% of precision rate and 92% of recall rate, which is very promising.",2008,"Mao-Hsiung Hung,C. Hsieh",Computer Science,39,16
18172204,Using Webcast Text for Semantic Event Detection in Broadcast Sports Video,"Sports video semantic event detection is essential for sports video summarization and retrieval. Extensive research efforts have been devoted to this area in recent years. However, the existing sports video event detection approaches heavily rely on either video content itself, which face the difficulty of high-level semantic information extraction from video content using computer vision and image processing techniques, or manually generated video ontology, which is domain specific and difficult to be automatically aligned with the video content. In this paper, we present a novel approach for sports video semantic event detection based on analysis and alignment of Webcast text and broadcast video. Webcast text is a text broadcast channel for sports game which is co-produced with the broadcast video and is easily obtained from the Web. We first analyze Webcast text to cluster and detect text events in an unsupervised way using probabilistic latent semantic analysis (pLSA). Based on the detected text event and video structure analysis, we employ a conditional random field model (CRFM) to align text event and video event by detecting event moment and event boundary in the video. Incorporation of Webcast text into sports video analysis significantly facilitates sports video semantic event detection. We conducted experiments on 33 hours of soccer and basketball games for Webcast analysis, broadcast video analysis and text/video semantic alignment. The results are encouraging and compared with the manually labeled ground truth.",2008,"Changsheng Xu,Yifan Zhang,Guangyu Zhu,Y. Rui,Hanqing Lu,Qingming Huang",Computer Science,158,41
36447350,Modality Mixture Projections for Semantic Video Event Detection,"Event detection is one of the most fundamental components for various kinds of domain applications of video information system. In recent years, it has gained a considerable interest of practitioners and academics from different areas. While detecting video event has been the subject of extensive research efforts recently, much less existing approach has considered multimodal information and related efficiency issues. In this paper, we use a subspace selection technique to achieve fast and accurate video event detection using a subspace selection technique. The approach is capable of discriminating different classes and preserving the intramodal geometry of samples within an identical class. With the method, feature vectors presenting different kind of multi data can be easily projected from different identities and modalities onto a unified subspace, on which recognition process can be performed. Furthermore, the training stage is carried out once and we have a unified transformation matrix to project different modalities. Unlike existing multimodal detection systems, the new system works well when some modalities are not available. Experimental results based on soccer video and TRECVID news video collections demonstrate the effectiveness, efficiency and robustness of the proposed MMP for individual recognition tasks in comparison to the existing approaches.",2008,"Jialie Shen,D. Tao,Xuelong Li",Computer Science,76,25
13936657,A new FPCA-based fast segmentation method for color images,"Fuzzy objective function-based clustering methods are proved to be fast tools for classification and segmentation purposes. Unfortunately, most of the available fuzzy clustering methods are using the spherical or ellipsoidal distances, which are proved to result in spurious clusters, when working on color data. In this paper, a general case of clustering is discussed and a general method is proposed and its convergence is proved. Also, it is proved that the FCM and the FCV methods are special cases of the proposed method. Based on the general method, a special case for color image processing is proposed. The clustering method is based on a likelihood measure, and is proved to outperform the Euclidean and the Mahalanobis distances, in color fields. Based on the proposed color clustering method, a new fast fuzzy segmentation method is proposed and is proved to be highly efficient Comparison of the results with the FCM, proves the superiority of the proposed segmentation method.",2004,"A. Abodpour,S. Kasaei",Mathematics,12,41
17156540,New Principle Component Analysis Based Colorizing Method,"Although many modern imaging systems are still producing grayscale images, colored-images are more preferred for the larger amount of information they are carrying. Computing the grayscale representation of a color image is a straightforward task, while the inverse problem has no objective solution. The search through out literature has not revealed much history of the past works. In this paper, after a brief review of related research, a new dimensionreduction method is proposed for natural color images and approved by both quantitative (PSNR) and subjective tests. Based on it a new class of colorizing methods is proposed and two sample formulations are presented, where the authors are aware of many other formulations available. Subjective test shows dominancy of our proposed method when our method is much faster than others. Our method is leading in face image colorizing where other methods have failed. Such colorization method can be used greatly in medical image processing, surveillance systems, and information visualization.",2004,"A. Abadpour,S. Kasaei",Computer Science,6,18
11713946,Colorization using optimization,"Colorization is a computer-assisted process of adding color to a monochrome image or movie. The process typically involves segmenting images into regions and tracking these regions across image sequences. Neither of these tasks can be performed reliably in practice; consequently, colorization requires considerable user intervention and remains a tedious, time-consuming, and expensive task.In this paper we present a simple colorization method that requires neither precise image segmentation, nor accurate region tracking. Our method is based on a simple premise; neighboring pixels in space-time that have similar intensities should have similar colors. We formalize this premise using a quadratic cost function and obtain an optimization problem that can be solved efficiently using standard techniques. In our approach an artist only needs to annotate the image with a few color scribbles, and the indicated colors are automatically propagated in both space and time to produce a fully colorized image or sequence. We demonstrate that high quality colorizations of stills and movie clips may be obtained from a relatively modest amount of user input.",2004,"Anat Levin,Dani Lischinski,Yair Weiss",Computer Science,1712,16
2780498,"Effect of colorspace transformation, the illuminance component, and color modeling on skin detection","Skin detection is an important preliminary process in human motion analysis. It is commonly performed in three steps: transforming the pixel color to a non-RGB colorspace, dropping the illuminance component of skin color, and classifying by modeling the skin color distribution. In this paper, we evaluate the effect of these three steps on the skin detection performance. The importance of this study is a new comprehensive colorspace and color modeling testing methodology that would allow for making the best choices for skin detection. Combinations of nine colorspaces, the presence of the absence of the illuminance component, and the two color modeling approaches are compared. The performance is measured by using a receiver operating characteristic (ROC) curve on a large dataset of 805 images with manual ground truth. The results reveal that (1) colorspace transformations can improve performance in certain instances, (2) the absence of the illuminance component decreases performance, and (3) skin color modeling has a greater impact than colorspace transformation. We found that the best performance was obtained by transforming the pixel color to the SCT or HSI colorspaces, keeping the illuminance component, and modeling the color with the histogram approach.",2004,"S. Jayaram,Stephen J. Schmugge,M. Shin,L. Tsap",Computer Science,85,16
1374207,Unsupervised colorization of black-and-white cartoons,"We present a novel color-by-example technique which combines image segmentation, patch-based sampling and probabilistic reasoning. This method is able to automate colorization when new color information is applied on the already designed black-and-white cartoon. Our technique is especially suitable for cartoons digitized from classical celluloid films, which were originally produced by a paper or cel based method. In this case, the background is usually a static image and only the dynamic foreground needs to be colored frame-by-frame. We also assume that objects in the foreground layer consist of several well visible outlines which will emphasize the shape of homogeneous regions.",2004,"D. Sýkora,J. Buriánek,J. Zára",Computer Science,111,24
29992220,Towards race-related face identification: research on skin color transfer,"We developed a novel skin-color transfer algorithm in order to explore the potential information from human racial groups to improve the face identification. We attempt to find a general technique for transferring human skin colors of different races. The idea is to match the intensity values of two images and transfer the entire mood of the source image to the target image. Further enhancement can be achieved in two ways. One is facial multi-region subdivision to limit the color transfer between corresponding regions. The other is to use ""region growing"" method based on hue values for color transfer in sub-areas, such as lip, where H channel is dominant in determining pixel colors. The technique appears to be quite simple and results turn out to be encouraging. Our new algorithm is analyzed and compared to other existing algorithm, and evaluated through the psychological study on race related identification. The experiment shows that skin color is amongst one of the factors for race identification, but not the dominant one. This is the first preliminary step as an initial screening process towards the race-related face identification.",2004,"L. Yin,Jingrong Jia,Joseph P. Morrissey",Computer Science,11,15
2141793,Linear color segmentation and its implementation,,2004,"D. Nikolaev,P. Nikolayev","Mathematics,Computer Science",51,32
221377169,Adaptive exploitation of pre-trained deep convolutional neural networks for robust visual tracking,,2020,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei",Computer Science,3,70
219305183,COMET: Context-Aware IoU-Guided Network for Small Object Tracking,,2020,"S. M. Marvasti-Zadeh,Javad Khaghani,Hossein Ghanei-Yakhdan,S. Kasaei,Li Cheng","Computer Science,Engineering",20,81
263883699,Correlation-Guided Attention for Corner Detection Based Visual Tracking,"Accurate bounding box estimation has recently attracted much attention in the tracking community because traditional multi-scale search strategies cannot estimate tight bounding boxes in many challenging scenarios involving changes to the target. A tracker capable of detecting target corners can flexibly adapt to such changes, but existing corner detection based tracking methods have not achieved adequate success. We analyze the reasons for their failure and propose a state-of-the-art tracker that performs correlation-guided attentional corner detection in two stages. First, a region of interest (RoI) is obtained by employing an efficient Siamese network to distinguish the target from the background. Second, a pixel-wise correlation-guided spatial attention module and a channel-wise correlation-guided channel attention module exploit the relationship between the target template and the RoI to highlight corner regions and enhance features of the RoI for corner detection. The correlation-guided attention modules improve the accuracy of corner detection, thus enabling accurate bounding box estimation. When trained on large-scale datasets using a novel RoI augmentation strategy, the performance of the proposed tracker, running at a high speed of 70 FPS, is comparable with that of state-of-the-art trackers in meeting five challenging performance benchmarks.",2020,"Fei Du,Peng Liu,Wei Zhao,Xianglong Tang",Computer Science,15,46
219617542,Recursive Least-Squares Estimator-Aided Online Learning for Visual Tracking,"Online learning is crucial to robust visual object tracking as it can provide high discrimination power in the presence of background distractors. However, there are two contradictory factors affecting its successful deployment on the real visual tracking platform: the discrimination issue due to the challenges in vanilla gradient descent, which does not guarantee good convergence; the robustness issue due to over-fitting resulting from excessive update with limited memory size (the oldest samples are discarded). Despite many dedicated techniques proposed to somehow treat those issues, in this paper we take a new way to strike a compromise between them based on the recursive least-squares estimation (LSE) algorithm. After connecting each fully-connected layer with LSE separately via normal equations, we further propose an improved mini-batch stochastic gradient descent algorithm for fully-connected network learning with memory retention in a recursive fashion. This characteristic can spontaneously reduce the risk of over-fitting resulting from catastrophic forgetting in excessive online learning. Meanwhile, it can effectively improve convergence though the cost function is computed over all the training samples that the algorithm has ever seen. We realize this recursive LSE-aided online learning technique in the state-of-the-art RT-MDNet tracker, and the consistent improvements on four challenging benchmarks prove its efficiency without additional offline training and too much tedious work on parameter adjusting.",2020,"Jin Gao,Weiming Hu,Yan Lu",Computer Science,9,41
219630333,One-Shot Adversarial Attacks on Visual Tracking With Dual Attention,"Almost all adversarial attacks in computer vision are aimed at pre-known object categories, which could be offline trained for generating perturbations. But as for visual object tracking, the tracked target categories are normally unknown in advance. However, the tracking algorithms also have potential risks of being attacked, which could be maliciously used to fool the surveillance systems. Meanwhile, it is still a challenging task that adversarial attacks on tracking since it has the free-model tracked target. Therefore, to help draw more attention to the potential risks, we study adversarial attacks on tracking algorithms. In this paper, we propose a novel one-shot adversarial attack method to generate adversarial examples for free-model single object tracking, where merely adding slight perturbations on the target patch in the initial frame causes state-of-the-art trackers to lose the target in subsequent frames. Specifically, the optimization objective of the proposed attack consists of two components and leverages the dual attention mechanisms. The first component adopts a targeted attack strategy by optimizing the batch confidence loss with confidence attention while the second one applies a general perturbation strategy by optimizing the feature loss with channel attention. Experimental results show that our approach can significantly lower the accuracy of the most advanced Siamese network-based trackers on three benchmarks.",2020,"Xuesong Chen,Xiyu Yan,Feng Zheng,Yong Jiang,Shutao Xia,Yong Zhao,Rongrong Ji",Computer Science,47,32
219004950,Intermittent Contextual Learning for Keyfilter-Aware UAV Object Tracking Using Deep Convolutional Feature,"Visual tracking, one of the most favorable multimedia applications, has been widely used in unmanned aerial vehicle (UAV) for civil infrastructure monitoring, aerial cinematography, autonomous navigation, etc. Most existing trackers utilize deep convolutional feature to enhance tracking robustness in scenarios of various appearance variation. However, they commonly neglect speed which is crucial for UAV with restricted calculation resources. In this work, a novel correlation filter-based keyfilter-aware tracker with a new intermittent context learning strategy is proposed to efficiently and effectively alleviate the problems of background clutter, deficient description, occlusion, illumination change, etc. Specifically, context information is utilized to empower the filter higher discriminating ability through response repression of the omnidirectional context patches. Furthermore, keyfilter is produced from the periodically selected keyframe. The latest produced keyfilter is used to restrain the current filter's corrupted changes. Most importantly, context learning of correlation filter is implemented intermittently to fully increase the tracking efficiency. This intermittent learning strategy can ensure every filter maintain context awareness owing to the restriction of keyfilter, periodically enhancing the context awareness. Substantial experiments on three challenging UAV benchmarks totally with 213 image sequences have shown that our tracker surpasses the state-of-the-art results, and exhibits a remarkable generality in short-term and long-term UAV tracking tasks as well as a variety of challenging attributes.",2020,"Yiming Li,Changhong Fu,Ziyuan Huang,Yinqiang Zhang,Jia Pan",Computer Science,29,56
215754230,Deformable Siamese Attention Networks for Visual Object Tracking,"Siamese-based trackers have achieved excellent performance on visual object tracking. However, the target template is not updated online, and the features of target template and search image are computed independently in a Siamese architecture. In this paper, we propose Deformable Siamese Attention Networks, referred to as SiamAttn, by introducing a new Siamese attention mechanism that computes deformable self-attention and cross-attention. The self-attention learns strong context information via spatial attention, and selectively emphasizes interdependent channel-wise features with channel attention. The crossattention is capable of aggregating rich contextual interdependencies between the target template and the search image, providing an implicit manner to adaptively update the target template. In addition, we design a region refinement module that computes depth-wise cross correlations between the attentional features for more accurate tracking. We conduct experiments on six benchmarks, where our method achieves new state-of-the-art results, outperforming recent strong baseline, SiamRPN++, by 0.464 to 0.537 and 0.415 to 0.470 EAO on VOT 2016 and 2018.",2020,"Yu Yu,Yilei Xiong,Weilin Huang,Matthew R. Scott",Computer Science,233,46
215238838,Efficient scale estimation methods using lightweight deep convolutional neural networks for visual tracking,,2020,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",8,68
215238859,Beyond Background-Aware Correlation Filters: Adaptive Context Modeling by Hand-Crafted and Deep RGB Features for Visual Tracking,"In recent years, the background-aware correlation filters have achie-ved a lot of research interest in the visual target tracking. However, these methods cannot suitably model the target appearance due to the exploitation of hand-crafted features. On the other hand, the recent deep learning-based visual tracking methods have provided a competitive performance along with extensive computations. In this paper, an adaptive background-aware correlation filter-based tracker is proposed that effectively models the target appearance by using either the histogram of oriented gradients (HOG) or convolutional neural network (CNN) feature maps. The proposed method exploits the fast 2D non-maximum suppression (NMS) algorithm and the semantic information comparison to detect challenging situations. When the HOG-based response map is not reliable, or the context region has a low semantic similarity with prior regions, the proposed method constructs the CNN context model to improve the target region estimation. Furthermore, the rejection option allows the proposed method to update the CNN context model only on valid regions. Comprehensive experimental results demonstrate that the proposed adaptive method clearly outperforms the accuracy and robustness of visual target tracking compared to the state-of-the-art methods on the OTB-50, OTB-100, TC-128, UAV-123, and VOT-2015 datasets.",2020,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",2,54
214794993,Effective Fusion of Deep Multitasking Representations for Robust Visual Tracking,,2020,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei,Kamal Nasrollahi,T. Moeslund","Computer Science,Engineering",1,112
14800809,Collaborative sparse unmixing of hyperspectral data,"Sparse unmixing aims at estimating the constituent materials (endmembers) and their respective fractional abundances in each pixel of a hyperspectral image by assuming that the endmembers are present in a large collection of pure spectral signatures (spectral library), known a priori. In this paper, we propose a refinement of the sparse unmixing approach by taking into account the fact that all the pixels of the image share the same set of endmembers, thus lying in a lower dimensional subspace. Our idea is based on the collaborative lasso, which enforces sparsity across the pixels. The goal of this line of attack is to obtain higher accuracy of the estimated fractional abundances, at the same time with a decrease in the number of endmembers used to explain the observed data. The experimental results, obtained with both simulated and real data, confirm the potential of the proposed approach in the unmixing problem.",2012,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,15,15
178457,Total Variation Spatial Regularization for Sparse Hyperspectral Unmixing,"Spectral unmixing aims at estimating the fractional abundances of pure spectral signatures (also called endmembers) in each mixed pixel collected by a remote sensing hyperspectral imaging instrument. In recent work, the linear spectral unmixing problem has been approached in semisupervised fashion as a sparse regression one, under the assumption that the observed image signatures can be expressed as linear combinations of pure spectra, known a priori and available in a library. It happens, however, that sparse unmixing focuses on analyzing the hyperspectral data without incorporating spatial information. In this paper, we include the total variation (TV) regularization to the classical sparse regression formulation, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Our experimental results, conducted with both simulated and real hyperspectral data sets, indicate the potential of including spatial information (through the TV term) on sparse unmixing formulations for improved characterization of mixed pixels in hyperspectral imagery.",2012,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,609,72
11112426,"Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse Regression-Based Approaches","Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-posed inverse problem because of model inaccuracies, observation noise, environmental conditions, endmember variability, and data set size. Researchers have devised and investigated many models searching for robust, stable, tractable, and accurate unmixing algorithms. This paper presents an overview of unmixing methods from the time of Keshava and Mustard's unmixing tutorial to the present. Mixing models are first discussed. Signal-subspace, geometrical, statistical, sparsity-based, and spatial-contextual unmixing algorithms are described. Mathematical problems and potential solutions are described. Algorithm characteristics are illustrated experimentally.",2012,"J. Bioucas-Dias,A. Plaza,N. Dobigeon,M. Parente,Q. Du,P. Gader,J. Chanussot","Computer Science,Physics,Mathematics",2384,223
7074492,Sparse Manifold Clustering and Embedding,"We propose an algorithm called Sparse Manifold Clustering and Embedding (SMCE) for simultaneous clustering and dimensionality reduction of data lying in multiple nonlinear manifolds. Similar to most dimensionality reduction methods, SMCE finds a small neighborhood around each data point and connects each point to its neighbors with appropriate weights. The key difference is that SMCE finds both the neighbors and the weights automatically. This is done by solving a sparse optimization problem, which encourages selecting nearby points that lie in the same manifold and approximately span a low-dimensional affine subspace. The optimal solution encodes information that can be used for clustering and dimensionality reduction using spectral clustering and embedding. Moreover, the size of the optimal neighborhood of a data point, which can be different for different points, provides an estimate of the dimension of the manifold to which the point belongs. Experiments demonstrate that our method can effectively handle multiple manifolds that are very close to each other, manifolds with non-uniform sampling and holes, as well as estimate the intrinsic dimensions of the manifolds.",2011,"Ehsan Elhamifar,R. Vidal","Computer Science,Mathematics",290,23
9915581,Building a better probabilistic model of images by factorization,"We describe a directed bilinear model that learns higher-order groupings among features of natural images. The model represents images in terms of two sets of latent variables: one set of variables represents which feature groups are active, while the other specifies the relative activity within groups. Such a factorized representation is beneficial because it is stable in response to small variations in the placement of features while still preserving information about relative spatial relationships. When trained on MNIST digits, the resulting representation provides state of the art performance in classification using a simple classifier. When trained on natural images, the model learns to group features according to proximity in position, orientation, and scale. The model achieves high log-likelihood (−94 nats), surpassing the current state of the art for natural images achievable with an mcRBM model.",2011,"B. J. Culpepper,Jascha Narain Sohl-Dickstein,B. Olshausen","Computer Science,Mathematics",14,40
12521016,"Learning Discriminative Sparse Representations for Modeling, Source Separation, and Mapping of Hyperspectral Imagery","A method is presented for subpixel modeling, mapping, and classification in hyperspectral imagery using learned block-structured discriminative dictionaries, where each block is adapted and optimized to represent a material in a compact and sparse manner. The spectral pixels are modeled by linear combinations of subspaces defined by the learned dictionary atoms, allowing for linear mixture analysis. This model provides flexibility in source representation and selection, thus accounting for spectral variability, small-magnitude errors, and noise. A spatial-spectral coherence regularizer in the optimization allows pixel classification to be influenced by similar neighbors. We extend the proposed approach for cases for which there is no knowledge of the materials in the scene, unsupervised classification, and provide experiments and comparisons with simulated and real data. We also present results when the data have been significantly undersampled and then reconstructed, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery.",2011,"Alexey Castrodad,Zhengming Xing,J. Greer,E. Bosch,L. Carin,G. Sapiro",Computer Science,129,69
2752017,Structured Sparsity in Structured Prediction,"Linear models have enjoyed great success in structured prediction in NLP. While a lot of progress has been made on efficient training with several loss functions, the problem of endowing learners with a mechanism for feature selection is still unsolved. Common approaches employ ad hoc filtering or L1-regularization; both ignore the structure of the feature space, preventing practicioners from encoding structural prior knowledge. We fill this gap by adopting regularizers that promote structured sparsity, along with efficient algorithms to handle them. Experiments on three tasks (chunking, entity recognition, and dependency parsing) show gains in performance, compactness, and model interpretability.",2011,"André F. T. Martins,Noah A. Smith,Mário A. T. Figueiredo,P. Aguiar",Computer Science,74,55
1380062,Hyperspectral unmixingwith sparse group lasso,"Sparse unmixing has been recently introduced as a mechanism to characterize mixed pixels in remotely sensed hyperspectral images. It assumes that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In available spectral libraries, it is observed that the spectral signatures appear organized in groups (e.g. different alterations of a single mineral in the U.S. Geological Survey spectral library). In this paper, we explore the potential of the sparse group lasso technique in solving hyperspectral unmixing problems. Our introspection in this work is that, when the spectral signatures appear in groups, this technique has the potential to yield better results than the standard sparse regression approach. Experimental results with both synthetic and real hyperspectral data are given to investigate this issue.",2011,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,34,13
15623173,Surveying and comparing simultaneous sparse approximation (or group-lasso) algorithms,,2011,A. Rakotomamonjy,"Computer Science,Mathematics",158,71
6383297,A Fast Algorithm for Recovery of Jointly Sparse Vectors based on the Alternating Direction Methods,"The standard compressive sensing (CS) aims to recover sparse signal from single measurement vector which is known as SMV model. By contrast, recovery of sparse signals from multiple measurement vectors is called MMV model. In this paper, we consider the recovery of jointly sparse signals in the MMV model where multiple signal measurements are represented as a matrix and the sparsity of signal occurs in common locations. The sparse MMV model can be formulated as a matrix (2, 1)-norm minimization problem, which is much more difficult to solve than the l1-norm minimization in standard CS. In this paper, we propose a very fast algorithm, called MMV-ADM, to solve the jointly sparse signal recovery problem in MMV settings based on the alternating direction method (ADM). The MMVADM alternately updates the recovered signal matrix, the Lagrangian multiplier and the residue, and all update rules only involve matrix or vector multiplications and summations, so it is simple, easy to implement and much faster than the state-of-the-art method MMVprox. Numerical simulations show that MMV-ADM is at least dozens of times faster than MMVprox with comparable recovery accuracy. Appearing in Proceedings of the 14 International Conference on Artificial Intelligence and Statistics (AISTATS) 2011, Fort Lauderdale, FL, USA. Volume 15 of JMLR: W&CP 15. Copyright 2011 by the authors.",2011,"Hongtao Lu,Xianzhong Long,Jingyuan Lv",Computer Science,42,31
221376515,Puzzle-AE: Novelty Detection in Images through Solving Puzzles,"Autoencoder, as an essential part of many anomaly detection methods, is lacking flexibility on normal data in complex datasets. U-Net is proved to be effective for this purpose but overfits on the training data if trained by just using reconstruction error similar to other AE-based frameworks. Puzzle-solving, as a pretext task of self-supervised learning (SSL) methods, has earlier proved its ability in learning semantically meaningful features. We show that training U-Nets based on this task is an effective remedy that prevents overfitting and facilitates learning beyond pixel-level features. Shortcut solutions, however, are a big challenge in SSL tasks, including jigsaw puzzles. We propose adversarial robust training as an effective automatic shortcut removal. We achieve competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Unlike many competitors, the proposed framework is stable, fast, data-efficient, and does not require unprincipled early stopping.",2020,"Mohammadreza Salehi,Ainaz Eftekhar,Niousha Sadjadi,M. Rohban,H. Rabiee",Computer Science,34,66
221141550,Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images,,2020,"Kang Zhou,Yuting Xiao,Jianlong Yang,Jun Cheng,Wen Liu,Weixin Luo,Zaiwang Gu,Jiang Liu,Shenghua Gao","Engineering,Computer Science,Physics",81,44
211549689,Classification-Based Anomaly Detection for General Data,"Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.",2020,"Liron Bergman,Yedid Hoshen","Computer Science,Mathematics",276,29
212675673,ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection,,2020,"Mohammadreza Salehi,Atrin Arya,Barbod Pajoum,Mohammad Otoofi,Amirreza Shaeiri,M. Rohban,H. Rabiee","Computer Science,Medicine",42,49
211572619,DROCC: Deep Robust One-Class Classification,"Classical approaches for one-class problems such as one-class SVM and isolation forest require careful feature engineering when applied to structured domains like images. State-of-the-art methods aim to leverage deep learning to learn appropriate features via two main approaches. The first approach based on predicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a) while successful in some domains, crucially depends on an appropriate domain-specific set of transformations that are hard to obtain in general. The second approach of minimizing a classical one-class loss on the learned final layer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the fundamental drawback of representation collapse. In this work, we propose Deep Robust One-Class Classification (DROCC) that is both applicable to most standard domains without requiring any side-information and robust to representation collapse. DROCC is based on the assumption that the points from the class of interest lie on a well-sampled, locally linear low dimensional manifold. Empirical evaluation demonstrates that DROCC is highly effective in two different one-class problem settings and on a range of real-world datasets across different domains: tabular data, images (CIFAR and ImageNet), audio, and time-series, offering up to 20% increase in accuracy over the state-of-the-art in anomaly detection. Code is available at this https URL.",2020,"Sachin Goyal,Aditi Raghunathan,Moksh Jain,H. Simhadri,Prateek Jain","Computer Science,Mathematics",117,41
211068987,Iterative energy-based projection on a normal data manifold for anomaly localization,"Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.",2020,"David Dehaene,Oriel Frigo,Sébastien Combrexelle,P. Eline",Computer Science,107,29
208527731,A Case for the Score: Identifying Image Anomalies using Variational Autoencoder Gradients,"Through training on unlabeled data, anomaly detection has the potential to impact computer-aided diagnosis by outlining suspicious regions. Previous work on deep-learning-based anomaly detection has primarily focused on the reconstruction error. We argue instead, that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate. In our experiments, Variational Autoencoder gradient-based rating outperforms other approaches on unsupervised pixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.",2019,"David Zimmerer,Jens Petersen,Simon A. A. Kohl,Klaus Maier-Hein","Engineering,Computer Science,Mathematics",21,20
215870627,Attention Guided Anomaly Localization in Images,,2019,"Shashanka Venkataramanan,Kuan-Chuan Peng,Rajat Vikram Singh,Abhijit Mahalanobis",Computer Science,149,65
207880670,Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings,"We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,375,37
196622802,Exploring Deep Anomaly Detection Methods Based on Capsule Net,,2019,"Xiaoyan Li,I. Kiringa,T. Yeap,Xiaodan Zhu,Yifeng Li","Computer Science,Mathematics",19,36
204092836,Joint Optimization of Offloading Utility and Privacy for Edge Computing Enabled IoT,"Currently, edge computing (EC), emerging as a burgeoning paradigm, is powerful in handling real-time resource provision for Internet of Things (IoT) applications. However, due to the spatial distribution of geographically sparse IoT devices and the resource limitations of EC units (ECUs), the resource utilization of corresponding edge servers is relatively insufficient and the execution performance is ineffective to some extent. A privacy leakage, including personal information, location, media data, etc., during the transmission process from IoT devices to edge servers severely restricts the application of ECUs in IoT. To address these challenges, a two-phase offloading optimization strategy is put forward for joint optimization of offloading utility and privacy in EC enabled IoT. Technically, a utility-aware task offloading method, named UTO, is devised first to obtain the goal of maximizing the resource utilization of ECUs and minimizing the implementation time cost. Then a joint optimization method, named JOM, for utility and privacy tradeoffs is designed to balance the privacy preservation and execution performance. Eventually, the experimental evaluations are designed to illustrate the efficiency and reliability of UTO and JOM.",2020,"Xiaolong Xu,Chengxun He,Zhanyang Xu,Lianyong Qi,Shaohua Wan,Md Zakirul Alam Bhuiyan",Computer Science,132,22
210871866,Spatial-temporal data-driven service recommendation with privacy-preservation,,2020,"Lianyong Qi,Xuyun Zhang,Shancang Li,Shaohua Wan,Yiping Wen,Wenwen Gong",Computer Science,77,32
59553271,Privacy Against Brute-Force Inference Attacks,"Privacy-preserving data release is about disclosing information about useful data while retaining the privacy of sensitive data. Assuming that the sensitive data is threatened by a brute-force adversary, we define Guessing Leakage as a measure of privacy, based on the concept of guessing. After investigating the properties of this measure, we derive the optimal utility-privacy trade-off via a linear program with any f-information adopted as the utility measure, and show that the optimal utility is a concave and piece-wise linear function of the privacy-leakage budget.",2019,"S. A. Ossia,Borzoo Rassouli,H. Haddadi,H. Rabiee,Deniz Gündüz","Computer Science,Mathematics",7,21
47017857,TAPAS: Tricks to Accelerate (encrypted) Prediction As a Service,"Machine learning methods are widely used for a variety of prediction problems. \emph{Prediction as a service} is a paradigm in which service providers with technological expertise and computational resources may perform predictions for clients. However, data privacy severely restricts the applicability of such services, unless measures to keep client data private (even from the service provider) are designed. Equally important is to minimize the amount of computation and communication required between client and server. Fully homomorphic encryption offers a possible way out, whereby clients may encrypt their data, and on which the server may perform arithmetic computations. The main drawback of using fully homomorphic encryption is the amount of time required to evaluate large machine learning models on encrypted data. We combine ideas from the machine learning literature, particularly work on binarization and sparsification of neural networks, together with algorithmic tools to speed-up and parallelize computation using encrypted data.",2018,"Amartya Sanyal,Matt J. Kusner,Adrià Gascón,Varun Kanade","Computer Science,Mathematics",93,44
3887658,Deep Learning in Mobile and Wireless Networking: A Survey,"The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.",2018,"Chaoyun Zhang,P. Patras,H. Haddadi",Computer Science,1104,581
3610884,Protecting Sensory Data against Sensitive Inferences,"There is growing concern about how personal data are used when users grant applications direct access to the sensors of their mobile devices. In fact, high resolution temporal data generated by motion sensors reflect directly the activities of a user and indirectly physical and demographic attributes. In this paper, we propose a feature learning architecture for mobile devices that provides flexible and negotiable privacy-preserving sensor data transmission by appropriately transforming raw sensor data. The objective is to move from the current binary setting of granting or not permission to an application, toward a model that allows users to grant each application permission over a limited range of inferences according to the provided services. The internal structure of each component of the proposed architecture can be flexibly changed and the trade-off between privacy and utility can be negotiated between the constraints of the user and the underlying application. We validated the proposed architecture in an activity recognition application using two real-world datasets, with the objective of recognizing an activity without disclosing gender as an example of private information. Results show that the proposed framework maintains the usefulness of the transformed data for activity recognition, with an average loss of only around three percentage points, while reducing the possibility of gender classification to around 50%, the target random guess, from more than 90% when using raw sensor data. We also present and distribute MotionSense, a new dataset for activity and attribute recognition collected from motion sensors.",2018,"M. Malekzadeh,R. Clegg,A. Cavallaro,H. Haddadi","Computer Science,Mathematics",125,18
11527748,Deep Private-Feature Extraction,"We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model which is trained and evaluated based on information theoretic constraints. Using the selective exchange of information between a user's device and a service provider, DPFE enables the user to prevent certain sensitive information from being shared with a service provider, while allowing them to extract approved information using their model. We introduce and utilize the log-rank privacy, a novel measure to assess the effectiveness of DPFE in removing sensitive information and compare different models based on their accuracy-privacy trade-off. We then implement and evaluate the performance of DPFE on smartphones to understand its complexity, resource demands, and efficiency trade-offs. Our results on benchmark image datasets demonstrate that under moderate resource utilization, DPFE can achieve high accuracy for primary tasks while preserving the privacy of sensitive information.",2018,"S. A. Ossia,A. Taheri,A. Shamsabadi,Kleomenis Katevas,H. Haddadi,H. Rabiee","Mathematics,Computer Science",78,63
3586777,Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis,"An increasing number of sensors on mobile, Internet of things (IoT), and wearable devices generate time-series measurements of physical activities. Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition, a wide range of potentially sensitive information about the individuals can also be discovered through access to sensory data and this cannot easily be protected using traditional privacy approaches. In this paper, we propose a privacy-preserving sensing framework for managing access to time-series data in order to provide utility while protecting individuals' privacy. We introduce Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences, to protect users' privacy. This efficiency is achieved by defining a user-customized objective function for deep autoencoders. Replacement will not only eliminate the possibility of recognition sensitive inferences, it also eliminates the possibility of detecting the occurrence of them, that is the main weakness of other approaches such as filtering or randomization. We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets. We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information. Finally, we utilize the GANs for detecting the occurrence of replacement, after releasing data, and show that this can be done only if the adversarial network is trained on the users' original data.",2017,"M. Malekzadeh,R. Clegg,H. Haddadi","Computer Science,Mathematics",65,46
2519922,DeepSecure: Scalable Provably-Secure Deep Learning,"This paper presents DeepSecure, the an scalable and provably secure Deep Learning (DL) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. In addition to the optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. Our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.",2017,"B. Rouhani,M. Riazi,F. Koushanfar",Computer Science,330,48
11605311,SecureML: A System for Scalable Privacy-Preserving Machine Learning,"Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",2017,"Payman Mohassel,Yupeng Zhang",Computer Science,1418,42
14715398,Abnormality Detection with Improved Histogram of Oriented Tracklets,,2015,"Hossein Mousavi,Moin Nabi,Hamed Kiani Galoogahi,A. Perina,Vittorio Murino",Computer Science,43,29
16837768,Crowd motion monitoring using tracklet-based commotion measure,"Abnormal detection in crowd is a challenging vision task due to the scarcity of real-world training examples and the lack of a clear definition of abnormality. To tackle these challenges, we propose a novel measure to capture the commotion of a crowd motion for the task of abnormality detection in crowd. The unsupervised nature of the proposed measure allows to detect abnormality adaptively (i.e. context dependent) with no training cost. The extensive experiments on three different levels (e.g. pixel, frame and video) show the superiority of the proposed approach compared to the state of the arts.",2015,"Hossein Mousavi,Moin Nabi,Hamed Kiani Galoogahi,A. Perina,Vittorio Murino",Computer Science,40,21
18021059,Analyzing Tracklets for the Detection of Abnormal Crowd Behavior,"This paper presents a novel video descriptor, referred to as Histogram of Oriented Tracklets, for recognizing abnormal situation in crowded scenes. Unlike standard approaches that use optical flow, which estimates motion vectors only from two successive frames, we built our descriptor over long-range motion trajectories which is called tracklets in the literature. Following the standard procedure, we divided video sequences in spatio-temporal cuboids within which we collected statistics on the tracklets passing through them. In particular, we quantized orientation and magnitude in a 2-dimensional histogram which encodes the motion patterns expected in each cuboid. We classify frames as normal and abnormal by using Latent Dirichlet Allocation and Support Vector Machines. We evaluated the effectiveness of the proposed descriptors on three datasets: UCSD, Violence in Crowds and UMN. The experiments demonstrated (i) very promising results in abnormality detection, (ii) setting new state-of-the-art on two of them, and (iii) outperforming former descriptors based on the optical flow, dense trajectories and the social force model.",2015,"Hossein Mousavi,Sadegh Mohammadi,A. Perina,R. Chellali,Vittorio Murino",Computer Science,116,27
5675557,Temporal Poselets for Collective Activity Detection and Recognition,"Detection and recognition of collective human activities are important modules of any system devoted to high level social behavior analysis. In this paper, we present a novel semantic-based spatio-temporal descriptor which can cope with several interacting people at different scales and multiple activities in a video. Our descriptor is suitable for modelling the human motion interaction in crowded environments - the scenario most difficult to analyse because of occlusions. In particular, we extend the Pose let detector approach by defining a descriptor based on Pose let activation patterns over time, named TPOS. We will show that this descriptor can effectively tackle complex real scenarios allowing to detect humans in the scene, to localize (in space-time) human activities, and perform collective group activity recognition in a joint manner, reaching state-of-the-art results.",2013,"Moin Nabi,A. D. Bue,Vittorio Murino",Computer Science,24,24
648645,The Large-Scale Crowd Behavior Perception Based on Spatio-Temporal Viscous Fluid Field,"Over the past decades, a wide attention has been paid to crowd control and management in the intelligent video surveillance area. Among the tasks for automatic surveillance video analysis, crowd motion modeling lays a crucial foundation for numerous subsequent analysis but encounters many unsolved challenges due to occlusions among pedestrians, complicated motion patterns in crowded scenarios, etc. Addressing the unsolved challenges, the authors propose a novel spatio-temporal viscous fluid field to model crowd motion patterns by exploring both appearance of crowd behaviors and interaction among pedestrians. Large-scale crowd events are hereby recognized based on characteristics of the fluid field. First, a spatio-temporal variation matrix is proposed to measure the local fluctuation of video signals in both spatial and temporal domains. After that, eigenvalue analysis is applied on the matrix to extract the principal fluctuations resulting in an abstract fluid field. Interaction force is then explored based on shear force in viscous fluid, incorporating with the fluctuations to characterize motion properties of a crowd. The authors then construct a codebook by clustering neighboring pixels with similar spatio-temporal features, and consequently, crowd behaviors are recognized using the latent Dirichlet allocation model. The convincing results obtained from the experiments on published datasets demonstrate that the proposed method obtains high-quality results for large-scale crowd behavior perception in terms of both robustness and effectiveness.",2013,"Hang Su,Hua Yang,Shibao Zheng,Yawen Fan,Sha Wei",Computer Science,64,42
3052515,Violent flows: Real-time detection of violent crowd behavior,"Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.",2012,"Tal Hassner,Yossi Itcher,Orit Kliper-Gross",Computer Science,417,34
9676536,Video Behaviour Mining Using a Dynamic Topic Model,,2011,"Timothy M. Hospedales,S. Gong,T. Xiang",Computer Science,116,55
215754778,Data-driven crowd analysis in videos,"In this work we present a new crowd analysis algorithm powered by behavior priors that are learned on a large database of crowd videos gathered from the Internet. The algorithm works by first learning a set of crowd behavior priors off-line. During testing, crowd patches are matched to the database and behavior priors are transferred. We adhere to the insight that despite the fact that the entire space of possible crowd behaviors is infinite, the space of distinguishable crowd motion patterns may not be all that large. For many individuals in a crowd, we are able to find analogous crowd patches in our database which contain similar patterns of behavior that can effectively act as priors to constrain the difficult task of tracking an individual in a crowd. Our algorithm is data-driven and, unlike some crowd characterization methods, does not require us to have seen the test video beforehand. It performs like state-of-the-art methods for tracking people having common crowd behaviors and outperforms the methods when the tracked individual behaves in an unusual way.",2011,"Mikel D. Rodriguez,Josef Sivic,I. Laptev,Jean-Yves Audibert",Computer Science,228,33
12909589,Crowd Analysis and Its Applications,,2011,"N. N. A. Sjarif,S. Shamsuddin,S. Z. M. Hashim,S. Yuhaniz",Computer Science,13,26
13537104,Action recognition by dense trajectories,"Feature trajectories have shown to be efficient for representing videos. Typically, they are extracted using the KLT tracker or matching SIFT descriptors between frames. However, the quality as well as quantity of these trajectories is often not sufficient. Inspired by the recent success of dense sampling in image classification, we propose an approach to describe videos by dense trajectories. We sample dense points from each frame and track them based on displacement information from a dense optical flow field. Given a state-of-the-art optical flow algorithm, our trajectories are robust to fast irregular motions as well as shot boundaries. Additionally, dense trajectories cover the motion information in videos well. We, also, investigate how to design descriptors to encode the trajectory information. We introduce a novel descriptor based on motion boundary histograms, which is robust to camera motion. This descriptor consistently outperforms other state-of-the-art descriptors, in particular in uncontrolled realistic videos. We evaluate our video description in the context of action classification with a bag-of-features approach. Experimental results show a significant improvement over the state of the art on four datasets of varying difficulty, i.e. KTH, YouTube, Hollywood2 and UCF sports.",2011,"Heng Wang,Alexander Kläser,C. Schmid,Cheng-Lin Liu","Computer Science,Mathematics",2340,37
44069023,Private and Scalable Personal Data Analytics Using Hybrid Edge-to-Cloud Deep Learning,"Although the ability to collect, collate, and analyze the vast amount of data generated from cyber-physical systems and Internet of Things devices can be beneficial to both users and industry, this process has led to a number of challenges, including privacy and scalability issues. The authors present a hybrid framework where user-centered edge devices and resources can complement the cloud for providing privacy-aware, accurate, and efficient analytics.",2018,"S. A. Ossia,A. Shamsabadi,A. Taheri,H. Rabiee,H. Haddadi",Computer Science,44,16
226953312,Comments on “Dropping Activation Outputs with Localized First-Layer Deep Network for Enhancing User Privacy and Data Security”,"Inference based on deep learning models is usually implemented by exposing sensitive user data to the outside models, which of course gives rise to acute privacy concerns. To deal with these concerns, Dong et al. recently proposed an approach, namely the dropping-activation-outputs (DAO) first layer. This approach was claimed to be a non-invertible transformation, such that the privacy of user data could not be compromised. However, In this paper, we prove that the DAO first layer, in fact, can generally be inverted, and hence fails to preserve privacy. We also provide a countermeasure against the privacy vulnerabilities that we examined.",2018,"Xinrui Tan,Hongjia Li,Liming Wang,Zhen Xu",Computer Science,6,27
4046474,Gazelle: A Low Latency Framework for Secure Neural Network Inference,"The growing popularity of cloud-based machine learning raises a natural question about the privacy guarantees that can be provided in such a setting. Our work tackles this problem in the context where a client wishes to classify private images using a convolutional neural network (CNN) trained by a server. Our goal is to build efficient protocols whereby the client can acquire the classification result without revealing their input to the server, while guaranteeing the privacy of the server's neural network. 
To this end, we design Gazelle, a scalable and low-latency system for secure neural network inference, using an intricate combination of homomorphic encryption and traditional two-party computation techniques (such as garbled circuits). Gazelle makes three contributions. First, we design the Gazelle homomorphic encryption library which provides fast algorithms for basic homomorphic operations such as SIMD (single instruction multiple data) addition, SIMD multiplication and ciphertext permutation. Second, we implement the Gazelle homomorphic linear algebra kernels which map neural network layers to optimized homomorphic matrix-vector multiplication and convolution routines. Third, we design optimized encryption switching protocols which seamlessly convert between homomorphic and garbled circuit encodings to enable implementation of complete neural network inference. 
We evaluate our protocols on benchmark neural networks trained on the MNIST and CIFAR-10 datasets and show that Gazelle outperforms the best existing systems such as MiniONN (ACM CCS 2017) by 20 times and Chameleon (Crypto Eprint 2017/1164) by 30 times in online runtime. Similarly when compared with fully homomorphic approaches like CryptoNets (ICML 2016) we demonstrate three orders of magnitude faster online run-time.",2018,"C. Juvekar,V. Vaikuntanathan,A. Chandrakasan",Computer Science,698,49
4860036,Dropping Activation Outputs With Localized First-Layer Deep Network for Enhancing User Privacy and Data Security,"Deep learning methods can play a crucial role in anomaly detection, prediction, and supporting decision making for applications like personal health-care, pervasive body sensing, and so on. However, current architecture of deep networks suffers the privacy issue that users need to give out their data to the model (typically hosted in a server or a cluster on Cloud) for training or prediction. This problem is getting more severe for those sensitive health-care or medical data (e.g., fMRI or body sensors measures like EEG signals). In addition to this, there is also a security risk of leaking these data during the data transmission from user to the model (especially when it is through the Internet). Targeting at these issues, in this paper, we proposed a new architecture for deep network in which users do not reveal their original data to the model. In our method, feed-forward propagation and data encryption are combined into one process: we migrate the first layer of deep network to users’ local devices and apply the activation functions locally, and then use the “dropping activation output” method to make the output non-invertible. The resulting approach is able to make model prediction without accessing users’ sensitive raw data. The experiment conducted in this paper showed that our approach achieves the desirable privacy protection requirement and demonstrated several advantages over the traditional approach with encryption/decryption.",2017,"Hao Dong,Chao Wu,Zhen Wei,Yike Guo",Computer Science,27,29
3586777,Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis,"An increasing number of sensors on mobile, Internet of things (IoT), and wearable devices generate time-series measurements of physical activities. Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition, a wide range of potentially sensitive information about the individuals can also be discovered through access to sensory data and this cannot easily be protected using traditional privacy approaches. In this paper, we propose a privacy-preserving sensing framework for managing access to time-series data in order to provide utility while protecting individuals' privacy. We introduce Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences, to protect users' privacy. This efficiency is achieved by defining a user-customized objective function for deep autoencoders. Replacement will not only eliminate the possibility of recognition sensitive inferences, it also eliminates the possibility of detecting the occurrence of them, that is the main weakness of other approaches such as filtering or randomization. We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets. We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information. Finally, we utilize the GANs for detecting the occurrence of replacement, after releasing data, and show that this can be done only if the adversarial network is trained on the users' original data.",2017,"M. Malekzadeh,R. Clegg,H. Haddadi","Computer Science,Mathematics",65,46
11886712,Privacy-Preserving Deep Inference for Rich User Data on The Cloud,"Deep neural networks are increasingly being used in a variety of machine learning applications applied to rich user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a particular way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also asses the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing costs, we can greatly reduce the level of information available to unintended tasks applied to the data feature on the cloud, and hence achieving the desired tradeoff between privacy and performance.",2017,"S. A. Ossia,A. Shamsabadi,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,14,58
2519922,DeepSecure: Scalable Provably-Secure Deep Learning,"This paper presents DeepSecure, the an scalable and provably secure Deep Learning (DL) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. In addition to the optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. Our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.",2017,"B. Rouhani,M. Riazi,F. Koushanfar",Computer Science,330,48
11605311,SecureML: A System for Scalable Privacy-Preserving Machine Learning,"Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",2017,"Payman Mohassel,Yupeng Zhang",Computer Science,1418,42
4909695,A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics,"Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user’s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.",2017,"Seyed Ali Osia,Ali Shahin Shamsabadi,Sina Sajadmanesh,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,204,70
6788781,Opening the Black Box of Deep Neural Networks via Information,"Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work proposed to analyze DNNs in the \textit{Information Plane}; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on {\emph compression} of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer.",2017,"Ravid Shwartz-Ziv,Naftali Tishby",Computer Science,1198,25
167211334,Deep learning for cellular image analysis,,2019,"Erick Moen,Dylan Bannon,Takamasa Kudo,William Graf,M. Covert,David Van Valen","Medicine,Computer Science",696,186
91595165,A deep learning framework for nucleus segmentation using image style transfer,"Single cell segmentation is typically one of the first and most crucial tasks of image-based cellular analysis. We present a deep learning approach aiming towards a truly general method for localizing nuclei across a diverse range of assays and light microscopy modalities. We outperform the 739 methods submitted to the 2018 Data Science Bowl on images representing a variety of realistic conditions, some of which were not represented in the training data. The key to our approach is to adapt our model to unseen and unlabeled data using image style transfer to generate augmented training samples. This allows the model to recognize nuclei in new and different experiments without requiring expert annotations.",2019,"Réka Hollandi,Ábel Szkalisity,Timea Toth,Ervin A. Tasnádi,Csaba Molnar,Botond Máthé,Istvan Grexa,József Molnár,Á. Bálind,Mate Gorbe,Mária Kovács,Ede Migh,A. Goodman,Tamás Balassa,K. Koos,Wenyu Wang,Norbert Bara,F. Kovács,L. Paavolainen,Tivadar Danka,A. Kriston,Anne E Carpenter,Kevin Smith,P. Horváth","Biology,Computer Science",40,18
56177573,"U-Net: deep learning for cell counting, detection, and morphometry",,2018,"Thorsten Falk,Dominic Mai,R. Bensch,Özgün Çiçek,A. Abdulkadir,Yassine Marrakchi,Anton Böhm,Jan Deubner,Zoe Jäckel,Katharina Seiwald,A. Dovzhenko,O. Tietz,C. Dal Bosco,Sean Walsh,Deniz Saltukoglu,Tuan Leng Tay,M. Prinz,K. Palme,M. Simons,I. Diester,T. Brox,O. Ronneberger","Medicine,Computer Science",1228,15
52195631,Object‐Oriented Segmentation of Cell Nuclei in Fluorescence Microscopy Images,"Cell nucleus segmentation remains an open and challenging problem especially to segment nuclei in cell clumps. Splitting a cell clump would be straightforward if the gradients of boundary pixels in‐between the nuclei were always higher than the others. However, imperfections may exist: inhomogeneities of pixel intensities in a nucleus may cause to define spurious boundaries whereas insufficient pixel intensity differences at the border of overlapping nuclei may cause to miss some true boundary pixels. In contrast, these imperfections are typically observed at the pixel‐level, causing local changes in pixel values without changing the semantics on a large scale. In response to these issues, this article introduces a new nucleus segmentation method that relies on using gradient information not at the pixel level but at the object level. To this end, it proposes to decompose an image into smaller homogeneous subregions, define edge‐objects at four different orientations to encode the gradient information at the object level, and devise a merging algorithm, in which the edge‐objects vote for subregion pairs along their orientations and the pairs are iteratively merged if they get sufficient votes from multiple orientations. Our experiments on fluorescence microscopy images reveal that this high‐level representation and the design of a merging algorithm using edge‐objects (gradients at the object level) improve the segmentation results.",2018,"C. Koyuncu,R. Cetin-Atalay,C. Gunduz-Demir","Medicine,Computer Science",11,25
49667613,CellProfiler 3.0: Next-generation image processing for biology,"CellProfiler has enabled the scientific research community to create flexible, modular image analysis pipelines since its release in 2005. Here, we describe CellProfiler 3.0, a new version of the software supporting both whole-volume and plane-wise analysis of three-dimensional (3D) image stacks, increasingly common in biomedical research. CellProfiler’s infrastructure is greatly improved, and we provide a protocol for cloud-based, large-scale image processing. New plugins enable running pretrained deep learning models on images. Designed by and for biologists, CellProfiler equips researchers with powerful computational tools via a well-documented user interface, empowering biologists in all fields to create quantitative, reproducible image analysis workflows.",2018,"C. McQuin,A. Goodman,V. Chernyshev,L. Kamentsky,B. Cimini,Kyle W. Karhohs,M. Doan,Liya Ding,S. Rafelski,D. Thirstrup,W. Wiegraebe,Shantanu Singh,Tim Becker,Juan C. Caicedo,Anne E Carpenter","Biology,Medicine",1395,41
46975689,On the Effect of Inter-observer Variability for a Reliable Estimation of Uncertainty of Medical Image Segmentation,,2018,"Alain Jungo,Raphael Meier,E. Ermiş,Marcela Blatti-Moreno,E. Herrmann,R. Wiest,M. Reyes",Computer Science,73,11
90996315,Evaluation of Deep Learning Strategies for Nucleus Segmentation in Fluorescence Images,"Identifying nuclei is often a critical first step in analyzing microscopy images of cells, and classical image processing algorithms are most commonly used for this task. Recent developments in deep learning can yield superior accuracy, but typical evaluation metrics for nucleus segmentation do not satisfactorily capture error modes that are relevant in cellular images. Besides, large image data sets with ground truth for evaluation have been limiting. We present an evaluation framework to measure accuracy, types of errors, and computational efficiency; and use it to compare two deep learning strategies (U-Net and DeepCell) alongside a classical approach implemented in CellProfiler. We publicly release a set of 23,165 manually annotated nuclei and source code to reproduce experiments. Our results show that U-Net outperforms both pixel-wise classification networks and classical algorithms. Also, our evaluation framework shows that deep learning improves accuracy and reduces the number of biologically relevant errors by half.",2018,"Juan C. Caicedo,Jonathan F Roth,A. Goodman,Tim Becker,Kyle W. Karhohs,C. McQuin,Shantanu Singh,Anne E Carpenter","Computer Science,Biology,Medicine",226,53
46992249,Comparison of Different Classifiers with Active Learning to Support Quality Control in Nucleus Segmentation in Pathology Images,"Segmentation of nuclei in whole slide tissue images is a common methodology in pathology image analysis. Most segmentation algorithms are sensitive to input algorithm parameters and the characteristics of input images (tissue morphology, staining, etc.). Because there can be large variability in the color, texture, and morphology of tissues within and across cancer types (heterogeneity can exist even within a tissue specimen), it is likely that a set of input parameters will not perform well across multiple images. It is, therefore, highly desired, and necessary in some cases, to carry out a quality control of segmentation results. This work investigates the application of machine learning in this process. We report on the application of active learning for segmentation quality assessment for pathology images and compare three classification methods, Support Vector Machine (SVM), Random Forest (RF) and Convolutional Neural Network (CNN), for their performance improvement and efficiency.",2018,"Si Wen,T. Kurç,L. Hou,J. Saltz,Rajarsi R. Gupta,R. Batiste,Tianhao Zhao,Vu Nguyen,D. Samaras,Wei Zhu","Computer Science,Medicine",35,26
3740145,A deep learning algorithm for one-step contour aware nuclei segmentation of histopathology images,,2018,"Yuxin Cui,Guiying Zhang,Zhonghao Liu,Zheng Xiong,Jianjun Hu","Computer Science,Mathematics,Medicine",101,38
3298854,Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification,"Recent studies demonstrate that machine learning algorithms can discriminate based on classes like race and gender. In this work, we present an approach to evaluate bias present in automated facial analysis algorithms and datasets with respect to phenotypic subgroups. Using the dermatologist approved Fitzpatrick Skin Type classiﬁcation system, we characterize the gender and skin type distribution of two facial analysis benchmarks, IJB-A and Adience. We ﬁnd that these datasets are overwhelm-ingly composed of lighter-skinned subjects (79 . 6% for IJB-A and 86 . 2% for Adience) and introduce a new facial analysis dataset which is balanced by gender and skin type. We evaluate 3 commercial gender classiﬁcation systems using our dataset and show that darker-skinned females are the most misclassiﬁed group (with error rates of up to 34 . 7%). The maximum error rate for lighter-skinned males is 0 . 8%. The substantial disparities in the accuracy of classifying darker females, lighter females, darker males, and lighter males in gender classiﬁcation systems require urgent attention if commercial companies are to build genuinely fair, transparent and accountable facial analysis algorithms.",2018,"Joy Buolamwini,Timnit Gebru",Computer Science,3271,59
221376515,Puzzle-AE: Novelty Detection in Images through Solving Puzzles,"Autoencoder, as an essential part of many anomaly detection methods, is lacking flexibility on normal data in complex datasets. U-Net is proved to be effective for this purpose but overfits on the training data if trained by just using reconstruction error similar to other AE-based frameworks. Puzzle-solving, as a pretext task of self-supervised learning (SSL) methods, has earlier proved its ability in learning semantically meaningful features. We show that training U-Nets based on this task is an effective remedy that prevents overfitting and facilitates learning beyond pixel-level features. Shortcut solutions, however, are a big challenge in SSL tasks, including jigsaw puzzles. We propose adversarial robust training as an effective automatic shortcut removal. We achieve competitive or superior results compared to the State of the Art (SOTA) anomaly detection methods on various toy and real-world datasets. Unlike many competitors, the proposed framework is stable, fast, data-efficient, and does not require unprincipled early stopping.",2020,"Mohammadreza Salehi,Ainaz Eftekhar,Niousha Sadjadi,M. Rohban,H. Rabiee",Computer Science,34,66
221141550,Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images,,2020,"Kang Zhou,Yuting Xiao,Jianlong Yang,Jun Cheng,Wen Liu,Weixin Luo,Zaiwang Gu,Jiang Liu,Shenghua Gao","Engineering,Computer Science,Physics",81,44
211549689,Classification-Based Anomaly Detection for General Data,"Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.",2020,"Liron Bergman,Yedid Hoshen","Computer Science,Mathematics",276,29
212675673,ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection,,2020,"Mohammadreza Salehi,Atrin Arya,Barbod Pajoum,Mohammad Otoofi,Amirreza Shaeiri,M. Rohban,H. Rabiee","Computer Science,Medicine",42,49
211572619,DROCC: Deep Robust One-Class Classification,"Classical approaches for one-class problems such as one-class SVM and isolation forest require careful feature engineering when applied to structured domains like images. State-of-the-art methods aim to leverage deep learning to learn appropriate features via two main approaches. The first approach based on predicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a) while successful in some domains, crucially depends on an appropriate domain-specific set of transformations that are hard to obtain in general. The second approach of minimizing a classical one-class loss on the learned final layer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the fundamental drawback of representation collapse. In this work, we propose Deep Robust One-Class Classification (DROCC) that is both applicable to most standard domains without requiring any side-information and robust to representation collapse. DROCC is based on the assumption that the points from the class of interest lie on a well-sampled, locally linear low dimensional manifold. Empirical evaluation demonstrates that DROCC is highly effective in two different one-class problem settings and on a range of real-world datasets across different domains: tabular data, images (CIFAR and ImageNet), audio, and time-series, offering up to 20% increase in accuracy over the state-of-the-art in anomaly detection. Code is available at this https URL.",2020,"Sachin Goyal,Aditi Raghunathan,Moksh Jain,H. Simhadri,Prateek Jain","Computer Science,Mathematics",117,41
211068987,Iterative energy-based projection on a normal data manifold for anomaly localization,"Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.",2020,"David Dehaene,Oriel Frigo,Sébastien Combrexelle,P. Eline",Computer Science,107,29
208527731,A Case for the Score: Identifying Image Anomalies using Variational Autoencoder Gradients,"Through training on unlabeled data, anomaly detection has the potential to impact computer-aided diagnosis by outlining suspicious regions. Previous work on deep-learning-based anomaly detection has primarily focused on the reconstruction error. We argue instead, that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate. In our experiments, Variational Autoencoder gradient-based rating outperforms other approaches on unsupervised pixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.",2019,"David Zimmerer,Jens Petersen,Simon A. A. Kohl,Klaus Maier-Hein","Engineering,Computer Science,Mathematics",21,20
215870627,Attention Guided Anomaly Localization in Images,,2019,"Shashanka Venkataramanan,Kuan-Chuan Peng,Rajat Vikram Singh,Abhijit Mahalanobis",Computer Science,149,65
207880670,Uninformed Students: Student-Teacher Anomaly Detection With Discriminative Latent Embeddings,"We introduce a powerful student-teacher framework for the challenging problem of unsupervised anomaly detection and pixel-precise anomaly segmentation in high-resolution images. Student networks are trained to regress the output of a descriptive teacher network that was pretrained on a large dataset of patches from natural images. This circumvents the need for prior data annotation. Anomalies are detected when the outputs of the student networks differ from that of the teacher network. This happens when they fail to generalize outside the manifold of anomaly-free training data. The intrinsic uncertainty in the student networks is used as an additional scoring function that indicates anomalies. We compare our method to a large number of existing deep learning based methods for unsupervised anomaly detection. Our experiments demonstrate improvements over state-of-the-art methods on a number of real-world datasets, including the recently introduced MVTec Anomaly Detection dataset that was specifically designed to benchmark anomaly segmentation algorithms.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,375,37
196622802,Exploring Deep Anomaly Detection Methods Based on Capsule Net,,2019,"Xiaoyan Li,I. Kiringa,T. Yeap,Xiaodan Zhu,Yifeng Li","Computer Science,Mathematics",19,36
3568870,A multi‐scale convolutional neural network for phenotyping high‐content cellular images,"Motivation: Identifying phenotypes based on high‐content cellular images is challenging. Conventional image analysis pipelines for phenotype identification comprise multiple independent steps, with each step requiring method customization and adjustment of multiple parameters. Results: Here, we present an approach based on a multi‐scale convolutional neural network (M‐CNN) that classifies, in a single cohesive step, cellular images into phenotypes by using directly and solely the images’ pixel intensity values. The only parameters in the approach are the weights of the neural network, which are automatically optimized based on training images. The approach requires no a priori knowledge or manual customization, and is applicable to single‐ or multi‐channel images displaying single or multiple cells. We evaluated the classification performance of the approach on eight diverse benchmark datasets. The approach yielded overall a higher classification accuracy compared with state‐of‐the‐art results, including those of other deep CNN architectures. In addition to using the network to simply obtain a yes‐or‐no prediction for a given phenotype, we use the probability outputs calculated by the network to quantitatively describe the phenotypes. This study shows that these probability values correlate with chemical treatment concentrations. This finding validates further our approach and enables chemical treatment potency estimation via CNNs. Availability and Implementation: The network specifications and solver definitions are provided in Supplementary Software 1. Contact: william_jose.godinez_navarro@novartis.com or xian‐1.zhang@novartis.com Supplementary information: Supplementary data are available at Bioinformatics online.",2017,"William J. Godinez,Imtiaz Hossain,S. Lazic,J. Davies,Xian Zhang","Medicine,Computer Science",130,63
205426582,Image Data Resource: a bioimage data integration and publication platform,,2017,"Eleanor Williams,Josh Moore,Simon W. Li,G. Rustici,Aleksandra Tarkowska,A. Chessel,Simone Leo,B. Antal,Richard K. Ferguson,Ugis Sarkans,A. Brazma,R. E. Carazo Salas,J. Swedlow","Medicine,Computer Science",205,60
205284145,Reproducibility of computational workflows is automated using continuous analysis,,2017,"B. Beaulieu-Jones,C. Greene","Computer Science,Medicine",130,25
3317091,Automated analysis of high‐content microscopy data with deep learning,"Existing computational pipelines for quantitative analysis of high‐content microscopy data rely on traditional machine learning approaches that fail to accurately classify more than a single dataset without substantial tuning and training, requiring extensive analysis. Here, we demonstrate that the application of deep learning to biological image data can overcome the pitfalls associated with conventional machine learning classifiers. Using a deep convolutional neural network (DeepLoc) to analyze yeast cell images, we show improved performance over traditional approaches in the automated classification of protein subcellular localization. We also demonstrate the ability of DeepLoc to classify highly divergent image sets, including images of pheromone‐arrested cells with abnormal cellular morphology, as well as images generated in different genetic backgrounds and in different laboratories. We offer an open‐source implementation that enables updating DeepLoc on new microscopy datasets. This study highlights deep learning as an important tool for the expedited analysis of high‐content microscopy data.",2017,,"Biology,Medicine",226,0
29663868,Repurposed high-throughput images enable biological activity prediction for drug discovery,"We repurpose a High-Throughput (cell) Imaging (HTI) screen of a glucocorticoid receptor assay to predict target protein activity in multiple other seemingly unrelated assays. In two ongoing drug discovery projects, our repurposing approach increased hit rates by 60- to 250-fold over that of the primary project assays while increasing the chemical structure diversity of the hits. Our results suggest that data from available HTI screens are a rich source of information that can be reused to empower drug discovery efforts.",2017,"J. Simm,G. Klambauer,Adam Arany,M. Steijaert,J. Wegner,Emmanuel Gustin,V. Chupakhin,Yolanda T. Chong,J. Vialard,P. Buijnsters,I. Velter,A. Vapirev,Shantanu Singh,Anne E Carpenter,Roel Wuyts,S. Hochreiter,Y. Moreau,H. Ceulemans",Biology,4,36
115146,Systematic morphological profiling of human gene and allele function via Cell Painting,"We hypothesized that human genes and disease-associated alleles might be systematically functionally annotated using morphological profiling of cDNA constructs, via a microscopy-based Cell Painting assay. Indeed, 50% of the 220 tested genes yielded detectable morphological profiles, which grouped into biologically meaningful gene clusters consistent with known functional annotation (e.g., the RAS-RAF-MEK-ERK cascade). We used novel subpopulation-based visualization methods to interpret the morphological changes for specific clusters. This unbiased morphologic map of gene function revealed TRAF2/c-REL negative regulation of YAP1/WWTR1-responsive pathways. We confirmed this discovery of functional connectivity between the NF-κB pathway and Hippo pathway effectors at the transcriptional level, thereby expanding knowledge of these two signaling pathways that critically regulate tumor initiation and progression. We make the images and raw data publicly available, providing an initial morphological map of major biological pathways for future study. DOI: http://dx.doi.org/10.7554/eLife.24060.001",2017,"M. Rohban,Shantanu Singh,Xiaoyun Wu,Julia B Berthet,M. Bray,Y. Shrestha,X. Varelas,J. Boehm,Anne E Carpenter","Medicine,Biology",103,81
23164938,Large‐scale image‐based screening and profiling of cellular phenotypes,"Cellular phenotypes are observable characteristics of cells resulting from the interactions of intrinsic and extrinsic chemical or biochemical factors. Image‐based phenotypic screens under large numbers of basal or perturbed conditions can be used to study the influences of these factors on cellular phenotypes. Hundreds to thousands of phenotypic descriptors can also be quantified from the images of cells under each of these experimental conditions. Therefore, huge amounts of data can be generated, and the analysis of these data has become a major bottleneck in large‐scale phenotypic screens. Here, we review current experimental and computational methods for large‐scale image‐based phenotypic screens. Our focus is on phenotypic profiling, a computational procedure for constructing quantitative and compact representations of cellular phenotypes based on the images collected in these screens. © 2016 International Society for Advancement of Cytometry",2017,"Nicola Bougen-Zhukov,Sheng Yang Michael Loh,H. Lee,L. Loo","Biology,Medicine",47,121
27400335,Machine learning and computer vision approaches for phenotypic profiling,"Grys et al. review computer vision and machine-learning methods that have been applied to phenotypic profiling of image-based data. Descriptions are provided for segmentation, feature extraction, selection, and dimensionality reduction, as well as clustering, outlier detection, and classification of data.",2017,"Ben T Grys,Dara S Lo,Nil Sahin,Oren Z. Kraus,Q. Morris,Charles Boone,B. Andrews","Biology,Medicine",130,79
89363691,Chapter 10:Multidimensional Profile Based Screening: Understanding Biology through Cellular Response Signatures,"The complexity of biology makes defining a single model system that recapitulates human disease a nearly impossible task. To overcome this inherent limitation, screening of many different systems across multiple measurement parameters enables the generation of response signatures or profiles that are more predictive and robust than measurements in single systems alone. The application of signature based discovery has included early efforts such as NCI-60, but has been limited by the amount of additional dimensional data and technical and logistical challenges that prevented collection of large scale profiles. With the recent development of large datasets of genomic characterization and annotations of cell lines, and the development of new technologies to enable measurements of profiles across hundreds of cellular systems in a cost and time efficient manner, it is now possible to routinely collect multidimensional profiles during the discovery process. Similarly, advancements in computational approaches such as the Connectivity Map allow for sophisticated queries across various profile based datasets to find correlations such as target identification and mechanisms of action. Taken together, multidimensional profile based screening can provide a wealth of information and actionable hypotheses at multiple stages of the drug development process.",2016,"C. Mader,A. Subramanian,Joshua A. Bittker",Biology,1,0
7389917,Automating Morphological Profiling with Generic Deep Convolutional Networks,"Morphological profiling aims to create signatures of genes, chemicals and diseases from microscopy images. Current approaches use classical computer vision-based segmentation and feature extraction. Deep learning models achieve state-of-the-art performance in many computer vision tasks such as classification and segmentation. We propose to transfer activation features of generic deep convolutional networks to extract features for morphological profiling. Our approach surpasses currently used methods in terms of accuracy and processing speed. Furthermore, it enables fully automated processing of microscopy images without need for single cell identification.",2016,"Nick Pawlowski,Juan C. Caicedo,Shantanu Singh,Anne E Carpenter,A. Storkey","Biology,Computer Science",75,16
15185982,Sparse signal recovery under poisson statistics for online marketing applications,"We are motivated by many applications such as problems that arise in online marketing applications, where the observations are governed by non-homogeneous Poisson models. We analyze the performance of a Maximum Likelihood (ML) decoder. We prove consistency and show an exponential rate of converge for sparse recovery in the high-dimensional Poisson setting. After verifying the efficiency of ML estimator empirically, we apply the ML decoder to study the dynamics of online marketing methods over time.",2014,"Delaram Motamedvaziri,M. Rohban,Venkatesh Saligrama",Computer Science,2,24
14727218,Sparse signal recovery under Poisson statistics,"We are motivated by problems that arise in a number of applications such as explosives detection and online Marketing, where the observations are governed by Poisson statistics. Here each observation is a Poisson random variable whose mean is a sparse linear superposition of known patterns. Unlike many conventional problems observations here are not identically distributed since they are associated with different sensing modalities. We analyse the performance of a Maximum Likelihood (ML) decoder, which for our Poisson setting is computationally tractable. We derive fundamental sample complexity bounds for sparse recovery in the high-dimensional setting. We show that when the sensing matrix satisfies the so-called Restricted Eigenvalue (RE) condition the ℓ1 regularized ML decoder is consistent. Moreover, it converges exponentially fast in terms of number of observations. Our results apply to both deterministic and random sensing matrices and we present several results for both cases.",2013,"Delaram Motamedvaziri,M. Rohban,Venkatesh Saligrama","Mathematics,Computer Science",8,27
21494997,Waffles: A Machine Learning Toolkit,We present a breadth-oriented collection of cross-platform command-line tools for researchers in machine learning called Waffles. The Waffles tools are designed to offer a broad spectrum of functionality in a manner that is friendly for scripted automation. All functionality is also available in a C++ class library. Waffles is available under the GNU Lesser General Public License.,2011,Michael S. Gashler,Computer Science,46,9
14166025,The Lasso under Heteroscedasticity,"The performance of the Lasso is well understood under the assumptions of the standard linear model with homoscedastic noise. However, in several appli- cations, the standard model does not describe the important features of the data. This paper examines how the Lasso performs on a non-standard model that is mo- tivated by medical imaging applications. In these applications, the variance of the noise scales linearly with the expectation of the observation. Like all heteroscedas- tic models, the noise terms in this Poisson-like model are not independent of the design matrix. More specically, this paper studies the sign consistency of the Lasso under a sparse Poisson-like model. In addition to studying sucient conditions for the sign consistency of the Lasso estimate, this paper also gives necessary conditions for sign consistency. Both sets of conditions are comparable to results for the homoscedastic model, showing that when a measure of the signal to noise ratio is large, the Lasso performs well on both Poisson-like data and homoscedastic data. Simulations reveal that the Lasso performs equally well in terms of model selec- tion performance on both Poisson-like data and homoscedastic data (with properly scaled noise variance), across a range of parameterizations. Taken as a whole, these results suggest that the Lasso is robust to the Poisson-like heteroscedastic noise.",2010,"Jinzhu Jia,Karl Rohe,Bin Yu",Mathematics,9,33
7994718,Performance Bounds for Expander-Based Compressed Sensing in Poisson Noise,"This paper provides performance bounds for compressed sensing in the presence of Poisson noise using expander graphs. The Poisson noise model is appropriate for a variety of applications, including low-light imaging and digital streaming, where the signal-independent and/or bounded noise models used in the compressed sensing literature are no longer applicable. In this paper, we develop a novel sensing paradigm based on expander graphs and propose a maximum a posteriori (MAP) algorithm for recovering sparse or compressible signals from Poisson observations. The geometry of the expander graphs and the positivity of the corresponding sensing matrices play a crucial role in establishing the bounds on the signal reconstruction error of the proposed algorithm. We support our results with experimental demonstrations of reconstructing average packet arrival rates and instantaneous packet counts at a router in a communication network, where the arrivals of packets in each flow follow a Poisson process.",2010,"M. Raginsky,Sina Jafarpour,Zachary T. Harmany,Roummel F. Marcia,R. Willett,Robert Calderbank","Computer Science,Mathematics",55,42
36675957,Detection of nitroaromatic explosives using a fluorescent-labeled imprinted polymer.,"Optical sensors have proven to be a useful method in identifying explosive devices by recognizing vapors of explosive compounds that become airborne and emanate from the device. To detect high explosive compounds such as TNT, a molecularly imprinted polymer (MIP) sensing mechanism was developed. This mechanism consists of MIP microparticles prepared using methacrylic acid as the functional monomer. The MIP microparticles are then combined with fluorescent quantum dots via a simple cross-linking procedure. The result is a highly robust optical sensing scheme that is capable of functioning in an array of environmental conditions. To study the sensing mechanisms's ability to detect nitroaromatic analytes, the fluorescent-labeled MIP particles were tested for their performance in detecting aqueous 2,4-dinitrotoluene (DNT), a nitroaromatic molecule very similar to TNT, as well as TNT itself. These preliminary data indicate that the system is capable of detecting nitroaromatic compounds in solution with high sensitivity, achieving lower limits of detection of 30.1 and 40.7 microM for DNT and TNT, respectively. The detection mechanism also acted rapidly, with response times as low as 1 min for TNT. Due to the results of this study, it can be concluded that the fluorescent-labeled MIP system is a feasible method for detecting high explosives, with the potential for future use in detecting vapors from explosive devices.",2010,"R. Stringer,S. Gangopadhyay,S. Grant","Chemistry,Medicine",178,0
6303469,"Lower Bounds for the Minimax Risk Using $f$-Divergences, and Applications","Lower bounds involving f-divergences between the underlying probability measures are proved for the minimax risk in estimation problems. Our proofs just use simple convexity facts. Special cases and straightforward corollaries of our bounds include well known inequalities for establishing minimax lower bounds such as Fano's inequality, Pinsker's inequality and inequalities based on global entropy conditions. Two applications are provided: a new minimax lower bound for the reconstruction of convex bodies from noisy support function measurements and a different proof of a recent minimax lower bound for the estimation of a covariance matrix.",2010,Adityanand Guntuboyina,"Computer Science,Mathematics",76,32
88512371,Restricted Eigenvalue Conditions on Subgaussian Random Matrices,"It is natural to ask: what kinds of matrices satisfy the Restr icted Eigenvalue (RE) condition? In this paper, we associate the RE condition (Bickel-Ritov-Tsybakov 09) with the complexity of a subset of the sphere in R p , where p is the dimensionality of the data, and show that a class of random matrices with independent rows, but not necessarily independent columns, satisfy the RE condition, when the sample size is above a certain lower bound. Here we explicitly introduce an additional covariance structure to the class of random matrices that we have known by now that satisfy the Restricted Isometry Property",2009,Shuheng Zhou,Mathematics,79,22
656534,A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers,"High-dimensional statistical inference deals with models in which the the number of parameters p is comparable to or larger than the sample size n. Since it is usually impossible to obtain consistent procedures unless p/n → 0, a line of recent work has studied models with various types of structure (e.g., sparse vectors; block-structured matrices; low-rank matrices; Markov assumptions). In such settings, a general approach to estimation is to solve a regularized convex program (known as a regularized M-estimator) which combines a loss function (measuring how well the model fits the data) with some regularization function that encourages the assumed structure. The goal of this paper is to provide a unified framework for establishing consistency and convergence rates for such regularized M-estimators under high-dimensional scaling. We state one main theorem and show how it can be used to re-derive several existing results, and also to obtain several new results on consistency and convergence rates. Our analysis also identifies two key properties of loss and regularization functions, referred to as restricted strong convexity and decomposability, that ensure the corresponding regularized M-estimators have fast convergence rates.",2009,"S. Negahban,Pradeep Ravikumar,M. Wainwright,Bin Yu","Computer Science,Mathematics",1314,107
199511239,Image Synthesis with a Single (Robust) Classifier,"We show that the basic classification framework alone can be used to tackle some of the most challenging tasks in image synthesis. In contrast to other state-of-the-art approaches, the toolkit we develop is rather minimal: it uses a single, off-the-shelf classifier for all these tasks. The crux of our approach is that we train this classifier to be adversarially robust. It turns out that adversarial robustness is precisely what we need to directly manipulate salient features of the input. Overall, our findings demonstrate the utility of robustness in the broader machine learning context. Code and models for our experiments can be found at this https URL.",2019,"Shibani Santurkar,Andrew Ilyas,Dimitris Tsipras,Logan Engstrom,Brandon Tran,A. Madry",Computer Science,173,57
166228027,Adversarially-trained autoencoders for robust unsupervised new physics searches,,2019,"A. Blance,M. Spannowsky,Philip Waite",Physics,105,102
146121358,"Adversarial Examples Are Not Bugs, They Are Features","Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.",2019,"Andrew Ilyas,Shibani Santurkar,Dimitris Tsipras,Logan Engstrom,Brandon Tran,A. Madry","Computer Science,Mathematics",1473,64
140311498,Adversarial Training and Robustness for Multiple Perturbations,"Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\ell_\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model's vulnerability. Our aim is to understand the reasons underlying this robustness trade-off, and to train models that are simultaneously robust to multiple perturbation types. We prove that a trade-off in robustness to different types of $\ell_p$-bounded and spatial perturbations must exist in a natural and simple statistical setting. We corroborate our formal analysis by demonstrating similar robustness trade-offs on MNIST and CIFAR10. Building upon new multi-perturbation adversarial training schemes, and a novel efficient attack for finding $\ell_1$-bounded adversarial examples, we show that no model trained against multiple attacks achieves robustness competitive with that of models trained on each attack individually. In particular, we uncover a pernicious gradient-masking phenomenon on MNIST, which causes adversarial training with first-order $\ell_\infty, \ell_1$ and $\ell_2$ adversaries to achieve merely $50\%$ accuracy. Our results question the viability and computational scalability of extending adversarial robustness, and adversarial training, to multiple perturbation types.",2019,"Florian Tramèr,D. Boneh","Computer Science,Mathematics",309,48
102353587,Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection,"Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder ""generalizes"" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",2019,"Dong Gong,Lingqiao Liu,Vuong Le,Budhaditya Saha,M. Mansour,S. Venkatesh,A. Hengel",Computer Science,853,54
84186723,OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations,"We present a novel model called OCGAN for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class. Our solution is based on learning latent representations of in-class examples using a de-noising auto-encoder network. The key contribution of our work is our proposal to explicitly constrain the latent space to exclusively represent the given class. In order to accomplish this goal, firstly, we force the latent space to have bounded support by introducing a tanh activation in the encoder's output layer. Secondly, using a discriminator in the latent space that is trained adversarially, we ensure that encoded representations of in-class examples resemble uniform random samples drawn from the same bounded space. Thirdly, using a second adversarial discriminator in the input space, we ensure all randomly drawn latent samples generate examples that look real. Finally, we introduce a gradient-descent based sampling technique that explores points in the latent space that generate potential out-of-class examples, which are fed back to the network to further train it to generate in-class examples from those points. The effectiveness of the proposed method is measured across four publicly available datasets using two one-class novelty detection protocols where we achieve state-of-the-art results.",2019,"Pramuditha Perera,Ramesh Nallapati,Bing Xiang",Computer Science,415,30
57825713,Deep Learning for Anomaly Detection: A Survey,"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.",2019,"Raghavendra Chalapathy,Sanjay Chawla","Computer Science,Mathematics,Geology",1201,477
54445285,Rare Event Detection Using Disentangled Representation Learning,"This paper presents a novel method for rare event detection from an image pair with class-imbalanced datasets. A straightforward approach for event detection tasks is to train a detection network from a large-scale dataset in an end-to-end manner. However, in many applications such as building change detection on satellite images, few positive samples are available for the training. Moreover, an image pair of scenes contains many trivial events, such as in illumination changes or background motions. These many trivial events and the class imbalance problem lead to false alarms for rare event detection. In order to overcome these difficulties, we propose a novel method to learn disentangled representations from only low-cost negative samples. The proposed method disentangles the different aspects in a pair of observations: variant and invariant factors that represent trivial events and image contents, respectively. The effectiveness of the proposed approach is verified by the quantitative evaluations on four change detection datasets, and the qualitative analysis shows that the proposed method can acquire the representations that disentangle rare events from trivial ones.",2018,"Ryuhei Hamaguchi,Ken Sakurada,R. Nakamura",Computer Science,32,35
49657108,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,"Novelty detection is the problem of identifying whether a new data point is considered to be an inlier or an outlier. We assume that training data is available to describe only the inlier distribution. Recent approaches primarily leverage deep encoder-decoder network architectures to compute a reconstruction error that is used to either compute a novelty score or to train a one-class classifier. While we too leverage a novel network of that kind, we take a probabilistic approach and effectively compute how likely it is that a sample was generated by the inlier distribution. We achieve this with two main contributions. First, we make the computation of the novelty probability feasible because we linearize the parameterized manifold capturing the underlying structure of the inlier distribution, and show how the probability factorizes and can be computed with respect to local coordinates of the manifold tangent space. Second, we improve the training of the autoencoder network. An extensive set of results show that the approach achieves state-of-the-art performance on several benchmark datasets.",2018,"Stanislav Pidhorskyi,Ranya Almohsen,D. Adjeroh,Gianfranco Doretto",Computer Science,268,61
49567058,Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders,"Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.",2018,"Paul Bergmann,Sindy Löwe,Michael Fauser,David Sattlegger,C. Steger",Computer Science,442,27
13924255,Esrrb Is a Pivotal Target of the Gsk3/Tcf3 Axis Regulating Embryonic Stem Cell Self-Renewal,,2012,"Graziano Martello,T. Sugimoto,E. Diamanti,A. Joshi,R. Hannah,S. Ohtsuka,B. Göttgens,H. Niwa,Austin G Smith","Biology,Medicine",357,56
18814385,Simultaneous Suppression of TGF-β and ERK Signaling Contributes to the Highly Efficient and Reproducible Generation of Mouse Embryonic Stem Cells from Previously Considered Refractory and Non-permissive Strains,,2012,"Seyedeh-Nafiseh Hassani,M. Totonchi,A. Farrokhi,A. Taei,M. R. Larijani,H. Gourabi,H. Baharvand","Biology,Medicine",41,36
9110515,The Transcriptional and Epigenomic Foundations of Ground State Pluripotency,,2012,"H. Marks,Tüzer Kalkan,R. Menafra,S. Denissov,K. Jones,H. Hofemeister,J. Nichols,J. Nichols,A. Kranz,A. F. Stewart,Austin G Smith,Austin G Smith,H. Stunnenberg","Medicine,Biology",809,95
205243682,BMP4 Signaling Acts via dual-specificity phosphatase 9 to control ERK activity in mouse embryonic stem cells.,,2012,"Zhongwei Li,Teng Fei,Jianping Zhang,Gaoyang Zhu,Lu Wang,Danyu Lu,Xiaochun Chi,Y. Teng,N. Hou,Xiao Yang,Hongquan Zhang,J. Han,Ye-Guang Chen","Biology,Medicine",147,45
3862582,Adenomatous Polyposis Coli (APC) Regulates Multiple Signaling Pathways by Enhancing Glycogen Synthase Kinase-3 (GSK-3) Activity*,"Background: Glycogen Synthase Kinase-3 (GSK-3) is a key regulator of multiple signaling pathways. Results: Adenomatous Polyposis Coli (APC) positively regulates GSK-3 activity in both Wnt- and Akt-dependent pathways. Conclusion: Canonical Wnt signaling disrupts APC-Axin interaction and reduces GSK-3 activity. Significance: APC regulation of GSK-3 provides a novel mechanism for signaling through GSK-3 by Wnt and non-Wnt pathways. Glycogen synthase kinase-3 (GSK-3) is essential for many signaling pathways and cellular processes. As Adenomatous Polyposis Coli (APC) functions in many of the same processes, we investigated a role for APC in the regulation of GSK-3-dependent signaling. We find that APC directly enhances GSK-3 activity. Furthermore, knockdown of APC mimics inhibition of GSK-3 by reducing phosphorylation of glycogen synthase and by activating mTOR, revealing novel roles for APC in the regulation of these enzymes. Wnt signaling inhibits GSK-3 through an unknown mechanism, and this results in both stabilization of β-catenin and activation of mTOR. We therefore hypothesized that Wnts may regulate GSK-3 by disrupting the interaction between APC and the Axin-GSK-3 complex. We find that Wnts rapidly induce APC dissociation from Axin, correlating with β-catenin stabilization. Furthermore, Axin interaction with the Wnt co-receptor LRP6 causes APC dissociation from Axin. We propose that APC regulates multiple signaling pathways by enhancing GSK-3 activity, and that Wnts induce APC dissociation from Axin to reduce GSK-3 activity and activate downstream signaling. APC regulation of GSK-3 also provides a novel mechanism for Wnt regulation of multiple downstream effectors, including β-catenin and mTOR.",2011,"Alexander J. Valvezan,Fang Zhang,J. Diehl,P. S. Klein","Medicine,Chemistry",87,66
9747567,Master Transcription Factors Determine Cell-Type-Specific Responses to TGF-β Signaling,,2011,"Alan C. Mullen,David A. Orlando,J. Newman,Jakob Lovén,Roshan M. Kumar,S. Bilodeau,J. Reddy,M. Guenther,R. DeKoter,R. Young","Medicine,Biology",570,74
9476597,Graded Nodal/Activin Signaling Titrates Conversion of Quantitative Phospho-Smad2 Levels into Qualitative Embryonic Stem Cell Fate Decisions,"Nodal and Activin are morphogens of the TGFbeta superfamily of signaling molecules that direct differential cell fate decisions in a dose- and distance-dependent manner. During early embryonic development the Nodal/Activin pathway is responsible for the specification of mesoderm, endoderm, node, and mesendoderm. In contradiction to this drive towards cellular differentiation, the pathway also plays important roles in the maintenance of self-renewal and pluripotency in embryonic and epiblast stem cells. The molecular basis behind stem cell interpretation of Nodal/Activin signaling gradients and the undertaking of disparate cell fate decisions remains poorly understood. Here, we show that any perturbation of endogenous signaling levels in mouse embryonic stem cells leads to their exit from self-renewal towards divergent differentiation programs. Increasing Nodal signals above basal levels by direct stimulation with Activin promotes differentiation towards the mesendodermal lineages while repression of signaling with the specific Nodal/Activin receptor inhibitor SB431542 induces trophectodermal differentiation. To address how quantitative Nodal/Activin signals are translated qualitatively into distinct cell fates decisions, we performed chromatin immunoprecipitation of phospho-Smad2, the primary downstream transcriptional factor of the Nodal/Activin pathway, followed by massively parallel sequencing, and show that phospho-Smad2 binds to and regulates distinct subsets of target genes in a dose-dependent manner. Crucially, Nodal/Activin signaling directly controls the Oct4 master regulator of pluripotency by graded phospho-Smad2 binding in the promoter region. Hence stem cells interpret and carry out differential Nodal/Activin signaling instructions via a corresponding gradient of Smad2 phosphorylation that selectively titrates self-renewal against alternative differentiation programs by direct regulation of distinct target gene subsets and Oct4 expression.",2011,"K. Lee,Sandy Keat Lim,Y. Orlov,L. Y. Yit,Henry Yang,L. Ang,L. Poellinger,B. Lim","Medicine,Biology",92,76
13753823,A precarious balance: pluripotency factors as lineage specifiers.,,2011,"K. Loh,B. Lim","Medicine,Biology",246,44
7908078,The Liberation of Embryonic Stem Cells,"Mouse embryonic stem (ES) cells are defined by their capacity to self-renew and their ability to differentiate into all adult tissues including the germ line. Along with efficient clonal propagation, these properties have made them an unparalleled tool for manipulation of the mouse genome. Traditionally, mouse ES (mES) cells have been isolated and cultured in complex, poorly defined conditions that only permit efficient derivation from the 129 mouse strain; genuine ES cells have not been isolated from another species in these conditions. Recently, use of small molecule inhibitors of glycogen synthase kinase 3 (Gsk3) and the Fgf-MAPK signaling cascade has permitted efficient derivation of ES cells from all tested mouse strains. Subsequently, the first verified ES cells were established from a non-mouse species, Rattus norvegicus. Here, we summarize the advances in our understanding of the signaling pathways regulating mES cell self-renewal that led to the first derivation of rat ES cells and highlight the new opportunities presented for transgenic modeling on diverse genetic backgrounds. We also comment on the implications of this work for our understanding of pluripotent stem cells across mammalian species.",2011,"Kathryn Blair,Jason P. Wray,Austin G Smith","Biology,Medicine",101,81
13562793,Smad2 mediates Activin/Nodal signaling in mesendoderm differentiation of mouse embryonic stem cells,,2010,"Teng Fei,Shanshan Zhu,K. Xia,Jianping Zhang,Zhongwei Li,J. Han,Ye-Guang Chen","Biology,Medicine",67,51
15349049,Pleiotropy of Glycogen Synthase Kinase-3 Inhibition by CHIR99021 Promotes Self-Renewal of Embryonic Stem Cells from Refractory Mouse Strains,"Background Inhibition of glycogen synthase kinase-3 (GSK-3) improves the efficiency of embryonic stem (ES) cell derivation from various strains of mice and rats, as well as dramatically promotes ES cell self-renewal potential. β-catenin has been reported to be involved in the maintenance of self-renewal of ES cells through TCF dependent and independent pathway. But the intrinsic difference between ES cell lines from different species and strains has not been characterized. Here, we dissect the mechanism of GSK-3 inhibition by CHIR99021 in mouse ES cells from refractory mouse strains. Methodology/Principal Findings We found that CHIR99021, a GSK-3 specific inhibitor, promotes self-renewal of ES cells from recalcitrant C57BL/6 (B6) and BALB/c mouse strains through stabilization of β-catenin and c-Myc protein levels. Stabilized β-catenin promoted ES self-renewal through two mechanisms. First, β-catenin translocated into the nucleus to maintain stem cell pluripotency in a lymphoid-enhancing factor/T-cell factor–independent manner. Second, β-catenin binds plasma membrane-localized E-cadherin, which ensures a compact, spherical morphology, a hallmark of ES cells. Further, elevated c-Myc protein levels did not contribute significantly to CH-mediated ES cell self-renewal. Instead, the role of c-Myc is dependent on its transformation activity and can be replaced by N-Myc but not L-Myc. β-catenin and c-Myc have similar effects on ES cells derived from both B6 and BALB/c mice. Conclusions/Significance Our data demonstrated that GSK-3 inhibition by CH promotes self-renewal of mouse ES cells with non-permissive genetic backgrounds by regulation of multiple signaling pathways. These findings would be useful to improve the availability of normally non-permissive mouse strains as research tools.",2012,"Shoudong Ye,L. Tan,R. Yang,Bo Fang,S. Qu,E. Schulze,Hou-yan Song,Qi-Long Ying,Ping Li","Biology,Medicine",80,61
22038309,Activin and BMP4 Synergistically Promote Formation of Definitive Endoderm in Human Embryonic Stem Cells,"Human embryonic stem cells (hESCs) herald tremendous promise for the production of clinically useful cell types for the treatment of injury and disease. Numerous reports demonstrate their differentiation into definitive endoderm (DE) cells, the germ layer from which pancreatic β cells and hepatocytes arise, solely from exposure to a high dose of recombinant Activin/Nodal. We show that combining a second related ligand, BMP4, in combination with Activin A yields 15%–20% more DE as compared with Activin A alone. The addition of recombinant BMP4 accelerates the downregulation of pluripotency genes, particularly SOX2, and results in upregulation of endogenous BMP2 and BMP4, which in turn leads to elevated levels of phospho‐SMAD1/5/8. Combined Activin A and BMP4 treatment also leads to an increase in the expression of DE genes CXCR4, SOX17, and FOXA2 when compared with Activin A addition alone. Comparative microarray studies between DE cells harvested on day 3 of differentiation further reveal a novel set of genes upregulated in response to initial BMP4 exposure. Several of these, including APLNR, LRIG3, MCC, LEPREL1, ROR2, and LZTS1, are expressed in the mouse primitive streak, the site of DE formation. Thus, this synergism between Activin A and BMP4 during the in vitro differentiation of hESC into DE suggests a complex interplay between BMP and Activin/Nodal signaling during the in vivo allocation and expansion of the endoderm lineage. STEM CELLS 2012; 30:631–642",2012,"A. Teo,Yusuf Ali,Kee‐Yew Wong,H. Chipperfield,Akila Sadasivam,Yogavalli Poobalan,E. Tan,Siew Tein Wang,S. Abraham,Norihiro Tsuneyoshi,L. Stanton,N. R. Dunn","Biology,Medicine",111,71
16570576,Differentiation and Transplantation of Human Induced Pluripotent Stem Cell-derived Hepatocyte-like Cells,,2011,"S. Asgari,M. Moslem,K. Bagheri-Lankarani,Behshad Pournasr,Maryam Miryounesi,H. Baharvand","Biology,Medicine",102,29
25745770,The evolving biology of small molecules: controlling cell fate and identity,"Small molecules have been playing important roles in elucidating basic biology and treatment of a vast number of diseases for nearly a century, making their use in the field of stem cell biology a comparatively recent phenomenon. Nonetheless, the power of biology-oriented chemical design and synthesis, coupled with significant advances in screening technology, has enabled the discovery of a growing number of small molecules that have improved our understanding of stem cell biology and allowed us to manipulate stem cells in unprecedented ways. This review focuses on recent small molecule studies of (i) the key pathways governing stem cell homeostasis, (ii) the pluripotent stem cell niche, (iii) the directed differentiation of stem cells, (iv) the biology of adult stem cells, and (v) somatic cell reprogramming. In a very short period of time, small molecules have defined a perhaps universally attainable naive ground state of pluripotency, and are facilitating the precise, rapid and efficient differentiation of stem cells into somatic cell populations relevant to the clinic. Finally, following the publication of numerous groundbreaking studies at a pace and consistency unusual for a young field, we are closer than ever to completely eliminating the need for genetic modification in reprogramming.",2011,"J. Efe,Sheng Ding","Biology,Medicine",71,97
10543823,New Approaches in the Differentiation of Human Embryonic Stem Cells and Induced Pluripotent Stem Cells toward Hepatocytes,,2011,"Iman Saramipoor Behbahan,Yuyou Duan,Alexander Lam,Shiva Khoobyari,Xiaocui Ma,Tijess P. Ahuja,M. Zern","Medicine,Biology",77,116
27723552,Cardiac induction of embryonic stem cells by a small molecule inhibitor of Wnt/β-catenin signaling.,"In vitro differentiation of embryonic stem cells is tightly regulated by the same key signaling pathways that control pattern formation during embryogenesis. Small molecules that selectively target these developmental pathways, including Wnt, and BMP signaling may be valuable for directing differentiation of pluripotent stem cells toward many desired tissue types, but to date only few such compounds have been shown to promote cardiac differentiation. Here, we show that XAV939, a recently discovered small molecule inhibitor of Wnt/β-catenin signaling, can robustly induce cardiomyogenesis in mouse ES cells. Our results suggest that a timely administration of XAV939 immediately following the formation of mesoderm progenitor cells promotes cardiomyogenic development at the expense of other mesoderm derived lineages, including the endothelial, smooth muscle, and hematopoietic lineages. Given the critical role that Wnt/β-catenin signaling plays in many aspects of embryogenesis and tissue regeneration, XAV939 is a valuable chemical probe to dissect in vitro differentiation of stem cells and to explore their regenerative potential in a variety of contexts.",2011,"Hanmin Wang,J. Hao,C. Hong","Biology,Medicine",124,21
7915564,Small molecule GSK-3 inhibitors increase neurogenesis of human neural progenitor cells,,2011,"Christian Lange,E. Mix,J. Frahm,Ä. Glass,Jana Müller,O. Schmitt,Anne-Caroline Schmöle,K. Klemm,S. Ortinau,R. Hübner,M. Frech,A. Wree,A. Rolfs","Biology,Medicine",99,28
5524686,Chemical control of stem cell fate and developmental potential.,"Potential applications of stem cells in medicine range from their inclusion in disease modeling and drug discovery to cell transplantation and regenerative therapies. However, before this promise can be realized several obstacles must be overcome, including the control of stem cell differentiation, allogeneic rejection and limited cell availability. This will require an improved understanding of the mechanisms that govern stem cell potential and the development of robust methods to efficiently control their fate. Recently, a number of small molecules have been identified that can be used both in vitro and in vivo as tools to expand stem cells, direct their differentiation, or reprogram somatic cells to a more naive state. These molecules have provided a wealth of insights into the signaling and epigenetic mechanisms that regulate stem cell biology, and are already beginning to contribute to the development of effective treatments for tissue repair and regeneration.",2011,"C. Lyssiotis,L. Lairson,Anthony E. Boitano,H. Wurdak,Shoutian Zhu,P. Schultz","Biology,Chemistry,Medicine",132,391
4371895,Directed differentiation of human pluripotent stem cells into intestinal tissue in vitro,,2010,"J. Spence,C. Mayhew,S. Rankin,Matthew F. Kuhar,Jefferson E. Vallance,Kathryn Tolle,Elizabeth E. Hoskins,V. Kalinichenko,S. Wells,A. Zorn,N. Shroyer,J. Wells","Medicine,Biology",1558,43
3909044,High‐Efficiency Induction of Neural Conversion in Human ESCs and Human Induced Pluripotent Stem Cells with a Single Chemical Inhibitor of Transforming Growth Factor Beta Superfamily Receptors,"Chemical compounds have emerged as powerful tools for modulating ESC functions and deriving induced pluripotent stem cells (iPSCs), but documentation of compound‐induced efficient directed differentiation in human ESCs (hESCs) and human iPSC (hiPSCs) is limited. By screening a collection of chemical compounds, we identified compound C (also denoted as dorsomorphin), a protein kinase inhibitor, as a potent regulator of hESC and hiPSC fate decisions. Compound C suppresses mesoderm, endoderm, and trophoectoderm differentiation and induces rapid and high‐efficiency neural conversion in both hESCs and hiPSCs, 88.7% and 70.4%, respectively. Interestingly, compound C is ineffective in inducing neural conversion in mouse ESCs (mESCs). Large‐scale kinase assay revealed that compound C targets at least seven transforming growth factor beta (TGF‐β) superfamily receptors, including both type I and type II receptors, and thereby blocks both the Activin and bone morphogenesis protein (BMP) signaling pathways in hESCs. Dual inhibition of Activin and BMP signaling accounts for the effects of compound C on hESC differentiation and neural conversion. We also identified muscle segment homeobox gene 2 (MSX2) as a downstream target gene of compound C and a key signaling intermediate of the BMP pathway in hESCs. Our findings provide a single‐step cost‐effective method for efficient derivation of neural progenitor cells in adherent culture from human pluripotent stem cells. Therefore, it will be uniquely suitable for the production of neural progenitor cells in large scale and should facilitate the use of stem cells in drug screening and regenerative medicine and study of early human neural development. STEM CELLS 2010;28:1741–1750",2010,"Jiaxi Zhou,Pei Su,Dong Li,Stephanie Tsang,E. Duan,Fei Wang","Medicine,Biology",173,40
198336185,"Theory of graph traversal edit distance, extensions, and applications",,2019,A. Boroojeny,Computer Science,2,0
4995769,GTED: Graph Traversal Edit Distance,,2018,"A. Boroojeny,Akash Shrestha,A. Sharifi-Zarchi,S. Gallagher,S. C. Sahinalp,H. Chitsaz",Computer Science,3,31
11276629,The Multiscale Laplacian Graph Kernel,"Many real world graphs, such as the graphs of molecules, exhibit structure at multiple different scales, but most existing kernels between graphs are either purely local or purely global in character. In contrast, by building a hierarchy of nested subgraphs, the Multiscale Laplacian Graph kernels (MLG kernels) that we define in this paper can account for structure at a range of different scales. At the heart of the MLG construction is another new graph kernel, called the Feature Space Laplacian Graph kernel (FLG kernel), which has the property that it can lift a base kernel defined on the vertices of two graphs to a kernel between the graphs. The MLG kernel applies such FLG kernels to subgraphs recursively. To make the MLG kernel computationally feasible, we also introduce a randomized projection procedure, similar to the Nystro m method, but for RKHS operators.",2016,"R. Kondor,Horace Pan","Mathematics,Computer Science",158,32
14487732,Propagation kernels: efficient graph kernels from propagated information,,2014,"Marion Neumann,R. Garnett,C. Bauckhage,K. Kersting","Mathematics,Computer Science",204,48
14923087,Efficient Synergistic Single-Cell Genome Assembly,"As the vast majority of all microbes are unculturable, single-cell sequencing has become a significant method to gain insight into microbial physiology. Single-cell sequencing methods, currently powered by multiple displacement genome amplification (MDA), have passed important milestones such as finishing and closing the genome of a prokaryote. However, the quality and reliability of genome assemblies from single cells are still unsatisfactory due to uneven coverage depth and the absence of scattered chunks of the genome in the final collection of reads caused by MDA bias. In this work, our new algorithm Hybrid De novo Assembler (HyDA) demonstrates the power of co-assembly of multiple single-cell genomic data sets through significant improvement of the assembly quality in terms of predicted functional elements and length statistics. Co-assemblies contain significantly more base pairs and protein coding genes, cover more subsystems, and consist of longer contigs compared to individual assemblies by the same algorithm as well as state-of-the-art single-cell assemblers SPAdes and IDBA-UD. Hybrid De novo Assembler (HyDA) is also able to avoid chimeric assemblies by detecting and separating shared and exclusive pieces of sequence for input data sets. By replacing one deep single-cell sequencing experiment with a few single-cell sequencing experiments of lower depth, the co-assembly method can hedge against the risk of failure and loss of the sample, without significantly increasing sequencing cost. Application of the single-cell coassembler HyDA to the study of three uncultured members of an alkane-degrading methanogenic community validated the usefulness of the co-assembly concept.",2014,"Narjes S. Movahedi,M. Embree,Harish Nagarajan,K. Zengler,H. Chitsaz","Biology,Medicine,Computer Science",4,48
218641537,Scalable kernels for graphs with continuous attributes,"While graphs with continuous node attributes arise in many applications, state-of-the-art graph kernels for comparing continuous-attributed graphs suffer from a high runtime complexity. For instance, the popular shortest path kernel scales as O(n4), where n is the number of nodes. In this paper, we present a class of graph kernels with computational complexity O(n2(m + log n + δ2 + d)), where δ is the graph diameter, m is the number of edges, and d is the dimension of the node attributes. Due to the sparsity and small diameter of real-world graphs, these kernels typically scale comfortably to large graphs. In our experiments, the presented kernels outperform state-of-the-art kernels in terms of speed and accuracy on classification benchmark datasets.",2013,"Aasa Feragen,Niklas Kasenburg,Jens Petersen,Marleen de Bruijne,K. Borgwardt","Computer Science,Mathematics",154,28
3027352,Distilled single-cell genome sequencing and de novo assembly for sparse microbial communities,"MOTIVATION
Identification of every single genome present in a microbial sample is an important and challenging task with crucial applications. It is challenging because there are typically millions of cells in a microbial sample, the vast majority of which elude cultivation. The most accurate method to date is exhaustive single-cell sequencing using multiple displacement amplification, which is simply intractable for a large number of cells. However, there is hope for breaking this barrier, as the number of different cell types with distinct genome sequences is usually much smaller than the number of cells.


RESULTS
Here, we present a novel divide and conquer method to sequence and de novo assemble all distinct genomes present in a microbial sample with a sequencing cost and computational complexity proportional to the number of genome types, rather than the number of cells. The method is implemented in a tool called Squeezambler. We evaluated Squeezambler on simulated data. The proposed divide and conquer method successfully reduces the cost of sequencing in comparison with the naïve exhaustive approach.


AVAILABILITY
Squeezambler and datasets are available at http://compbio.cs.wayne.edu/software/squeezambler/.",2013,"Zeinab Taghavi,Narjes S. Movahedi,S. Drăghici,H. Chitsaz","Biology,Computer Science,Medicine",9,37
18414126,De novo co-assembly of bacterial genomes from multiple single cells,"Recent progress in DNA amplification techniques, particularly multiple displacement amplification (MDA), has made it possible to sequence and assemble bacterial genomes from a single cell. However, the quality of single cell genome assembly has not yet reached the quality of normal multiceli genome assembly due to the coverage bias and errors caused by MDA. Using a template of more than one cell for MDA or combining separate MDA products has been shown to improve the result of genome assembly from few single cells, but providing identical single cells, as a necessary step for these approaches, is a challenge. As a solution to this problem, we give an algorithm for de novo co-assembly of bacterial genomes from multiple single cells. Our novel method not only detects the outlier cells in a pool, it also identifies and eliminates their genomic sequences from the final assembly. Our proposed co-assembly algorithm is based on colored de Bruijn graph which has been recently proposed for de novo structural variation detection. Our results show that de novo co-assembly of bacterial genomes from multiple single cells outperforms single cell assembly of each individual one in all standard metrics. Moreover, co-assembly outperforms mixed assembly in which the input datasets are simply concatenated. We implemented our algorithm in a software tool called HyDA which is available from http://compbio.cs.wayne.edu/software/hyda.",2012,"Narjes S. Movahedi,Elmira Forouzmand,H. Chitsaz","Computer Science,Biology",28,38
1313840,SEQuel: improving the accuracy of genome assemblies,"Motivation: Assemblies of next-generation sequencing (NGS) data, although accurate, still contain a substantial number of errors that need to be corrected after the assembly process. We develop SEQuel, a tool that corrects errors (i.e. insertions, deletions and substitution errors) in the assembled contigs. Fundamental to the algorithm behind SEQuel is the positional de Bruijn graph, a graph structure that models k-mers within reads while incorporating the approximate positions of reads into the model. Results: SEQuel reduced the number of small insertions and deletions in the assemblies of standard multi-cell Escherichia coli data by almost half, and corrected between 30% and 94% of the substitution errors. Further, we show SEQuel is imperative to improving single-cell assembly, which is inherently more challenging due to higher error rates and non-uniform coverage; over half of the small indels, and substitution errors in the single-cell assemblies were corrected. We apply SEQuel to the recently assembled Deltaproteobacterium SAR324 genome, which is the first bacterial genome with a comprehensive single-cell genome assembly, and make over 800 changes (insertions, deletions and substitutions) to refine this assembly. Availability: SEQuel can be used as a post-processing step in combination with any NGS assembler and is freely available at http://bix.ucsd.edu/SEQuel/. Contact: ppevzner@cs.ucsd.edu",2012,"R. Ronen,C. Boucher,H. Chitsaz,P. Pevzner","Biology,Computer Science,Medicine",59,40
3168183,P3BSseq: parallel processing pipeline software for automatic analysis of bisulfite sequencing data,"Motivation: Bisulfite sequencing (BSseq) processing is among the most cumbersome next generation sequencing (NGS) applications. Though some BSseq processing tools are available, they are scattered, require puzzling parameters and are running‐time and memory‐usage demanding. Results: We developed P3BSseq, a parallel processing pipeline for fast, accurate and automatic analysis of BSseq reads that trims, aligns, annotates, records the intermediate results, performs bisulfite conversion quality assessment, generates BED methylome and report files following the NIH standards. P3BSseq outperforms the known BSseq mappers regarding running time, computer hardware requirements (processing power and memory use) and is optimized to process the upcoming, extended BSseq reads. We optimized the P3BSseq parameters for directional and non‐directional libraries, and for single‐end and paired‐end reads of Whole Genome and Reduced Representation BSseq. P3BSseq is a user‐friendly streamlined solution for BSseq upstream analysis, requiring only basic computer and NGS knowledge. Availability and Implementation: P3BSseq binaries and documentation are available at: http://sourceforge.net/p/p3bsseq/wiki/Home/ Contact: mararabra@yahoo.co.uk Supplementary information: Supplementary data are available at Bioinformatics online.",2016,"Phuc-Loi Luu,Daniela Gerovska,Mikel Arrospide-Elgarresta,Sugoi Retegi-Carrión,H. Schöler,M. Araúzo-Bravo","Computer Science,Medicine",14,24
14721199,An Epigenetic Regulator: Methyl-CpG-Binding Domain Protein 1 (MBD1),"DNA methylation is an important form of epigenetic regulation in both normal development and cancer. Methyl-CpG-binding domain protein 1 (MBD1) is highly related to DNA methylation. Its MBD domain recognizes and binds to methylated CpGs. This binding allows it to trigger methylation of H3K9 and results in transcriptional repression. The CXXC3 domain of MBD1 makes it a unique member of the MBD family due to its affinity to unmethylated DNA. MBD1 acts as an epigenetic regulator via different mechanisms, such as the formation of the MCAF1/MBD1/SETDB1 complex or the MBD1-HDAC3 complex. As methylation status always changes along with carcinogenesis or neurogenesis, MBD1 with its interacting partners, including proteins and non-coding RNAs, participates in normal or pathological processes and functions in different regulatory systems. Because of the important role of MBD1 in epigenetic regulation, it is a good candidate as a therapeutic target for diseases.",2015,"Lu Li,Bi-Feng Chen,W. Chan","Biology,Medicine",35,82
4921882,Zic2 is an enhancer-binding factor required for embryonic stem cell specification,,2015,"Zhuojuan Luo,Xin Gao,Chengqi Lin,Edwin R. Smith,Stacy A. Marshall,Selene K Swanson,L. Florens,M. Washburn,A. Shilatifard","Biology,Medicine",88,62
7740686,The selection and function of cell type-specific enhancers,,2015,"S. Heinz,C. Romanoski,C. Benner,C. Glass","Biology,Medicine",803,143
16986739,Gateways to the FANTOM5 promoter level mammalian expression atlas,,2015,"M. Lizio,J. Harshbarger,H. Shimoji,J. Severin,T. Kasukawa,S. Şahin,I. Abugessaisa,S. Fukuda,Fumi Hori,Sachi Ishikawa-Kato,C. Mungall,E. Arner,J. Baillie,N. Bertin,H. Bono,Michiel J. L. de Hoon,A. Diehl,Emmanuel Dimont,T. Freeman,Kaori Fujieda,Winston A Hide,R. Kaliyaperumal,Toshiaki Katayama,T. Lassmann,T. Meehan,Koro Nishikata,Hiromasa ONO,M. Rehli,A. Sandelin,E. Schultes,P. ’. ’t Hoen,Zuotian Tatum,Mark Thompson,Tetsuro Toyoda,Derek W. Wright,C. Daub,M. Itoh,Piero Carninci,Y. Hayashizaki,A. Forrest,H. Kawaji","Biology,Medicine",668,78
17442073,KDM5B focuses H3K4 methylation near promoters and enhancers during embryonic stem cell self-renewal and differentiation,,2014,"Benjamin L. Kidder,Gangqing Hu,K. Zhao","Biology,Medicine",113,64
15131305,"MBD3 Localizes at Promoters, Gene Bodies and Enhancers of Active Genes","The Mi-2/nucleosome remodeling and histone deacetylase (NuRD) complex is a multiprotein machine proposed to regulate chromatin structure by nucleosome remodeling and histone deacetylation activities. Recent reports describing localization of NuRD provide new insights that question previous models on NuRD action, but are not in complete agreement. Here, we provide location analysis of endogenous MBD3, a component of NuRD complex, in two human breast cancer cell lines (MCF-7 and MDA-MB-231) using two independent genomic techniques: DNA adenine methyltransferase identification (DamID) and ChIP-seq. We observed concordance of the resulting genomic localization, suggesting that these studies are converging on a robust map for NuRD in the cancer cell genome. MBD3 preferentially associated with CpG rich promoters marked by H3K4me3 and showed cell-type specific localization across gene bodies, peaking around the transcription start site. A subset of sites bound by MBD3 was enriched in H3K27ac and was in physical proximity to promoters in three-dimensional space, suggesting function as enhancers. MBD3 enrichment was also noted at promoters modified by H3K27me3. Functional analysis of chromatin indicated that MBD3 regulates nucleosome occupancy near promoters and in gene bodies. These data suggest that MBD3, and by extension the NuRD complex, may have multiple roles in fine tuning expression for both active and silent genes, representing an important step in defining regulatory mechanisms by which NuRD complex controls chromatin structure and modification status.",2013,"T. Shimbo,Ying Du,Sara A. Grimm,Archana Dhasarathy,D. Mav,Ruchir R. Shah,Huidong Shi,P. Wade","Biology,Medicine",105,55
206233977,"Disclosing the crosstalk among DNA methylation, transcription factors, and histone marks in human pluripotent cells through discovery of DNA methylation motifs","Gene expression regulation is gated by promoter methylation states modulating transcription factor binding. The known DNA methylation/unmethylation mechanisms are sequence unspecific, but different cells with the same genome have different methylomes. Thus, additional processes bringing specificity to the methylation/unmethylation mechanisms are required. Searching for such processes, we demonstrated that CpG methylation states are influenced by the sequence context surrounding the CpGs. We used such a property to develop a CpG methylation motif discovery algorithm. The newly discovered motifs reveal “methylation/unmethylation factors” that could recruit the “methylation/unmethylation machinery” to the loci specified by the motifs. Our methylation motif discovery algorithm provides a synergistic approach to the differently methylated region algorithms. Since our algorithm searches for commonly methylated regions inside the same sample, it requires only a single sample to operate. The motifs that were found discriminate between hypomethylated and hypermethylated regions. The hypomethylation-associated motifs have a high CG content, their targets appear in conserved regions near transcription start sites, they tend to co-occur within transcription factor binding sites, they are involved in breaking the H3K4me3/H3K27me3 bivalent balance, and they transit the enhancers from repressive H3K27me3 to active H3K27ac during ES cell differentiation. The new methylation motifs characterize the pluripotent state shared between ES and iPS cells. Additionally, we found a collection of motifs associated with the somatic memory inherited by the iPS from the initial fibroblast cells, thus revealing the existence of epigenetic somatic memory on a fine methylation scale.",2013,"Phuc-Loi Luu,H. Schöler,M. Araúzo-Bravo","Medicine,Biology",32,59
4453001,Uhrf1-dependent H3K23 ubiquitylation couples maintenance DNA methylation and replication,,2013,"A. Nishiyama,Luna Yamaguchi,J. Sharif,Yoshikazu Johmura,T. Kawamura,Keiko Nakanishi,Shintaro Shimamura,K. Arita,T. Kodama,F. Ishikawa,H. Koseki,M. Nakanishi","Biology,Medicine",303,37
206502796,Differential insulin and steroidogenic signaling in insulin resistant and non-insulin resistant human luteinized granulosa cells—A study in PCOS patients,,2018,"Muskaan Belani,Abhilash Deo,Preeti B Shah,M. Banker,P. Singal,Sarita Gupta","Medicine,Chemistry",38,52
15865989,Role of Versican and ADAMTS-1 in Polycystic Ovary Syndrome,"Objective: ADAMTS-1 is a matrix metalloproteinase which cleaves versican in the cumulus oocyte complex under the effect of luteinizing hormone surge in the periovulatory period. Altered levels may have a role in the pathogenesis of polycystic ovary syndrome (PCOS). We aimed to determine the serum versican and ADAMTS-1 (a disintegrin and metalloproteinase with thrombospondin motif-1) levels in PCOS patients and compare the results with healthy controls. Methods: Thirty-eight patients with PCOS and forty healthy controls aged between 15 and 22 years were included in the study. They were sampled according to their basal hormone, serum versican, and ADAMTS-1 levels. Serum versican and ADAMTS-1 levels were measured by enzyme-linked immunosorbent assay. A multivariate logistic regression model was used to identify the independent risk factors of PCOS. Results: Serum versican levels were significantly decreased in the PCOS group when compared with the controls. The best versican cut-off value for PCOS was calculated to be 33.65 with 76.74% sensitivity and 52.94% specificity. Serum versican levels, homeostasis model assessment of insulin resistance index, a Ferriman-Gallwey score higher than 8, and oligomenorrhea were the strongest predictors of PCOS. Serum versican levels were significantly decreased in PCOS patients. Besides, serum ADAMTS-1 and versican levels were significantly and positively correlated with each other. Conclusion: Serum versican levels were significantly decreased in patients with PCOS. This suggests a possible role of versican in ovulatory dysfunction and in the pathogenesis of PCOS.",2017,"S. Özler,E. Öztaş,A. Tokmak,M. Ergin,Meryem Kuru Pekcan,Başak Gümüş Güler,H. Yakut,N. Yılmaz",Medicine,10,29
17606294,"Single-cell analysis of differences in transcriptomic profiles of oocytes and cumulus cells at GV, MI, MII stages from PCOS patients",,2016,"Qiwei Liu,Yu-mei Li,Yun Feng,Chaojie Liu,Jieliang Ma,Yifei Li,Hui-fen Xiang,Yazhong Ji,Yunxia Cao,X. Tong,Zhigang Xue",Medicine,51,83
21201292,Identification of Maturation-Specific Proteins by Single-Cell Proteomics of Human Oocytes,"Oocytes undergo a range of complex processes via oogenesis, maturation, fertilization, and early embryonic development, eventually giving rise to a fully functioning organism. To understand proteome composition and diversity during maturation of human oocytes, here we have addressed crucial aspects of oocyte collection and proteome analysis, resulting in the first proteome and secretome maps of human oocytes. Starting from 100 oocytes collected via a novel serum-free hanging drop culture system, we identified 2,154 proteins, whose function indicate that oocytes are largely resting cells with a proteome that is tailored for homeostasis, cellular attachment, and interaction with its environment via secretory factors. In addition, we have identified 158 oocyte-enriched proteins (such as ECAT1, PIWIL3, NLRP7)1 not observed in high-coverage proteomics studies of other human cell lines or tissues. Exploiting SP3, a novel technology for proteomic sample preparation using magnetic beads, we scaled down proteome analysis to single cells. Despite the low protein content of only ∼100 ng per cell, we consistently identified ∼450 proteins from individual oocytes. When comparing individual oocytes at the germinal vesicle (GV) and metaphase II (MII) stage, we found that the Tudor and KH domain-containing protein (TDRKH) is preferentially expressed in immature oocytes, while Wee2, PCNA, and DNMT1 were enriched in mature cells, collectively indicating that maintenance of genome integrity is crucial during oocyte maturation. This study demonstrates that an innovative proteomics workflow facilitates analysis of single human oocytes to investigate human oocyte biology and preimplantation development. The approach presented here paves the way for quantitative proteomics in other quantity-limited tissues and cell types. Data associated with this study are available via ProteomeXchange with identifier PXD004142.",2016,"I. Virant-Klun,S. Leicht,Christopher S. Hughes,J. Krijgsveld","Biology,Medicine",139,60
11921173,Functional microarray analysis of differentially expressed genes in granulosa cells from women with polycystic ovary syndrome related to MAPK/ERK signaling,,2015,"Chen‐Wei Lan,Mei-Jou Chen,K. Tai,Danny Cw Yu,Yu-Chieh Yang,Pey-shynan Jan,Yu‐Shih Yang,Hsin‐Fu Chen,H. Ho","Biology,Medicine",53,54
21978086,Oocyte glycoproteins regulate the form and function of the follicle basal lamina and theca cells.,,2015,"Alice P. Christensen,Saloni Patel,P. Grasa,H. Christian,S. Williams","Biology,Medicine",14,64
45136123,ECM1 promotes the Warburg effect through EGF-mediated activation of PKM2.,,2015,"Kyung-min Lee,K. Nam,Sunhwa Oh,Juyeon Lim,Taehoon G. Lee,I. Shin","Biology,Medicine",34,34
8219351,Development of the follicular basement membrane during human gametogenesis and early folliculogenesis,,2015,"A. Heeren,L. van Iperen,Daniëlle B Klootwijk,A. de Melo Bernardo,M. Roost,Maria M. Gomes Fernandes,L. Louwé,C. Hilders,F. Helmerhorst,L. V. D. van der Westerlaken,S. M. Chuva de Sousa Lopes","Biology,Medicine",69,36
215779704,The transcriptome of corona radiata cells from individual MІІ oocytes that after ICSI developed to embryos selected for transfer: PCOS women compared to healthy women,,2014,"M. L. Wissing,S. B. Sonne,D. Westergaard,Kho do Nguyen,Kirstine Belling,T. Høst,A. Mikkelsen","Biology,Medicine",14,48
8938496,"Associations Between Insulin Resistance, Free Fatty Acids, and Oocyte Quality in Polycystic Ovary Syndrome During In Vitro Fertilization","Context: Both polycystic ovary syndrome (PCOS) and obesity are associated with specific reproductive health complications, including lower oocyte quality and clinical pregnancy rates in assisted conception cycles, which may be a result of metabolism-induced changes in the oocyte through the microenvironment of follicular fluid. Free fatty acids (FFAs) are important biomedical indicators of abnormal lipid metabolism and have pronounced effects on cells, leading to changes in metabolism, cell growth, and differentiation Objective: Our objective was to determine the effect of FFA metabolism in plasma and follicular fluid on oocyte quality in the women with PCOS undergoing in vitro fertilization. Design and Setting: Ninety-three women undergoing in vitro fertilization treatment, including 55 with PCOS and 38 age-matched controls, were recruited. PCOS patients were divided into obese and nonobese subgroups on the basis of their body mass index. Main Outcome Measures: Embryo quality was morphologically assessed, and serum sex hormone and insulin levels were measured. FFAs in plasma and follicular fluid were measured using gas chromatography-mass spectrometry. Results: PCOS was found to be associated with significantly higher LH/FSH, total T, free androgen index (FAI), and lower SHBG levels, independent of obesity(P < .05). Obese women with PCOS had a significantly higher total T level, FAI, fasting insulin, insulin resistance index as determined by homeostasis model assessment for insulin resistance, and lower SHBG levels than the nonobese women with PCOS (P < .05). The embryo fragmentation score was significantly positively correlated with the oleic acid concentration in all PCOS patients (r = 0.22, P = .04, for nonobese patients and r = 0.25, P = .03, for obese patients). Conclusions: Our findings clearly demonstrated that PCOS is associated with significantly higher FAI and insulin resistance levels and decreased plasma SHBG levels, independent of body mass index. Obese PCOS patients had higher palmitoleic acid and oleic acid levels in both the plasma and follicular fluid than did the control subject and nonobese PCOS patients. Our results indicated that developmental competence is associated with oleic and stearic acid concentrations, which may contribute to the poor pregnancy outcomes in patients with PCOS.",2014,"Zhihong Niu,Nanhe Lin,Ruihuan Gu,Yijuan Sun,Yun Feng","Biology,Medicine",94,49
227501121,"World Alzheimer Report 2019: Attitudes to dementia, a global survey","In 2019 Alzheimer’s Disease International (ADI) undertook the biggest global survey on attitudes to dementia, with 70,000 people across 54 countries participating. Alongside expert essays, case studies and programmes to tackle stigma, the survey results formed the core of the 2019 World Alzheimer Report",2020,Christy Lynch,Psychology,241,0
226343760,Linguistic markers predict onset of Alzheimer's disease,,2020,"Elif Eyigoz,Sachin Mathur,Mar Santamaria,G. Cecchi,M. Naylor",Medicine,87,43
202753304,Automatic Hierarchical Attention Neural Network for Detecting AD,",",2019,"Yilin Pan,B. Mirheidari,M. Reuber,A. Venneri,D. Blackburn,H. Christensen",Computer Science,28,28
195069387,XLNet: Generalized Autoregressive Pretraining for Language Understanding,"With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling. However, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy. In light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation. Furthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining. Empirically, under comparable experiment settings, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking.",2019,"Zhilin Yang,Zihang Dai,Yiming Yang,J. Carbonell,R. Salakhutdinov,Quoc V. Le",Computer Science,6814,47
174800445,Multilingual prediction of Alzheimer’s disease through domain adaptation and concept-based language modelling,"There is growing evidence that changes in speech and language may be early markers of dementia, but much of the previous NLP work in this area has been limited by the size of the available datasets. Here, we compare several methods of domain adaptation to augment a small French dataset of picture descriptions (n = 57) with a much larger English dataset (n = 550), for the task of automatically distinguishing participants with dementia from controls. The first challenge is to identify a set of features that transfer across languages; in addition to previously used features based on information units, we introduce a new set of features to model the order in which information units are produced by dementia patients and controls. These concept-based language model features improve classification performance in both English and French separately, and the best result (AUC = 0.89) is achieved using the multilingual training set with a combination of information and language model features.",2019,"Kathleen C. Fraser,N. Linz,Bai Li,K. L. Fors,Frank Rudzicz,A. König,J. Alexandersson,P. Robert,D. Kokkinakis",Computer Science,13,55
84833325,Automatic Diagnosis of Alzheimer’s Disease Using Neural Network Language Models,"In today’s aging society, the number of neurodegenerative diseases such as Alzheimer’s disease (AD) increases. Reliable tools for automatic early screening as well as monitoring of AD patients are necessary. For that, semantic deficits have been shown to be useful indicators. We present a way to significantly improve the method introduced by Wankerl et al. [1]. The purely statistical approach of n-gram language models (LMs) is enhanced by using the rwthlm toolkit to create neural network language models (NNLMs) with Long Short Term-Memory (LSTM) cells. The prediction is solely based on evaluating the perplexity of transliterations of descriptions of the Cookie Theft picture from DementiaBank’s Pitt Corpus. Each transliteration is evaluated on LMs of both control and Alzheimer speakers in a leave-one-speaker-out cross-validation scheme. The resulting perplexity values reveal enough discrepancy to classify patients on just those two values with an accuracy of 85.6% at equal-error-rate.",2019,"J. Fritsch,Sebastian Wankerl,E. Nöth",Computer Science,48,18
67856188,Detecting dementia in Mandarin Chinese using transfer learning from a parallel corpus,"Machine learning has shown promise for automatic detection of Alzheimer’s disease (AD) through speech; however, efforts are hampered by a scarcity of data, especially in languages other than English. We propose a method to learn a correspondence between independently engineered lexicosyntactic features in two languages, using a large parallel corpus of out-of-domain movie dialogue data. We apply it to dementia detection in Mandarin Chinese, and demonstrate that our method outperforms both unilingual and machine translation-based baselines. This appears to be the first study that transfers feature domains in detecting cognitive decline.",2019,"Bai Li,Y. Hsu,Frank Rudzicz","Medicine,Computer Science",10,23
58981712,Cross-lingual Language Model Pretraining,"Recent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models (XLMs): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On XNLI, our approach pushes the state of the art by an absolute gain of 4.9% accuracy. On unsupervised machine translation, we obtain 34.3 BLEU on WMT’16 German-English, improving the previous state of the art by more than 9 BLEU. On supervised machine translation, we obtain a new state of the art of 38.5 BLEU on WMT’16 Romanian-English, outperforming the previous best approach by more than 4 BLEU. Our code and pretrained models will be made publicly available.",2019,"Guillaume Lample,Alexis Conneau",Computer Science,2274,52
57759363,Transformer-XL: Attentive Language Models beyond a Fixed-Length Context,"Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-XL that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-XL learns dependency that is 80% longer than RNNs and 450% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on WikiText-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on WikiText-103, Transformer-XL manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and PyTorch.",2019,"Zihang Dai,Zhilin Yang,Yiming Yang,J. Carbonell,Quoc V. Le,R. Salakhutdinov","Computer Science,Mathematics",2931,71
56482333,Conditional BERT Contextual Augmentation,,2018,"Xing Wu,Shangwen Lv,Liangjun Zang,Jizhong Han,Songlin Hu",Computer Science,242,42
209393462,Overview of the HASOC track at FIRE 2020: Hate Speech and Offensive Content Identification in Indo-European Languages,"With the growth of social media, the spread of hate speech is also increasing rapidly. Social media are widely used in many countries. Also Hate Speech is spreading in these countries. This brings a need for multilingual Hate Speech detection algorithms. Much research in this area is dedicated to English at the moment. The HASOC track intends to provide a platform to develop and optimize Hate Speech detection algorithms for Hindi, German and English. The dataset is collected from a Twitter archive and pre-classified by a machine learning system. HASOC has two sub-task for all three languages: task A is a binary classification problem (Hate and Not Offensive) while task B is a fine-grained classification problem for three classes (HATE) Hate speech, OFFENSIVE and PROFANITY. Overall, 252 runs were submitted by 40 teams. The performance of the best classification algorithms for task A are F1 measures of 0.51, 0.53 and 0.52 for English, Hindi, and German, respectively. For task B, the best classification algorithms achieved F1 measures of 0.26, 0.33 and 0.29 for English, Hindi, and German, respectively. This article presents the tasks and the data development as well as the results. The best performing algorithms were mainly variants of the transformer architecture BERT. However, also other systems were applied with good success",2021,"Thomas Mandl,Sandip J Modha,Prasenjit Majumder,Daksh Patel,Mohana Dave,Chintak Mandalia,Aditya Patel",Computer Science,289,48
211043589,LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation,"Graph Convolution Network (GCN) has become new state-of-the-art for collaborative filtering. Nevertheless, the reasons of its effectiveness for recommendation are not well understood. Existing work that adapts GCN to recommendation lacks thorough ablation analyses on GCN, which is originally designed for graph classification tasks and equipped with many neural network operations. However, we empirically find that the two most common designs in GCNs -- feature transformation and nonlinear activation -- contribute little to the performance of collaborative filtering. Even worse, including them adds to the difficulty of training and degrades recommendation performance. In this work, we aim to simplify the design of GCN to make it more concise and appropriate for recommendation. We propose a new model named LightGCN, including only the most essential component in GCN -- neighborhood aggregation -- for collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings learned at all layers as the final embedding. Such simple, linear, and neat model is much easier to implement and train, exhibiting substantial improvements (about 16.0% relative improvement on average) over Neural Graph Collaborative Filtering (NGCF) -- a state-of-the-art GCN-based recommender model -- under exactly the same experimental setting. Further analyses are provided towards the rationality of the simple LightGCN from both analytical and empirical perspectives.",2020,"Xiangnan He,Kuan Deng,Xiang Wang,Yan Li,Yongdong Zhang,Meng Wang",Computer Science,1904,54
208201975,Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction,"Knowledge graph embedding, which aims to represent entities and relations as low dimensional vectors (or matrices, tensors, etc.), has been shown to be a powerful technique for predicting missing links in knowledge graphs. Existing knowledge graph embedding models mainly focus on modeling relation patterns such as symmetry/antisymmetry, inversion, and composition. However, many existing approaches fail to model semantic hierarchies, which are common in real-world applications. To address this challenge, we propose a novel knowledge graph embedding model—namely, Hierarchy-Aware Knowledge Graph Embedding (HAKE)—which maps entities into the polar coordinate system. HAKE is inspired by the fact that concentric circles in the polar coordinate system can naturally reflect the hierarchy. Specifically, the radial coordinate aims to model entities at different levels of the hierarchy, and entities with smaller radii are expected to be at higher levels; the angular coordinate aims to distinguish entities at the same level of the hierarchy, and these entities are expected to have roughly the same radii but different angles. Experiments demonstrate that HAKE can effectively model the semantic hierarchies in knowledge graphs, and significantly outperforms existing state-of-the-art methods on benchmark datasets for the link prediction task.",2019,"Zhanqiu Zhang,Jianyu Cai,Yongdong Zhang,Jie Wang","Computer Science,Mathematics",254,33
208006241,KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation,"Abstract Pre-trained language representation models (PLMs) cannot well capture factual knowledge from text. In contrast, knowledge embedding (KE) methods can effectively represent the relational facts in knowledge graphs (KGs) with informative entity embeddings, but conventional KE models cannot take full advantage of the abundant textual information. In this paper, we propose a unified model for Knowledge Embedding and Pre-trained LanguagERepresentation (KEPLER), which can not only better integrate factual knowledge into PLMs but also produce effective text-enhanced KE with the strong PLMs. In KEPLER, we encode textual entity descriptions with a PLM as their embeddings, and then jointly optimize the KE and language modeling objectives. Experimental results show that KEPLER achieves state-of-the-art performances on various NLP tasks, and also works remarkably well as an inductive KE model on KG link prediction. Furthermore, for pre-training and evaluating KEPLER, we construct Wikidata5M1 , a large-scale KG dataset with aligned entity descriptions, and benchmark state-of-the-art KE methods on it. It shall serve as a new KE benchmark and facilitate the research on large KG, inductive KE, and KG with text. The source code can be obtained from https://github.com/THU-KEG/KEPLER.",2019,"Xiaozhi Wang,Tianyu Gao,Zhaocheng Zhu,Zhiyuan Liu,Juan-Zi Li,Jian Tang",Computer Science,419,75
208117506,HuggingFace's Transformers: State-of-the-art Natural Language Processing,"Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \url{this https URL}.",2019,"Thomas Wolf,Lysandre Debut,Victor Sanh,Julien Chaumond,Clement Delangue,Anthony Moi,Pierric Cistac,Tim Rault,Rémi Louf,Morgan Funtowicz,Jamie Brew",Computer Science,9840,65
202661068,Enriching BERT with Knowledge Graph Embeddings for Document Classification,"In this paper, we focus on the classification of books using short descriptive texts (cover blurbs) and additional metadata. Building upon BERT, a deep neural language model, we demonstrate how to combine text representations with metadata and knowledge graph embeddings, which encode author information. Compared to the standard BERT approach we achieve considerably better results for the classification task. For a more coarse-grained classification using eight labels we achieve an F1- score of 87.20, while a detailed classification using 343 labels yields an F1-score of 64.70. We make the source code and trained models of our experiments publicly available",2019,"Malte Ostendorff,Peter Bourgonje,Maria Berger,J. Schneider,Georg Rehm,Bela Gipp",Computer Science,68,18
202539519,KG-BERT: BERT for Knowledge Graph Completion,"Knowledge graphs are important resources for many artificial intelligence tasks but often suffer from incompleteness. In this work, we propose to use pre-trained language models for knowledge graph completion. We treat triples in knowledge graphs as textual sequences and propose a novel framework named Knowledge Graph Bidirectional Encoder Representations from Transformer (KG-BERT) to model these triples. Our method takes entity and relation descriptions of a triple as input and computes scoring function of the triple with the KG-BERT language model. Experimental results on multiple benchmark knowledge graphs show that our method can achieve state-of-the-art performance in triple classification, link prediction and relation prediction tasks.",2019,"Liang Yao,Chengsheng Mao,Yuan Luo",Computer Science,359,44
199001173,What BERT Is Not: Lessons from a New Suite of Psycholinguistic Diagnostics for Language Models,"Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction— and, in particular, it shows clear insensitivity to the contextual impacts of negation.",2019,Allyson Ettinger,Computer Science,489,40
189998980,Barack’s Wife Hillary: Using Knowledge Graphs for Fact-Aware Language Modeling,"Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model’s ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.",2019,"IV RobertL.Logan,Nelson F. Liu,Matthew E. Peters,Matt Gardner,Sameer Singh",Computer Science,158,29
205717769,Mechanistic Model‐Informed Proarrhythmic Risk Assessment of Drugs: Review of the “CiPA” Initiative and Design of a Prospective Clinical Validation Study,"The Comprehensive in vitro Proarrhythmia Assay (CiPA) initiative is developing and validating a mechanistic‐based assessment of the proarrhythmic risk of drugs. CiPA proposes to assess a drug's effect on multiple ion channels and integrate the effects in a computer model of the human cardiomyocyte to predict proarrhythmic risk. Unanticipated or missed effects will be assessed with human stem cell‐derived cardiomyocytes and electrocardiogram (ECG) analysis in early phase I clinical trials. This article provides an overview of CiPA and the rationale and design of the CiPA phase I ECG validation clinical trial, which involves assessing an additional ECG biomarker (J‐Tpeak) for QT prolonging drugs. If successful, CiPA will 1) create a pathway for drugs with hERG block / QT prolongation to advance without intensive ECG monitoring in phase III trials if they have low proarrhythmic risk; and 2) enable updating drug labels to be more informative about proarrhythmic risk, not just QT prolongation.",2017,"J. Vicente,R. Zusterzeel,L. Johannesen,J. Mason,P. Sager,Vikram Patel,M. Matta,Zhihua Li,Jiang Liu,C. Garnett,N. Stockbridge,I. Zineh,D. Strauss",Medicine,92,58
3809477,Effects of hawthorn (Crataegus pentagyna) leaf extract on electrophysiologic properties of cardiomyocytes derived from human cardiac arrhythmia‐specific induced pluripotent stem cells,"Cardiac arrhythmias are major life‐threatening conditions. The landmark discovery of induced pluripotent stem cells has provided a promising in vitro system for modeling hereditary cardiac arrhythmias as well as drug development and toxicity testing. Nowadays, nutraceuticals are frequently used as supplements for cardiovascular therapy. Here we studied the cardiac effects of hawthorn (Crataegus pentagyna) leaf extract using cardiomyocytes (CMs) differentiated from healthy human embryonic stem cells, long QT syndrome type 2 (LQTS2), and catecholaminergic polymorphic ventricular tachycardia type 1 (CPVT1) patient‐specific induced pluripotent stem cells. The hydroalcoholic extract resulted in a dose‐dependent negative chronotropic effect in all CM preparations leading to a significant reduction at 1000 μg/ml. This was accompanied by prolongation of field potential durations, although with different magnitudes in CMs from different human embryonic stem cell and iPSC lines. Hawthorn further prolonged field potential durations in LQTS2 CMs but reduced the beating frequencies and occurrence of immature field potentials triggered by β1‐adrenergic stimulation in CPVT1 CMs at 300 and 1000 μg/ml. Furthermore, isoquercetin and vitexin flavonoids significantly slowed down isoproterenol (5 μM)‐induced beating frequencies at 3 and 10 μg/ml. Therefore, C. pentagyna leaf extract and its isoquercetin and vitexin flavonoids may be introduced as a novel nutraceutical with antiarrhythmic potential for CPVT1 patients.—Pahlavan, S., Tousi, M. S., Ayyari, M., Alirezalu, A., Ansari, H., Saric, T., Baharvand, H. Effects of hawthorn (Crataegus pentagyna) leaf extract on electrophysiologic properties of cardiomyocytes derived from human cardiac arrhythmia‐specific induced pluripotent stem cells. FASEB J. 32,1440‐1451 (2018). www.fasebj.org",2017,"S. Pahlavan,M. Tousi,M. Ayyari,A. Alirezalu,H. Ansari,T. Šarić,H. Baharvand","Biology,Medicine",20,66
7649281,Electrocardiographic biomarkers to confirm drug's electrophysiological effects used for proarrhythmic risk prediction under CiPA.,,2017,"J. Vicente,Meisam Hosseini,L. Johannesen,D. Strauss",Medicine,14,19
152602,Nonclinical cardiovascular safety of pitolisant: comparing International Conference on Harmonization S7B and Comprehensive in vitro Pro‐arrhythmia Assay initiative studies,We evaluated the concordance of results from two sets of nonclinical cardiovascular safety studies on pitolisant.,2017,"X. Ligneau,R. Shah,I. Berrebi‐Bertrand,Gary R. Mirams,P. Robert,L. Landais,P. Maison-Blanche,J. Faivre,J. Lecomte,J. Schwartz",Medicine,13,55
6823583,Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias,,2017,"S. Kiranyaz,T. Ince,M. Gabbouj","Computer Science,Medicine",89,23
4906448,CSAHi study‐2: Validation of multi‐electrode array systems (MEA60/2100) for prediction of drug‐induced proarrhythmia using human iPS cell‐derived cardiomyocytes: Assessment of reference compounds and comparison with non‐clinical studies and clinical information,,2017,"Yumiko Nozaki,Y. Honda,Hitoshi Watanabe,Shota Saiki,K. Koyabu,T. Itoh,Chiho Nagasawa,Chiaki Nakamori,Chiaki Nakayama,Hiroshi Iwasaki,Shinobu Suzuki,Kohji Tanaka,Etsushi Takahashi,Kaori Miyamoto,Kaoru Morimura,Atsuhiro Yamanishi,H. Endo,J. Shinozaki,H. Nogawa,T. Shinozawa,Fumiyo Saito,T. Kunimatsu",Medicine,27,70
4244020,The Evolving Roles of Human iPSC-Derived Cardiomyocytes in Drug Safety and Discovery.,,2017,"G. Gintant,B. Fermini,N. Stockbridge,D. Strauss","Biology,Medicine",67,9
5045541,Electrophysiological Analysis of human Pluripotent Stem Cell-derived Cardiomyocytes (hPSC-CMs) Using Multi-electrode Arrays (MEAs),"Cardiomyocytes can now be derived with high efficiency from both human embryonic and human induced-Pluripotent Stem Cells (hPSC). hPSC-derived cardiomyocytes (hPSC-CMs) are increasingly recognized as having great value for modeling cardiovascular diseases in humans, especially arrhythmia syndromes. They have also demonstrated relevance as in vitro systems for predicting drug responses, which makes them potentially useful for drug-screening and discovery, safety pharmacology and perhaps eventually for personalized medicine. This would be facilitated by deriving hPSC-CMs from patients or susceptible individuals as hiPSCs. For all applications, however, precise measurement and analysis of hPSC-CM electrical properties are essential for identifying changes due to cardiac ion channel mutations and/or drugs that target ion channels and can cause sudden cardiac death. Compared with manual patch-clamp, multi-electrode array (MEA) devices offer the advantage of allowing medium- to high-throughput recordings. This protocol describes how to dissociate 2D cell cultures of hPSC-CMs to small aggregates and single cells and plate them on MEAs to record their spontaneous electrical activity as field potential. Methods for analyzing the recorded data to extract specific parameters, such as the QT and the RR intervals, are also described here. Changes in these parameters would be expected in hPSC-CMs carrying mutations responsible for cardiac arrhythmias and following addition of specific drugs, allowing detection of those that carry a cardiotoxic risk.",2017,"L. Sala,D. Ward-van Oostwaard,L. Tertoolen,C. Mummery,M. Bellin",Medicine,36,62
2088679,A survey on deep learning in medical image analysis,,2017,"G. Litjens,Thijs Kooi,B. Bejnordi,A. Setio,F. Ciompi,Mohsen Ghafoorian,J. Laak,B. Ginneken,C. I. Sánchez","Computer Science,Medicine",8608,401
3902629,Interpretation of field potentials measured on a multi electrode array in pharmacological toxicity screening on primary and human pluripotent stem cell-derived cardiomyocytes,,2017,"L. Tertoolen,S. Braam,B. V. Meer,R. Passier,C. Mummery,C. Mummery","Medicine,Chemistry",53,11
5791183,Unsupervised Learning of Discriminative Attributes and Visual Representations,"Attributes offer useful mid-level features to interpret visual data. While most attribute learning methods are supervised by costly human-generated labels, we introduce a simple yet powerful unsupervised approach to learn and predict visual attributes directly from data. Given a large unlabeled image collection as input, we train deep Convolutional Neural Networks (CNNs) to output a set of discriminative, binary attributes often with semantic meanings. Specifically, we first train a CNN coupled with unsupervised discriminative clustering, and then use the cluster membership as a soft supervision to discover shared attributes from the clusters while maximizing their separability. The learned attributes are shown to be capable of encoding rich imagery properties from both natural images and contour patches. The visual representations learned in this way are also transferrable to other tasks such as object detection. We show other convincing results on the related tasks of image retrieval and classification, and contour detection.",2016,"Chen Huang,Chen Change Loy,Xiaoou Tang",Computer Science,93,59
288278,Semi-supervised Zero-Shot Learning by a Clustering-based Approach,"In some of object recognition problems, labeled data may not be available for all categories. Zero-shot learning utilizes auxiliary information (also called signatures) describing each category in order to find a classifier that can recognize samples from categories with no labeled instance. In this paper, we propose a novel semi-supervised zero-shot learning method that works on an embedding space corresponding to abstract deep visual features. We seek a linear transformation on signatures to map them onto the visual features, such that the mapped signatures of the seen classes are close to labeled samples of the corresponding classes and unlabeled data are also close to the mapped signatures of one of the unseen classes. 
We use the idea that the rich deep visual features provide a representation space in which samples of each class are usually condensed in a cluster. The effectiveness of the proposed method is demonstrated through extensive experiments on four public benchmarks improving the state-of-the-art prediction accuracy on three of them.",2016,"Seyed Mohsen Shojaee,M. Baghshah",Computer Science,35,44
15669481,Neighborhood Sensitive Mapping for Zero-Shot Classification using Independently Learned Semantic Embeddings,"In a traditional setting, classifiers are trained to approximate a target function $f:X \rightarrow Y$ where at least a sample for each $y \in Y$ is presented to the training algorithm. In a zero-shot setting we have a subset of the labels $\hat{Y} \subset Y$ for which we do not observe any corresponding training instance. Still, the function $f$ that we train must be able to correctly assign labels also on $\hat{Y}$. In practice, zero-shot problems are very important especially when the label set is large and the cost of editorially label samples for all possible values in the label set might be prohibitively high. Most recent approaches to zero-shot learning are based on finding and exploiting relationships between labels using semantic embeddings. We show in this paper that semantic embeddings, despite being very good at capturing relationships between labels, are not very good at capturing the relationships among labels in a data-dependent manner. For this reason, we propose a novel two-step process for learning a zero-shot classifier. In the first step, we learn what we call a \emph{property embedding space} capturing the ""\emph{learnable}"" features of the label set. Then, we exploit the learned properties in order to reduce the generalization error for a linear nearest neighbor-based classifier.",2016,"Gaurav Singh,F. Silvestri,J. Shawe-Taylor",Computer Science,1,29
13525770,Semi-supervised Vocabulary-Informed Learning,"Despite significant progress in object categorization, in recent years, a number of important challenges remain, mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels. Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa. We propose the notion of semi-supervised vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition using a unified framework. Specifically, we propose a maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms, ensuring that labeled samples are projected closest to their correct prototypes, in the embedding space, than to others. We show that resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.",2016,"Yanwei Fu,L. Sigal","Computer Science,Mathematics",129,53
13897053,Less is More: Zero-Shot Learning from Online Textual Documents with Noise Suppression,"Classifying a visual concept merely from its associated online textual source, such as a Wikipedia article, is an attractive research topic in zero-shot learning because it alleviates the burden of manually collecting semantic attributes. Recent work has pursued this approach by exploring various ways of connecting the visual and text domains. In this paper, we revisit this idea by going further to consider one important factor: the textual representation is usually too noisy for the zero-shot learning application. This observation motivates us to design a simple yet effective zero-shot learning method that is capable of suppressing noise in the text. Specifically, we propose an l2,1-norm based objective function which can simultaneously suppress the noisy signal in the text and learn a function to match the text document and visual features. We also develop an optimization algorithm to efficiently solve the resulting problem. By conducting experiments on two large datasets, we demonstrate that the proposed method significantly outperforms those competing methods which rely on online information sources but with no explicit noise suppression. Furthermore, we make an in-depth analysis of the proposed method and provide insight as to what kind of information in documents is useful for zero-shot learning.",2016,"Ruizhi Qiao,Lingqiao Liu,Chunhua Shen,A. Hengel",Computer Science,174,28
11621384,Multi-cue Zero-Shot Learning with Strong Supervision,"Scaling up visual category recognition to large numbers of classes remains challenging. A promising research direction is zero-shot learning, which does not require any training data to recognize new classes, but rather relies on some form of auxiliary information describing the new classes. Ultimately, this may allow to use textbook knowledge that humans employ to learn about new classes by transferring knowledge from classes they know well. The most successful zero-shot learning approaches currently require a particular type of auxiliary information - namely attribute annotations performed by humans - that is not readily available for most classes. Our goal is to circumvent this bottleneck by substituting such annotations by extracting multiple pieces of information from multiple unstructured text sources readily available on the web. To compensate for the weaker form of auxiliary information, we incorporate stronger supervision in the form of semantic part annotations on the classes from which we transfer knowledge. We achieve our goal by a joint embedding framework that maps multiple text parts as well as multiple semantic parts into a common space. Our results consistently and significantly improve on the state-of-the-art in zero-short recognition and retrieval.",2016,"Zeynep Akata,Mateusz Malinowski,Mario Fritz,B. Schiele",Computer Science,138,55
2004024,Latent Embeddings for Zero-Shot Classification,"We present a novel latent embedding model for learning a compatibility function between image and class embeddings, in the context of zero-shot classification. The proposed method augments the state-of-the-art bilinear compatibility model by incorporating latent variables. Instead of learning a single bilinear map, it learns a collection of maps with the selection, of which map to use, being a latent variable for the current image-class pair. We train the model with a ranking based objective function which penalizes incorrect rankings of the true class for a given image. We empirically demonstrate that our model improves the state-of-the-art for various class embeddings consistently on three challenging publicly available datasets for the zero-shot setting. Moreover, our method leads to visually highly interpretable results with clear clusters of different fine-grained object properties that correspond to different latent variable maps.",2016,"Yongqin Xian,Zeynep Akata,Gaurav Sharma,Quynh N. Nguyen,Matthias Hein,B. Schiele","Computer Science,Mathematics",666,43
1580181,Synthesized Classifiers for Zero-Shot Learning,"Given semantic descriptions of object classes, zero-shot learning aims to accurately recognize objects of the unseen classes, from which no examples are available at the training stage, by associating them to the seen classes, from which labeled examples are provided. We propose to tackle this problem from the perspective of manifold learning. Our main idea is to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. To this end, we introduce a set of ""phantom"" object classes whose coordinates live in both the semantic space and the model space. Serving as bases in a dictionary, they can be optimized from labeled data such that the synthesized real object classifiers achieve optimal discriminative performance. We demonstrate superior accuracy of our approach over the state of the art on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 dataset with more than 20,000 unseen classes.",2016,"Soravit Changpinyo,Wei-Lun Chao,Boqing Gong,Fei Sha",Computer Science,710,55
15942776,Semi-Supervised Zero-Shot Classification with Label Representation Learning,"Given the challenge of gathering labeled training data, zero-shot classification, which transfers information from observed classes to recognize unseen classes, has become increasingly popular in the computer vision community. Most existing zero-shot learning methods require a user to first provide a set of semantic visual attributes for each class as side information before applying a two-step prediction procedure that introduces an intermediate attribute prediction problem. In this paper, we propose a novel zero-shot classification approach that automatically learns label embeddings from the input data in a semi-supervised large-margin learning framework. The proposed framework jointly considers multi-class classification over all classes (observed and unseen) and tackles the target prediction problem directly without introducing intermediate prediction problems. It also has the capacity to incorporate semantic label information from different sources when available. To evaluate the proposed approach, we conduct experiments on standard zero-shot data sets. The empirical results show the proposed approach outperforms existing state-of-the-art zero-shot learning methods.",2015,"X. Li,Yuhong Guo,Dale Schuurmans",Computer Science,115,34
446581,Zero-Shot Learning via Semantic Similarity Embedding,"In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided. The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information (e.g. attributes) for unseen classes. Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class. This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured. We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation. Our test results are compelling, leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition.",2015,"Ziming Zhang,Venkatesh Saligrama","Computer Science,Mathematics",581,49
208138555,SiamCAR: Siamese Fully Convolutional Classification and Regression for Visual Tracking,"By decomposing the visual tracking task into two subproblems as classification for pixel category and regression for object bounding box at this pixel, we propose a novel fully convolutional Siamese network to solve visual tracking end-to-end in a per-pixel manner. The proposed framework SiamCAR consists of two simple subnetworks: one Siamese subnetwork for feature extraction and one classification-regression subnetwork for bounding box prediction. Different from state-of-the-art trackers like Siamese-RPN, SiamRPN++ and SPM, which are based on region proposal, the proposed framework is both proposal and anchor free. Consequently, we are able to avoid the tricky hyper-parameter tuning of anchors and reduce human intervention. The proposed framework is simple, neat and effective. Extensive experiments and comparisons with state-of-the-art trackers are conducted on challenging benchmarks including GOT-10K, LaSOT, UAV123 and OTB-50. Without bells and whistles, our SiamCAR achieves the leading performance with a considerable real-time speed. The code is available at https://github.com/ohhhyeahhh/SiamCAR.",2019,"Dongyan Guo,Jun Wang,Ying Cui,Zhenhua Wang,Shengyong Chen",Computer Science,415,42
207925044,The Seventh Visual Object Tracking VOT2019 Challenge Results,"The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on ""real-time"" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.",2019,"M. Kristan,Jiri Matas,A. Leonardis,M. Felsberg,R. Pflugfelder,Joni-Kristian,Kämäräinen,L. Č. Zajc,O. Drbohlav,A. Lukežič,Amanda Berg,Abdelrahman,Eldesokey,Jani Käpylä,G. Fernandez,Abel Gonzalez-Garcia,Alireza,Memarmoghadam,Andong Lu,Anfeng He,A. Varfolomieiev,Antoni B. Chan,Ardhendu Shekhar,Tripathi,A. Smeulders,Bala Suraj Pedasingu,B. Chen,Baopeng Zhang,Baoyuan Wu,Bi,Li,Bin He,Bin Yan,Bing Bai,Bing Li,Bo Li,B. Kim,Chao Ma,Chen Fang,Chen,Qian,Cheng Chen,Chenglong Li,Chengquan Zhang,Chi-Yi Tsai,Chong Luo,Christian,Micheloni,Chunhui Zhang,D. Tao,Deepak Gupta,Dejia Song,Dong Wang,Efstratios,Gavves,Eunu Yi,F. Khan,Fangyi Zhang,Fei Wang,Fei Zhao,George De,Ath,Goutam Bhat,Guang-Gui Chen,Guangting Wang,Guoxuan Li,Hakan Çevikalp,Hao Du,Haojie,Zhao,Hasan Saribas,Ho Min Jung,Hongliang Bai,Hongyuan Yu,Houwen Peng,Huchuan,Lǔ,Hui Li,Jia-Ke Li,Jianhua Li,Jianlong Fu,Jie Chen,Jie Gao,Jie Zhao,Jin Tang,Jing,Jingjing Wu,Jingtuo Liu,Jinqiao Wang,Jinqing Qi,Jinyue Zhang,John Tsotsos,J. Hyuk,Lee,Joost van de Weijer,J. Kittler,Jun Ha Lee,Junfei Zhuang,Kangkai Zhang,Kangkang,Wang,Kenan Dai,Lei Chen,Lei Liu,Leida Guo,Li Zhang,Liang Wang,Liang Wang,Lichao,Zhang,Lijun Wang,Lijun Zhou,Linyu Zheng,Litu Rout,L. Gool,Luca Bertinetto,Martin,Danelljan,Matteo Dunnhofer,Meng Ni,M. Y. Kim,Ming Tang,Ming-Hsuan Yang,Naveen,Paluru,N. Martinel,Pengfei Xu,Pengfei Zhang,Pengkun Zheng,Pengyu Zhang,S. PhilipH.,Torr,Q. Wang,Qing Guo,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Richard,Everson,Ruize Han,Ruohan Zhang,Shan You,Shaochuan Zhao,Shengwei Zhao,Shihu,Shikun Li,Shiming Ge,Shuai Bai,Shuosen Guan,Tengfei Xing,Tianyang Xu,Tianyu,Yang,Ting Zhang,Tomás Vojír,Wei Feng,Wei Hu,Weizhao Wang,Wenjie Tang,Wenjun,Zeng,Wenyu Liu,Xi Chen,Xi Qiu,Xiang Bai,Xiaojun Wu,Xiaoyun Yang,Xier,Xin Li,Xingyuan Sun,Xingyu Chen,Xinmei Tian,Xuwen Tang,Xuefeng Zhu,Yan-ping Huang,Yanan,Yanchao Lian,Yang Gu,Y. Liu,Yanjie Chen,Yi Zhang,Yinda Xu,Yingming,Yingping Li,Yu Zhou,Yuan Dong,Yufei Xu,Yunhua Zhang,Yunkun Li,Zeyu Zhao,Luo,Zhaoliang Zhang,Zhenhua Feng,Zhenyu He,Zhichao Song,Zhihao Chen,Zhipeng,Zhirong Wu,Zhiwei Xiong,Zhongjian Huang,Zhu Teng,Zihan Ni",Computer Science,366,114
203642130,On the Efficacy of Knowledge Distillation,"In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don’t make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher’s training early. Our results generalize across datasets and models.",2019,"Jang Hyun Cho,B. Hariharan",Computer Science,408,28
207994757,Distillation-Based Training for Multi-Exit Architectures,"Multi-exit architectures, in which a stack of processing layers is interleaved with early output layers, allow the processing of a test example to stop early and thus save computation time and/or energy. In this work, we propose a new training procedure for multi-exit architectures based on the principle of knowledge distillation. The method encourages early exits to mimic later, more accurate exits, by matching their probability outputs. Experiments on CIFAR100 and ImageNet show that distillation-based training significantly improves the accuracy of early exits while maintaining state-of-the-art accuracy for late ones. The method is particularly beneficial when training data is limited and also allows a straight-forward extension to semi-supervised learning, i.e. make use also of unlabeled data at training time. Moreover, it takes only a few lines to implement and imposes almost no computational overhead at training time, and none at all at test time.",2019,"Mary Phuong,Christoph H. Lampert",Computer Science,122,52
202661166,Visual Tracking by Means of Deep Reinforcement Learning and an Expert Demonstrator,"In the last decade many different algorithms have been proposed to track a generic object in videos. Their execution on recent large-scale video datasets can produce a great amount of various tracking behaviours. New trends in Reinforcement Learning showed that demonstrations of an expert agent can be efficiently used to speed-up the process of policy learning. Taking inspiration from such works and from the recent applications of Reinforcement Learning to visual tracking, we propose two novel trackers, A3CT, which exploits demonstrations of a state-of-the-art tracker to learn an effective tracking policy, and A3CTD, that takes advantage of the same expert tracker to correct its behaviour during tracking. Through an extensive experimental validation on the GOT-10k, OTB-100, LaSOT, UAV123 and VOT benchmarks, we show that the proposed trackers achieve state-of-the-art performance while running in real-time.",2019,"Matteo Dunnhofer,N. Martinel,G. Foresti,C. Micheloni",Computer Science,29,51
202578069,GradNet: Gradient-Guided Network for Visual Object Tracking,"The fully-convolutional siamese network based on template matching has shown great potentials in visual tracking. During testing, the template is fixed with the initial target feature and the performance totally relies on the general matching ability of the siamese network. However, this manner cannot capture the temporal variations of targets or background clutter. In this work, we propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations. To be specific, the algorithm can utilize the information from the gradient to update the template in the current frame. In addition, a template generalization training method is proposed to better use gradient information and avoid overfitting. To our knowledge, this work is the first attempt to exploit the information in the gradient for template update in siamese-based trackers. Extensive experiments on recent benchmarks demonstrate that our method achieves better performance than other state-of-the-art trackers.",2019,"Peixia Li,Boyu Chen,Wanli Ouyang,Dong Wang,Xiaoyun Yang,Huchuan Lu",Computer Science,198,46
199528271,On the Variance of the Adaptive Learning Rate and Beyond,"The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Here, we study its mechanism in details. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate (i.e., it has problematically large variance in the early stage), suggest warmup works as a variance reduction technique, and provide both empirical and theoretical evidence to verify our hypothesis. We further propose RAdam, a new variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Extensive experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the effectiveness and robustness of our proposed method. All implementations are available at: this https URL.",2019,"Liyuan Liu,Haoming Jiang,Pengcheng He,Weizhu Chen,Xiaodong Liu,Jianfeng Gao,Jiawei Han","Computer Science,Mathematics",1480,39
198967933,ROAM: Recurrently Optimizing Tracking Model,"In this paper, we design a tracking model consisting of response generation and bounding box regression, where the first component produces a heat map to indicate the presence of the object at different positions and the second part regresses the relative bounding box shifts to anchors mounted on sliding-window locations. Thanks to the resizable convolutional filters used in both components to adapt to the shape changes of objects, our tracking model does not need to enumerate different sized anchors, thus saving model parameters. To effectively adapt the model to appearance variations, we propose to offline train a recurrent neural optimizer to update tracking model in a meta-learning setting, which can converge the model in a few gradient steps. This improves the convergence speed of updating the tracking model while achieving better performance. We extensively evaluate our trackers, ROAM and ROAM++, on the OTB, VOT, LaSOT, GOT-10K and TrackingNet benchmark and our methods perform favorably against state-of-the-art algorithms.",2019,"Tianyu Yang,Pengfei Xu,Runbo Hu,Hua Chai,Antoni B. Chan",Computer Science,81,62
198229725,Teacher-Students Knowledge Distillation for Siamese Trackers,"With the development of Siamese network based trackers, a variety of techniques have been fused into this framework for real-time object tracking. However, Siamese trackers suffer from the dilemma between high memory cost and strict constraints on memory budget for practical applications. In this paper, we propose a novel distilled Siamese tracker framework to learn small, fast yet accurate trackers (students), which can capture critical knowledge from large Siamese trackers (teachers) by a teacher-students knowledge distillation model. This model is intuitively inspired by a one teacher vs multi-students learning mechanism, which is the most usual teaching method in the school. In particular, it contains a single teacher-student distillation model and a student-student knowledge sharing mechanism. The first one is designed by a tracking-specific distillation strategy to transfer knowledge from teacher to students. The second one is applied for mutual learning between students to enable more in-depth knowledge understanding. Moreover, to demonstrate its generality and effectiveness, we conduct theoretical analysis and extensive empirical evaluations on two Siamese trackers, on several popular tracking benchmarks. The results show that the distilled trackers achieve compression rates of 13$\times$--18$\times$, while maintaining the same or even slightly improved tracking accuracy.",2019,"Yuanpei Liu,Xingping Dong,Wenguan Wang,Jianbing Shen",Computer Science,19,59
198179975,Real-Time Correlation Tracking Via Joint Model Compression and Transfer,"Correlation filters (CF) have received considerable attention in visual tracking because of their computational efficiency. Leveraging deep features via off-the-shelf CNN models (e.g., VGG), CF trackers achieve state-of-the-art performance while consuming a large number of computing resources. This limits deep CF trackers to be deployed to many mobile platforms on which only a single-core CPU is available. In this paper, we propose to jointly compress and transfer off-the-shelf CNN models within a knowledge distillation framework. We formulate a CNN model pretrained from the image classification task as a teacher network, and distill this teacher network into a lightweight student network as the feature extractor to speed up CF trackers. In the distillation process, we propose a fidelity loss to enable the student network to maintain the representation capability of the teacher network. Meanwhile, we design a tracking loss to adapt the objective of the student network from object recognition to visual tracking. The distillation process is performed offline on multiple layers and adaptively updates the student network using a background-aware online learning scheme. The online adaptation stage exploits the background contents to improve the feature discrimination of the student network. Extensive experiments on six standard datasets demonstrate that the lightweight student network accelerates the speed of state-of-the-art deep CF trackers to real-time on a single-core CPU while maintaining almost the same tracking accuracy.",2019,"Ning Wang,Wen-gang Zhou,Yibing Song,Chao Ma,Houqiang Li","Computer Science,Medicine",31,72
207905041,Deep Adaptive Fusion Network for High Performance RGBT Tracking,"Due to the complementarity of RGB and thermal data, RGBT tracking has received more and more attention in recent years because it can effectively solve the degradation of tracking performance in dark environments and bad weather conditions. How to effectively fuse the information from RGB and thermal modality is the key to give full play to their complementarities for effective RGBT tracking. In this paper, we propose a high performance RGBT tracking framework based on a novel deep adaptive fusion network, named DAFNet. Our DAFNet consists of a recursive fusion chain that could adaptively integrate all layer features in an end-to-end manner. Due to simple yet effective operations in DAFNet, our tracker is able to reach the near-real-time speed. Comparing with the state-of-the-art trackers on two public datasets, our DAFNet tracker achieves the outstanding performance and yields a new state-of-the-art in RGBT tracking.",2019,"Yuan Gao,Chenglong Li,Yabin Zhu,Jin Tang,Tao He,Futian Wang",Computer Science,68,38
69981130,Learning Local-Global Multi-Graph Descriptors for RGB-T Object Tracking,"RGB-thermal (RGB-T) object tracking, which has attracted much recent attention, uses thermal infrared information to assist object tracking with visible light information. However, it still faces many challenging problems, especially the background inclusion in the target bounding box which easily results in model drifting. To handle this problem, we propose a novel and general approach to learn a local-global multi-graph descriptor to suppress background effects for RGB-T tracking. Our approach relies on a novel graph learning algorithm. First, the object is represented with multiple graphs, with a set of multi-modal image patches as nodes, for the robustness to prevent deformation and partial occlusion. Second, we dynamically learn a joint graph over time with both local and global considerations using spatial smoothness and low-rank representation. In particular, we design a single unified alternating direction method of multipliers-based optimization framework to learn graph structure, edge weights, and node weights simultaneously. Third, we combine multi-graph information with corresponding graph node weights to form a robust object descriptor, and tracking is finally carried out by adopting the structured support vector machine. Extensive experiments conducted on the tracking benchmark data sets demonstrate the effectiveness of the proposed approach against the state-of-the-art RGB-T trackers.",2019,"Chenglong Li,Chengli Zhu,Jian Zhang,B. Luo,Xiaohao Wu,Jin Tang",Computer Science,38,58
207925044,The Seventh Visual Object Tracking VOT2019 Challenge Results,"The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on ""real-time"" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.",2019,"M. Kristan,Jiri Matas,A. Leonardis,M. Felsberg,R. Pflugfelder,Joni-Kristian,Kämäräinen,L. Č. Zajc,O. Drbohlav,A. Lukežič,Amanda Berg,Abdelrahman,Eldesokey,Jani Käpylä,G. Fernandez,Abel Gonzalez-Garcia,Alireza,Memarmoghadam,Andong Lu,Anfeng He,A. Varfolomieiev,Antoni B. Chan,Ardhendu Shekhar,Tripathi,A. Smeulders,Bala Suraj Pedasingu,B. Chen,Baopeng Zhang,Baoyuan Wu,Bi,Li,Bin He,Bin Yan,Bing Bai,Bing Li,Bo Li,B. Kim,Chao Ma,Chen Fang,Chen,Qian,Cheng Chen,Chenglong Li,Chengquan Zhang,Chi-Yi Tsai,Chong Luo,Christian,Micheloni,Chunhui Zhang,D. Tao,Deepak Gupta,Dejia Song,Dong Wang,Efstratios,Gavves,Eunu Yi,F. Khan,Fangyi Zhang,Fei Wang,Fei Zhao,George De,Ath,Goutam Bhat,Guang-Gui Chen,Guangting Wang,Guoxuan Li,Hakan Çevikalp,Hao Du,Haojie,Zhao,Hasan Saribas,Ho Min Jung,Hongliang Bai,Hongyuan Yu,Houwen Peng,Huchuan,Lǔ,Hui Li,Jia-Ke Li,Jianhua Li,Jianlong Fu,Jie Chen,Jie Gao,Jie Zhao,Jin Tang,Jing,Jingjing Wu,Jingtuo Liu,Jinqiao Wang,Jinqing Qi,Jinyue Zhang,John Tsotsos,J. Hyuk,Lee,Joost van de Weijer,J. Kittler,Jun Ha Lee,Junfei Zhuang,Kangkai Zhang,Kangkang,Wang,Kenan Dai,Lei Chen,Lei Liu,Leida Guo,Li Zhang,Liang Wang,Liang Wang,Lichao,Zhang,Lijun Wang,Lijun Zhou,Linyu Zheng,Litu Rout,L. Gool,Luca Bertinetto,Martin,Danelljan,Matteo Dunnhofer,Meng Ni,M. Y. Kim,Ming Tang,Ming-Hsuan Yang,Naveen,Paluru,N. Martinel,Pengfei Xu,Pengfei Zhang,Pengkun Zheng,Pengyu Zhang,S. PhilipH.,Torr,Q. Wang,Qing Guo,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Richard,Everson,Ruize Han,Ruohan Zhang,Shan You,Shaochuan Zhao,Shengwei Zhao,Shihu,Shikun Li,Shiming Ge,Shuai Bai,Shuosen Guan,Tengfei Xing,Tianyang Xu,Tianyu,Yang,Ting Zhang,Tomás Vojír,Wei Feng,Wei Hu,Weizhao Wang,Wenjie Tang,Wenjun,Zeng,Wenyu Liu,Xi Chen,Xi Qiu,Xiang Bai,Xiaojun Wu,Xiaoyun Yang,Xier,Xin Li,Xingyuan Sun,Xingyu Chen,Xinmei Tian,Xuwen Tang,Xuefeng Zhu,Yan-ping Huang,Yanan,Yanchao Lian,Yang Gu,Y. Liu,Yanjie Chen,Yi Zhang,Yinda Xu,Yingming,Yingping Li,Yu Zhou,Yuan Dong,Yufei Xu,Yunhua Zhang,Yunkun Li,Zeyu Zhao,Luo,Zhaoliang Zhang,Zhenhua Feng,Zhenyu He,Zhichao Song,Zhihao Chen,Zhipeng,Zhirong Wu,Zhiwei Xiong,Zhongjian Huang,Zhu Teng,Zihan Ni",Computer Science,366,114
201698179,Multi-Modal Fusion for End-to-End RGB-T Tracking,"We propose an end-to-end tracking framework for fusing the RGB and TIR modalities in RGB-T tracking. Our baseline tracker is DiMP (Discriminative Model Prediction), which employs a carefully designed target prediction network trained end-to-end using a discriminative loss. We analyze the effectiveness of modality fusion in each of the main components in DiMP, i.e. feature extractor, target estimation network, and classifier. We consider several fusion mechanisms acting at different levels of the framework, including pixel-level, feature-level and response-level. Our tracker is trained in an end-to-end manner, enabling the components to learn how to fuse the information from both modalities. As data to train our model, we generate a large-scale RGB-T dataset by considering an annotated RGB tracking dataset (GOT-10k) and synthesizing paired TIR images using an image-to-image translation approach. We perform extensive experiments on VOT-RGBT2019 dataset and RGBT210 dataset, evaluating each type of modality fusing on each model component. The results show that the proposed fusion mechanisms improve the performance of the single modality counterparts. We obtain our best results when fusing at the feature-level on both the IoU-Net and the model predictor, obtaining an EAO score of 0.391 on VOT-RGBT2019 dataset. With this fusion mechanism we achieve the state-of-the-art performance on RGBT210 dataset.",2019,"Lichao Zhang,Martin Danelljan,Abel Gonzalez-Garcia,Joost van de Weijer,F. Khan",Computer Science,81,57
71142966,FusionGAN: A generative adversarial network for infrared and visible image fusion,,2019,"Jiayi Ma,Wei Yu,Pengwei Liang,Chang Li,Junjun Jiang",Computer Science,888,46
198229527,Dense Feature Aggregation and Pruning for RGBT Tracking,"How to perform effective information fusion of different modalities is a core factor in boosting the performance of RGBT tracking. This paper presents a novel deep fusion algorithm based on the representations from an end-to-end trained convolutional neural network. To deploy the complementarity of features of all layers, we propose a recursive strategy to densely aggregate these features that yield robust representations of target objects in each modality. In different modalities, we propose to prune the densely aggregated features of all modalities in a collaborative way. In a specific, we employ the operations of global average pooling and weighted random selection to perform channel scoring and selection, which could remove redundant and noisy features to achieve more robust feature representation. Experimental results on two RGBT tracking benchmark datasets suggest that our tracker achieves clear state-of-the-art against other RGB and RGBT tracking methods.",2019,"Yabin Zhu,Chenglong Li,B. Luo,Jin Tang,Xiao Wang",Computer Science,113,47
197431256,Multi-Adapter RGBT Tracking,"The task of RGBT tracking aims to take the complementary advantages from visible spectrum and thermal infrared data to achieve robust visual tracking, and receives more and more attention in recent years. Existing works focus on modality-specific information integration by introducing modality weights to achieve adaptive fusion or learning robust feature representations of different modalities. Although these methods could effectively deploy the modality-specific properties, they ignore the potential values of modality-shared cues as well as instance-aware information, which are crucial for effective fusion of different modalities in RGBT tracking. In this paper, we propose a novel Multi-Adapter convolutional Network (MANet) to jointly perform modality-shared, modality-specific and instance-aware feature learning in an end-to-end trained deep framework for RGBT tracking. We design three kinds of adapters within our network. In a specific, the generality adapter is to extract shared object representations, the modality adapter aims at encoding modality-specific information to deploy their complementary advantages, and the instance adapter is to model the appearance properties and temporal variations of a certain object. Moreover, to reduce computational complexity for real-time demand of visual tracking, we design a parallel structure of generic adapter and modality adapter. Extensive experiments on two RGBT tracking benchmark datasets demonstrate the outstanding performance of the proposed tracker against other state-ofthe-art RGB and RGBT tracking algorithms.",2019,"Chenglong Li,Andong Lu,A. Zheng,Zhengzheng Tu,Jin Tang",Computer Science,94,37
54475412,Fast Online Object Tracking and Segmentation: A Unifying Approach,"In this paper we illustrate how to perform both visual object tracking and semi-supervised video object segmentation, in real-time, with a single simple approach. Our method, dubbed SiamMask, improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task. Once trained, SiamMask solely relies on a single bounding box initialisation and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 55 frames per second. Despite its simplicity, versatility and fast speed, our strategy allows us to establish a new state-of-the-art among real-time trackers on VOT-2018, while at the same time demonstrating competitive performance and the best speed for the semi-supervised video object segmentation task on DAVIS-2016 and DAVIS-2017.",2018,"Qiang Wang,Li Zhang,Luca Bertinetto,Weiming Hu,Philip H. S. Torr",Computer Science,1039,78
173992143,FuCoLoT - A Fully-Correlational Long-Term Tracker,,2018,"A. Lukežič,L. Č. Zajc,Tomás Vojír,Jiri Matas,M. Kristan",Computer Science,62,39
53756188,FANet: Quality-Aware Feature Aggregation Network for RGB-T Tracking,"This paper investigates how to perform robust visual tracking in adverse and challenging conditions using complementary visual and thermal infrared data (RGB-T tracking). We propose a novel deep network architecture ""quality-aware Feature Aggregation Network (FANet)"" to achieve quality-aware aggregations of both hierarchical features and multimodal information for robust online RGB-T tracking. Unlike existing works that directly concatenate hierarchical deep features, our FANet learns the layer weights to adaptively aggregate them to handle the challenge of significant appearance changes caused by deformation, abrupt motion, background clutter and occlusion within each modality. Moreover, we employ the operations of max pooling, interpolation upsampling and convolution to transform these hierarchical and multi-resolution features into a uniform space at the same resolution for more effective feature aggregation. In different modalities, we elaborately design a multimodal aggregation sub-network to integrate all modalities collaboratively based on the predicted reliability degrees. Extensive experiments on large-scale benchmark datasets demonstrate that our FANet significantly outperforms other state-of-the-art RGB-T tracking methods.",2018,"Yabin Zhu,Chenglong Li,Yijuan Lu,Liang Lin,B. Luo,Jin Tang",Computer Science,18,38
232404168,Transformer Tracking,"Correlation acts as a critical role in the tracking field, especially in recent popular Siamese-based trackers. The correlation operation is a simple fusion manner to consider the similarity between the template and the search region. However, the correlation operation itself is a local linear matching process, leading to lose semantic information and fall into local optimum easily, which may be the bottleneck of designing high-accuracy tracking algorithms. Is there any better feature fusion method than correlation? To address this issue, inspired by Transformer, this work presents a novel attention-based feature fusion network, which effectively combines the template and search region features solely using attention. Specifically, the proposed method includes an ego-context augment module based on self-attention and a cross-feature augment module based on cross-attention. Finally, we present a Transformer tracking (named TransT) method based on the Siamese-like feature extraction backbone, the designed attention-based fusion mechanism, and the classification and regression head. Experiments show that our TransT achieves very promising results on six challenging datasets, especially on large-scale LaSOT, TrackingNet, and GOT-10k benchmarks. Our tracker runs at approximatively 50 fps on GPU. Code and models are available at https://github.com/chenxin-dlut/TransT.",2021,"Xin Chen,Bin Yan,Jiawen Zhu,Dong Wang,Xiaoyun Yang,Huchuan Lu",Computer Science,551,50
231732518,The Eighth Visual Object Tracking VOT2020 Challenge Results,,2020,"M. Kristan,A. Leonardis,Jiri Matas,M. Felsberg,R. Pflugfelder,Joni-Kristian Kämäräinen,Martin Danelljan,L. Č. Zajc,A. Lukežič,O. Drbohlav,Linbo He,Yushan Zhang,Song Yan,Jinyu Yang,G. Fernandez,A. Hauptmann,Alireza Memarmoghadam,Álvaro García-Martín,Andreas Robinson,A. Varfolomieiev,Awet Haileslassie Gebrehiwot,Bedirhan Uzun,Bin Yan,Bing Li,C. Qian,Chi-Yi Tsai,C. Micheloni,Dong Wang,Fei Wang,Fei Xie,Felix Järemo Lawin,F. Gustafsson,G. Foresti,Goutam Bhat,Guang-Gui Chen,Haibin Ling,Haitao Zhang,Hakan Cevikalp,Haojie Zhao,Haoran Bai,Hari Chandana Kuchibhotla,Hasan Saribas,Heng Fan,Hossein Ghanei-Yakhdan,Houqiang Li,Houwen Peng,Huchuan Lu,Hui Li,Javad Khaghani,Jesús Bescós,Jianhua Li,Jianlong Fu,Jiaqian Yu,Jingtao Xu,J. Kittler,Jun Yin,Junhyun Lee,Kaicheng Yu,Kaiwen Liu,Kang Yang,Kenan Dai,Li Cheng,Li Zhang,Lijun Wang,Linyuan Wang,L. Gool,Luca Bertinetto,Matteo Dunnhofer,Miao Cheng,Mohana Murali Dasari,Ning Wang,Pengyu Zhang,Philip H. S. Torr,Qiang Wang,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Seokeon Choi,S. M. Marvasti-Zadeh,Shaochuan Zhao,S. Kasaei,Shoumeng Qiu,Shuhao Chen,Thomas Bo Schön,Tianyang Xu,W. Lu,Weiming Hu,Wen-gang Zhou,Xi Qiu,Xiao Ke,Xiaojun Wu,Xiaolin Zhang,Xiaoyun Yang,Xuefeng Zhu,Yingjie Jiang,Yingming Wang,Yiwei Chen,Yu Ye,Yuezhou Li,Yuncon Yao,Yunsung Lee,Yuzhang Gu,Zezhou Wang,Zhangyong Tang,Zhenhua Feng,Zhijun Mai,Zhipeng Zhang,Zhirong Wu,Ziang Ma",Computer Science,187,87
221090791,RPT: Learning Point Set Representation for Siamese Visual Tracking,,2020,"Ziang Ma,Linyuan Wang,Haitao Zhang,Wei Lu,J. Yin",Computer Science,49,39
219793067,Ocean: Object-aware Anchor-free Tracking,,2020,"Zhipeng Zhang,Houwen Peng",Computer Science,439,50
215754230,Deformable Siamese Attention Networks for Visual Object Tracking,"Siamese-based trackers have achieved excellent performance on visual object tracking. However, the target template is not updated online, and the features of target template and search image are computed independently in a Siamese architecture. In this paper, we propose Deformable Siamese Attention Networks, referred to as SiamAttn, by introducing a new Siamese attention mechanism that computes deformable self-attention and cross-attention. The self-attention learns strong context information via spatial attention, and selectively emphasizes interdependent channel-wise features with channel attention. The crossattention is capable of aggregating rich contextual interdependencies between the target template and the search image, providing an implicit manner to adaptively update the target template. In addition, we design a region refinement module that computes depth-wise cross correlations between the attentional features for more accurate tracking. We conduct experiments on six benchmarks, where our method achieves new state-of-the-art results, outperforming recent strong baseline, SiamRPN++, by 0.464 to 0.537 and 0.415 to 0.470 EAO on VOT 2016 and 2018.",2020,"Yu Yu,Yilei Xiong,Weilin Huang,Matthew R. Scott",Computer Science,233,46
214743010,High-Performance Long-Term Tracking With Meta-Updater,"Long-term visual tracking has drawn increasing attention because it is much closer to practical applications than short-term tracking. Most top-ranked long-term trackers adopt the offline-trained Siamese architectures, thus,they cannot benefit from great progress of short-term trackers with online update. However, it is quite risky to straightforwardly introduce online-update-based trackers to solve the long-term problem, due to long-term uncertain and noisy observations. In this work, we propose a novel offline-trained Meta-Updater to address an important but unsolved problem: Is the tracker ready for updating in the current frame? The proposed meta-updater can effectively integrate geometric, discriminative, and appearance cues in a sequential manner, and then mine the sequential information with a designed cascaded LSTM module. Our meta-updater learns a binary output to guide the tracker’s update and can be easily embedded into different trackers. This work also introduces a long-term tracking framework consisting of an online local tracker, an online verifier, a SiamRPN-based re-detector, and our meta-updater. Numerous experimental results on the VOT2018LT,VOT2019LT, OxUvALT, TLP, and LaSOT benchmarks show that our tracker performs remarkably better than other competing algorithms. Our project is available on the website: https://github.com/Daikenan/LTMU.",2020,"Kenan Dai,Yunhua Zhang,Dong Wang,Jianhua Li,Huchuan Lu,Xiaoyun Yang",Computer Science,141,57
214693026,Probabilistic Regression for Visual Tracking,"Visual tracking is fundamentally the problem of regressing the state of the target in each video frame. While significant progress has been achieved, trackers are still prone to failures and inaccuracies. It is therefore crucial to represent the uncertainty in the target estimation. Although current prominent paradigms rely on estimating a state-dependent confidence score, this value lacks a clear probabilistic interpretation, complicating its use. In this work, we therefore propose a probabilistic regression formulation and apply it to tracking. Our network predicts the conditional probability density of the target state given an input image. Crucially, our formulation is capable of modeling label noise stemming from inaccurate annotations and ambiguities in the task. The regression network is trained by minimizing the Kullback-Leibler divergence. When applied for tracking, our formulation not only allows a probabilistic representation of the output, but also substantially improves the performance. Our tracker sets a new state-of-the-art on six datasets, achieving 59.8% AUC on LaSOT and 75.8% Success on TrackingNet. The code and models are available at https://github.com/visionml/pytracking.",2020,"Martin Danelljan,L. Gool,R. Timofte",Computer Science,350,53
208512936,Siam R-CNN: Visual Tracking by Re-Detection,"We present Siam R-CNN, a Siamese re-detection architecture which unleashes the full power of two-stage object detection approaches for visual object tracking. We combine this with a novel tracklet-based dynamic programming algorithm, which takes advantage of re-detections of both the first-frame template and previous-frame predictions, to model the full history of both the object to be tracked and potential distractor objects. This enables our approach to make better tracking decisions, as well as to re-detect tracked objects after long occlusion. Finally, we propose a novel hard example mining strategy to improve Siam R-CNN's robustness to similar looking objects. Siam R-CNN achieves the current best performance on ten tracking benchmarks, with especially strong results for long-term tracking. We make our code and models available at www.vision.rwth-aachen.de/page/siamrcnn.",2019,"P. Voigtlaender,Jonathon Luiten,Philip H. S. Torr,B. Leibe",Computer Science,381,118
208175650,D3S – A Discriminative Single Shot Segmentation Tracker,"Template-based discriminative trackers are currently the dominant tracking paradigm due to their robustness, but are restricted to bounding box tracking and a limited range of transformation models, which reduces their localization accuracy. We propose a discriminative single-shot segmentation tracker - D3S, which narrows the gap between visual object tracking and video object segmentation. A single-shot network applies two target models with complementary geometric properties, one invariant to a broad range of transformations, including non-rigid deformations, the other assuming a rigid object to simultaneously achieve high robustness and online target segmentation. Without per-dataset finetuning and trained only for segmentation as the primary output, D3S outperforms all trackers on VOT2016, VOT2018 and GOT-10k benchmarks and performs close to the state-of-the-art trackers on the TrackingNet. D3S outperforms the leading segmentation tracker SiamMask on video segmentation benchmark and performs on par with top video object segmentation algorithms, while running an order of magnitude faster, close to real-time.",2019,"A. Lukežič,Jiri Matas,M. Kristan",Computer Science,176,52
208006288,SiamFC++: Towards Robust and Accurate Visual Tracking with Target Estimation Guidelines,"Visual tracking problem demands to efficiently perform robust classification and accurate target state estimation over a given target at the same time. Former methods have proposed various ways of target state estimation, yet few of them took the particularity of the visual tracking problem itself into consideration. Based on a careful analysis, we propose a set of practical guidelines of target state estimation for high-performance generic object tracker design. Following these guidelines, we design our Fully Convolutional Siamese tracker++ (SiamFC++) by introducing both classification and target state estimation branch (G1), classification score without ambiguity (G2), tracking without prior knowledge (G3), and estimation quality score (G4). Extensive analysis and ablation studies demonstrate the effectiveness of our proposed guidelines. Without bells and whistles, our SiamFC++ tracker achieves state-of-the-art performance on five challenging benchmarks(OTB2015, VOT2018, LaSOT, GOT-10k, TrackingNet), which proves both the tracking and generalization ability of the tracker. Particularly, on the large-scale TrackingNet dataset, SiamFC++ achieves a previously unseen AUC score of 75.4 while running at over 90 FPS, which is far above the real-time requirement.",2019,"Yinda Xu,Zeyu Wang,Zuoxin Li,Yuan Ye,Gang Yu",Computer Science,559,37
208512936,Siam R-CNN: Visual Tracking by Re-Detection,"We present Siam R-CNN, a Siamese re-detection architecture which unleashes the full power of two-stage object detection approaches for visual object tracking. We combine this with a novel tracklet-based dynamic programming algorithm, which takes advantage of re-detections of both the first-frame template and previous-frame predictions, to model the full history of both the object to be tracked and potential distractor objects. This enables our approach to make better tracking decisions, as well as to re-detect tracked objects after long occlusion. Finally, we propose a novel hard example mining strategy to improve Siam R-CNN's robustness to similar looking objects. Siam R-CNN achieves the current best performance on ten tracking benchmarks, with especially strong results for long-term tracking. We make our code and models available at www.vision.rwth-aachen.de/page/siamrcnn.",2019,"P. Voigtlaender,Jonathon Luiten,Philip H. S. Torr,B. Leibe",Computer Science,381,118
207925044,The Seventh Visual Object Tracking VOT2019 Challenge Results,"The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on ""real-time"" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.",2019,"M. Kristan,Jiri Matas,A. Leonardis,M. Felsberg,R. Pflugfelder,Joni-Kristian,Kämäräinen,L. Č. Zajc,O. Drbohlav,A. Lukežič,Amanda Berg,Abdelrahman,Eldesokey,Jani Käpylä,G. Fernandez,Abel Gonzalez-Garcia,Alireza,Memarmoghadam,Andong Lu,Anfeng He,A. Varfolomieiev,Antoni B. Chan,Ardhendu Shekhar,Tripathi,A. Smeulders,Bala Suraj Pedasingu,B. Chen,Baopeng Zhang,Baoyuan Wu,Bi,Li,Bin He,Bin Yan,Bing Bai,Bing Li,Bo Li,B. Kim,Chao Ma,Chen Fang,Chen,Qian,Cheng Chen,Chenglong Li,Chengquan Zhang,Chi-Yi Tsai,Chong Luo,Christian,Micheloni,Chunhui Zhang,D. Tao,Deepak Gupta,Dejia Song,Dong Wang,Efstratios,Gavves,Eunu Yi,F. Khan,Fangyi Zhang,Fei Wang,Fei Zhao,George De,Ath,Goutam Bhat,Guang-Gui Chen,Guangting Wang,Guoxuan Li,Hakan Çevikalp,Hao Du,Haojie,Zhao,Hasan Saribas,Ho Min Jung,Hongliang Bai,Hongyuan Yu,Houwen Peng,Huchuan,Lǔ,Hui Li,Jia-Ke Li,Jianhua Li,Jianlong Fu,Jie Chen,Jie Gao,Jie Zhao,Jin Tang,Jing,Jingjing Wu,Jingtuo Liu,Jinqiao Wang,Jinqing Qi,Jinyue Zhang,John Tsotsos,J. Hyuk,Lee,Joost van de Weijer,J. Kittler,Jun Ha Lee,Junfei Zhuang,Kangkai Zhang,Kangkang,Wang,Kenan Dai,Lei Chen,Lei Liu,Leida Guo,Li Zhang,Liang Wang,Liang Wang,Lichao,Zhang,Lijun Wang,Lijun Zhou,Linyu Zheng,Litu Rout,L. Gool,Luca Bertinetto,Martin,Danelljan,Matteo Dunnhofer,Meng Ni,M. Y. Kim,Ming Tang,Ming-Hsuan Yang,Naveen,Paluru,N. Martinel,Pengfei Xu,Pengfei Zhang,Pengkun Zheng,Pengyu Zhang,S. PhilipH.,Torr,Q. Wang,Qing Guo,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Richard,Everson,Ruize Han,Ruohan Zhang,Shan You,Shaochuan Zhao,Shengwei Zhao,Shihu,Shikun Li,Shiming Ge,Shuai Bai,Shuosen Guan,Tengfei Xing,Tianyang Xu,Tianyu,Yang,Ting Zhang,Tomás Vojír,Wei Feng,Wei Hu,Weizhao Wang,Wenjie Tang,Wenjun,Zeng,Wenyu Liu,Xi Chen,Xi Qiu,Xiang Bai,Xiaojun Wu,Xiaoyun Yang,Xier,Xin Li,Xingyuan Sun,Xingyu Chen,Xinmei Tian,Xuwen Tang,Xuefeng Zhu,Yan-ping Huang,Yanan,Yanchao Lian,Yang Gu,Y. Liu,Yanjie Chen,Yi Zhang,Yinda Xu,Yingming,Yingping Li,Yu Zhou,Yuan Dong,Yufei Xu,Yunhua Zhang,Yunkun Li,Zeyu Zhao,Luo,Zhaoliang Zhang,Zhenhua Feng,Zhenyu He,Zhichao Song,Zhihao Chen,Zhipeng,Zhirong Wu,Zhiwei Xiong,Zhongjian Huang,Zhu Teng,Zihan Ni",Computer Science,366,114
202577565,Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution,"This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN) for improving the region-proposal quality and detection performance by systematically addressing the limitation of the conventional RPN that heuristically defines the anchors and aligns the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a single anchor per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, adaptive convolution is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves 13.4 point AR higher than that of the conventional RPN, surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively. The code will be made publicly available at https://github.com/thangvubk/Cascade-RPN.",2019,"Thang Vu,Hyunjun Jang,T. Pham,C. Yoo",Computer Science,111,47
202578069,GradNet: Gradient-Guided Network for Visual Object Tracking,"The fully-convolutional siamese network based on template matching has shown great potentials in visual tracking. During testing, the template is fixed with the initial target feature and the performance totally relies on the general matching ability of the siamese network. However, this manner cannot capture the temporal variations of targets or background clutter. In this work, we propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations. To be specific, the algorithm can utilize the information from the gradient to update the template in the current frame. In addition, a template generalization training method is proposed to better use gradient information and avoid overfitting. To our knowledge, this work is the first attempt to exploit the information in the gradient for template update in siamese-based trackers. Extensive experiments on recent benchmarks demonstrate that our method achieves better performance than other state-of-the-art trackers.",2019,"Peixia Li,Boyu Chen,Wanli Ouyang,Dong Wang,Xiaoyun Yang,Huchuan Lu",Computer Science,198,46
196700924,Graph Convolutional Tracking,"Tracking by siamese networks has achieved favorable performance in recent years. However, most of existing siamese methods do not take full advantage of spatial-temporal target appearance modeling under different contextual situations. In fact, the spatial-temporal information can provide diverse features to enhance the target representation, and the context information is important for online adaption of target localization. To comprehensively leverage the spatial-temporal structure of historical target exemplars and get benefit from the context information, in this work, we present a novel Graph Convolutional Tracking (GCT) method for high-performance visual tracking. Specifically, the GCT jointly incorporates two types of Graph Convolutional Networks (GCNs) into a siamese framework for target appearance modeling. Here, we adopt a spatial-temporal GCN to model the structured representation of historical target exemplars. Furthermore, a context GCN is designed to utilize the context of the current frame to learn adaptive features for target localization. Extensive results on 4 challenging benchmarks show that our GCT method performs favorably against state-of-the-art trackers while running around 50 frames per second.",2019,"Junyu Gao,Tianzhu Zhang,Changsheng Xu",Computer Science,212,88
119296375,CenterNet: Keypoint Triplets for Object Detection,"In object detection, keypoint-based approaches often experience the drawback of a large number of incorrect object bounding boxes, arguably due to the lack of an additional assessment inside cropped regions. This paper presents an efficient solution that explores the visual patterns within individual cropped regions with minimal costs. We build our framework upon a representative one-stage keypoint-based detector named CornerNet. Our approach, named CenterNet, detects each object as a triplet, rather than a pair, of keypoints, which improves both precision and recall. Accordingly, we design two customized modules, cascade corner pooling, and center pooling, that enrich information collected by both the top-left and bottom-right corners and provide more recognizable information from the central regions. On the MS-COCO dataset, CenterNet achieves an AP of 47.0 %, outperforming all existing one-stage detectors by at least 4.9%. Furthermore, with a faster inference speed than the top-ranked two-stage detectors, CenterNet demonstrates a comparable performance to these detectors. Code is available at https://github.com/Duankaiwen/CenterNet.",2019,"Kaiwen Duan,S. Bai,Lingxi Xie,H. Qi,Qingming Huang,Q. Tian",Computer Science,1867,54
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
102487133,Unsupervised Deep Tracking,"We propose an unsupervised visual tracking method in this paper. Different from existing approaches using extensive annotated data for supervised learning, our CNN model is trained on large-scale unlabeled videos in an unsupervised manner. Our motivation is that a robust tracker should be effective in both the forward and backward predictions (i.e., the tracker can forward localize the target object in successive frames and backtrace to its initial position in the first frame). We build our framework on a Siamese correlation filter network, which is trained using unlabeled raw videos. Meanwhile, we propose a multiple-frame validation method and a cost-sensitive loss to facilitate unsupervised learning. Without bells and whistles, the proposed unsupervised tracker achieves the baseline accuracy of fully supervised trackers, which require complete and accurate labels during training. Furthermore, unsupervised framework exhibits a potential in leveraging unlabeled or weakly labeled data to further improve the tracking accuracy.",2019,"Ning Wang,Yibing Song,Chao Ma,Wen-gang Zhou,W. Liu,Houqiang Li",Computer Science,291,59
91184137,FCOS: Fully Convolutional One-Stage Object Detection,"We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box free, as well as proposal free. By eliminating the pre-defined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating overlapping during training. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often very sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), FCOS with ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale testing, surpassing previous one-stage detectors with the advantage of being much simpler. For the first time, we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that the proposed FCOS framework can serve as a simple and strong alternative for many other instance-level tasks. Code is available at: https://tinyurl.com/FCOSv1",2019,"Zhi Tian,Chunhua Shen,Hao Chen,Tong He",Computer Science,3594,37
104291974,SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking,"The greatest challenge facing visual object tracking is the simultaneous requirements on robustness and discrimination power. In this paper, we propose a SiamFC-based tracker, named SPM-Tracker, to tackle this challenge. The basic idea is to address the two requirements in two separate matching stages. Robustness is strengthened in the coarse matching (CM) stage through generalized training while discrimination power is enhanced in the fine matching (FM) stage through a distance learning network. The two stages are connected in series as the input proposals of the FM stage are generated by the CM stage. They are also connected in parallel as the matching scores and box location refinements are fused to generate the final results. This innovative series-parallel structure takes advantage of both stages and results in superior performance. The proposed SPM-Tracker, running at 120fps on GPU, achieves an AUC of 0.687 on OTB-100 and an EAO of 0.434 on VOT-16, exceeding other real-time trackers by a notable margin.",2019,"Guangting Wang,Chong Luo,Zhiwei Xiong,Wenjun Zeng",Computer Science,160,60
214693026,Probabilistic Regression for Visual Tracking,"Visual tracking is fundamentally the problem of regressing the state of the target in each video frame. While significant progress has been achieved, trackers are still prone to failures and inaccuracies. It is therefore crucial to represent the uncertainty in the target estimation. Although current prominent paradigms rely on estimating a state-dependent confidence score, this value lacks a clear probabilistic interpretation, complicating its use. In this work, we therefore propose a probabilistic regression formulation and apply it to tracking. Our network predicts the conditional probability density of the target state given an input image. Crucially, our formulation is capable of modeling label noise stemming from inaccurate annotations and ambiguities in the task. The regression network is trained by minimizing the Kullback-Leibler divergence. When applied for tracking, our formulation not only allows a probabilistic representation of the output, but also substantially improves the performance. Our tracker sets a new state-of-the-art on six datasets, achieving 59.8% AUC on LaSOT and 75.8% Success on TrackingNet. The code and models are available at https://github.com/visionml/pytracking.",2020,"Martin Danelljan,L. Gool,R. Timofte",Computer Science,350,53
211507084,ICE-BeeM: Identifiable Conditional Energy-Based Deep Models,"Despite the growing popularity of energy-based models, their identifiability properties are not well-understood. In this paper we establish sufficient conditions under which a large family of conditional energy-based models is identifiable in function space, up to a simple transformation. Our results build on recent developments in the theory of nonlinear ICA, showing that the latent representations in certain families of deep latent-variable models are identifiable. We extend these results to a very broad family of conditional energy-based models. In this family, the energy function is simply the dot-product between two feature extractors, one for the dependent variable, and one for the conditioning variable. We show that under mild conditions, the features are unique up to scaling and permutation. Second, we propose the framework of independently modulated component analysis (IMCA), a new form of nonlinear ICA where the indepencence assumption is relaxed. Importantly, we show that our energy-based model can be used for the estimation of the components: the features learned are a simple and often trivial transformation of the latents.",2020,"Ilyes Khemakhem,R. Monti,Diederik P. Kingma,Aapo Hyvärinen","Mathematics,Computer Science",81,38
211096730,A Simple Framework for Contrastive Learning of Visual Representations,"This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels.",2020,"Ting Chen,Simon Kornblith,Mohammad Norouzi,Geoffrey E. Hinton","Computer Science,Mathematics",12256,67
208857409,Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One,"We propose to reinterpret a standard discriminative classifier of p(y|x) as an energy based model for the joint distribution p(x,y). In this setting, the standard class probabilities can be easily computed as well as unnormalized values of p(x) and p(x|y). Within this framework, standard discriminative architectures may beused and the model can also be trained on unlabeled data. We demonstrate that energy based training of the joint distribution improves calibration, robustness, andout-of-distribution detection while also enabling our models to generate samplesrivaling the quality of recent GAN approaches. We improve upon recently proposed techniques for scaling up the training of energy based models and presentan approach which adds little overhead compared to standard classification training. Our approach is the first to achieve performance rivaling the state-of-the-artin both generative and discriminative learning within one hybrid model.",2019,"Will Grathwohl,Kuan-Chieh Jackson Wang,J. Jacobsen,D. Duvenaud,Mohammad Norouzi,Kevin Swersky","Computer Science,Mathematics",423,52
202786778,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.",2019,"Adam Paszke,Sam Gross,Francisco Massa,Adam Lerer,James Bradbury,Gregory Chanan,Trevor Killeen,Zeming Lin,N. Gimelshein,L. Antiga,Alban Desmaison,Andreas Köpf,E. Yang,Zach DeVito,Martin Raison,A. Tejani,Sasank Chilamkurthy,Benoit Steiner,Lu Fang,Junjie Bai,Soumith Chintala","Computer Science,Mathematics",29772,39
208527348,Flow Contrastive Estimation of Energy-Based Models,"This paper studies a training method to jointly estimate an energy-based model and a flow-based model, in which the two models are iteratively updated based on a shared adversarial value function. This joint training method has the following traits. (1) The update of the energy-based model is based on noise contrastive estimation, with the flow model serving as a strong noise distribution. (2) The update of the flow model approximately minimizes the Jensen-Shannon divergence between the flow model and the data distribution. (3) Unlike generative adversarial networks (GAN) which estimates an implicit probability distribution defined by a generator model, our method estimates two explicit probabilistic distributions on the data. Using the proposed method we demonstrate a significant improvement on the synthesis quality of the flow model, and show the effectiveness of unsupervised feature learning by the learned energy-based model. Furthermore, the proposed training method can be easily adapted to semi-supervised learning. We achieve competitive results to the state-of-the-art semi-supervised learning methods.",2019,"Ruiqi Gao,Erik Nijkamp,Diederik P. Kingma,Zhen Xu,Andrew M. Dai,Y. Wu","Computer Science,Mathematics",93,80
208512936,Siam R-CNN: Visual Tracking by Re-Detection,"We present Siam R-CNN, a Siamese re-detection architecture which unleashes the full power of two-stage object detection approaches for visual object tracking. We combine this with a novel tracklet-based dynamic programming algorithm, which takes advantage of re-detections of both the first-frame template and previous-frame predictions, to model the full history of both the object to be tracked and potential distractor objects. This enables our approach to make better tracking decisions, as well as to re-detect tracked objects after long occlusion. Finally, we propose a novel hard example mining strategy to improve Siam R-CNN's robustness to similar looking objects. Siam R-CNN achieves the current best performance on ten tracking benchmarks, with especially strong results for long-term tracking. We make our code and models available at www.vision.rwth-aachen.de/page/siamrcnn.",2019,"P. Voigtlaender,Jonathon Luiten,Philip H. S. Torr,B. Leibe",Computer Science,381,118
209439838,Learning Energy-Based Models in High-Dimensional Spaces with Multiscale Denoising-Score Matching,"Energy-based models (EBMs) assign an unnormalized log probability to data samples. This functionality has a variety of applications, such as sample synthesis, data denoising, sample restoration, outlier detection, Bayesian reasoning and many more. But, the training of EBMs using standard maximum likelihood is extremely slow because it requires sampling from the model distribution. Score matching potentially alleviates this problem. In particular, denoising-score matching has been successfully used to train EBMs. Using noisy data samples with one fixed noise level, these models learn fast and yield good results in data denoising. However, demonstrations of such models in the high-quality sample synthesis of high-dimensional data were lacking. Recently, a paper showed that a generative model trained by denoising-score matching accomplishes excellent sample synthesis when trained with data samples corrupted with multiple levels of noise. Here we provide an analysis and empirical evidence showing that training with multiple noise levels is necessary when the data dimension is high. Leveraging this insight, we propose a novel EBM trained with multiscale denoising-score matching. Our model exhibits a data-generation performance comparable to state-of-the-art techniques such as GANs and sets a new baseline for EBMs. The proposed model also provides density information and performs well on an image-inpainting task.",2019,"Zengyi Li,Yubei Chen,F. Sommer","Medicine,Computer Science,Mathematics",17,64
213901480,Learning Deep Conditional Target Densities for Accurate Regression,"While deep learning-based classification is generally tackled using standardized approaches, a wide variety of techniques are employed for regression. In computer vision, one particularly popular such technique is that of confidence-based regression, which entails predicting a confidence value for each input-target pair (x,y). While this approach has demonstrated impressive results, it requires important task-dependent design choices, and the predicted confidences lack a natural probabilistic meaning. We address these issues by proposing a general and conceptually simple regression method with a clear probabilistic interpretation. In our proposed approach, we create an energy-based model of the conditional target density p(y|x), using a deep neural network to predict the un-normalized density from (x,y). This model of p(y|x) is trained by directly minimizing the associated negative log-likelihood, approximated using Monte Carlo sampling. We perform comprehensive experiments on four computer vision regression tasks. Our approach outperforms direct regression, as well as other probabilistic and confidence-based methods. Notably, our model achieves a 2.2% AP improvement over Faster-RCNN for object detection on the COCO dataset, and sets a new state-of-the-art on visual tracking when applied for bounding box estimation. In contrast to confidence-based methods, our approach is also shown to be directly applicable to more general tasks such as age and head-pose estimation.",2019,"F. Gustafsson,Martin Danelljan,Goutam Bhat,Thomas Bo Schön",Computer Science,1,37
204743893,Annealed Denoising Score Matching: Learning Energy-Based Models in High-Dimensional Spaces,"Energy-Based Models (EBMs) outputs unmormalized log-probability values given data samples. Such an estimation is essential in a variety of applications such as sample generation, denoising, sample restoration, outlier detection, Bayesian reasoning, and many more. However, standard maximum likelihood training is computationally expensive due to the requirement of sampling the model distribution. Score matching potentially alleviates this problem, and denoising score matching is a particularly convenient version. However, previous works do not produce models capable of high quality sample synthesis in high dimensional datasets from random initialization. We believe that is because the score is only matched over a single noise scale, which corresponds to a small set in high-dimensional space. To overcome this limitation, here we instead learn an energy function using denoising score matching over all noise scales. When sampled from random initialization using Annealed Langevin Dynamics and single-step denoising jump, our model produced high-quality samples comparable to state-of-the-art techniques such as GANs. The learned model also provide density information and set a new sample quality baseline in energy-based models. We further demonstrate that the proposed method generalizes well with an image inpainting task.",2019,"Zengyi Li,Yubei Chen,F. Sommer",Computer Science,13,64
207930212,Momentum Contrast for Unsupervised Visual Representation Learning,"We present Momentum Contrast (MoCo) for unsupervised visual representation learning. From a perspective on contrastive learning as dictionary look-up, we build a dynamic dictionary with a queue and a moving-averaged encoder. This enables building a large and consistent dictionary on-the-fly that facilitates contrastive unsupervised learning. MoCo provides competitive results under the common linear protocol on ImageNet classification. More importantly, the representations learned by MoCo transfer well to downstream tasks. MoCo can outperform its supervised pre-training counterpart in 7 detection/segmentation tasks on PASCAL VOC, COCO, and other datasets, sometimes surpassing it by large margins. This suggests that the gap between unsupervised and supervised representation learning has been largely closed in many vision tasks.",2019,"Kaiming He,Haoqi Fan,Yuxin Wu,Saining Xie,Ross B. Girshick",Computer Science,8418,65
90262243,Video Object Segmentation Using Space-Time Memory Networks,"We propose a novel solution for semi-supervised video object segmentation. By the nature of the problem, available cues (e.g. video frame(s) with object masks) become richer with the intermediate predictions. However, the existing methods are unable to fully exploit this rich source of information. We resolve the issue by leveraging memory networks and learn to read relevant information from all available sources. In our framework, the past frames with object masks form an external memory, and the current frame as the query is segmented using the mask information in the memory. Specifically, the query and the memory are densely matched in the feature space, covering all the space-time pixel locations in a feed-forward fashion. Contrast to the previous approaches, the abundant use of the guidance information allows us to better handle the challenges such as appearance changes and occlussions. We validate our method on the latest benchmark sets and achieved the state-of-the-art performance (overall score of 79.4 on Youtube-VOS val set, J of 88.7 and 79.2 on DAVIS 2016/2017 val set respectively) while having a fast runtime (0.16 second/frame on DAVIS 2016 val set).",2019,"Seoung Wug Oh,Joon-Young Lee,N. Xu,Seon Joo Kim",Computer Science,507,47
76668057,RVOS: End-To-End Recurrent Network for Video Object Segmentation,"Multiple object video object segmentation is a challenging task, specially for the zero-shot case, when no object mask is given at the initial frame and the model has to find the objects to be segmented along the sequence. In our work, we propose a Recurrent network for multiple object Video Object Segmentation (RVOS) that is fully end-to-end trainable. Our model incorporates recurrence on two different domains: (i) the spatial, which allows to discover the different object instances within a frame, and (ii) the temporal, which allows to keep the coherence of the segmented objects along time. We train RVOS for zero-shot video object segmentation and are the first ones to report quantitative results for DAVIS-2017 and YouTube-VOS benchmarks. Further, we adapt RVOS for one-shot video object segmentation by using the masks obtained in previous time steps as inputs to be processed by the recurrent module. Our model reaches comparable results to state-of-the-art techniques in YouTube-VOS benchmark and outperforms all previous video object segmentation methods not using online learning in the DAVIS-2017 benchmark. Moreover, our model achieves faster inference runtimes than previous methods, reaching 44ms/frame on a P100 GPU.",2019,"Carles Ventura,Miriam Bellver,Andreu Girbau,Amaia Salvador,F. Marqués,Xavier Giró-i-Nieto",Computer Science,183,36
67856723,FEELVOS: Fast End-To-End Embedding Learning for Video Object Segmentation,"Many of the recent successful methods for video object segmentation (VOS) are overly complicated, heavily rely on fine-tuning on the first frame, and/or are slow, and are hence of limited practical use. In this work, we propose FEELVOS as a simple and fast method which does not rely on fine-tuning. In order to segment a video, for each frame FEELVOS uses a semantic pixel-wise embedding together with a global and a local matching mechanism to transfer information from the first frame and from the previous frame of the video to the current frame. In contrast to previous work, our embedding is only used as an internal guidance of a convolutional network. Our novel dynamic segmentation head allows us to train the network, including the embedding, end-to-end for the multiple object segmentation task with a cross entropy loss. We achieve a new state of the art in video object segmentation without fine-tuning with a J&F measure of 71.5% on the DAVIS 2017 validation set. We make our code and models available at https://github.com/tensorflow/models/tree/master/research/feelvos.",2019,"P. Voigtlaender,Yuning Chai,Florian Schroff,Hartwig Adam,B. Leibe,Liang-Chieh Chen",Computer Science,346,39
52957146,Unsupervised Video Object Segmentation with Motion-Based Bilateral Networks,,2018,"Siyang Li,Bryan Seybold,A. Vorobyov,Xuejing Lei,C.-C. Jay Kuo",Computer Science,108,40
263866037,Unsupervised Learning of Multi-Frame Optical Flow with Occlusions,,2018,"J. Janai,F. Güney,Anurag Ranjan,Michael J. Black,Andreas Geiger",Computer Science,33,48
52181738,YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark,"Learning long-term spatial-temporal features are critical for many video analysis tasks. However, existing video segmentation methods predominantly rely on static image segmentation techniques, and methods capturing temporal dependency for segmentation have to depend on pretrained optical flow models, leading to suboptimal solutions for the problem. End-to-end sequential learning to explore spatialtemporal features for video segmentation is largely limited by the scale of available video segmentation datasets, i.e., even the largest video segmentation dataset only contains 90 short video clips. To solve this problem, we build a new large-scale video object segmentation dataset called YouTube Video Object Segmentation dataset (YouTube-VOS). Our dataset contains 4,453 YouTube video clips and 94 object categories. This is by far the largest video object segmentation dataset to our knowledge and has been released at this http URL We further evaluate several existing state-of-the-art video object segmentation algorithms on this dataset which aims to establish baselines for the development of new algorithms in the future.",2018,"N. Xu,L. Yang,Yuchen Fan,Dingcheng Yue,Yuchen Liang,Jianchao Yang,Thomas S. Huang",Computer Science,372,34
52154491,VideoMatch: Matching based Video Object Segmentation,,2018,"Yuan-Ting Hu,Jia-Bin Huang,A. Schwing",Computer Science,224,62
50773378,"PReMVOS: Proposal-generation, Refinement and Merging for Video Object Segmentation",,2018,"Jonathon Luiten,P. Voigtlaender,B. Leibe",Computer Science,220,33
52847087,Fast Video Object Segmentation by Reference-Guided Mask Propagation,"We present an efficient method for the semi-supervised video object segmentation. Our method achieves accuracy competitive with state-of-the-art methods while running in a fraction of time compared to others. To this end, we propose a deep Siamese encoder-decoder network that is designed to take advantage of mask propagation and object detection while avoiding the weaknesses of both approaches. Our network, learned through a two-stage training process that exploits both synthetic and real data, works robustly without any online learning or post-processing. We validate our method on four benchmark sets that cover single and multiple object segmentation. On all the benchmark sets, our method shows comparable accuracy while having the order of magnitude faster runtime. We also provide extensive ablation and add-on studies to analyze and evaluate our framework.",2018,"Seoung Wug Oh,Joon-Young Lee,Kalyan Sunkavalli,Seon Joo Kim",Computer Science,334,46
214611612,Cooling-Shrinking Attack: Blinding the Tracker With Imperceptible Noises,"Adversarial attack of CNN aims at deceiving models to misbehave by adding imperceptible perturbations to images. This feature facilitates to understand neural networks deeply and to improve the robustness of deep learning models. Although several works have focused on attacking image classifiers and object detectors, an effective and efficient method for attacking single object trackers of any target in a model-free way remains lacking. In this paper, a cooling-shrinking attack method is proposed to deceive state-of-the-art SiameseRPN-based trackers. An effective and efficient perturbation generator is trained with a carefully designed adversarial loss, which can simultaneously cool hot regions where the target exists on the heatmaps and force the predicted bounding box to shrink, making the tracked target invisible to trackers. Numerous experiments on OTB100, VOT2018, and LaSOT datasets show that our method can effectively fool the state-of-the-art SiameseRPN++ tracker by adding small perturbations to the template or the search regions. Besides, our method has good transferability and is able to deceive other top-performance trackers such as DaSiamRPN, DaSiamRPN-UpdateNet, and DiMP. The source codes are available at https://github.com/MasterBin-IIAU/CSA.",2020,"B. Yan,Dong Wang,Huchuan Lu,Xiaoyun Yang",Computer Science,50,40
209404866,GlobalTrack: A Simple and Strong Baseline for Long-term Tracking,"A key capability of a long-term tracker is to search for targets in very large areas (typically the entire image) to handle possible target absences or tracking failures. However, currently there is a lack of such a strong baseline for global instance search. In this work, we aim to bridge this gap. Specifically, we propose GlobalTrack, a pure global instance search based tracker that makes no assumption on the temporal consistency of the target's positions and scales. GlobalTrack is developed based on two-stage object detectors, and it is able to perform full-image and multi-scale search of arbitrary instances with only a single query as the guide. We further propose a cross-query loss to improve the robustness of our approach against distractors. With no online learning, no punishment on position or scale changes, no scale smoothing and no trajectory refinement, our pure global instance search based tracker achieves comparable, sometimes much better performance on four large-scale tracking benchmarks (i.e., 52.1% AUC on LaSOT, 63.8% success rate on TLP, 60.3% MaxGM on OxUvA and 75.4% normalized precision on TrackingNet), compared to state-of-the-art approaches that typically require complex post-processing. More importantly, our tracker runs without cumulative errors, i.e., any type of temporary tracking failures will not affect its performance on future frames, making it ideal for long-term tracking. We hope this work will be a strong baseline for long-term tracking and will stimulate future works in this area.",2019,"Lianghua Huang,Xin Zhao,Kaiqi Huang",Computer Science,156,36
208527176,Deep Learning for Visual Tracking: A Comprehensive Survey,"Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years – predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.",2019,"S. M. Marvasti-Zadeh,Li Cheng,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",205,272
207925044,The Seventh Visual Object Tracking VOT2019 Challenge Results,"The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on ""real-time"" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.",2019,"M. Kristan,Jiri Matas,A. Leonardis,M. Felsberg,R. Pflugfelder,Joni-Kristian,Kämäräinen,L. Č. Zajc,O. Drbohlav,A. Lukežič,Amanda Berg,Abdelrahman,Eldesokey,Jani Käpylä,G. Fernandez,Abel Gonzalez-Garcia,Alireza,Memarmoghadam,Andong Lu,Anfeng He,A. Varfolomieiev,Antoni B. Chan,Ardhendu Shekhar,Tripathi,A. Smeulders,Bala Suraj Pedasingu,B. Chen,Baopeng Zhang,Baoyuan Wu,Bi,Li,Bin He,Bin Yan,Bing Bai,Bing Li,Bo Li,B. Kim,Chao Ma,Chen Fang,Chen,Qian,Cheng Chen,Chenglong Li,Chengquan Zhang,Chi-Yi Tsai,Chong Luo,Christian,Micheloni,Chunhui Zhang,D. Tao,Deepak Gupta,Dejia Song,Dong Wang,Efstratios,Gavves,Eunu Yi,F. Khan,Fangyi Zhang,Fei Wang,Fei Zhao,George De,Ath,Goutam Bhat,Guang-Gui Chen,Guangting Wang,Guoxuan Li,Hakan Çevikalp,Hao Du,Haojie,Zhao,Hasan Saribas,Ho Min Jung,Hongliang Bai,Hongyuan Yu,Houwen Peng,Huchuan,Lǔ,Hui Li,Jia-Ke Li,Jianhua Li,Jianlong Fu,Jie Chen,Jie Gao,Jie Zhao,Jin Tang,Jing,Jingjing Wu,Jingtuo Liu,Jinqiao Wang,Jinqing Qi,Jinyue Zhang,John Tsotsos,J. Hyuk,Lee,Joost van de Weijer,J. Kittler,Jun Ha Lee,Junfei Zhuang,Kangkai Zhang,Kangkang,Wang,Kenan Dai,Lei Chen,Lei Liu,Leida Guo,Li Zhang,Liang Wang,Liang Wang,Lichao,Zhang,Lijun Wang,Lijun Zhou,Linyu Zheng,Litu Rout,L. Gool,Luca Bertinetto,Martin,Danelljan,Matteo Dunnhofer,Meng Ni,M. Y. Kim,Ming Tang,Ming-Hsuan Yang,Naveen,Paluru,N. Martinel,Pengfei Xu,Pengfei Zhang,Pengkun Zheng,Pengyu Zhang,S. PhilipH.,Torr,Q. Wang,Qing Guo,R. Timofte,Rama Krishna Sai Subrahmanyam Gorthi,Richard,Everson,Ruize Han,Ruohan Zhang,Shan You,Shaochuan Zhao,Shengwei Zhao,Shihu,Shikun Li,Shiming Ge,Shuai Bai,Shuosen Guan,Tengfei Xing,Tianyang Xu,Tianyu,Yang,Ting Zhang,Tomás Vojír,Wei Feng,Wei Hu,Weizhao Wang,Wenjie Tang,Wenjun,Zeng,Wenyu Liu,Xi Chen,Xi Qiu,Xiang Bai,Xiaojun Wu,Xiaoyun Yang,Xier,Xin Li,Xingyuan Sun,Xingyu Chen,Xinmei Tian,Xuwen Tang,Xuefeng Zhu,Yan-ping Huang,Yanan,Yanchao Lian,Yang Gu,Y. Liu,Yanjie Chen,Yi Zhang,Yinda Xu,Yingming,Yingping Li,Yu Zhou,Yuan Dong,Yufei Xu,Yunhua Zhang,Yunkun Li,Zeyu Zhao,Luo,Zhaoliang Zhang,Zhenhua Feng,Zhenyu He,Zhichao Song,Zhihao Chen,Zhipeng,Zhirong Wu,Zhiwei Xiong,Zhongjian Huang,Zhu Teng,Zihan Ni",Computer Science,366,114
202578069,GradNet: Gradient-Guided Network for Visual Object Tracking,"The fully-convolutional siamese network based on template matching has shown great potentials in visual tracking. During testing, the template is fixed with the initial target feature and the performance totally relies on the general matching ability of the siamese network. However, this manner cannot capture the temporal variations of targets or background clutter. In this work, we propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations. To be specific, the algorithm can utilize the information from the gradient to update the template in the current frame. In addition, a template generalization training method is proposed to better use gradient information and avoid overfitting. To our knowledge, this work is the first attempt to exploit the information in the gradient for template update in siamese-based trackers. Extensive experiments on recent benchmarks demonstrate that our method achieves better performance than other state-of-the-art trackers.",2019,"Peixia Li,Boyu Chen,Wanli Ouyang,Dong Wang,Xiaoyun Yang,Huchuan Lu",Computer Science,198,46
202539960,‘Skimming-Perusal’ Tracking: A Framework for Real-Time and Robust Long-Term Tracking,"Compared with traditional short-term tracking, long-term tracking poses more challenges and is much closer to realistic applications. However, few works have been done and their performance have also been limited. In this work, we present a novel robust and real-time long-term tracking framework based on the proposed skimming and perusal modules. The perusal module consists of an effective bounding box regressor to generate a series of candidate proposals and a robust target verifier to infer the optimal candidate with its confidence score. Based on this score, our tracker determines whether the tracked object being present or absent, and then chooses the tracking strategies of local search or global search respectively in the next frame. To speed up the image-wide global search, a novel skimming module is designed to efficiently choose the most possible regions from a large number of sliding windows. Numerous experimental results on the VOT-2018 long-term and OxUvA long-term benchmarks demonstrate that the proposed method achieves the best performance and runs in real-time. The source codes are available at https://github.com/iiau-tracker/SPLT.",2019,"B. Yan,Haojie Zhao,Dong Wang,Huchuan Lu,Xiaoyun Yang",Computer Science,130,43
69968895,Re2EMA: Regularized and Reinitialized Exponential Moving Average for Target Model Update in Object Tracking,"Target model update plays an important role in visual object tracking. However, performing optimal model update is challenging. In this work, we propose to achieve an optimal target model by learning a transformation matrix from the last target model to the newly generated one, which results into a minimization objective. In this objective, there exists two challenges. The first is that the newly generated target model is unreliable. To overcome this problem, we propose to impose a penalty to limit the distance between the learned target model and the last one. The second is that as time evolves, we can not decide whether the last target model has been corrupted or not. To get out of this dilemma, we propose a reinitialization term. Besides, to control the complexity of the transformation matrix, we also add a regularizer. We find that the optimization formula’s solution, with some simplifications, degenerates to EMA. Finally, despite the simplicity, extensive experiments conducted on several commonly used benchmarks demonstrate the effectiveness of our proposed approach in relatively long term scenarios.",2019,"Jianglei Huang,Wen-gang Zhou",Computer Science,16,38
189927886,MMDetection: Open MMLab Detection Toolbox and Benchmark,"We present MMDetection, an object detection toolbox that contains a rich set of object detection and instance segmentation methods as well as related components and modules. The toolbox started from a codebase of MMDet team who won the detection track of COCO Challenge 2018. It gradually evolves into a unified platform that covers many popular detection methods and contemporary modules. It not only includes training and inference codes, but also provides weights for more than 200 network models. We believe this toolbox is by far the most complete detection toolbox. In this paper, we introduce the various features of this toolbox. In addition, we also conduct a benchmarking study on different methods, components, and their hyper-parameters. We wish that the toolbox and benchmark could serve the growing research community by providing a flexible toolkit to reimplement existing methods and develop their own new detectors. Code and models are available at this https URL. The project is under active development and we will keep this document updated.",2019,"Kai Chen,Jiaqi Wang,Jiangmiao Pang,Yuhang Cao,Yu Xiong,Xiaoxiao Li,Shuyang Sun,Wansen Feng,Ziwei Liu,Jiarui Xu,Zheng Zhang,Dazhi Cheng,Chenchen Zhu,Tianheng Cheng,Qijie Zhao,Buyu Li,Xin Lu,Rui Zhu,Yue Wu,Jifeng Dai,Jingdong Wang,Jianping Shi,Wanli Ouyang,Chen Change Loy,Dahua Lin","Computer Science,Engineering",2047,44
160009490,Hierarchical attentive Siamese network for real-time visual tracking,,2019,"Kang Yang,Huihui Song,Kaihua Zhang,Qingshan Liu",Computer Science,13,49
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
202888990,DCTD: Deep Conditional Target Densities for Accurate Regression,"While deep learning-based classification is generally addressed using standardized approaches, a wide variety of techniques are employed for regression. In computer vision, one particularly popular such technique is that of confidence-based regression, which entails predicting a confidence value for each input-target pair (x, y). While this approach has demonstrated impressive results, it requires important task-dependent design choices, and the predicted confidences often lack a natural probabilistic meaning. We address these issues by proposing Deep Conditional Target Densities (DCTD), a novel and general regression method with a clear probabilistic interpretation. DCTD models the conditional target density p(y|x) by using a neural network to directly predict the un-normalized density from (x, y). This model of p(y|x) is trained by minimizing the associated negative log-likelihood, approximated using Monte Carlo sampling. We perform comprehensive experiments on four computer vision regression tasks. Our approach outperforms direct regression, as well as other probabilistic and confidence-based methods. Notably, our regression model achieves a 1.9% AP improvement over Faster-RCNN for object detection on the COCO dataset, and sets a new state-of-the-art on visual tracking when applied for bounding box regression.",2019,"F. Gustafsson,Martin Danelljan,Goutam Bhat,Thomas Bo Schön","Computer Science,Mathematics",3,60
199405431,Learning the Model Update for Siamese Trackers,"Siamese approaches address the visual tracking problem by extracting an appearance template from the current frame, which is used to localize the target in the next frame. In general, this template is linearly combined with the accumulated template from the previous frame, resulting in an exponential decay of information over time. While such an approach to updating has led to improved results, its simplicity limits the potential gain likely to be obtained by learning to update. Therefore, we propose to replace the handcrafted update function with a method which learns to update. We use a convolutional neural network, called UpdateNet, which given the initial template, the accumulated template and the template of the current frame aims to estimate the optimal template for the next frame. The UpdateNet is compact and can easily be integrated into existing Siamese trackers. We demonstrate the generality of the proposed approach by applying it to two Siamese trackers, SiamFC and DaSiamRPN. Extensive experiments on VOT2016, VOT2018, LaSOT, and TrackingNet datasets demonstrate that our UpdateNet effectively predicts the new target template, outperforming the standard linear update. On the large-scale TrackingNet dataset, our UpdateNet improves the results of DaSiamRPN with an absolute gain of 3.9% in terms of success score.",2019,"Lichao Zhang,Abel Gonzalez-Garcia,Joost van de Weijer,Martin Danelljan,F. Khan",Computer Science,241,51
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
76665153,Tracking Without Bells and Whistles,"The problem of tracking multiple objects in a video sequence poses several challenging tasks. For tracking-by-detection, these include object re-identification, motion prediction and dealing with occlusions. We present a tracker (without bells and whistles) that accomplishes tracking without specifically targeting any of these tasks, in particular, we perform no training or optimization on tracking data. To this end, we exploit the bounding box regression of an object detector to predict the position of an object in the next frame, thereby converting a detector into a Tracktor. We demonstrate the potential of Tracktor and provide a new state-of-the-art on three multi-object tracking benchmarks by extending it with a straightforward re-identification and camera motion compensation. We then perform an analysis on the performance and failure cases of several state-of-the-art tracking methods in comparison to our Tracktor. Surprisingly, none of the dedicated tracking methods are considerably better in dealing with complex tracking scenarios, namely, small and occluded objects or missing detections. However, our approach tackles most of the easy tracking scenarios. Therefore, we motivate our approach as a new tracking paradigm and point out promising future research directions. Overall, Tracktor yields superior tracking performance than any current tracking method and our analysis exposes remaining and unsolved tracking challenges to inspire future research directions.",2019,"Philipp Bergmann,Tim Meinhardt,L. Leal-Taixé",Computer Science,707,70
67856425,Deep High-Resolution Representation Learning for Human Pose Estimation,"In this paper, we are interested in the human pose estimation problem with a focus on learning reliable high-resolution representations. Most existing methods recover high-resolution representations from low-resolution representations produced by a high-to-low resolution network. Instead, our proposed network maintains high-resolution representations through the whole process. We start from a high-resolution subnetwork as the first stage, gradually add high-to-low resolution subnetworks one by one to form more stages, and connect the mutli-resolution subnetworks in parallel. We conduct repeated multi-scale fusions such that each of the high-to-low resolution representations receives information from other parallel representations over and over, leading to rich high-resolution representations. As a result, the predicted keypoint heatmap is potentially more accurate and spatially more precise. We empirically demonstrate the effectiveness of our network through the superior pose estimation results over two benchmark datasets: the COCO keypoint detection dataset and the MPII Human Pose dataset. In addition, we show the superiority of our network in pose tracking on the PoseTrack dataset. The code and models have been publicly available at https://github.com/leoxiaobin/deep-high-resolution-net.pytorch.",2019,"Ke Sun,Bin Xiao,Dong Liu,Jingdong Wang",Computer Science,2889,87
57189581,SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks,"Siamese network based trackers formulate tracking as convolutional feature cross-correlation between target template and searching region. However, Siamese trackers still have accuracy gap compared with state-of-the-art algorithms and they cannot take advantage of feature from deep networks, such as ResNet-50 or deeper. In this work we prove the core reason comes from the lack of strict translation invariance. By comprehensive theoretical analysis and experimental validations, we break this restriction through a simple yet effective spatial aware sampling strategy and successfully train a ResNet-driven Siamese tracker with significant performance gain. Moreover, we propose a new model architecture to perform depth-wise and layer-wise aggregations, which not only further improves the accuracy but also reduces the model size. We conduct extensive ablation studies to demonstrate the effectiveness of the proposed tracker, which obtains currently the best results on four large tracking benchmarks, including OTB2015, VOT2018, UAV123, and LaSOT. Our model will be released to facilitate further studies based on this problem.",2018,"Bo Li,Wei Wu,Qiang Wang,Fangyi Zhang,Junliang Xing,Junjie Yan",Computer Science,1396,55
53712235,ATOM: Accurate Tracking by Overlap Maximization,"While recent years have witnessed astonishing improvements in visual tracking robustness, the advancements in tracking accuracy have been limited. As the focus has been directed towards the development of powerful classifiers, the problem of accurate target state estimation has been largely overlooked. In fact, most trackers resort to a simple multi-scale search in order to estimate the target bounding box. We argue that this approach is fundamentally limited since target estimation is a complex task, requiring high-level knowledge about the object. We address this problem by proposing a novel tracking architecture, consisting of dedicated target estimation and classification components. High level knowledge is incorporated into the target estimation through extensive offline learning. Our target estimation component is trained to predict the overlap between the target object and an estimated bounding box. By carefully integrating target-specific information, our approach achieves previously unseen bounding box accuracy. We further introduce a classification component that is trained online to guarantee high discriminative power in the presence of distractors. Our final tracking framework sets a new state-of-the-art on five challenging benchmarks. On the new large-scale TrackingNet dataset, our tracker ATOM achieves a relative gain of 15% over the previous best approach, while running at over 30 FPS. Code and models are available at https://github.com/visionml/pytracking.",2018,"Martin Danelljan,Goutam Bhat,F. Khan,M. Felsberg",Computer Science,838,43
53102207,GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild,"We introduce here a large tracking database that offers an unprecedentedly wide coverage of common moving objects in the wild, called GOT-10k. Specifically, GOT-10k is built upon the backbone of WordNet structure <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> and it populates the majority of over 560 classes of moving objects and 87 motion patterns, magnitudes wider than the most recent similar-scale counterparts <xref ref-type=""bibr"" rid=""ref19"">[19]</xref>, <xref ref-type=""bibr"" rid=""ref20"">[20]</xref>, <xref ref-type=""bibr"" rid=""ref23"">[23]</xref>, <xref ref-type=""bibr"" rid=""ref26"">[26]</xref>. By releasing the large high-diversity database, we aim to provide a unified training and evaluation platform for the development of class-agnostic, generic purposed short-term trackers. The features of GOT-10k and the contributions of this article are summarized in the following. (1) GOT-10k offers over 10,000 video segments with more than 1.5 million manually labeled bounding boxes, enabling unified training and stable evaluation of deep trackers. (2) GOT-10k is by far the first video trajectory dataset that uses the semantic hierarchy of WordNet to guide class population, which ensures a comprehensive and relatively unbiased coverage of diverse moving objects. (3) For the first time, GOT-10k introduces the <italic>one-shot</italic> protocol for tracker evaluation, where the training and test classes are <italic>zero-overlapped</italic>. The protocol avoids biased evaluation results towards familiar objects and it promotes generalization in tracker development. (4) GOT-10k offers additional labels such as motion classes and object visible ratios, facilitating the development of motion-aware and occlusion-aware trackers. (5) We conduct extensive tracking experiments with 39 typical tracking algorithms and their variants on GOT-10k and analyze their results in this paper. (6) Finally, we develop a comprehensive platform for the tracking community that offers full-featured evaluation toolkits, an online evaluation server, and a responsive leaderboard. The annotations of GOT-10k’s test data are kept private to avoid tuning parameters on it.",2018,"Lianghua Huang,Xin Zhao,Kaiqi Huang","Computer Science,Medicine",906,104
52350875,LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking,"In this paper, we present LaSOT, a high-quality benchmark for Large-scale Single Object Tracking. LaSOT consists of 1,400 sequences with more than 3.5M frames in total. Each frame in these sequences is carefully and manually annotated with a bounding box, making LaSOT the largest, to the best of our knowledge, densely annotated tracking benchmark. The average video length of LaSOT is more than 2,500 frames, and each sequence comprises various challenges deriving from the wild where target objects may disappear and re-appear again in the view. By releasing LaSOT, we expect to provide the community with a large-scale dedicated benchmark with high quality for both the training of deep trackers and the veritable evaluation of tracking algorithms. Moreover, considering the close connections of visual appearance and natural language, we enrich LaSOT by providing additional language specification, aiming at encouraging the exploration of natural linguistic feature for tracking. A thorough experimental evaluation of 35 tracking algorithms on LaSOT is presented with detailed analysis, and the results demonstrate that there is still a big room for improvements.",2018,"Heng Fan,Liting Lin,Fan Yang,Peng Chu,Ge Deng,Sijia Yu,Hexin Bai,Yong Xu,Chunyuan Liao,Haibin Ling",Computer Science,849,60
59222267,The Sixth Visual Object Tracking VOT2018 Challenge Results,,2018,"M. Kristan,A. Leonardis,Jiri Matas,M. Felsberg,R. Pflugfelder,L. Č. Zajc,Tomás Vojír,Goutam Bhat,A. Lukežič,Abdelrahman Eldesokey,G. Fernandez,Álvaro García-Martín,Álvaro Iglesias-Arias,Aydin Alatan,Abel Gonzalez-Garcia,A. Petrosino,Alireza Memarmoghadam,A. Vedaldi,A. Muhic,Anfeng He,A. Smeulders,Asanka G. Perera,Bo Li,Boyu Chen,Changick Kim,Changsheng Xu,Changzhen Xiong,Cheng Tian,Chong Luo,Chong Sun,Cong Hao,Daijin Kim,Deepak Mishra,Deming Chen,Dong Wang,Dongyoon Wee,E. Gavves,Erhan Gundogdu,Erik Velasco-Salido,F. Khan,Fan Yang,Fei Zhao,Feng Li,Francesco Battistone,George De Ath,G. R. S. Subrahmanyam,G. Bastos,Haibin Ling,Hamed Kiani Galoogahi,Hankyeol Lee,Haojie Li,Haojie Zhao,Heng Fan,Honggang Zhang,Horst Possegger,Houqiang Li,Huchuan Lu,Hui Zhi,Huiyun Li,Hyemin Lee,H. Chang,I. Drummond,Jack Valmadre,Jaime Spencer Martin,J. Chahl,J. Choi,Jing Li,Jinqiao Wang,Jinqing Qi,Jinyoung Sung,Joakim Johnander,João F. Henriques,Jongwon Choi,Joost van de Weijer,J. Herranz,J. Sanchez,J. Kittler,Junfei Zhuang,Junyu Gao,Klemen Grm,Lichao Zhang,Lijun Wang,Lingxiao Yang,Litu Rout,Liu Si,Luca Bertinetto,Lutao Chu,Manqiang Che,M. Maresca,Martin Danelljan,Ming-Hsuan Yang,Mohamed H. Abdelpakey,M. Shehata,M. Kang,Namhoon Lee,Ning Wang,O. Mikšík,P. Moallem,Pablo Vicente-Moñivar,P. Senna,Peixia Li,Philip H. S. Torr,Priya Mariam Raju,Ruihe Qian,Qiang Wang,Qin Zhou,Qing Guo,Rafael Martin Nieto,Rama Krishna Sai Subrahmanyam Gorthi,R. Tao,R. Bowden,R. Everson,Runling Wang,Sangdoo Yun,Seokeon Choi,Sergio Vivas,Shuai Bai,Shuangping Huang,Sihang Wu,Simon Hadfield,Siwen Wang,S. Golodetz,Ming Tang,Tianyang Xu,Tianzhu Zhang,Tobias Fischer,V. Santopietro,V. Štruc,Wei Wang,W. Zuo,Wei Feng,Wei Wu,Wei Zou,Weiming Hu,Wen-gang Zhou,W. Zeng,Xiaofan Zhang,Xiaohe Wu,Xiaojun Wu,Xinmei Tian,Yan Li,Yan Lu,Yee Wei Law,Yi Wu,Y. Demiris,Yicai Yang,Yifan Jiao,Yuhong Li,Yunhua Zhang,Yuxuan Sun,Zheng Zhang,Zhengyu Zhu,Zhenhua Feng,Zhihui Wang,Zhiqun He",Computer Science,656,100
52239961,Motion-Guided Cascaded Refinement Network for Video Object Segmentation,"In this work, we propose a motion-guided cascaded refinement network for video object segmentation. By assuming the foreground objects show different motion patterns from the background, for each video frame we apply an active contour model on optical flow to coarsely segment the foreground. The proposed Cascaded Refinement Network (CRN) then takes as guidance the coarse segmentation to generate an accurate segmentation in full resolution. In this way, the motion information and the deep CNNs can complement each other well to accurately segment the foreground objects from video frames. To deal with multi-instance cases, we extend our method with a spatial-temporal instance embedding model that further segments the foreground regions into instances and propagates instance labels. We further introduce a single-channel residual attention module in CRN to incorporate the coarse segmentation map as attention, which makes the network effective and efficient in both training and testing. We perform experiments on popular benchmarks and the results show that our method achieves state-of-the-art performance with high time efficiency.",2020,"Ping Hu,G. Wang,Xiangfei Kong,Jason Kuen,Yap-Peng Tan","Medicine,Computer Science",92,65
214693026,Probabilistic Regression for Visual Tracking,"Visual tracking is fundamentally the problem of regressing the state of the target in each video frame. While significant progress has been achieved, trackers are still prone to failures and inaccuracies. It is therefore crucial to represent the uncertainty in the target estimation. Although current prominent paradigms rely on estimating a state-dependent confidence score, this value lacks a clear probabilistic interpretation, complicating its use. In this work, we therefore propose a probabilistic regression formulation and apply it to tracking. Our network predicts the conditional probability density of the target state given an input image. Crucially, our formulation is capable of modeling label noise stemming from inaccurate annotations and ambiguities in the task. The regression network is trained by minimizing the Kullback-Leibler divergence. When applied for tracking, our formulation not only allows a probabilistic representation of the output, but also substantially improves the performance. Our tracker sets a new state-of-the-art on six datasets, achieving 59.8% AUC on LaSOT and 75.8% Success on TrackingNet. The code and models are available at https://github.com/visionml/pytracking.",2020,"Martin Danelljan,L. Gool,R. Timofte",Computer Science,350,53
211678059,Learning Fast and Robust Target Models for Video Object Segmentation,"Video object segmentation (VOS) is a highly challenging problem since the initial mask, defining the target object, is only given at test-time. The main difficulty is to effectively handle appearance changes and similar background objects, while maintaining accurate segmentation. Most previous approaches fine-tune segmentation networks on the first frame, resulting in impractical frame-rates and risk of overfitting. More recent methods integrate generative target appearance models, but either achieve limited robustness or require large amounts of training data. We propose a novel VOS architecture consisting of two network components. The target appearance model consists of a light-weight module, which is learned during the inference stage using fast optimization techniques to predict a coarse but robust target segmentation. The segmentation model is exclusively trained offline, designed to process the coarse scores into high quality segmentation masks. Our method is fast, easily trainable and remains highly effective in cases of limited training data. We perform extensive experiments on the challenging YouTube-VOS and DAVIS datasets. Our network achieves favorable performance, while operating at higher frame-rates compared to state-of-the-art. Code and trained models are available at https://github.com/andr345/frtm-vos.",2020,"Andreas Robinson,Felix Järemo Lawin,Martin Danelljan,F. Khan,M. Felsberg",Computer Science,113,52
208512936,Siam R-CNN: Visual Tracking by Re-Detection,"We present Siam R-CNN, a Siamese re-detection architecture which unleashes the full power of two-stage object detection approaches for visual object tracking. We combine this with a novel tracklet-based dynamic programming algorithm, which takes advantage of re-detections of both the first-frame template and previous-frame predictions, to model the full history of both the object to be tracked and potential distractor objects. This enables our approach to make better tracking decisions, as well as to re-detect tracked objects after long occlusion. Finally, we propose a novel hard example mining strategy to improve Siam R-CNN's robustness to similar looking objects. Siam R-CNN achieves the current best performance on ten tracking benchmarks, with especially strong results for long-term tracking. We make our code and models available at www.vision.rwth-aachen.de/page/siamrcnn.",2019,"P. Voigtlaender,Jonathon Luiten,Philip H. S. Torr,B. Leibe",Computer Science,381,118
207993627,AGSS-VOS: Attention Guided Single-Shot Video Object Segmentation,"Most video object segmentation approaches process objects separately. This incurs high computational cost when multiple objects exist. In this paper, we propose AGSS-VOS to segment multiple objects in one feed-forward path via instance-agnostic and instance-specific modules. Information from the two modules is fused via an attention-guided decoder to simultaneously segment all object instances in one path. The whole framework is end-to-end trainable with instance IoU loss. Experimental results on Youtube- VOS and DAVIS-2017 dataset demonstrate that AGSS-VOS achieves competitive results in terms of both accuracy and efficiency.",2019,"Huaijia Lin,Xiaojuan Qi,Jiaya Jia",Computer Science,76,26
203593815,Meta Learning with Differentiable Closed-form Solver for Fast Video Object Segmentation,"Video object segmentation plays a vital role to many robotic tasks, beyond the satisfied accuracy, quickly adapt to the new scenario with very limited annotations and conduct a quick inference are also important. In this paper, we are specifically concerned with the task of fast segmenting all pixels of a target object in all frames, given the annotation mask in the first frame. Even when such annotation is available, this remains a challenging problem because of the changing appearance and shape of the object over time. In this paper, we tackle this task by formulating it as a meta-learning problem, where the base learner grasping the semantic scene understanding for a general type of objects, and the meta learner quickly adapting the appearance of the target object with a few examples. Our proposed meta-learning method uses a closed form optimizer, the so-called ""ridge regression"", which has been shown to be conducive for fast and better training convergence. Moreover, we propose a mechanism, named ""block splitting"", to further speed up the training process as well as to reduce the number of learning parameters. In comparison with the state-of-the art methods, our proposed framework achieves significant boost up in processing speed, while having highly comparable performance compared to the best performing methods on the widely used datasets. Video demo can be found here 1.",2019,"Yu Liu,Lingqiao Liu,Haokui Zhang,S. H. Rezatofighi,I. Reid",Computer Science,8,46
201070350,RANet: Ranking Attention Network for Fast Video Object Segmentation,"Despite online learning (OL) techniques have boosted the performance of semi-supervised video object segmentation (VOS) methods, the huge time costs of OL greatly restricts their practicality. Matching based and propagation based methods run at a faster speed by avoiding OL techniques. However, they are limited by sub-optimal accuracy, due to mismatching and drifting problems. In this paper, we develop a real-time yet very accurate Ranking Attention Network (RANet) for VOS. Specifically, to integrate the insights of matching based and propagation based methods, we employ an encoder-decoder framework to learn pixel-level similarity and segmentation in an end-to-end manner. To better utilize the similarity maps, we propose a novel ranking attention module, which automatically ranks and selects these maps for fine-grained VOS performance. Experiments on DAVIS16 and DAVIS17 datasets show that our RANet achieves the best speed-accuracy trade-off, e.g., with 33 milliseconds per frame and J&F=85.5% on DAVIS16. With OL, our RANet reaches J&F=87.1% on DAVIS16, exceeding state-of-the-art VOS methods. The code can be found at https://github.com/Storife/RANet.",2019,"Ziqin Wang,Jun Xu,Li Liu,Fan Zhu,Ling Shao",Computer Science,177,61
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
102351194,Meta-Learning With Differentiable Convex Optimization,"Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.",2019,"Kwonjoon Lee,Subhransu Maji,Avinash Ravichandran,Stefano Soatto",Computer Science,1057,36
90262243,Video Object Segmentation Using Space-Time Memory Networks,"We propose a novel solution for semi-supervised video object segmentation. By the nature of the problem, available cues (e.g. video frame(s) with object masks) become richer with the intermediate predictions. However, the existing methods are unable to fully exploit this rich source of information. We resolve the issue by leveraging memory networks and learn to read relevant information from all available sources. In our framework, the past frames with object masks form an external memory, and the current frame as the query is segmented using the mask information in the memory. Specifically, the query and the memory are densely matched in the feature space, covering all the space-time pixel locations in a feed-forward fashion. Contrast to the previous approaches, the abundant use of the guidance information allows us to better handle the challenges such as appearance changes and occlussions. We validate our method on the latest benchmark sets and achieved the state-of-the-art performance (overall score of 79.4 on Youtube-VOS val set, J of 88.7 and 79.2 on DAVIS 2016/2017 val set respectively) while having a fast runtime (0.16 second/frame on DAVIS 2016 val set).",2019,"Seoung Wug Oh,Joon-Young Lee,N. Xu,Seon Joo Kim",Computer Science,507,47
20289017,A fuzzy rule-based approach for characterization of mammogram masses into BI-RADS shape categories,,2013,"A. Vadivel,B Surendiran","Mathematics,Medicine,Computer Science",69,41
13208853,"Wavelet packet energy, Tsallis entropy and statistical parameterization for support vector-based and neural-based classification of mammographic regions",,2012,"Juan F. Ramirez-Villegas,D. F. Ramirez-Moreno","Mathematics,Computer Science",39,37
261399167,A comparative study of object-level spatial context techniques for semantic image analysis,,2011,"G. Papadopoulos,C. Saathoff,H. J. Escalante,V. Mezaris,Y. Kompatsiaris,M. Strintzis",Computer Science,21,67
1639551,Mammographic mass segmentation: Embedding multiple features in vector-valued level set in ambiguous regions,,2011,"Ying Wang,D. Tao,Xinbo Gao,Xuelong Li,Bin Wang","Mathematics,Computer Science",41,45
5670140,Classification of benign and malignant masses based on Zernike moments,,2011,"Amir Tahmasbi,Fatemeh Saki,S. B. Shokouhi","Mathematics,Medicine,Computer Science",247,54
1946248,Spatial-DiscLDA for visual recognition,"Topic models such as pLSA, LDA and their variants have been widely adopted for visual recognition. However, most of the adopted models, if not all, are unsupervised, which neglected the valuable supervised labels during model training. In this paper, we exploit recent advancement in supervised topic modeling, more particularly, the DiscLDA model for object recognition. We extend it to a part based visual representation to automatically identify and model different object parts. We call the proposed model as Spatial-DiscLDA (S-DiscLDA). It models the appearances and locations of the object parts simultaneously, which also takes the supervised labels into consideration. It can be directly used as a classifier to recognize the object. This is performed by an approximate inference algorithm based on Gibbs sampling and bridge sampling methods. We examine the performance of our model by comparing its performance with another supervised topic model on two scene category datasets, i.e., LabelMe and UIUC-sport dataset. We also compare our approach with other approaches which model spatial structures of visual features on the popular Caltech-4 dataset. The experimental results illustrate that it provides competitive performance.",2011,"Zhenxing Niu,G. Hua,Xinbo Gao,Q. Tian",Computer Science,35,26
3467933,"A survey of vision-based methods for action representation, segmentation and recognition",,2011,"Daniel Weinland,Rémi Ronfard,Edmond Boyer",Computer Science,1051,159
208925415,Spatial-bag-of-features,"In this paper, we study the problem of large scale image retrieval by developing a new class of bag-of-features to encode geometric information of objects within an image. Beyond existing orderless bag-of-features, local features of an image are first projected to different directions or points to generate a series of ordered bag-of-features, based on which different families of spatial bag-of-features are designed to capture the invariance of object translation, rotation, and scaling. Then the most representative features are selected based on a boosting-like method to generate a new bag-of-features-like vector representation of an image. The proposed retrieval framework works well in image retrieval task owing to the following three properties: 1) the encoding of geometric information of objects for capturing objects' spatial transformation, 2) the supervised feature selection and combination strategy for enhancing the discriminative power, and 3) the representation of bag-of-features for effective image matching and indexing for large scale image retrieval. Extensive experiments on 5000 Oxford building images and 1 million Panoramio images show the effectiveness and efficiency of the proposed features as well as the retrieval framework.",2010,"Yang Cao,Changhu Wang,Zhiwei Li,Liqing Zhang,Lei Zhang",Computer Science,244,18
9214098,Mammographic image classification using histogram intersection,"In this paper we propose using histogram intersection for mammographic image classification. First, we use the bag-of-words model for image representation, which captures the texture information by collecting local patch statistics. Then, we propose using normalized histogram intersection (HI) as a similarity measure with the K-nearest neighbor (KNN) classifier. Furthermore, by taking advantage of the fact that HI forms a Mercer kernel, we combine HI with support vector machines (SVM), which further improves the classification performance. The proposed methods are evaluated on a galactographic dataset and are compared with several previously used methods. In a thorough evaluation containing about 288 different experimental configurations, the proposed methods demonstrate promising results.",2010,"Erkang Cheng,Nianhua Xie,Haibin Ling,P. Bakic,Andrew D. A. Maidment,V. Megalooikonomou","Computer Science,Mathematics",35,15
42588979,Classification of benign and malignant patterns in digital mammograms for the diagnosis of breast cancer,,2010,"B. Verma,P. McLeod,A. Klevansky",Computer Science,99,25
16947346,A new automatic method for mass detection in mammography with false positives reduction by supported vector machine,"Mass localization is important in computer-aided detection (CAD) system for the diagnosis of suspicious regions in mammograms. In this paper, we present an automated classification system for the detection of masses in mammographic images. Suspicious regions are located with an adaptive region growing firstly. Then, the initial regions are further refined with narrow band based active contour, which can improve the segmentation accuracy of masses. CLBP (Complete Local Binary Pattern) texture features are extracted from the ROIs (regions of interest) containing the segmented suspicious regions. Finally, the ROIs are classified by means of support vector machine (SVM), with supervision provided by the radiologist's diagnosis. The method was evaluated on a dataset with 231 images, containing 245 masses. Among them, 125 images containing 133 masses are used to optimize the parameters and are used to train SVM. The remaining 106 images are used to test the performance. It obtained 1.36 FPsI at the sensitivity 76.8%. It shows that the proposed method is a promising approach to achieve low FPsI while maintain a high sensitivity.",2011,"Xiaoming Liu,Xin Xu,Jun Liu,Zhilin Feng",Computer Science,21,21
961425,LIBSVM: A library for support vector machines,"LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",2011,"Chih-Chung Chang,Chih-Jen Lin",Computer Science,42944,59
20236563,Effect of Pixel Resolution on Texture Features of Breast Masses in Mammograms,,2010,"R. Rangayyan,T. Nguyen,F. Ayres,A. Nandi","Medicine,Mathematics,Computer Science",29,16
30575633,A Benign and Malignant Mass Classification Algorithm Based on an Improved Level Set Segmentation and Texture Feature Analysis,"In this paper, we investigate the classification of masses with texture features. We propose an improved level set method to find the boundary of a mass, based on the initial contour provided by radiologists. After the boundary of a mass is found, texture features from Gray Level Co-occurrence Matrix (GLCM) are extracted from the surrounding area of the boundary of the mass. The extracted texture features are used as the input of Linear discriminant analysis and a support vector machine to classify the mass as benign or malignant. Mammography images from DDSM were used in the experiments and the classification accuracy was evaluated using the area under the receiver operating characteristic (ROC) curve. In the proposed method the area under the ROC curve is Az =0.7. The experimental result shows the effectiveness of the proposed method.",2010,"Xiaoming Liu,Jun Liu,Dongfeng Zhou,Jinshan Tang",Mathematics,41,14
30215159,A comparison of wavelet and curvelet for breast cancer diagnosis in digital mammogram,,2010,"M. Eltoukhy,I. Faye,S. Belhaouari","Computer Science,Medicine,Mathematics",129,29
11785806,SVM-RFE With MRMR Filter for Gene Selection,"We enhance the support vector machine recursive feature elimination (SVM-RFE) method for gene selection by incorporating a minimum-redundancy maximum-relevancy (MRMR) filter. The relevancy of a set of genes are measured by the mutual information among genes and class labels, and the redundancy is given by the mutual information among the genes. The method improved identification of cancer tissues from benign tissues on several benchmark datasets, as it takes into account the redundancy among the genes during their selection. The method selected a less number of genes compared to MRMR or SVM-RFE on most datasets. Gene ontology analyses revealed that the method selected genes that are relevant for distinguishing cancerous samples and have similar functional properties. The method provides a framework for combining filter methods and wrapper methods of gene selection, as illustrated with MRMR and SVM-RFE methods.",2010,"P. Mundra,Jagath Rajapakse","Medicine,Computer Science",300,39
18476325,Computer-Aided Detection and Diagnosis of Breast Cancer With Mammography: Recent Advances,"Breast cancer is the second-most common and leading cause of cancer death among women. It has become a major health issue in the world over the past 50 years, and its incidence has increased in recent years. Early detection is an effective way to diagnose and manage breast cancer. Computer-aided detection or diagnosis (CAD) systems can play a key role in the early detection of breast cancer and can reduce the death rate among women with breast cancer. The purpose of this paper is to provide an overview of recent advances in the development of CAD systems and related techniques. We begin with a brief introduction to some basic concepts related to breast cancer detection and diagnosis. We then focus on key CAD techniques developed recently for breast cancer, including detection of calcifications, detection of masses, detection of architectural distortion, detection of bilateral asymmetry, image enhancement, and image retrieval.",2009,"Jinshan Tang,R. Rangayyan,Jun Xu,I. El-Naqa,Yongyi Yang","Medicine,Computer Science",603,164
6340275,Normalized Mutual Information Feature Selection,"A filter method of feature selection based on mutual information, called normalized mutual information feature selection (NMIFS), is presented. NMIFS is an enhancement over Battiti's MIFS, MIFS-U, and mRMR methods. The average normalized mutual information is proposed as a measure of redundancy among features. NMIFS outperformed MIFS, MIFS-U, and mRMR on several artificial and benchmark data sets without requiring a user-defined parameter. In addition, NMIFS is combined with a genetic algorithm to form a hybrid filter/wrapper method called GAMIFS. This includes an initialization procedure and a mutation operator based on NMIFS to speed up the convergence of the genetic algorithm. GAMIFS overcomes the limitations of incremental search algorithms that are unable to find dependencies between groups of features.",2009,"P. Estévez,M. Tesmer,C. Pérez,J. Zurada","Medicine,Computer Science",1032,55
771112,Minimization of Region-Scalable Fitting Energy for Image Segmentation,"Intensity inhomogeneities often occur in real-world images and may cause considerable difficulties in image segmentation. In order to overcome the difficulties caused by intensity inhomogeneities, we propose a region-based active contour model that draws upon intensity information in local regions at a controllable scale. A data fitting energy is defined in terms of a contour and two fitting functions that locally approximate the image intensities on the two sides of the contour. This energy is then incorporated into a variational level set formulation with a level set regularization term, from which a curve evolution equation is derived for energy minimization. Due to a kernel function in the data fitting term, intensity information in local regions is extracted to guide the motion of the contour, which thereby enables our model to cope with intensity inhomogeneity. In addition, the regularity of the level set function is intrinsically preserved by the level set regularization term to ensure accurate computation and avoids expensive reinitialization of the evolving level set function. Experimental results for synthetic and real images show desirable performances of our method.",2008,"Yunyun Yang,Chunming Li,C. Kao,S. Osher","Computer Science,Mathematics,Medicine",1735,30
34593701,CAD systems for mammography: a real opportunity? A review of the literature,,2007,"M. Bazzocchi,F. Mazzarella,C. del Frate,F. Girometti,C. Zuiani",Medicine,47,80
69837874,A Comparative Study of Breast Mass Classification based on Spherical Wavelet Transform using ANN and KNN Classifiers,"Breast cancer may be missed by the radiologists at the early ages because of the mammography artifacts. Computer aided diagnosis can decrease the mortality rate by providing a second eye. The artifacts exist due to the noise and the inappropriate contrast in mammograms. Therefore a study that classifies the cropped region of interests (ROI’s) as benign or malign and provides a second eye to the radiologists is proposed. The study consists of two steps: First step is the application of Spherical Wavelet Transform (SWT) to the original ROI matrix prior to feature extraction. Second step is to extract some predetermined pixel and shape features both from wavelet and scaling coefficients. Finally, for classification the prepared feature matrix is given to Artificial Neural Networks (ANN) and K-Nearest Neighbour (KNN) systems which are widely used in image processing. The algorithms are tested on 60 abnormal digitized mammogram ROIs acquised from The Mammographic Image Analysis Society (MIAS) which is a free mammogram database",2012,"P. Gorgel,A. Sertbas,O. Ucan",Computer Science,1,9
42781475,Directional features for automatic tumor classification of mammogram images,,2011,"I. Buciu,Alexandru Gacsádi","Mathematics,Computer Science",113,33
5670140,Classification of benign and malignant masses based on Zernike moments,,2011,"Amir Tahmasbi,Fatemeh Saki,S. B. Shokouhi","Mathematics,Medicine,Computer Science",247,54
23315331,A Wavelet-Based Mammographic Image Denoising and Enhancement with Homomorphic Filtering,,2010,"P. Gorgel,A. Sertbas,O. Ucan","Computer Science,Medicine",49,22
30215159,A comparison of wavelet and curvelet for breast cancer diagnosis in digital mammogram,,2010,"M. Eltoukhy,I. Faye,S. Belhaouari","Computer Science,Medicine,Mathematics",129,29
21612083,Classification of breast tissues using Moran's index and Geary's coefficient as texture signatures and SVM,,2009,"G. B. Junior,A. Paiva,A. Silva,A. Oliveira","Medicine,Computer Science",75,27
6238557,Breast Cancer Diagnosis: Analyzing Texture of Tissue Surrounding Microcalcifications,"The current study investigates texture properties of the tissue surrounding microcalcification (MC) clusters on mammograms for breast cancer diagnosis. The case sample analyzed consists of 85 dense mammographic images, originating from the digital database for screening mammography. mammograms analyzed contain 100 subtle MC clusters (46 benign and 54 malignant). The tissue surrounding MCs is defined on original and wavelet decomposed images, based on a redundant discrete wavelet transform. Gray-level texture and wavelet coefficient texture features at three decomposition levels are extracted from surrounding tissue regions of interest (ST-ROIs). Specifically, gray-level first-order statistics, gray-level cooccurrence matrices features, and Lawspsila texture energy measures are extracted from original image ST-ROIs. Wavelet coefficient first-order statistics and wavelet coefficient cooccurrence matrices features are extracted from subimages ST-ROIs. The ability of each feature set in differentiating malignant from benign tissue is investigated using a probabilistic neural network. Classification outputs of most discriminating feature sets are combined using a majority voting rule. The proposed combined scheme achieved an area under receiver operating characteristic curve (Az) of 0.989. Results suggest that MCspsila ST texture analysis can contribute to computer-aided diagnosis of breast cancer.",2008,"A. Karahaliou,I. Boniatis,S. Skiadopoulos,Filippos Sakellaropoulos,N. Arikidis,E. Likaki,George Panayiotakis,L. Costaridou","Medicine,Computer Science",130,46
6264088,A multi-stage neural network aided system for detection of microcalcifications in digitized mammograms,,2008,"N. Pal,B. Bhowmick,Sanjaya K. Patel,S. Pal,J. Das",Computer Science,65,20
3162373,Morphological Component Analysis and Inpainting on the Sphere: Application in Physics and Astrophysics,,2007,"P. Abrial,Y. Moudden,Jean-Luc Starck,B. Afeyan,J. Bobin,J. Fadili,Maï K. Nguyen",Mathematics,66,69
43258899,Ontology-based mammography annotation and Case-based Retrieval of breast masses,,2012,"Hakan Bulu,A. Alpkocak,P. Balcı",Computer Science,13,13
11770931,Mammogram retrieval on similar mass lesions,,2012,"Chia-Hung Wei,Sherry Y. Chen,Xiaohui Liu","Medicine,Computer Science",67,33
27066789,Spot addressing for microarray images structured in hexagonal grids,,2012,"N. Giannakeas,F. Kalatzis,M. Tsipouras,D. Fotiadis","Computer Science,Medicine",16,27
5695347,An algorithm for calculi segmentation on ureteroscopic images,,2011,"Benoît Rosa,P. Mozer,J. Szewczyk","Computer Science,Medicine",14,24
26561892,Hybrid segmentation of mass in mammograms using template matching and dynamic programming.,,2010,"E. Song,Shengzhou Xu,Xiangyang Xu,Jianye Zeng,Yihua Lan,Shenyi Zhang,C. Hung","Computer Science,Medicine",38,33
12268967,Multilevel learning-based segmentation of ill-defined and spiculated masses in mammograms.,"PURPOSE
A learning-based approach integrating the use of pixel-level statistical modeling and spiculation detection is presented for the segmentation of mammographic masses with ill-defined margins and spiculations.


METHODS
The algorithm involves a multiphase pixel-level classification, using a comprehensive group of features computed from regional intensity, shape, and textures, to generate a mass-conditional probability map (PM). Then, the mass candidate, along with the background clutters consisting of breast fibroglandular and other nonmass tissues, is extracted from the PM by integrating the prior knowledge of shape and location of masses. A multiscale steerable ridge detection algorithm is employed to detect spiculations. Finally, all the object-level findings, including mass candidate, detected spiculations, and clutters, along with the PM, are integrated by graph cuts to generate the final segmentation mask.


RESULTS
The method was tested on 54 masses (51 malignant and 3 benign), all with ill-defined margins and irregular shape or spiculations. The ground truth delineations were provided by five experienced radiologists. Area overlapping ratio of 0.689 (±0.160) and 0.540 (±0.164) were obtained for segmenting entire mass and margin portion only, respectively. Williams index of area and contour based measurements indicated that the segmentation results of the algorithm agreed well with the radiologists' delineation.


CONCLUSIONS
The proposed approach could closely delineate the mass body. Most importantly, it is capable of including mass margin and its spicule extensions which are considered as key features for breast lesion analyses.",2010,"Yimo Tao,S. Lo,M. Freedman,E. Makariou,J. Xuan","Computer Science,Medicine",22,25
19506186,Contour tracing for segmentation of mammographic masses,"CADx systems have the potential to support radiologists in the difficult task of discriminating benign and malignant mammographic lesions. The segmentation of mammographic masses from the background tissue is an important module of CADx systems designed for the characterization of mass lesions. In this work, a novel approach to this task is presented. The segmentation is performed by automatically tracing the mass' contour in-between manually provided landmark points defined on the mass' margin. The performance of the proposed approach is compared to the performance of implementations of three state-of-the-art approaches based on region growing and dynamic programming. For an unbiased comparison of the different segmentation approaches, optimal parameters are selected for each approach by means of tenfold cross-validation and a genetic algorithm. Furthermore, segmentation performance is evaluated on a dataset of ROI and ground-truth pairs. The proposed method outperforms the three state-of-the-art methods. The benchmark dataset will be made available with publication of this paper and will be the first publicly available benchmark dataset for mass segmentation.",2010,"M. Elter,C. Held,T. Wittenberg","Physics,Computer Science,Medicine",18,38
99055,State-of-the-Art of Computer-Aided Detection/Diagnosis (CAD),,2010,"H. Fujita,J. You,Qin Li,H. Arimura,R. Tanaka,S. Sanada,N. Niki,Gobert N. Lee,T. Hara,D. Fukuoka,C. Muramatsu,T. Katafuchi,G. Iinuma,M. Miyake,Y. Arai,N. Moriyama","Computer Science,Medicine",13,19
6424609,A comparison of two methods for the segmentation of masses in the digital mammograms,,2010,"R. Dubey,M. Hanmandlu,S. Gupta","Computer Science,Medicine",44,18
5563547,A review of automatic mass detection and segmentation in mammographic images,,2010,"A. Oliver,J. Freixenet,J. Martí,Elsa Pérez,J. Pont,E. Denton,R. Zwiggelaar","Computer Science,Medicine",410,276
12660679,Mass computer-aided diagnosis method in mammogram based on texture features,"Computer-aided diagnosis (CAD) system can promote the detection accuracy by providing a “second opinion” to the radiologist, so high accuracy detection of mass in mammogram is critical for improving the performance and efficiency. In this paper, we designed a mass auto-diagnosis method in mammogram based on texture features. First, the mass was detected base on bilateral comparison, and the center of region of interest (ROI) was located. Second, fractal dimension and two-dimensional entropy were calculated as the texture features. Last, the kinds of ROI were diagnosed by Support Vector Machine (SVM), mass or normal region. A total of 106 prior mammograms were automatically detected, experimental results indicate that mass and suspected region have obvious difference in the fractal dimension and other texture features, and SVM is an effective classify method, and reduce the error rate in the mass detection, and the performance of the method is a sensitivity of 85.11% at 1.44 false positives per image.",2010,"Li Ke,Nannan Mu,Yan Kang",Computer Science,31,14
16560599,Breast density classification using histogram moments of multiple resolution mammograms,"Breast density is a strong indicator for breast cancer, which can be assessed by experienced radiologists using mammograms. In this paper, an automatic approach for breast density classification is studied. Mammographic images are pre-processed to separate breast tissues from the background using intensity and morphology-based algorithms. Histograms of multiple resolution mammograms are calculated on the processed images. The statistical moments are retrieved from the multiple resolution histograms, which are employed as the breast density features. The support vector machine (SVM) techniques are implemented onto the feature space to classify the mammograms into different density categories. Experiments on a public dataset verify the performance of the proposed method.",2010,"Li Liu,Jian Wang,Kai He",Mathematics,22,14
15832152,Hybrid Mammogram Classification Using Rough Set and Fuzzy Classifier,"We propose a computer aided detection (CAD) system for the detection and classification of suspicious regions in mammographic images. This system combines a dimensionality reduction module (using principal component analysis), a feature extraction module (using independent component analysis), and a feature subset selection module (using rough set model). Rough set model is used to reduce the effect of data inconsistency while a fuzzy classifier is integrated into the system to label subimages into normal or abnormal regions. The experimental results show that this system has an accuracy of 84.03% and a recall percentage of 87.28%.",2009,"F. Abu-Amara,I. Abdel-Qader","Computer Science,Medicine",21,25
1828046,Trademark image retrieval using synthetic features for describing global shape and interior structure,,2009,"Chia-Hung Wei,Yue Li,W. Chau,Chang-Tsun Li",Computer Science,216,35
36794296,A novel hybrid intelligent method based on C4.5 decision tree classifier and one-against-all approach for multi-class classification problems,,2009,"K. Polat,S. Günes",Computer Science,263,11
15487114,Region-based image retrieval with high-level semantics using decision tree learning,,2008,"Y. Liu,Dengsheng Zhang,Guojun Lu",Computer Science,164,41
62098430,Texture Features Selection for Masses Detection In Digital Mammogram,,2008,"A. M. Khuzi,R. Besar,W. Zaki",Computer Science,30,7
36979378,A Statistical-Genetic Algorithm to Select the Most Significant Features in Mammograms,,2007,"Gonzalo Vegas-Sánchez-Ferrero,J. I. Arribas","Computer Science,Mathematics",10,17
5563547,A review of automatic mass detection and segmentation in mammographic images,,2010,"A. Oliver,J. Freixenet,J. Martí,Elsa Pérez,J. Pont,E. Denton,R. Zwiggelaar","Computer Science,Medicine",410,276
1828046,Trademark image retrieval using synthetic features for describing global shape and interior structure,,2009,"Chia-Hung Wei,Yue Li,W. Chau,Chang-Tsun Li",Computer Science,216,35
64004863,Artificial Intelligence for Maximizing Content Based Image Retrieval,"The increasing trend of multimedia data use is likely to accelerate creating an urgent need of providing a clear means of capturing, storing, indexing, retrieving, analyzing, and summarizing data through image data.Artificial Intelligence for Maximizing Content Based Image Retrieval discusses major aspects of content-based image retrieval (CBIR) using current technologies and applications within the artificial intelligence (AI) field. Providing state-of-the-art research from leading international experts, this book offers a theoretical perspective and practical solutions for academicians, researchers, and industry practitioners.",2008,Zongmin Ma,Computer Science,19,0
394880,Characterization of mammographic masses using a gradient-based segmentation algorithm and a neural classifier,,2007,"P. Delogu,M. Fantacci,P. Kasae,A. Retico","Physics,Medicine,Computer Science",85,58
18595695,Multi-scaled morphological features for the characterization of mammographic masses using statistical classification schemes,,2007,"H. Georgiou,M. Mavroforakis,N. Dimitropoulos,D. Cavouras,S. Theodoridis","Computer Science,Medicine",52,74
10061564,The association between mammographic breast density and bone mineral density in the study of women's health across the nation.,,2007,"C. Crandall,Yan Zheng,A. Karlamangla,B. Sternfeld,L. Habel,N. Oestreicher,J. Johnston,J. Cauley,G. Greendale",Medicine,13,41
205452569,A new class of Zernike moments for computer vision applications,,2007,"G. Papakostas,Y. Boutalis,Dimitrios Alexios Karras,Basil G. Mertzios","Mathematics,Computer Science",117,33
490787,Determination of subjective similarity for pairs of masses and pairs of clustered microcalcifications on mammograms: comparison of similarity ranking scores and absolute similarity ratings.,"The presentation of images that are similar to that of an unknown lesion seen on a mammogram may be helpful for radiologists to correctly diagnose that lesion. For similar images to be useful, they must be quite similar from the radiologists' point of view. We have been trying to quantify the radiologists' impression of similarity for pairs of lesions and to establish a ""gold standard"" for development and evaluation of a computerized scheme for selecting such similar images. However, it is considered difficult to reliably and accurately determine similarity ratings, because they are subjective. In this study, we compared the subjective similarities obtained by two different methods, an absolute rating method and a 2-alternative forced-choice (2AFC) method, to demonstrate that reliable similarity ratings can be determined by the responses of a group of radiologists. The absolute similarity ratings were previously obtained for pairs of masses and pairs of microcalcifications from five and nine radiologists, respectively. In this study, similarity ranking scores for eight pairs of masses and eight pairs of microcalcifications were determined by use of the 2AFC method. In the first session, the eight pairs of masses and eight pairs of microcalcifications were grouped and compared separately for determining the similarity ranking scores. In the second session, another similarity ranking score was determined by use of mixed pairs, i.e., by comparison of the similarity of a mass pair with that of a calcification pair. Four pairs of masses and four pairs of microcalcifications were grouped together to create two sets of eight pairs. The average absolute similarity ratings and the average similarity ranking scores showed very good correlations in the first study (Pearson's correlation coefficients: 0.94 and 0.98 for masses and microcalcifications, respectively). Moreover, in the second study, the correlations between the absolute ratings and the ranking scores were also very high (0.92 and 0.96), which implies that the observers were able to compare the similarity of a mass pair with that of a calcification pair consistently. These results provide evidence that the concept of similarity for pairs of images is robust, even across different lesion types, and that radiologists are able to reliably determine subjective similarity for pairs of breast lesions.",2007,"C. Muramatsu,Qiang Li,R. Schmidt,J. Shiraishi,Kenji Suzuki,G. Newstead,K. Doi","Mathematics,Medicine",42,29
33211037,On the computational aspects of Zernike moments,,2007,"Chong-Yaw Wee,R. Paramesran","Mathematics,Computer Science",153,25
21716007,Computer-aided detection of mammographic masses based on content-based image retrieval,"A method for computer-aided detection (CAD) of mammographic masses is proposed and a prototype CAD system is presented. The method is based on content-based image retrieval (CBIR). A mammogram database containing 2000 mammographic regions is built in our prototype CBIR-CAD system. Every region of interested (ROI) in the database has known pathology. Specifically, there are 583 ROIs depicting biopsy-proven masses, and the rest 1417 ROIs are normal. Whenever a suspicious ROI is detected in a mammogram by a radiologist, it can be submitted as a query to this CBIRCAD system. As the query results, a series of similar ROI images together with their known pathology knowledge will be retrieved from the database and displayed in the screen in descending order of their similarities to the query ROI to help the radiologist to make the diagnosis decision. Furthermore, our CBIR-CAD system will output a decision index (DI) to quantitatively indicate the probability that the query ROI contains a mass. The DI is calculated by the query matches. In the querying process, 24 features are extracted from each ROI to form a 24-dimensional vector. Euclidean distance in the 24-dimensional feature vector space is applied to measure the similarities between ROIs. The prototype CBIR-CAD system is evaluated based on the leave-one-out sampling scheme. The experiment results showed that the system can achieve a receiver operating characteristic (ROC) area index AZ =0.84 for detection of mammographic masses, which is better than the best results achieved by the other known mass CAD systems.",2007,"Renchao Jin,Bo Meng,E. Song,Xiangyang Xu,Luan Jiang","Computer Science,Engineering",7,15
7425921,Pattern recognition using pulse-coupled neural networks and discrete Fourier transforms,,2003,R. Muresan,Computer Science,83,16
559831,Bayesian MLP neural networks for image analysis,,2000,"Aki Vehtari,J. Lampinen",Computer Science,48,14
110007042,Efficient control chart pattern recognition through synergistic and distributed artificial neural networks,"Abstract Accurate and fast control chart pattern recognition is essential for efficient system monitoring to maintain the production of high-quality goods. This paper addresses three major issues of control chart pattern recognition: (a) transparency, (b) accuracy and (c) fast detection of abnormal patterns. A new approach is described which uses novel shape features extracted from a control chart pattern (CCP) instead of the unprocessed CCP data or its statistical properties. These features represent the shape of the CCP explicitly. A set of algorithms is described for extraction of the shape features from a CCP. The paper discusses the use of artificial neural networks for recognition of the shape features. Synergistic, distributed and distributed synergistic neural networks are proposed for learning efficiently non-linear characteristics and overlapping ranges of values of the data set describing CCPs. The paper presents the results of analysing several hundred control chart patterns and gives a comparison with those reported in previous work.",1999,"M. Wani,D. Pham",Engineering,26,19
62358690,Neural networks for image analysis,"The author discusses three applications of neural networks to image processing: the silicon retina of C.A. Mead and M.A. Mahowald (1988); a method of echo inversion described by N.H. Farhat and B. Bai (1989); and the fingerprint recognition method of M.-T. Leung et al. (1990). Mead's work is significant because it forms a front-end for image analysis with a morphology modeled on the eye. Farhat's group has down work on the use of neural networks in image reconstruction. A description of some of this is included because it concerns the regularization of an inverse problem, which is similar to many ultrasonic, medical, and geophysical imaging applications. The method of M.-T. Leung et al. is noteworthy not only as an example of neuromorphic image processing, but also because the representation of the data is inspired by measurements of the mammalian brain. Current areas of research in ultrasonic applications of neural networks are discussed.<<ETX>>",1990,C. Daft,Computer Science,9,11
124585677,Computer Image Processing,,1979,R. Bracewell,Physics,88,6
8588592,A Versatile Machine Vision System for Complex Industrial Parts,"As a step to automate assembly of various industrial parts, this paper describes a versatile machine vision system that can recognize a variety of complex industrial parts and measure the necessary parameters for assembly, such as the locations of screw holes. Emphasis is given to a method for extracting useful features from the scene data for complex industrial parts so that accurate recognition of them is possible. The proposed method has the following features: 1) simple features are detected first in the scene and more complex features are examined later, using the locations of the previously found features; 2) the system is provided with a high-level supervisor that analyzes the current information obtained from the scene and structural models of various objects, and proposes the feartures to be examined next for recognizing the objects in the scene; 3) the supervisor has problem-solving capabilities to select the most promising feature among many others; 4) the structural models are used to suggest the locations of the features to be examined; and 5) several sophisticated feature extractors are used to detect the complex features. An effort is also made to make the system versatile so that it can be readily applied to a variety of different industrial parts. The proposed system has been tested on several sets of parts for small industrial gasoline engines and the results were satisfactory.",1977,"M. Yachida,S. Tsuji",Computer Science,72,15
192934,Statistical Pattern Recognition: A Review,"The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.",2000,"Anil K. Jain,R. Duin,J. Mao",Computer Science,6749,239
1616522,Issues in Stacked Generalization,"Stacked generalization is a general method of using a high-level model to combine lower-level models to achieve greater predictive accuracy. In this paper we address two crucial issues which have been considered to be a 'black art' in classification tasks ever since the introduction of stacked generalization in 1992 by Wolpert: the type of generalizer that is suitable to derive the higher-level model, and the kind of attributes that should be used as its input. We find that best results are obtained when the higher-level model combines the confidence (and not just the predictions) of the lower-level ones. 
 
We demonstrate the effectiveness of stacked generalization for combining three different types of learning algorithms for classification tasks. We also compare the performance of stacked generalization with majority vote and published results of arcing and bagging.",2011,"K. Ting,I. Witten",Computer Science,695,30
8664587,Building multiple weak segmentors for strong mass segmentation in mammogram,"This paper proposes to build multiple segmentations for identifying mass contours for a suspicious mass in a mammogram. In this study, by using various parameter settings of the image enhancement functions, we perform multiple segmentations for each suspicious mass (region of interest (ROI)), and multiple mass contours are generated. Each of such segmentations is called a ""weak segmentor"", since there is no single image enhancement which produces the optimal segmentation for all mass images. Then for each image, we select the contour which has the highest overlapping ratio as the final segmentation (i.e., the ""strong segmentor""). The results show that the overall success rate (81.22%) of the strong segmentor was higher than that of any single weak segmentor. This indicates that using multiple weak segmentors is an effective method to generate a strong mass segmentation for mammograms.",2011,"Yu Zhang,Noriko Tomuro,J. Furst,D. Raicu","Computer Science,Engineering",2,20
267269531,Toward breast cancer diagnosis based on automated segmentation of masses in mammograms,,2009,"A. R. Domínguez,A. Nandi",Computer Science,6,49
36615468,Breast Mass Segmentation in Mammographic Images by an Effective Region Growing Algorithm,,2008,"A. Mencattini,G. Rabottino,M. Salmeri,R. Lojacono,E. Colini",Computer Science,44,12
17188537,A dual-stage method for lesion segmentation on digital mammograms.,"Mass lesion segmentation on mammograms is a challenging task since mass lesions are usually embedded and hidden in varying densities of parenchymal tissue structures. In this article, we present a method for automatic delineation of lesion boundaries on digital mammograms. This method utilizes a geometric active contour model that minimizes an energy function based on the homogeneities inside and outside of the evolving contour. Prior to the application of the active contour model, a radial gradient index (RGI)-based segmentation method is applied to yield an initial contour closer to the lesion boundary location in a computationally efficient manner. Based on the initial segmentation, an automatic background estimation method is applied to identify the effective circumstance of the lesion, and a dynamic stopping criterion is implemented to terminate the contour evolution when it reaches the lesion boundary. By using a full-field digital mammography database with 739 images, we quantitatively compare the proposed algorithm with a conventional region-growing method and an RGI-based algorithm by use of the area overlap ratio between computer segmentation and manual segmentation by an expert radiologist. At an overlap threshold of 0.4, 85% of the images are correctly segmented with the proposed method, while only 69% and 73% of the images are correctly delineated by our previous developed region-growing and RGI methods, respectively. This resulting improvement in segmentation is statistically significant.",2007,"Yading Yuan,M. Giger,Hui Li,Kenji Suzuki,C. Sennett","Computer Science,Medicine",113,38
394880,Characterization of mammographic masses using a gradient-based segmentation algorithm and a neural classifier,,2007,"P. Delogu,M. Fantacci,P. Kasae,A. Retico","Physics,Medicine,Computer Science",85,58
13118104,Approaches for automated detection and classification of masses in mammograms,,2006,"Heng-Da Cheng,Xiangjun Shi,R. Min,Liming Hu,Xiaopeng Cai,H. Du","Medicine,Computer Science",497,208
72957044,Computer-Aided Detection and Diagnosis in Mammography,,2005,"M. Sampat,M. Markey,A. Bovik",Computer Science,330,128
62520273,Application Of t-Cherry Junction Trees in Pattern Recognition,Pattern recognition aims to classify data (patterns) based ei- ther on a priori knowledge or on statistical information extracted from the data. In this paper we will concentrate on statistical pattern recognition using a new probabilistic approach which makes possible to select the so called 'informative' features. We develop a pattern recognition algorithm which is based on the conditional independence structure underlying the statistical data. Our method was succesfully applied on a real problem of recognizing Parkinson's disease on the basis of voice disorders.,2010,"E. Kovács,T. Szántai",Computer Science,7,0
122284235,Upper bounds for the probability of a union by multitrees,"The problem of finding bounds for P(A 1 ∪ ⋯ ∪ A n ) based on P(A k 1 ∩ ⋯ ∩ A k i ) (1 ≤ k 1 < ⋯ < k i ≤ n, i = 1,…,d) goes back to Boole (1854), (1868) and Bonferroni (1937). In this paper upper bounds are presented using methods in graph theory. The main theorem is a common generalization of the earlier results of Hunter, Worsley and recent results of Prékopa and the author. Algorithms are given to compute bounds. Examples for bounding values of multivariate normal distribution functions are presented.",2001,J. Bukszár,Mathematics,12,16
35440944,Probability Bounds with Cherry Trees,"A third order upper bound is presented on the probability of the union of a finite number of events, by means of graphs called cherry trees. These are graphs that we construct recursively in such a way that every time we pick a new vertex, connect it with two already existing vertices. If the latters are always adjacent, we call the cherry tree a t-cherry tree. A cherry tree has a weight that provides us with the upper bound on the union. Any Hunter-Worsley bound can be majorized by a t-cherry bound constructed by the use of the Hunter-Worsley tree. A cherry tree bound can be identified as a feasible solution to the dual of the Boolean probability bounding problem. A t-cherry tree bound can be identified as the objective function value of the dual vector corresponding to a dual feasible basis in the Boolean problem. This enables us to improve on the bound algorithmically, if we use the dual method of linear programming.",2001,"J. Bukszár,A. Prékopa","Mathematics,Computer Science",74,14
1641118,A new approach for learning belief networks using independence criteria,,2000,"L. M. D. Campos,J. Huete","Computer Science,Mathematics",122,31
32379969,Probabilistic Networks and Expert Systems,,1999,"R. Cowell,A. Dawid,S. Lauritzen,D. Spiegelhalter","Mathematics,Computer Science",1968,286
41024324,Expert Systems and Probabilistic Network Models,,1996,"E. Castillo,J. Gutiérrez,A. Hadi","Engineering,Computer Science",771,209
206605576,Content Extraction and Interpretation of Superimposed Captions for Broadcasted Sports Videos,"This paper illustrates how to interpret the superimposed caption box (SCB) in broadcasted sports videos of which the SCB template is presumably not given as a priori. The embedded captions in sports video programs represent digested key information of the video content. Most of the previous studies assume that the SCB template and the character bitmaps are known. The major contributions of this paper are (1) caption template extraction and identification, (2) symbol extraction and modeling, and (3) semantic interpretation of the identified captions and symbols. Experimental results show that the algorithm performs the SCB contents understanding for several commercial sports video programs.",2008,"H. Shih,Chung-Lin Huang",Computer Science,14,38
46176,A Novel Framework for Semantic Annotation and Personalized Retrieval of Sports Video,"Sports video annotation is important for sports video semantic analysis such as event detection and personalization. In this paper, we propose a novel approach for sports video semantic annotation and personalized retrieval. Different from the state of the art sports video analysis methods which heavily rely on audio/visual features, the proposed approach incorporates web-casting text into sports video analysis. Compared with previous approaches, the contributions of our approach include the following. 1) The event detection accuracy is significantly improved due to the incorporation of web-casting text analysis. 2) The proposed approach is able to detect exact event boundary and extract event semantics that are very difficult or impossible to be handled by previous approaches. 3) The proposed method is able to create personalized summary from both general and specific point of view related to particular game, event, player or team according to user's preference. We present the framework of our approach and details of text analysis, video analysis, text/video alignment, and personalized retrieval. The experimental results on event boundary detection in sports video are encouraging and comparable to the manually selected events. The evaluation on personalized retrieval is effective in helping meet users' expectations.",2008,"Changsheng Xu,Jinjun Wang,Hanqing Lu,Yifan Zhang",Computer Science,138,52
19061091,"Integrated Mining of Visual Features, Speech Features, and Frequent Patterns for Semantic Video Annotation","To support effective multimedia information retrieval, video annotation has become an important topic in video content analysis. Existing video annotation methods put the focus on either the analysis of low-level features or simple semantic concepts, and they cannot reduce the gap between low-level features and high-level concepts. In this paper, we propose an innovative method for semantic video annotation through integrated mining of visual features, speech features, and frequent semantic patterns existing in the video. The proposed method mainly consists of two main phases: 1) Construction of four kinds of predictive annotation models, namely speech-association, visual-association, visual-sequential, and statistical models from annotated videos. 2) Fusion of these models for annotating un-annotated videos automatically. The main advantage of the proposed method lies in that all visual features, speech features, and semantic patterns are considered simultaneously. Moreover, the utilization of high-level rules can effectively complement the insufficiency of statistics-based methods in dealing with complex and broad keyword identification in video annotation. Through empirical evaluation on NIST TRECVID video datasets, the proposed approach is shown to enhance the performance of annotation substantially in terms of precision, recall, and F-measure.",2008,"V. Tseng,Ja-Hwung Su,Jhih-Hong Huang,Chih-Jen Chen",Computer Science,62,34
17510421,Event detection in field sports video using audio-visual features and a support vector Machine,"In this paper, we propose a novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports. Features indicating significant events are selected and robust detectors built. These features are rooted in characteristics common to all genres of field sports. The evidence gathered by the feature detectors is combined by means of a support vector machine, which infers the occurrence of an event based on a model generated during a training phase. The system is tested generically across multiple genres of field sports including soccer, rugby, hockey, and Gaelic football and the results suggest that high event retrieval and content rejection statistics are achievable.",2005,"D. A. Sadlier,N. O’Connor",Computer Science,255,44
14695418,Generic slow-motion replay detection in sports video,"Slow-motion replays highlight important and exciting events in sports videos. Previous works for slow-motion replay detection, however, are usually limited to only some specific production rules such as frame repetition, special video effects and transitions. In this paper, we present a generic method for detecting slow-motion replays in sports video based on the difference of motions between slow-motion replays and normal shots within the same shot class. Experiments on different types of sports videos have verified our approach and achieve reasonable results.",2004,"Lei Wang,X. Liu,Steve Lin,Guangyou Xu,H. Shum",Computer Science,31,12
8968963,Offense based temporal segmentation for event detection in soccer video,"Sports video is regarded as a good testing bed for techniques on content based video analysis and processing. Although partially successful systems have been designed for specific sports domains with limited data, most previous works do not adequately address the problem of temporal segmentation for event detection, nor the event representation problem. In this paper, we present an analysis of soccer video for detecting the semantic notion of <i>offense</i>. It is not only useful as a new semantic concept of sports video analysis, but also provides temporal segmentation for video event detection and representation. We propose a system to detect the offensive unit in soccer video automatically. The offensive unit is then used to calculate new semantics like <i>possession</i>, as well as to detect goal events in video. Experimental results on various sources of soccer video have verified that our approach extracts the new semantic notions successfully and facilitates video event detection and representation",2004,"Lei Wang,M. Lew,Guangyou Xu",Computer Science,21,29
15623660,The power of play-break for automatic detection and browsing of self-consumable sport video highlights,"To enable content-based retrieval, highlights extraction from broadcasted sport video has been an active research topic in the last decade. There is a well-known theory that high-level semantic, such as goal in soccer can be detected based on the occurrences of specific audio and visual features that can be extracted automatically. However, there is yet a definitive solution for the scope (i.e. start and end) of the detection for self-consumable highlights. Thus, in this paper we will primarily demonstrate the benefits of using play-break for this purpose. Moreover, we also propose a browsing scheme that is based on integrated play-break and highlights (extended from [1]). To validate our approach, we will present the results from some experiments and a user study",2004,"D. Tjondronegoro,Yi-Ping Phoebe Chen,Binh Pham",Computer Science,37,14
15640100,Highlights for more complete sports video summarization,"Summarization is an essential requirement for achieving a more compact and interesting representation of sports video contents. We propose a framework that integrates highlights into play segments and reveal why we should still retain breaks. Experimental results show that fast detections of whistle sounds, crowd excitement, and text boxes can complement existing techniques for play-breaks and highlights localization.",2004,"D. Tjondronegoro,Yi-Ping Phoebe Chen,Binh Pham",Computer Science,82,17
12877042,Semantic indexing of soccer audio-visual sequences: a multimodal approach based on controlled Markov chains,"Content characterization of sport videos is a subject of great interest to researchers working on the analysis of multimedia documents. In this paper, we propose a semantic indexing algorithm which uses both audio and visual information for salient event detection in soccer. The video signal is processed first by extracting low-level visual descriptors directly from an MPEG-2 bit stream. It is assumed that any instance of an event of interest typically affects two consecutive shots and is characterized by a different temporal evolution of the visual descriptors in the two shots. This motivates the introduction of a controlled Markov chain to describe such evolution during an event of interest, with the control input modeling the occurrence of a shot transition. After adequately training different controlled Markov chain models, a list of video segments can be extracted to represent a specific event of interest using the maximum likelihood criterion. To reduce the presence of false alarms, low-level audio descriptors are processed to order the candidate video segments in the list so that those associated to the event of interest are likely to be found in the very first positions. We focus in particular on goal detection, which represents a key event in a soccer game, using camera motion information as a visual cue and the ""loudness"" as an audio descriptor. The experimental results show the effectiveness of the proposed multimodal approach.",2004,"R. Leonardi,P. Migliorati,M. Prandini",Computer Science,120,29
93091,Computer vision based analysis in sport environments,,2009,"D. Magee,J. Pers",Computer Science,15,0
4787483,Virtual Viewpoint Replay for a Soccer Match by View Interpolation From Multiple Cameras,"This paper presents a novel method for virtual view synthesis that allows viewers to virtually fly through real soccer scenes, which are captured by multiple cameras in a stadium. The proposed method generates images of arbitrary viewpoints by view interpolation of real camera images near the chosen viewpoints. In this method, cameras do not need to be strongly calibrated since projective geometry between cameras is employed for the interpolation. For avoiding the complex and unreliable process of 3-D recovery, object scenes are segmented into several regions according to the geometric property of the scene. Dense correspondence between real views, which is necessary for intermediate view generation, is automatically obtained by applying projective geometry to each region. By superimposing intermediate images for all regions, virtual views for the entire soccer scene are generated. The efforts for camera calibration are reduced and correspondence matching requires no manual operation; hence, the proposed method can be easily applied to dynamic events in a large space. An application for fly-through observations of soccer match replays is introduced along with the algorithm of view synthesis and experimental results. This is a new approach for providing arbitrary views of an entire dynamic event.",2007,"Naho Inamoto,H. Saito",Computer Science,61,24
6110402,Trajectory-Based Ball Detection and Tracking in Broadcast Soccer Video,"This paper presents a novel trajectory-based detection and tracking algorithm for locating the ball in broadcast soccer video (BSV). The problem of ball detection and tracking in BSV is well known to be very challenging because of the wide variation in the appearance of the ball over frames. Direct detection algorithms do not work well because the image of the ball may be distorted due to the high speed of the ball, occlusion, or merging with other objects in the frame. To overcome these challenges, we propose a two-phase trajectory-based algorithm in which we first generate a set of ball-candidates for each frame, and then use them to compute the set of ball trajectories. Informally, the two key ideas behind our strategy are 1) while it is very challenging to achieve high accuracy in locating the precise location of the ball, it is relatively easy to achieve very high accuracy in locating the ball among a set of ball-like candidates and 2) it is much better to study the trajectory information of the ball since the ball is the ""most active"" object in the BSV. Once the ball trajectories are computed, the ball locations can be reliably recovered from them. One important advantage of our algorithm is that it is able to reliably detect partially occluded or merged balls in the sequence. Two videos from the 2002 FIFA World Cup were used to evaluate our algorithm. It achieves a high accuracy of about 81% for ball location",2006,"Xinguo Yu,H. Leong,Changsheng Xu,Q. Tian",Computer Science,113,34
12543685,Extracting 3D information from broadcast soccer video,,2006,"Yang Liu,Dawei Liang,Qingming Huang,Wen Gao",Computer Science,54,31
3513,A System for Automatic Judgment of Offsides in Soccer Games,"In this paper, we propose a system for automatic judgment of offsides in soccer games. We detect and track players in fixed multi camera images and calculate the world coordinates of them. Furthermore, we do a formation analysis by classifying uniforms and calculate the position of an offside line. On the other hand, we calculate the 3D coordinates and the trajectories of a ball in world coordinates from the plane coordinates of a ball in multi cameras and recognize the moment of a play from the 3D trajectories of a ball. In addition, we make a judge player's interfering with play by analyzing the spatial relationship between a ball and players. Finally, we make an offside judgment by integrating these results. We apply our system to a real soccer match and demonstrate the availability of this system by showing the experimental results",2006,"Sadatsugu Hashimoto,S. Ozawa",Computer Science,22,8
207160458,Camera-based observation of football games for analyzing multi-agent activities,"This paper describes a camera-based observation system for football games that is used for the automatic analysis of football games and reasoning about multi-agent activity. The observation system runs on video streams produced by cameras set up for TV broadcasting. The observation system achieves reliability and accuracy through various mechanisms for adaptation, probabilistic estimation, and exploiting domain constraints. It represents motions compactly and segments them into classified ball actions.",2006,"M. Beetz,N. V. Hoyningen-Huene,Jan Bandouch,Bernhard Kirchlechner,Suat Gedikli,A. Maldonado",Computer Science,58,17
1012594,Multi-feature Graph-Based Object Tracking,,2006,"M. Taj,Emilio Maggio,A. Cavallaro","Mathematics,Computer Science",43,20
15923740,Background recovering in outdoor image sequences: An example of soccer players segmentation,,2006,"Pascual J. Figueroa,N. J. Leite,R. Barros",Computer Science,76,17
15060081,Tracking soccer players aiming their kinematical motion analysis,,2006,"Pascual J. Figueroa,N. J. Leite,R. Barros",Computer Science,160,24
10562255,Detection driven adaptive multi-cue integration for multiple human tracking,"In video surveillance scenarios, appearances of both human and their nearby scenes may experience large variations due to scale and view angle changes, partial occlusions, or interactions of a crowd. These challenges may weaken the effectiveness of a dedicated target observation model even based on multiple cues, which demands for an agile framework to adjust target observation models dynamically to maintain their discriminative power. Towards this end, we propose a new adaptive way to integrate multi-cue in tracking multiple human driven by human detections. Given a human detection can be reliably associated with an existing trajectory, we adapt the way how to combine specifically devised models based on different cues in this tracker so as to enhance the discriminative power of the integrated observation model in its local neighborhood. This is achieved by solving a regression problem efficiently. Specifically, we employ 3 observation models for a single person tracker based on color models of part of torso regions, an elliptical head model, and bags of local features, respectively. Extensive experiments on 3 challenging surveillance datasets demonstrate long-term reliable tracking performance of this method.",2009,"Ming Yang,Fengjun Lv,W. Xu,Yihong Gong",Computer Science,88,30
1634674,Machine Recognition of Human Activities: A Survey,"The past decade has witnessed a rapid proliferation of video cameras in all walks of life and has resulted in a tremendous explosion of video content. Several applications such as content-based video annotation and retrieval, highlight extraction and video summarization require recognition of the activities occurring in the video. The analysis of human activities in videos is an area with increasingly important consequences from security and surveillance to entertainment and personal archiving. Several challenges at various levels of processing-robustness against errors in low-level processing, view and rate-invariant representations at midlevel processing and semantic representation of human activities at higher level processing-make this problem hard to solve. In this review paper, we present a comprehensive survey of efforts in the past couple of decades to address the problems of representation, recognition, and learning of human activities from video and related applications. We discuss the problem at two major levels of complexity: 1) ""actions"" and 2) ""activities."" ""Actions"" are characterized by simple motion patterns typically executed by a single human. ""Activities"" are more complex and involve coordinated actions among a small number of humans. We will discuss several approaches and classify them according to their ability to handle varying degrees of complexity as interpreted above. We begin with a discussion of approaches to model the simplest of action classes known as atomic or primitive actions that do not require sophisticated dynamical modeling. Then, methods to model actions with more complex dynamics are discussed. The discussion then leads naturally to methods for higher level representation of complex activities.",2008,"P. Turaga,R. Chellappa,V. S. Subrahmanian,O. Udrea",Computer Science,1459,173
36447350,Modality Mixture Projections for Semantic Video Event Detection,"Event detection is one of the most fundamental components for various kinds of domain applications of video information system. In recent years, it has gained a considerable interest of practitioners and academics from different areas. While detecting video event has been the subject of extensive research efforts recently, much less existing approach has considered multimodal information and related efficiency issues. In this paper, we use a subspace selection technique to achieve fast and accurate video event detection using a subspace selection technique. The approach is capable of discriminating different classes and preserving the intramodal geometry of samples within an identical class. With the method, feature vectors presenting different kind of multi data can be easily projected from different identities and modalities onto a unified subspace, on which recognition process can be performed. Furthermore, the training stage is carried out once and we have a unified transformation matrix to project different modalities. Unlike existing multimodal detection systems, the new system works well when some modalities are not available. Experimental results based on soccer video and TRECVID news video collections demonstrate the effectiveness, efficiency and robustness of the proposed MMP for individual recognition tasks in comparison to the existing approaches.",2008,"Jialie Shen,D. Tao,Xuelong Li",Computer Science,76,25
3890487,Real-time human action recognition by luminance field trajectory analysis,"The explosive growth of video content in recent years fueled by the technological leaps in computing and communication has created new challenges for video content analysis that can serve applications in video surveillance, video searching and mining. Human action detection and recognition is one of the important tasks in this effort. In this paper, we present a luminance field manifold trajectory analysis based solution for human activity recognition, without explicit object level information extraction and understanding. This approach is computationally efficient and can operate in real time. The recognition performance is also comparable with the state of art in comparable set ups.",2008,"Zhuo Li,Yun Fu,Thomas S. Huang,Shuicheng Yan",Computer Science,45,12
2132067,Video event detection using motion relativity and visual relatedness,"Event detection plays an essential role in video content analysis. However, the existing features are still weak in event detection because: i) most features just capture what is involved in an event or how the event evolves separately, and thus cannot completely describe the event; ii) to capture event evolution information, only motion distribution over the whole frame is used which proves to be noisy in unconstrained videos; iii) the estimated object motion is usually distorted by camera movement. To cope with these problems, in this paper, we propose a new motion feature, namely Expanded Relative Motion Histogram of Bag-of-Visual-Words (ERMH-BoW) to employ motion relativity and visual relatedness for event detection. In ERMH-BoW, by representing what aspect of an event with Bag-of-Visual-Words (BoW), we construct relative motion histograms between visual words to depict the object activities or how aspect of the event. ERMH-BoW thus integrates both what and how aspects for a complete event description. Instead of motion distribution features, local motion of visual words is employed which is more discriminative in event detection. Meanwhile, we show that by employing relative motion, ERMH-BoW is able to honestly describe object activities in an event regardless of varying camera movement. Besides, to alleviate the visual word correlation problem in BoW, we propose a novel method to expand the relative motion histogram. The expansion is achieved by diffusing the relative motion among correlated visual words measured by visual relatedness. To validate the effectiveness of the proposed feature, ERMH-BoW is used to measure video clip similarity with Earth Mover's Distance (EMD) for event detection. We conduct experiments for detecting LSCOM events in TRECVID 2005 video corpus, and performance is improved by 74% and 24% compared with existing motion distribution feature and BoW feature respectively.",2008,"Feng Wang,Yu-Gang Jiang,C. Ngo",Computer Science,99,38
12365014,Learning realistic human actions from movies,"The aim of this paper is to address recognition of natural human actions in diverse and realistic video settings. This challenging but important subject has mostly been ignored in the past due to several problems one of which is the lack of realistic and annotated video datasets. Our first contribution is to address this limitation and to investigate the use of movie scripts for automatic annotation of human actions in videos. We evaluate alternative methods for action retrieval from scripts and show benefits of a text-based classifier. Using the retrieved action samples for visual learning, we next turn to the problem of action classification in video. We present a new method for video classification that builds upon and extends several recent ideas including local space-time features, space-time pyramids and multi-channel non-linear SVMs. The method is shown to improve state-of-the-art results on the standard KTH action dataset by achieving 91.8% accuracy. Given the inherent problem of noisy labels in automatic annotation, we particularly investigate and show high tolerance of our method to annotation errors in the training set. We finally apply the method to learning and classifying challenging action classes in movies and show promising results.",2008,"I. Laptev,Marcin Marszalek,C. Schmid,Benjamin Rozenfeld",Computer Science,3772,32
18429243,Video Semantic Event/Concept Detection Using a Subspace-Based Multimedia Data Mining Framework,"In this paper, a subspace-based multimedia data mining framework is proposed for video semantic analysis, specifically video event/concept detection, by addressing two basic issues, i.e., semantic gap and rare event/concept detection. The proposed framework achieves full automation via multimodal content analysis and intelligent integration of distance-based and rule-based data mining techniques. The content analysis process facilitates the comprehensive video analysis by extracting low-level and middle-level features from audio/visual channels. The integrated data mining techniques effectively address these two basic issues by alleviating the class imbalance issue along the process and by reconstructing and refining the feature dimension automatically. The promising experimental performance on goal/corner event detection and sports/commercials/building concepts extraction from soccer videos and TRECVID news collections demonstrates the effectiveness of the proposed framework. Furthermore, its unique domain-free characteristic indicates the great potential of extending the proposed multimedia data mining framework to a wide range of different application domains.",2008,"M. Shyu,Zongxing Xie,Min Chen,Shu‐Ching Chen",Computer Science,149,38
17144146,Event Detection in Crowded Videos,"Real-world actions occur often in crowded, dynamic environments. This poses a difficult challenge for current approaches to video event detection because it is difficult to segment the actor from the background due to distracting motion from other objects in the scene. We propose a technique for event recognition in crowded videos that reliably identifies actions in the presence of partial occlusion and background clutter. Our approach is based on three key ideas: (1) we efficiently match the volumetric representation of an event against oversegmented spatio-temporal video volumes; (2) we augment our shape-based features using flow; (3) rather than treating an event template as an atomic entity, we separately match by parts (both in space and time), enabling robustness against occlusions and actor variability. Our experiments on human actions, such as picking up a dropped object or waving in a crowd show reliable detection with few false positives.",2007,"Yan Ke,R. Sukthankar,M. Hebert",Computer Science,442,33
10087484,A Biologically Inspired System for Action Recognition,"We present a biologically-motivated system for the recognition of actions from video sequences. The approach builds on recent work on object recognition based on hierarchical feedforward architectures [25, 16, 20] and extends a neurobiological model of motion processing in the visual cortex [10]. The system consists of a hierarchy of spatio-temporal feature detectors of increasing complexity: an input sequence is first analyzed by an array of motion- direction sensitive units which, through a hierarchy of processing stages, lead to position-invariant spatio-temporal feature detectors. We experiment with different types of motion-direction sensitive units as well as different system architectures. As in [16], we find that sparse features in intermediate stages outperform dense ones and that using a simple feature selection approach leads to an efficient system that performs better with far fewer features. We test the approach on different publicly available action datasets, in all cases achieving the highest results reported to date.",2007,"Hueihan Jhuang,Thomas Serre,Lior Wolf,T. Poggio",Computer Science,798,84
15199783,Towards optimal bag-of-features for object categorization and semantic video retrieval,"Bag-of-features (BoF) deriving from local keypoints has recently appeared promising for object and scene classification. Whether BoF can naturally survive the challenges such as reliability and scalability of visual classification, nevertheless, remains uncertain due to various implementation choices. In this paper, we evaluate various factors which govern the performance of BoF. The factors include the choices of detector, kernel, vocabulary size and weighting scheme. We offer some practical insights in how to optimize the performance by choosing good keypoint detector and kernel. For the weighting scheme, we propose a novel soft-weighting method to assess the significance of a visual word to an image. We experimentally show that the proposed soft-weighting scheme can consistently offer better performance than other popular weighting methods. On both PASCAL-2005 and TRECVID-2006 datasets, our BoF setting generates competitive performance compared to the state-of-the-art techniques. We also show that the BoF is highly complementary to global features. By incorporating the BoF with color and texture features, an improvement of 50% is reported on TRECVID-2006 dataset.",2007,"Yu-Gang Jiang,C. Ngo,Jun Yang",Computer Science,717,25
59766734,"A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way","Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford UniversityThe new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications.Features:* Balances presentation of the mathematics with applications to signal processing* Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox* Companion website for instructors and selected solutions and code available for studentsNew in this edition* Sparse signal representations in dictionaries* Compressive sensing, super-resolution and source separation* Geometric image processing with curvelets and bandlets* Wavelets for computer graphics with lifting on surfaces* Time-frequency audio processing and denoising* Image compression with JPEG-2000* New and updated exercisesA Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R&D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering.Stephane Mallat is Professor in Applied Mathematics at cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company.Companion website: A Numerical Tour of Signal Processing Includes all the latest developments since the book was published in 1999, including itsapplication to JPEG 2000 and MPEG-4Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolboxBalances presentation of the mathematics with applications to signal processing",2008,S. Mallat,Computer Science,1187,0
17510421,Event detection in field sports video using audio-visual features and a support vector Machine,"In this paper, we propose a novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports. Features indicating significant events are selected and robust detectors built. These features are rooted in characteristics common to all genres of field sports. The evidence gathered by the feature detectors is combined by means of a support vector machine, which infers the occurrence of an event based on a model generated during a training phase. The system is tested generically across multiple genres of field sports including soccer, rugby, hockey, and Gaelic football and the results suggest that high event retrieval and content rejection statistics are achievable.",2005,"D. A. Sadlier,N. O’Connor",Computer Science,255,44
8407839,A Generic Framework for Semantic Sports Video Analysis Using Dynamic Bayesian Networks,"Automatic detection of semantic events in sport videos is a challenging task. In this paper, we propose a multimodal multilayer statistical inference framework for semantic sports video analysis using Dynamic Bayesian Networks (DBNs). Based on this framework, three instances including factorial hierarchical hidden Markov model (FHHMM), coupled hierarchical hidden Markov model (CHHMM), and product hierarchical hidden Markov model (PHHMM), are constructed and compared. Play-break detection in soccer videos is used as a testbed with hierarchical hidden Markov model (HHMM) as a baseline. Experimental results indicate the superior capability of the PHHMM, because it not only effectively models dynamic interactions between different modalities, but also sufficiently utilizes context constraints in multilayer structures.",2005,"Fei Wang,Yu-Fei Ma,HongJiang Zhang,Jintao Li",Computer Science,45,22
11885669,A decision tree-based multimodal data mining framework for soccer goal detection,"We propose a new multimedia data mining framework for the extraction of soccer goal events in soccer videos by using combined multimodal analysis and decision tree logic. The extracted events can be used to index the soccer videos. We first adopt an advanced video shot detection method to produce shot boundaries and some important visual features. Then, the visual/audio features are extracted for each shot at different granularities. This rich multimodal feature set is filtered by a pre-filtering step to clean the noise as well as to reduce the irrelevant data. A decision tree model is built upon the cleaned data set and is used to classify the goal shots. Finally, the experimental results demonstrate the effectiveness of our framework for soccer goal extraction.",2004,"Shu‐Ching Chen,M. Shyu,Min Chen,Chengcui Zhang",Computer Science,82,9
12877042,Semantic indexing of soccer audio-visual sequences: a multimodal approach based on controlled Markov chains,"Content characterization of sport videos is a subject of great interest to researchers working on the analysis of multimedia documents. In this paper, we propose a semantic indexing algorithm which uses both audio and visual information for salient event detection in soccer. The video signal is processed first by extracting low-level visual descriptors directly from an MPEG-2 bit stream. It is assumed that any instance of an event of interest typically affects two consecutive shots and is characterized by a different temporal evolution of the visual descriptors in the two shots. This motivates the introduction of a controlled Markov chain to describe such evolution during an event of interest, with the control input modeling the occurrence of a shot transition. After adequately training different controlled Markov chain models, a list of video segments can be extracted to represent a specific event of interest using the maximum likelihood criterion. To reduce the presence of false alarms, low-level audio descriptors are processed to order the candidate video segments in the list so that those associated to the event of interest are likely to be found in the very first positions. We focus in particular on goal detection, which represents a key event in a soccer game, using camera motion information as a visual cue and the ""loudness"" as an audio descriptor. The experimental results show the effectiveness of the proposed multimodal approach.",2004,"R. Leonardi,P. Migliorati,M. Prandini",Computer Science,120,29
36704272,A new algorithm for ball recognition using circle Hough transform and neural classifier,,2004,"T. D’orazio,C. Guaragnella,Marco Leo,A. Distante","Mathematics,Computer Science",159,31
14547451,Automatic Soccer Video Analysis and Summarization,"We propose a fully automatic and computationally efficient framework for analysis and summarization of soccer videos using cinematic and object-based features. The proposed framework includes some novel low-level soccer video processing algorithms, such as dominant color region detection, robust shot boundary detection, and shot classification, as well as some higher-level algorithms for goal detection, referee detection, and penalty-box detection. The system can output three types of summaries: i) all slow-motion segments in a game, ii) all goals in a game, and iii) slow-motion segments classified according to object-based features. The first two types of summaries are based on cinematic features only for speedy processing, while the summaries of the last type contain higher-level semantics. The proposed framework is efficient, effective, and robust for soccer video processing. It is efficient in the sense that there is no need to compute object-based features when cinematic features are sufficient for the detection of certain events, e.g. goals in soccer. It is effective in the sense that the framework can also employ object-based features when needed to increase accuracy (at the expense of more computation). The efficiency, effectiveness, and the robustness of the proposed framework are demonstrated over a large data set, consisting of more than 13 hours of soccer video, captured at different countries and conditions.",2003,"A. Ekin,A. Tekalp,R. Mehrotra","Computer Science,Engineering,Medicine",926,31
11211682,Detection ellipses by finding lines of symmetry in the images via an hough transform applied to straight lines,,2001,"A. Sewisy,F. Leberl","Mathematics,Computer Science",35,8
2559322,Example-Based Object Detection in Images by Components,"We present a general example-based framework for detecting objects in static images by components. The technique is demonstrated by developing a system that locates people in cluttered scenes. The system is structured with four distinct example-based detectors that are trained to separately find the four components of the human body: the head, legs, left arm, and right arm. After ensuring that these components are present in the proper geometric configuration, a second example-based classifier combines the results of the component detectors to classify a pattern as either a ""person"" or a ""nonperson."" We call this type of hierarchical architecture, in which learning occurs at multiple stages, an adaptive combination of classifiers (ACC). We present results that show that this system performs significantly better than a similar full-body person detector. This suggests that the improvement in performance is due to the component-based approach and the ACC data classification architecture. The algorithm is also more robust than the full-body person detection method in that it is capable of locating partially occluded views of people and people whose body parts have little contrast with the background.",2001,"A. Mohan,C. Papageorgiou,T. Poggio",Computer Science,1165,27
1573122,Markov Chain Monte Carlo Data Association for Multi-Target Tracking,"This paper presents Markov chain Monte Carlo data association (MCMCDA) for solving data association problems arising in multitarget tracking in a cluttered environment. When the number of targets is fixed, the single-scan version of MCMCDA approximates joint probabilistic data association (JPDA). Although the exact computation of association probabilities in JPDA is NP-hard, we prove that the single-scan MCMCDA algorithm provides a fully polynomial randomized approximation scheme for JPDA. For general multitarget tracking problems, in which unknown numbers of targets appear and disappear at random times, we present a multi-scan MCMCDA algorithm that approximates the optimal Bayesian filter. We also present extensive simulation studies supporting theoretical results in this paper. Our simulation results also show that MCMCDA outperforms multiple hypothesis tracking (MHT) by a significant margin in terms of accuracy and efficiency under extreme conditions, such as a large number of targets in a dense environment, low detection probabilities, and high false alarm rates.",2009,"Songhwai Oh,S. Russell,S. Sastry","Mathematics,Computer Science",329,53
4923317,Visual Event Recognition in News Video using Kernel Methods with Multi-Level Temporal Alignment,"In this work, we systematically study the problem of visual event recognition in unconstrained news video sequences. We adopt the discriminative kernel-based method for which video clip similarity plays an important role. First, we represent a video clip as a bag of orderless descriptors extracted from all of the constituent frames and apply Earth mover's distance (EMD) to integrate similarities among frames from two clips. Observing that a video clip is usually comprised of multiple sub-clips corresponding to event evolution over time, we further build a multilevel temporal pyramid. At each pyramid level, we integrate the information from different sub-clips with Integer-value-constrained EMD to explicitly align the sub-clips. By fusing the information from the different pyramid levels, we develop temporally aligned pyramid matching (TAPM) for measuring video similarity. We conduct comprehensive experiments on the Trecvid 2005 corpus, which contains more than 6,800 clips. Our experiments demonstrate that 1) the TAPM multi-level method clearly outperforms single-level EMD, and 2) single-level EMD outperforms by a large margin (43.0% in Mean Average Precision) basic detection methods that use only a single key-frame. Extensive analysis of the results also reveals an intuitive interpretation of subclip alignment at different levels.",2007,"Dong Xu,Shih-Fu Chang",Computer Science,73,23
7745754,Multiple Target Tracking Using Spatio-Temporal Markov Chain Monte Carlo Data Association,"We propose a framework for general multiple target tracking, where the input is a set of candidate regions in each frame, as obtained from a state of the art background learning, and the goal is to recover trajectories of targets over time from noisy observations. Due to occlusions by targets and static objects, noisy segmentation and false alarms, one foreground region may not correspond to one target faithfully. Therefore the one-to-one assumption used in most data association algorithm is not always satisfied. Our method overcomes the one-to-one assumption by formulating the visual tracking problem in terms of finding the best spatial and temporal association of observations, which maximizes the consistency of both motion and appearance of trajectories. To avoid enumerating all possible solutions, we take a data driven Markov chain Monte Carlo (DD-MCMC) approach to sample the solution space efficiently. The sampling is driven by an informed proposal scheme controlled by a joint probability model combining motion and appearance. To make sure the Markov chain to converge to a desired distribution, we propose an automatic approach to determine the parameters in the target distribution. Comparative experiments with quantitative evaluations are provided.",2007,"Qian Yu,G. Medioni,I. Cohen",Computer Science,153,16
10003085,Map-Enhanced Detection and Tracking from a Moving Platform with Local and Global Data Association,"We present an approach to detect and track moving objects from a moving platform. Moreover, given a global map, such as a satellite image, our approach can locate and track the targets in geo-coordinates, namely longitude and latitude. The map information is used as a global constraint for compensating the camera motion, which is critical for motion detection on a moving platform. In addition, by projecting the targets¿ position to a global map, tracking is performed in coordinates with physical meaning and thus the motion model is more meaningful than tracking in image coordinate. In a real scenario, targets can leave the field of view or be occluded. Thus we address tracking as a data association problem at the local and global levels. At the local level, the moving image blobs, provided from the motion detection, are associated into tracklets by a MCMC (Markov Chain Monte Carlo) Data Association algorithm. Both motion and appearance likelihood are considered when local data association is performed. Then, at the global level, tracklets are linked by their appearance and spatio-temporal consistence on the global map. Experiments show that our method can deal with long term occlusion and segmented tracks even when targets leave the field of view.",2007,"Qian Yu,G. Medioni",Computer Science,19,14
11962297,Object tracking: A survey,"The goal of this article is to review the state-of-the-art tracking methods, classify them into different categories, and identify new trends. Object tracking, in general, is a challenging problem. Difficulties in tracking objects can arise due to abrupt object motion, changing appearance patterns of both the object and the scene, nonrigid object structures, object-to-object and object-to-scene occlusions, and camera motion. Tracking is usually performed in the context of higher-level applications that require the location and/or shape of the object in every frame. Typically, assumptions are made to constrain the tracking problem in the context of a particular application. In this survey, we categorize the tracking methods on the basis of the object and motion representations used, provide detailed descriptions of representative methods in each category, and examine their pros and cons. Moreover, we discuss the important issues related to tracking including the use of appropriate image features, selection of motion models, and detection of objects.",2006,"A. Yilmaz,O. Javed,M. Shah",Computer Science,5573,173
11977130,Soccer Highlight Detection using Two-Dependence Bayesian Network,"Soccer highlight detection is an active research topic in recent years. One of the difficult problems is how to effectively fuse multi-modality cues, i.e. audio, visual and textual information, to improve the detection performance. This paper proposes a novel two-dependence Bayesian network (2d-BN) based fusion approach to soccer highlight detection. 2d-BN is a particular Bayesian network which assumes that each variable depends on two other variables at most. Through this assumption, 2d-BN can not only characterize the relationships among features but also be trained efficiently. Extensive experiments demonstrate the effectiveness of the proposed method",2006,"Jianguo Li,Tao Wang,Wei Hu,Mingliang Sun,Yimin Zhang",Computer Science,29,10
731259,Multi-Target Tracking - Linking Identities using Bayesian Network Inference,"Multi-target tracking requires locating the targets and labeling their identities. The latter is a challenge when many targets, with indistinct appearances, frequently occlude one another, as in football and surveillance tracking. We present an approach to solving this labeling problem. When isolated, a target can be tracked and its identity maintained. While, if targets interact this is not always the case. This paper assumes a track graph exists, denoting when targets are isolated and describing how they interact. Measures of similarity between isolated tracks are defined. The goal is to associate the identities of the isolated tracks, by exploiting the graph constraints and similarity measures. We formulate this as a Bayesian network inference problem, allowing us to use standard message propagation to find the most probable set of paths in an efficient way. The high complexity inevitable in large problems is gracefully reduced by removing dependency links between tracks. We apply the method to a 10 min sequence of an international football game and compare results to ground truth.",2006,"Peter Nillius,Josephine Sullivan,S. Carlsson",Computer Science,177,16
18937967,Tracking and Labelling of Interacting Multiple Targets,,2006,"Josephine Sullivan,S. Carlsson",Computer Science,85,11
6075144,"TextonBoost: Joint Appearance, Shape and Context Modeling for Multi-class Object Recognition and Segmentation",,2006,"J. Shotton,J. Winn,C. Rother,A. Criminisi",Computer Science,1368,25
25458323,Scene-based event detection for baseball videos,,2007,"C. Lien,Chiu-Lung Chiang,Chang-Hsing Lee",Computer Science,46,22
2089009,Semantic analysis of soccer video using dynamic Bayesian network,"Video semantic analysis is formulated based on the low-level image features and the high-level knowledge which is encoded in abstract, nongeometric representations. This paper introduces a semantic analysis system based on Bayesian network (BN) and dynamic Bayesian network (DBN). It is validated in the particular domain of soccer game videos. Based on BN/DBN, it can identify the special events in soccer games such as goal event, corner kick event, penalty kick event, and card event. The video analyzer extracts the low-level evidences, whereas the semantic analyzer uses BN/DBN to interpret the high-level semantics. Different from previous shot-based semantic analysis approaches, the proposed semantic analysis is frame-based for each input frame, it provides the current semantics of the event nodes as well as the hidden nodes. Another contribution is that the BN and DBN are automatically generated by the training process instead of determined by ad hoc. The last contribution is that we introduce a so-called temporal intervening network to improve the accuracy of the semantics output",2006,"Chung-Lin Huang,H. Shih,Chung-Yuan Chao",Computer Science,163,24
9188436,A Novel Model-based Segmentation Approach to Extract Caption Contents on Sports Videos,"The study proposes a novel scheme to extract and recognize the caption contents of various sports captions. A caption extraction process based on an iteratively temporal averaging technique is used to detect and locate a caption region in a series of video frames. Moreover, a caption-content extraction process based on caption identification and model-based segmentation processes is used to extract accurately the contents of various sports captions. Finally, some low-quality character images extracted from the caption contents are recognized using a commercial OCR. Experimental results show that the proposed model-based segmentation approach is very efficient to extract the contents of the various sports captions. Furthermore, the recognition performance from the application of the segmentation approach can be improved about 7.72% in test numeral set, compared to the projection-based segmentation method",2006,"Yih-Ming Su,C. Hsieh",Computer Science,11,16
1321024,MSN: statistical understanding of broadcasted baseball video using multi-level semantic network,"The information processing of sports video yields valuable semantics for content delivery over narrowband networks. Traditional image/video processing is formulated in terms of low-level features describing image/video structure and intensity, while the high-level knowledge such as common sense and human perceptual knowledge are encoded in abstract and nongeometric representations. The management of semantic information in video becomes more and more difficult because of the large difference in representations, levels of knowledge, and abstract episodes. This paper proposes a semantic highlight detection scheme using a Multi-level Semantic Network (MSN) for baseball video interpretation. The probabilistic structure can be applied for highlight detection and shot classification. Satisfactory results will be shown to illustrate better performance compared with the traditional ones.",2005,"H. Shih,Chung-Lin Huang",Computer Science,38,30
26522967,Maximum entropy model-based baseball highlight detection and classification,,2004,"Yihong Gong,Mei Han,W. Hua,W. Xu",Computer Science,58,18
12877042,Semantic indexing of soccer audio-visual sequences: a multimodal approach based on controlled Markov chains,"Content characterization of sport videos is a subject of great interest to researchers working on the analysis of multimedia documents. In this paper, we propose a semantic indexing algorithm which uses both audio and visual information for salient event detection in soccer. The video signal is processed first by extracting low-level visual descriptors directly from an MPEG-2 bit stream. It is assumed that any instance of an event of interest typically affects two consecutive shots and is characterized by a different temporal evolution of the visual descriptors in the two shots. This motivates the introduction of a controlled Markov chain to describe such evolution during an event of interest, with the control input modeling the occurrence of a shot transition. After adequately training different controlled Markov chain models, a list of video segments can be extracted to represent a specific event of interest using the maximum likelihood criterion. To reduce the presence of false alarms, low-level audio descriptors are processed to order the candidate video segments in the list so that those associated to the event of interest are likely to be found in the very first positions. We focus in particular on goal detection, which represents a key event in a soccer game, using camera motion information as a visual cue and the ""loudness"" as an audio descriptor. The experimental results show the effectiveness of the proposed multimodal approach.",2004,"R. Leonardi,P. Migliorati,M. Prandini",Computer Science,120,29
583652,Event detection in baseball video using superimposed caption recognition,"We have developed a novel system for baseball video event detection and summarization using superimposed caption text detection and recognition. The system detects different types of semantic level events in baseball video including scoring and last pitch of each batter. The system has two components: event detection and event boundary detection. Event detection is realized by change detection and recognition of game stat texts (such as text information showing in score box). Event boundary detection is achieved using our previously developed algorithm, which detects the pitch view as the event beginning and nonactive view as potential endings of the event. One unique contribution of the system is its capability to accurately detect the semantic level events by combining video text recognition with camera view recognition. Another unique feature is the real-time processing speed by taking advantage of compressed-domain approaches in part of the algorithms such as caption detection. To the best of our knowledge, this is the first system achieving accurate detection of multiple types of high-level semantic events in baseball videos.",2002,"Dongqing Zhang,Shih-Fu Chang",Computer Science,160,6
106662039,Video Processing and Communications,"From the Publisher: 
Yao Wang received the B.S. and M.S. degrees in electrical engineering from Tsinghua University, Beijing, China, in 1983 and 1985, respectively, and the Ph.D. degree in electrical and computer engineering from the University of California at Santa Barbara in 1990. Since 1990, she has been with the Faculty of Electrical Engineering, Polytechnic University, Brooklyn, NY. Her research areas include video communications, multimedia signal processing, and medical imaging. She has authored and co-authored over 100 papers in journals and conference proceedings. She is a senior member of IEEE and has served as an Associate Editor for the IEEE Transactions on Circuits and Systems for Video Technology and the IEEE Transactions on Multimedia. She won the Mayor's Award of the City of New York for Excellence in Science and Technology in the Young Investigator category in 2000. 
 
Jvrn Ostermann studied electrical engineering and communications engineering at the University of Hannover and Imperial College London, respectively. He received Dipl.-Ing. and Dr.-Ing. from the University of Hannover in 1988 and 1994, respectively. He has been a staff member with Image Processing and Technology Research, AT&T Labs>Research since 1996, where he is engaged in research on video coding, shape coding, multi-modal human-computer interfaces with talking avatars, standardization, and image analysis. He is a German National Foundation scholar. In 1998, he received the AT&T Standards Recognition Award and the ISO award. He is a member of the IEEE, the IEEE Technical Committee on Multimedia Signal Processing, and chair of the IEEE CAS Visual Signal Processing and Communications (VSPC) TechnicalCommittee. 
 
Ya-Qin Zhang received the B.S. and M.S. degrees in electrical engineering from the University of Science and Technology of China (USTC) in 1983 and 1985, respectively, and the Ph.D. degree from George Washington University in 1989. He is currently the Managing Director of Microsoft Research in Beijing, after leaving his post as the Director of Multimedia Technology Laboratory at the Sarnoff Corporation in Princeton, NJ (formerly the David Sarnoff Research Center, and RCA Laboratories). He has been engaged in research and commercialization of MPEG2/DTV, MPEG4/VLBR, and multimedia information technologies. He has authored and co-authored over 200-refereed papers in leading international conference proceedings and journals. He has been granted over 40 U.S. patents in digital video, Internet, multimedia, wireless and satellite communications. He was the Editor-in-Chief of the IEEE Transactions on Circuits and Systems for Video Technology from 1997 to 1999. He is a Fellow of the IEEE.",2001,"Yao Wang,Yaqian Zhang,J. Ostermann",Engineering,824,0
3252915,Latent semantic analysis,"A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (""semantic structure"") in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. Initial tests find this completely automatic method for retrieval to be promising.",2008,"T. Landauer,S. Dumais","Computer Science,Physics",11001,36
46176,A Novel Framework for Semantic Annotation and Personalized Retrieval of Sports Video,"Sports video annotation is important for sports video semantic analysis such as event detection and personalization. In this paper, we propose a novel approach for sports video semantic annotation and personalized retrieval. Different from the state of the art sports video analysis methods which heavily rely on audio/visual features, the proposed approach incorporates web-casting text into sports video analysis. Compared with previous approaches, the contributions of our approach include the following. 1) The event detection accuracy is significantly improved due to the incorporation of web-casting text analysis. 2) The proposed approach is able to detect exact event boundary and extract event semantics that are very difficult or impossible to be handled by previous approaches. 3) The proposed method is able to create personalized summary from both general and specific point of view related to particular game, event, player or team according to user's preference. We present the framework of our approach and details of text analysis, video analysis, text/video alignment, and personalized retrieval. The experimental results on event boundary detection in sports video are encouraging and comparable to the manually selected events. The evaluation on personalized retrieval is effective in helping meet users' expectations.",2008,"Changsheng Xu,Jinjun Wang,Hanqing Lu,Yifan Zhang",Computer Science,138,52
2612335,Live sports event detection based on broadcast video and web-casting text,"Event detection is essential for sports video summarization, indexing and retrieval and extensive research efforts have been devoted to this area. However, the previous approaches are heavily relying on video content itself and require the whole video content for event detection. Due to the semantic gap between low-level features and high-level events, it is difficult to come up with a generic framework to achieve a high accuracy of event detection. In addition, the dynamic structures from different sports domains further complicate the analysis and impede the implementation of live event detection systems. In this paper, we present a novel approach for event detection from the live sports game using web-casting text and broadcast video. Web-casting text is a text broadcast source for sports game and can be live captured from the web. Incorporating web-casting text into sports video analysis significantly improves the event detection accuracy. Compared with previous approaches, the proposed approach is able to: (1) detect live event only based on the partial content captured from the web and TV; (2) extract detailed event semantics and detect exact event boundary, which are very difficult or impossible to be handled by previous approaches; and (3) create personalized summary related to certain event, player or team according to user's preference. We present the framework of our approach and details of text analysis, video analysis and text/video alignment. We conducted experiments on both live games and recorded games. The results are encouraging and comparable to the manually detected events. We also give scenarios to illustrate how to apply the proposed solution to professional and consumer services.",2006,"Changsheng Xu,Jinjun Wang,K. Wan,Yiqun Li,Ling-yu Duan",Computer Science,169,22
6716753,Automatic video annotation by semi-supervised learning with kernel density estimation,"Insufficiency of labeled training data is a major obstacle for automatically annotating large-scale video databases with semantic concepts. Existing semi-supervised learning algorithms based on parametric models try to tackle this issue by incorporating the information in a large amount of unlabeled data. However, they are based on a ""model assumption"" that the assumed generative model is correct, which usually cannot be satisfied in automatic video annotation due to the large variations of video semantic concepts. In this paper, we propose a novel semi-supervised learning algorithm, named Semi Supervised Learning by Kernel Density Estimation (SSLKDE), which is based on a non-parametric method, and therefore the ""model assumption"" is avoided. While only labeled data are utilized in the classical Kernel Density Estimation (KDE) approach, in SSLKDE both labeled and unlabeled data are leveraged to estimate class conditional probability densities based on an extended form of KDE. We also investigate the connection between SSLKDE and existing graph-based semi-supervised learning algorithms. Experiments prove that SSLKDE significantly outperforms existing supervised methods for video annotation.",2006,"Meng Wang,Yan Song,Xun Yuan,HongJiang Zhang,Xiansheng Hua,Shipeng Li",Computer Science,47,29
14696737,Fusion of AV features and external information sources for event detection in team sports video,"The use of AV features alone is insufficient to induce high-level semantics. This article proposes a framework that utilizes both internal AV features and various types of external information sources for event detection in team sports video. Three schemes are also proposed to tackle the asynchronism between the fusion of AV and external information. The framework is extensible as it can provide increasing functionalities given more detailed external information and domain knowledge. By demonstrating its effectiveness on soccer and American football, we believe that with the availability of appropriate domain knowledge, the framework is applicable to other team sports.",2006,"Huaxin Xu,Tat-Seng Chua",Computer Science,56,32
6655935,Automatic generation of personalized music sports video,"In this paper, we propose a novel automatic approach for personalized music sports video generation. Two research challenges, semantic sports video content selection and automatic video composition, are addressed. For the first challenge, we propose to use multi-modal (audio, video and text) feature analysis and alignment to detect the semantic of events in sports video. For the second challenge, we propose video-centric and music-centric music video composition schemes to automatically generate personalized music sports video based on user's preference. The experimental results and user evaluations are promising and show that our system's generated music sports video is comparable to manually generated ones. The proposed approach greatly facilitates the automatic music sports video generation for both professionals and amateurs.",2005,"Jinjun Wang,Changsheng Xu,Chng Eng Siong,Ling-yu Duan,K. Wan,Q. Tian",Computer Science,47,25
191396,Survey of clustering algorithms,"Data analysis plays an indispensable role for understanding various phenomena. Cluster analysis, primitive exploration with little or no prior knowledge, consists of research developed across a wide variety of communities. The diversity, on one hand, equips us with many tools. On the other hand, the profusion of options causes confusion. We survey clustering algorithms for data sets appearing in statistics, computer science, and machine learning, and illustrate their applications in some benchmark data sets, the traveling salesman problem, and bioinformatics, a new field attracting intensive efforts. Several tightly related topics, proximity measure, and cluster validation, are also discussed.",2005,"R. Xu,D. Wunsch","Medicine,Computer Science",5966,313
17581900,The fusion of audio-visual features and external knowledge for event detection in team sports video,"Most existing systems detect events in broadcast team sports video using only internal audio-visual (AV) features with limited success. We found that there are many widely available external knowledge sources - such as match reports and real-time game logs in newspapers and on the Web - that can help in detecting events. This paper proposes a scalable framework that utilizes both internal AV features and external knowledge sources to detect events and identify their boundaries in full-length match videos. Besides detecting events, the framework has the potential of discovering detailed semantics and performing question answering regarding these semantics. We demonstrate the effectiveness of the framework using three full-length soccer matches",2004,"Huaxin Xu,Tat-Seng Chua",Computer Science,53,25
7737871,Multimodal biometrics using geometry preserving projections,,2008,"Tianhao Zhang,Xuelong Li,D. Tao,Jie Yang",Computer Science,82,32
18429243,Video Semantic Event/Concept Detection Using a Subspace-Based Multimedia Data Mining Framework,"In this paper, a subspace-based multimedia data mining framework is proposed for video semantic analysis, specifically video event/concept detection, by addressing two basic issues, i.e., semantic gap and rare event/concept detection. The proposed framework achieves full automation via multimodal content analysis and intelligent integration of distance-based and rule-based data mining techniques. The content analysis process facilitates the comprehensive video analysis by extracting low-level and middle-level features from audio/visual channels. The integrated data mining techniques effectively address these two basic issues by alleviating the class imbalance issue along the process and by reconstructing and refining the feature dimension automatically. The promising experimental performance on goal/corner event detection and sports/commercials/building concepts extraction from soccer videos and TRECVID news collections demonstrates the effectiveness of the proposed framework. Furthermore, its unique domain-free characteristic indicates the great potential of extending the proposed multimedia data mining framework to a wide range of different application domains.",2008,"M. Shyu,Zongxing Xie,Min Chen,Shu‐Ching Chen",Computer Science,149,38
4525064,Rank-One Projections With Adaptive Margins for Face Recognition,"In supervised dimensionality reduction, tensor representations of images have recently been employed to enhance classification of high dimensional data with small training sets. Previous approaches for handling tensor data have been formulated with tight restrictions on projection directions that, along with convergence issues and the assumption of Gaussian-distributed class data, limit its face-recognition performance. To overcome these problems, we propose a method of rank-one projections with adaptive margins (RPAM) that gives a provably convergent solution for tensor data over a more general class of projections, while accounting for margins between samples of different classes. In contrast to previous margin-based works which determine margin sample pairs within the original high dimensional feature space, RPAM aims instead to maximize the margins defined in the expected lower dimensional feature subspace by progressive margin refinement after each rank-one projection. In addition to handling tensor data, vector-based variants of RPAM are presented for linear mappings and for nonlinear mappings using kernel tricks. Comprehensive experimental results demonstrate that RPAM brings significant improvement in face recognition over previous subspace learning techniques.",2007,"Dong Xu,Stephen Lin,Shuicheng Yan,Xiaoou Tang","Mathematics,Medicine",28,25
742889,Element Rearrangement for Tensor-Based Subspace Learning,"The success of tensor-based subspace learning depends heavily on reducing correlations along the column vectors of the mode-k flattened matrix. In this work, we study the problem of rearranging elements within a tensor in order to maximize these correlations, so that information redundancy in tensor data can be more extensively removed by existing tensor-based dimensionality reduction algorithms. An efficient iterative algorithm is proposed to tackle this essentially integer optimization problem. In each step, the tensor structure is refined with a spatially-constrained Earth Mover's Distance procedure that incrementally rearranges tensors to become more similar to their low rank approximations, which have high correlation among features along certain tensor dimensions. Monotonic convergence of the algorithm is proven using an auxiliary function analogous to that used for proving convergence of the Expectation-Maximization algorithm. In addition, we present an extension of the algorithm for conducting supervised subspace learning with tensor data. Experiments in both unsupervised and supervised subspace learning demonstrate the effectiveness of our proposed algorithms in improving data compression performance and classification accuracy.",2007,"Shuicheng Yan,Dong Xu,Stephen Lin,Thomas S. Huang,Shih-Fu Chang","Computer Science,Mathematics",21,19
4923317,Visual Event Recognition in News Video using Kernel Methods with Multi-Level Temporal Alignment,"In this work, we systematically study the problem of visual event recognition in unconstrained news video sequences. We adopt the discriminative kernel-based method for which video clip similarity plays an important role. First, we represent a video clip as a bag of orderless descriptors extracted from all of the constituent frames and apply Earth mover's distance (EMD) to integrate similarities among frames from two clips. Observing that a video clip is usually comprised of multiple sub-clips corresponding to event evolution over time, we further build a multilevel temporal pyramid. At each pyramid level, we integrate the information from different sub-clips with Integer-value-constrained EMD to explicitly align the sub-clips. By fusing the information from the different pyramid levels, we develop temporally aligned pyramid matching (TAPM) for measuring video similarity. We conduct comprehensive experiments on the Trecvid 2005 corpus, which contains more than 6,800 clips. Our experiments demonstrate that 1) the TAPM multi-level method clearly outperforms single-level EMD, and 2) single-level EMD outperforms by a large margin (43.0% in Mean Average Precision) basic detection methods that use only a single key-frame. Extensive analysis of the results also reveals an intuitive interpretation of subclip alignment at different levels.",2007,"Dong Xu,Shih-Fu Chang",Computer Science,73,23
145638,Rank-one Projections with Adaptive Margins for Face Recognition,"In supervised dimensionality reduction, tensor representations of images have recently been employed to enhance classification of high-dimensional data with small training sets. To handle tensor data, this approach has been formulated with tight restrictions on projection directions that, along with convergence issues and the assumption of Gaussian distributed class data, limits its face recognition performance. To overcome these problems, we propose a method of rank-one projections with adaptive margins (RPAM) that gives a provably convergent solution for tensor data over a more general class of projections, while accounting for margins between samples of different classes. In contrast to previous margin based works which determine margin sample pairs within the original high dimensional space, RPAM instead aims to maximize the margins defined in the expected lower dimensional feature subspace by progressive margin refinement after each rank-one projection. In addition to handling tensor data, vector-based variants of RPAM are presented for linear mappings and for nonlinear mappings using kernel tricks. Comprehensive experimental results demonstrate that RPAM brings significant improvement in face recognition over previous subspace learning techniques.",2006,"Dong Xu,Stephen Lin,Shuicheng Yan,Xiaoou Tang",Computer Science,37,26
7138891,Efficient visual event detection using volumetric features,"This paper studies the use of volumetric features as an alternative to popular local descriptor approaches for event detection in video sequences. Motivated by the recent success of similar ideas in object detection on static images, we generalize the notion of 2D box features to 3D spatio-temporal volumetric features. This general framework enables us to do real-time video analysis. We construct a realtime event detector for each action of interest by learning a cascade of filters based on volumetric features that efficiently scans video sequences in space and time. This event detector recognizes actions that are traditionally problematic for interest point methods - such as smooth motions where insufficient space-time interest points are available. Our experiments demonstrate that the technique accurately detects actions on real-world sequences and is robust to changes in viewpoint, scale and action speed. We also adapt our technique to the related task of human action classification and confirm that it achieves performance comparable to a current interest point based human activity recognizer on a standard database of human activities.",2005,"Yan Ke,R. Sukthankar,M. Hebert",Computer Science,642,24
17510421,Event detection in field sports video using audio-visual features and a support vector Machine,"In this paper, we propose a novel audio-visual feature-based framework for event detection in broadcast video of multiple different field sports. Features indicating significant events are selected and robust detectors built. These features are rooted in characteristics common to all genres of field sports. The evidence gathered by the feature detectors is combined by means of a support vector machine, which infers the occurrence of an event based on a model generated during a training phase. The system is tested generically across multiple genres of field sports including soccer, rugby, hockey, and Gaelic football and the results suggest that high event retrieval and content rejection statistics are achievable.",2005,"D. A. Sadlier,N. O’Connor",Computer Science,255,44
12877042,Semantic indexing of soccer audio-visual sequences: a multimodal approach based on controlled Markov chains,"Content characterization of sport videos is a subject of great interest to researchers working on the analysis of multimedia documents. In this paper, we propose a semantic indexing algorithm which uses both audio and visual information for salient event detection in soccer. The video signal is processed first by extracting low-level visual descriptors directly from an MPEG-2 bit stream. It is assumed that any instance of an event of interest typically affects two consecutive shots and is characterized by a different temporal evolution of the visual descriptors in the two shots. This motivates the introduction of a controlled Markov chain to describe such evolution during an event of interest, with the control input modeling the occurrence of a shot transition. After adequately training different controlled Markov chain models, a list of video segments can be extracted to represent a specific event of interest using the maximum likelihood criterion. To reduce the presence of false alarms, low-level audio descriptors are processed to order the candidate video segments in the list so that those associated to the event of interest are likely to be found in the very first positions. We focus in particular on goal detection, which represents a key event in a soccer game, using camera motion information as a visual cue and the ""loudness"" as an audio descriptor. The experimental results show the effectiveness of the proposed multimodal approach.",2004,"R. Leonardi,P. Migliorati,M. Prandini",Computer Science,120,29
44925993,Automatic extraction of soccer video highlights using a combination of motion and audio features,"We present a technique for rapidly generating highlights of soccer videos using peaks in audio volume in conjunction with temporal patterns of motion activity extracted in the compressed domain. Our intuition is that any interesting event, such as a goal, in a soccer match leads to an interruption of the game for a non-trivial duration. Furthermore, interesting events are associated with a sharp increase (or peak) in audio volume since the crowd noise goes up in anticipation of the event or as a result of the event. We thus use the temporal patterns of motion activity around each audio peak to detect and capture interesting events. Our preliminary results indicate that the scheme works well for a variety of soccer content from different parts of the world. The computational simplicity of our scheme enables rapid and flexible generation of highlights.",2003,"R. Cabasson,Ajay Divakaran","Computer Science,Engineering",28,6
119852155,Fuzzy c-varieties/elliptotypes clustering in reproducing kernel Hilbert space,,2004,J. Łȩski,Mathematics,33,36
3166156,Robust local principal component analyzer with fuzzy clustering,"Non-linear extensions of principal component analysis (PCA) have been developed for detecting the lower-dimensional representations of real world data sets and local linear approaches are used widely because of their computational simplicity and understandability. Fuzzy c-varieties (FCV) is the linear fuzzy clustering algorithm that estimates local principal component vectors as the vectors spanning prototypes of clusters. Least squares techniques, however, often fail to account for ""outliers"", which are common in real applications. In this paper, we propose a technique for making the FCV algorithm robust to intra-sample outliers. The objective function based on the lower rank approximation of the data matrix is minimized by a robust M-estimation algorithm that is similar to FCM-type iterative procedures.",2003,"K. Honda,N. Sugiura,H. Ichihashi",Mathematics,10,22
30415560,Robust Fuzzy Principal Component Analysis (FPCA). A Comparative Study Concerning Interaction of Carbon-Hydrogen Bonds with Molybdenum-Oxo Bonds,"Principal component analysis (PCA) is a favorite tool in chemometrics for data compression and information extraction. PCA finds linear combinations of the original measurement variables that describe the significant variations in the data. However, it is well-known that PCA, as with any other multivariate statistical method, is sensitive to outliers, missing data, and poor linear correlation between variables due to poorly distributed variables. As a result data transformations have a large impact upon PCA. In this regard one of the most powerful approaches to improve PCA appears to be the fuzzification of the matrix data, thus diminishing the influence of outliers. In this paper we discuss a robust fuzzy PCA algorithm (FPCA). The new algorithm is illustrated on a data set concerning interaction of carbon-hydrogen bonds with transition metal-oxo bonds in molybdenum complexes. Considering, for example, a two component model, FPCA accounts for 97.20% of the total variance and PCA accounts only for 69.75%.",2002,"T. Cundari,C. Sârbu,Horia F. Pop","Computer Science,Medicine,Mathematics",39,22
43535812,Clustering algorithms based on volume criteria,"Clustering algorithms such as the K-means algorithm and the fuzzy C-means algorithm are based on the minimization of the trace of the (fuzzy) within-fluster scatter matrix. In this paper, we explore the use of determinant (volume) criteria for clustering. We derive an algorithm called the minimum scatter volume (MSV) algorithm, that minimizes the scatter volume, and another algorithm called the minimum cluster volume (MCV) that minimizes the sum of the volumes of the individual clusters. The behavior of MSV is shown to be similar to that of K-means, whereas MCV is more versatile.",2000,"R. Krishnapuram,Jongwoo Kim","Mathematics,Computer Science",63,12
20917605,Fuzzy and possibilistic shell clustering algorithms and their application to boundary detection and surface approximation. I,"Shell clustering algorithms are ideally suited for computer vision tasks such as boundary detection and surface approximation, particularly when the boundaries have jagged or scattered edges and when the range data is sparse. This is because shell clustering is insensitive to local aberrations, it can be performed directly in image space, and unlike traditional approaches it does assume dense data and does not use additional features such as curvatures and surface normals. The shell clustering algorithms introduced in Part I of this paper assume that the number of clusters is known, however, which is not the case in many boundary detection and surface approximation applications. This problem can be overcome by considering cluster validity. We introduce a validity measure called surface density which is explicitly meant for the type of applications considered in this paper, we show through theoretical derivations that surface density is relatively invariant to size and partiality (incompleteness) of the clusters. We describe unsupervised clustering algorithms that use the surface density measure and other measures to determine the optimum number of shell clusters automatically, and illustrate the application of the proposed algorithms to boundary detection in the case of intensity images and to surface approximation in the case of range images. >",1995,"R. Krishnapuram,H. Frigui,O. Nasraoui","Mathematics,Computer Science",223,64
1143137,A possibilistic approach to clustering,"The clustering problem is cast in the framework of possibility theory. The approach differs from the existing clustering methods in that the resulting partition of the data can be interpreted as a possibilistic partition, and the membership values can be interpreted as degrees of possibility of the points belonging to the classes, i.e., the compatibilities of the points with the class prototypes. An appropriate objective function whose minimum will characterize a good possibilistic partition of the data is constructed, and the membership and prototype update equations are derived from necessary conditions for minimization of the criterion function. The advantages of the resulting family of possibilistic algorithms are illustrated by several examples. >",1993,"R. Krishnapuram,J. Keller","Mathematics,Computer Science",2524,32
53624641,Fundamentals of Digital Image Processing,Introduction. 1. Two Dimensional Systems and Mathematical Preliminaries. 2. Image Perception. 3. Image Sampling and Quantization. 4. Image Transforms. 5. Image Representation by Stochastic Models. 6. Image Enhancement. 7. Image Filtering and Restoration. 8. Image Analysis and Computer Vision. 9. Image Reconstruction From Projections. 10. Image Data Compression.,2018,Anil K. Jain,Computer Science,3703,94
14022333,Colorizing infrared home videos,"A color video always conveys more vivid sentiments than a grayscale one. Obtaining a grayscale video from a color video is almost trivial but the converse is known to be hard. Nowadays, digital camcorders come equipped with an infrared device for night shot that enables one to shoot home videos in the dark. Unfortunately, the infrared lighting device used generates a ""green-scale"" video which is akin to a grayscale video albeit possessing all tints of green. In this paper, we present a novel technique for colorizing infrared home videos. We first convert the green scale video into grayscale, afterwards our technique involves generating key-frames for every shot and then building up a one to one correspondence map between the key frames and the designated color images. These pairs are used to generate the color palette table for the video segment, which is then utilized to colorize that segment of the home video. Our novel technique could also be applied for colorizing X-ray videos generated by diagnostic imaging devices as well as surveillance videos generated by baggage scanners at airports.",2003,"W. Yan,M. Kankanhalli",Computer Science,16,5
2629563,Does colorspace transformation make any difference on skin detection?,"Skin detection is an important process in many of computer vision algorithms. It usually is a process that starts at a pixel-level, and that involves a pre-process of colorspace transformation followed by a classification process. A colorspace transformation is assumed to increase separability between skin and non-skin classes, to increase similarity among different skin tones, and to bring a robust performance under varying illumination conditions, without any sound reasonings. In this work, we examine if the colorspace transformation does bring those benefits by measuring four separability measurements on a large dataset of 805 images with different skin tones and illumination. Surprising results indicate that most of the colorspace transformations do not bring the benefits which have been assumed.",2002,"M. Shin,K. Chang,L. Tsap",Computer Science,219,25
14088925,Color Transfer between Images,We use a simple statistical analysis to impose one image's color characteristics on another. We can achieve color correction by choosing an appropriate source image and apply its characteristic to another image.,2001,"E. Reinhard,M. Ashikhmin,B. Gooch,P. Shirley",Computer Science,2639,14
11959218,Independent component analysis: algorithms and applications,,2000,"Aapo Hyvärinen,E. Oja","Mathematics,Computer Science,Medicine",8299,53
16135158,Fast and robust fixed-point algorithms for independent component analysis,"Independent component analysis (ICA) is a statistical method for transforming an observed multidimensional random vector into components that are statistically as independent from each other as possible. In this paper, we use a combination of two different approaches for linear ICA: Comon's information-theoretic approach and the projection pursuit approach. Using maximum entropy approximations of differential entropy, we introduce a family of new contrast (objective) functions for ICA. These contrast functions enable both the estimation of the whole decomposition by minimizing mutual information, and estimation of individual independent components as projection pursuit directions. The statistical properties of the estimators based on such contrast functions are analyzed under the assumption of the linear mixture model, and it is shown how to choose contrast functions that are robust and/or of minimum variance. Finally, we introduce simple fixed-point algorithms for practical optimization of the contrast functions. These algorithms optimize the contrast functions very fast and reliably.",1999,Aapo Hyvärinen,"Medicine,Computer Science,Mathematics",6184,40
15447203,Statistics of cone responses to natural images: implications for visual coding,"We gathered hyperspectral images of natural, foliage-dominated scenes and converted them to human cone quantal catches to characterize the second-order redundancy present within the retinal photoreceptor array under natural conditions. The data are expressed most simply in a logarithmic response space, wherein an orthogonal decorrelation robustly produces three principal axes, one corresponding to simple changes in radiance and two that are reminiscent of the blue–yellow and red–green chromatic-opponent mechanisms found in the primate visual system. Further inclusion of spatial stimulus dimensions demonstrates a complete spatial decorrelation of these three cone-space axes in natural cone responses.",1998,"D. Ruderman,T. Cronin,C. Chiao","Mathematics,Computer Science",738,39
197521593,THE REVERSIBILITY OF 6 GEOMETRIC COLOR SPACES,"Color coordinate systems provide a way to address, to describe, and to manipulate colors. In the field of image processing and computer graphics, several color models in common use include RGB, HVC, HSV, HLS, and ISH. In this study, the reversibility of several color coordinate systems and their numerical characteristics are studied. All these models are classified as user-oriented and related to the perceptual color space.",1995,T. Shih,Geography,40,0
121890149,Color information for region segmentation,,1980,"Y. Ohta,T. Kanade,T. Sakai",Mathematics,999,2
2533214,Properties and applications of shape recipes,"In low-level vision, the representation of scene properties such as shape, albedo, etc., are very high dimensional as they have to describe complicated structures. The approach proposed here is to let the image itself bear as much of the representational burden as possible. In many situations, scene and image are closely related and it is possible to find a functional relationship between them. The scene information can be represented in reference to the image where the functional specifies how to translate the image into the associated scene. We illustrate the use of this representation for encoding shape information. We show how this representation has appealing properties such as locality and slow variation across space and scale. These properties provide a way of improving shape estimates coming from other sources of information like stereo.",2003,"A. Torralba,W. Freeman",Computer Science,48,14
1483254,Multi-sensor super-resolution,"Image sensing is usually done with multiple sensors, like the RGB sensors in color imaging, the IR and EO sensors in surveillance and satellite imaging, etc. The resolution of each sensor can be increased by considering the images of the other sensors, and using the statistical redundancy among the sensors. Particularly, we use the fact that most discontinuities in the image of one sensor correspond to discontinuities in the other sensors. Two applications are presented: Increasing the resolution of a single color image by using the correlation among the three color channels, and enhancing noisy IR images.",2002,"A. Zomet,Shmuel Peleg",Computer Science,95,20
1202704,Color image enhancement via chromaticity diffusion,"A novel approach for color image denoising is proposed in this paper. The algorithm is based on separating the color data into chromaticity and brightness, and then processing each one of these components with partial differential equations or diffusion flows. In the proposed algorithm, each color pixel is considered as an n-dimensional vector. The vectors' direction, a unit vector, gives the chromaticity, while the magnitude represents the pixel brightness. The chromaticity is processed with a system of coupled diffusion equations adapted from the theory of harmonic maps in liquid crystals. This theory deals with the regularization of vectorial data, while satisfying the intrinsic unit norm constraint of directional data such as chromaticity. Both isotropic and anisotropic diffusion flows are presented for this n-dimensional chromaticity diffusion flow. The brightness is processed by a scalar median filter or any of the popular and well established anisotropic diffusion flows for scalar image enhancement. We present the underlying theory, a number of examples, and briefly compare with the current literature.",2001,"Bei Tang,G. Sapiro,V. Caselles","Mathematics,Computer Science,Medicine",222,40
14848918,Normalized cuts and image segmentation,"We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images and found results very encouraging.",1997,"Jianbo Shi,J. Malik","Mathematics,Computer Science",16659,34
108972045,Museum of Broadcast Communications Encyclopaedia of Television,,1997,S. James,Engineering,18,0
15208137,"Numerical recipes in C++: the art of scientific computing, 2nd Edition (C++ ed., print. is corrected to software version 2.10)","IS B N 0-523108-5) C opright (C ) 19-1992 by C am bidge U nirsity P rss. P rogram s C opright (C ) 19-1992 by N um eical R eipes S ftw are. P rm ission is grnted or inrnet uers to m ke ne pper cpy or teir ow n peonal use. F uther repruction, or ny coying of m acineredable fles (inluding his one) to ny srver om pter, is sictly proibited. T o oder N um eical R eipes boks, disettes, or C D R O M s visit w esite hp://w w w .n.com or call 1-8072-7423 (N orth A m erica oly), or snd em il to trde@ cu.cam .ac.uk (otside N orth A m eca). Numerical Recipes in C",1994,W. Press,"Economics,Computer Science",9471,58
145134327,Colorization and Moral Rights: Should the United States Adopt Unified Protection for Artists?,"The recent trend to colorize early, often classic black and white films has created controversy as a result of the clash of artistic creativity, copyright laws, and technology. This study cites efforts by Congress and some state legislatures to protect creative rights, along with allowing for market forces. The study summarizes perspectives of film directors, producers, and others, and suggests policy guidelines.",1991,R. Cooper,Sociology,8,0
62717952,Numerical Recipes in C: The Art of Scientific Computing,,1989,"M. C. Seiler,F. A. Seiler",Computer Science,15346,0
2629563,Does colorspace transformation make any difference on skin detection?,"Skin detection is an important process in many of computer vision algorithms. It usually is a process that starts at a pixel-level, and that involves a pre-process of colorspace transformation followed by a classification process. A colorspace transformation is assumed to increase separability between skin and non-skin classes, to increase similarity among different skin tones, and to bring a robust performance under varying illumination conditions, without any sound reasonings. In this work, we examine if the colorspace transformation does bring those benefits by measuring four separability measurements on a large dataset of 805 images with different skin tones and illumination. Surprising results indicate that most of the colorspace transformations do not bring the benefits which have been assumed.",2002,"M. Shin,K. Chang,L. Tsap",Computer Science,219,25
15398205,Face detection in color images,"Human face detection is often the first step in applications such as video surveillance, human computer interface, face recognition, and image database management. We propose a face detection algorithm for color images in the presence of varying lighting conditions as well as complex backgrounds. Our method detects skin regions over the entire image, and then generates face candidates based on the spatial arrangement of these skin patches. The algorithm constructs eye, mouth, and boundary maps for verifying each face candidate. Experimental results demonstrate successful detection over a wide variety of facial variations in color, position, scale, rotation, pose, and expression from several photo collections.",2002,"Rein-Lien Hsu,M. Abdel-Mottaleb,Anil K. Jain",Computer Science,2189,64
1504713,Optimum color spaces for skin detection,"The objective of this paper is to show that for every color space there exists an optimum skin detector scheme such that the performance of all these skin detectors schemes is the same. To that end, a theoretical proof is provided and experiments are presented which show that the separability of the skin and no skin classes is independent of the color space chosen.",2001,"A. Albiol,L. Torres,E. Delp","Mathematics,Computer Science",246,15
39824480,Comparative performance of different skin chrominance models and chrominance spaces for the automatic detection of human faces in color images,"This paper presents an analysis of the performance of two different skin chrominance models and of nine different chrominance spaces for the color segmentation and subsequent detection of human faces in two-dimensional static images. For each space, we use the single Gaussian model based on the Mahalanobis metric and a Gaussian mixture density model to segment faces from scene backgrounds. In the case of the mixture density model, the skin chrominance distribution is estimated by use of the expectation-maximisation (EM) algorithm. Feature extraction is performed on the segmented images by use of invariant Fourier-Mellin moments. A multilayer perceptron neural network (NN), with the invariant moments as the input vector, is then applied to distinguish faces from distractors. With the single Gaussian model, normalized color spaces are shown to produce the best segmentation results, and subsequently the highest rate of face detection. The results are comparable to those obtained with the more sophisticated mixture density model. However, the mixture density model improves the segmentation and face detection results significantly for most of the un-normalized color spaces. Ultimately, we show that, for each chrominance space, the detection efficiency depends on the capacity of each model to estimate the skin chrominance distribution and, most importantly, on the discriminability between skin and ""non-skin"" distributions.",2000,"J. Terrillon,H. Fukamachi,S. Akamatsu,M. N. Shirazi",Computer Science,476,23
2773627,Comparison of five color models in skin pixel classification,"Detection of skin in video is an important component of systems for detecting, recognizing, and tracking faces and hands. Different skin detection methods have used different color spaces. This paper presents a comparative evaluation of pixel classification performance of two skin detection methods in five color spaces. The skin detection methods used in this paper are color-histogram based approaches that are intended to work with a wide variety of individuals, lighting conditions, and skin tones. One is the widely-used lookup table method, the other makes use of Bayesian decision theory. Two types of enhancements, based on spatial and texture analyses, are also evaluated.",1999,"B.D. Zarit,B. Super,Freddie Quek",Computer Science,442,17
294771,Edge detector evaluation using empirical ROC curves,"A method is demonstrated to evaluate edge detector performance using receiver operating characteristic curves. It involves matching edges to manually specified ground truth to count true positive and false positive detections. Edge detector parameter settings are trained and tested on different images, and aggregate test ROC curves presented for two sets of 10 images. The performance of eight different edge detectors is compared. The Canny and Heitger detectors provide the best performance.",1999,"K. Bowyer,Christine Kranenburg,Sean Dougherty","Computer Science,Mathematics",413,36
2527220,Statistical Color Models with Application to Skin Detection,,1999,"Michael J. Jones,James M. Rehg",Computer Science,1914,34
17165284,A flexible image database system for content-based retrieval,"There is a growing need for the ability to query image databases based on similarity of image content rather than strict keyword search. As distance computations can be expensive, there is a need for indexing systems and algorithms that can eliminate candidate images without performing distance calculations. As user needs may change from session to session, there is also a need for run-time creation of distance measures. In this paper we present FIDS (flexible image database system). FIDS allows the user to query the database based on complex combinations of dozens of pre-defined distance measures. Using an indexing scheme and algorithms based on the triangle inequality, FIDS can often return matches to the query image without directly comparing the query image to more than a small percentage of the database.",1998,"A. Berman,L. Shapiro",Computer Science,118,50
11775703,Detecting human faces in color images,"A method is introduced that detects human faces in color images by first separating skin regions from non-skin regions and then locating faces within the skin regions. A chroma chart is prepared via a training process that shows likelihoods of different colors representing the skin. Using the chroma chart, a color image is transformed into a gray-scale image, with the gray value at a pixel showing the likelihood of the pixel representing the skin. By segmenting the gray-scale image, skin regions are separated from non-skin regions. Then, using the luminance component of the color image and by template matching, faces are located within skin regions.",1998,"J. Cai,A. Goshtasby,Clement T. Yu",Computer Science,430,32
86580024,Evaluating Medical Tests: Objective and Quantitative Guidelines,,1993,S. Traub,Medicine,346,0
3518156,Computer-assisted auto coloring by region matching,"Computer-assisted auto coloring (CAAC) has great potential in terms of lowering production cost and saving time in cel animation production. In this paper, a novel approach to automatically color the animation character of line drawings based on region matching and master frames is proposed. Firstly, some important attributes of a region such as curve length, character points, area etc. are investigated. Then, based on these attributes, a detailed process of region matching is presented followed by the coloring process. The results show that our approach can straightforwardly handle most cases, hence the aim of saving time and labor is realized.",2003,"Jie Qiu,S. H. Soon,Feng Tian,Quan Chen,K. Melikhov",Computer Science,17,16
1025228,Segmentation of black and white cartoons,"We introduce novel semi-automatic, fast and accurate segmentation technique that allow us to simplify color transfer to the old black and white cartoons produced by classical paper or foil technology, where foreground parts are represented by homogeneous regions with constant grey-scale intensity surrounded by bold dark contours. We assume that original analogue material has been converted to the sequence of digital grey-scale images with PAL resolution suitable for TV broadcasting.",2003,"D. Sýkora,J. Buriánek,J. Zára",Computer Science,25,28
5558414,"Class-Specific, Top-Down Segmentation",,2002,"Eran Borenstein,S. Ullman","Mathematics,Computer Science",492,21
14088925,Color Transfer between Images,We use a simple statistical analysis to impose one image's color characteristics on another. We can achieve color correction by choosing an appropriate source image and apply its characteristic to another image.,2001,"E. Reinhard,M. Ashikhmin,B. Gooch,P. Shirley",Computer Science,2639,14
2201072,Image analogies,"This paper describes a new framework for processing images by example, called “image analogies.” The framework involves two stages: a design phase, in which a pair of images, with one image purported to be a “filtered” version of the other, is presented as “training data”; and an application phase, in which the learned filter is applied to some new target image in order to create an “analogous” filtered result. Image analogies are based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis. By choosing different types of source image pairs as input, the framework supports a wide variety of “image filter” effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are “texturized” with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface.",2001,"Aaron Hertzmann,Charles E. Jacobs,Nuria Oliver,B. Curless,D. Salesin",Computer Science,1795,56
15448589,Real-time texture synthesis by patch-based sampling,"We present an algorithm for synthesizing textures from an input sample. This patch-based sampling algorithm is fast and it makes high-quality texture synthesis a real-time process. For generating textures of the same size and comparable quality, patch-based sampling is orders of magnitude faster than existing algorithms. The patch-based sampling algorithm works well for a wide variety of textures ranging from regular to stochastic. By sampling patches according to a nonparametric estimation of the local conditional MRF density function, we avoid mismatching features across patch boundaries. We also experimented with documented cases for which pixel-based nonparametric sampling algorithms cease to be effective but our algorithm continues to work well.",2001,"Lin Liang,Ce Liu,Ying-Qing Xu,B. Guo,H. Shum",Computer Science,755,35
8193729,An optimal algorithm for approximate nearest neighbor searching fixed dimensions,"Consider a set of <italic>S</italic> of <italic>n</italic> data points  in real <italic>d</italic>-dimensional space, R<supscrpt>d</supscrpt>, where distances are measured using any Minkowski metric. In nearest neighbor searching, we preprocess <italic>S</italic> into a data structure, so that given any query point <italic>q</italic><inline-equation> <f>∈</f></inline-equation> R<supscrpt>d</supscrpt>, is the closest point of S to <italic>q</italic> can be reported quickly. Given any positive real ε, data point <italic>p</italic> is a (1 +ε)-<italic>approximate nearest neighbor</italic> of <italic>q</italic> if its distance from <italic>q</italic> is within a factor of (1 + ε) of the distance to the true nearest neighbor. We show that it is possible to preprocess a    set of <italic>n</italic> points in     R<supscrpt>d</supscrpt> in <italic>O(dn</italic> log <italic>n</italic>) time and <italic>O(dn)</italic> space, so that given a query point <italic> q</italic> <inline-equation> <f>∈</f></inline-equation> R<supscrpt>d</supscrpt>, and ε > 0, a (1 + ε)-approximate nearest neighbor of <italic>q</italic> can be computed in <italic>O</italic>(<italic>c</italic><subscrpt><italic>d</italic>, ε</subscrpt> log <italic>n</italic>) time, where <italic>c<subscrpt>d,ε</subscrpt></italic>≤<italic>d</italic> <inline-equation> <f><fen lp=""ceil"">1 + 6d/<g>e</g><rp post=""ceil""></fen></f></inline-equation>;<supscrpt>d</supscrpt> is a factor depending only on dimension and ε. In general, we show that given an integer <italic>k</italic> ≥ 1, (1 + ε)-approximations  to the  <italic>k</italic> nearest neighbors of <italic>q</italic> can  be computed in additional <italic>O(kd</italic> log <italic>n</italic>) time.",1998,"S. Arya,D. Mount,N. Netanyahu,R. Silverman,A. Wu","Computer Science,Mathematics",2770,59
33072875,Automatic Cel Painting in Computer-assisted Cartoon Production using Similarity Recognition,"The task of painting each cel of an animated sequence has always been a tedious work using traditional methods. In order to simplify and speed up the process, the development of an automatic cel painting system is desired. This paper presents a method for assisting the production of cartoon animation using computers in order to reduce the production expense and to improve the overall quality. It signals a great improvement in the working environment where 2-D animation is produced. The basic idea of our automatic cel painting mechanism is to extract both statistical and topological features of regions from input animation drawings, and to search for similar corresponding regions in the previous drawing. If the similarity measures are within the accepted thresholds, the corresponding colour will be inherited. A new integrated labelling algorithm constructing statistical region and topological graph features is proposed. Furthermore, a similarity measure of regions is defined and an algorithm of partial matching of attribute graphs is presented. The experimental result shows the feasibility and practicability of the proposed approach. © 1997 John Wiley & Sons, Ltd.",1997,"Chueh-Wei Chang,Suh-Yin Lee",Computer Science,27,8
6562358,"An FFT-based technique for translation, rotation, and scale-invariant image registration","This correspondence discusses an extension of the well-known phase correlation technique to cover translation, rotation, and scaling. Fourier scaling properties and Fourier rotational properties are used to find scale and rotational movement. The phase correlation technique determines the translational movement. This method shows excellent robustness against random noise.",1996,"B. Reddy,B. N. Chatterji","Computer Science,Mathematics,Medicine",1935,13
12331515,Face recognition: A literature survey,"As one of the most successful applications of image analysis and understanding, face recognition has recently received significant attention, especially during the past several years. At least two reasons account for this trend: the first is the wide range of commercial and law enforcement applications, and the second is the availability of feasible technologies after 30 years of research. Even though current machine recognition systems have reached a certain level of maturity, their success is limited by the conditions imposed by many real applications. For example, recognition of face images acquired in an outdoor environment with changes in illumination and/or pose remains a largely unsolved problem. In other words, current systems are still far away from the capability of the human perception system.This paper provides an up-to-date critical survey of still- and video-based face recognition research. There are two underlying motivations for us to write this survey paper: the first is to provide an up-to-date review of the existing literature, and the second is to offer some insights into the studies of machine recognition of faces. To provide a comprehensive survey, we not only categorize existing recognition techniques but also present detailed descriptions of representative methods within each category. In addition, relevant topics such as psychophysical studies, system evaluation, and issues of illumination and pose variation are covered.",2003,"Wen Zhao,R. Chellappa,P. Phillips,A. Rosenfeld",Computer Science,7201,285
1856904,Image-based skin color and texture analysis/synthesis by extracting hemoglobin and melanin information in the skin,"This paper proposes an E-cosmetic function for digital images based on physics and physiologically-based image processing. A practical skin color and texture analysis/synthesis technique is introduced for this E-cosmetic function. Shading on the face is removed by a simple color vector analysis in the optical density domain as an inverse lighting technique. The image without shading is analyzed by a previously introduced technique that extracts hemoglobin and melanin components by independent component analysis. Experimental results using UV-B irradiation and the application of methyl nicotinate on the arms support the physiological validity of the analysis and the effectiveness of the proposed shading removal. We synthesized the way facial images changed due to tanning or alcohol consumption, and compared the synthesized images with images of actual changes in skin color. The comparison shows an excellent match between the synthesized and actual images of changes due to tanning and alcohol consumption. We also proposed a technique to synthesize the change of texture in pigment due to aging or the application of cosmetics. The pyramid-based texture analysis/synthesis technique was used for the spatial processing of texture. Using the proposed technique, we could realistically change the skin color and texture of a 50 year-old woman to that of a 20 year-old woman.",2003,"N. Tsumura,Nobutoshi Ojima,Kayoko Sato,M. Shiraishi,Hideto Shimizu,Hirohide Nabeshima,S. Akazaki,K. Hori,Y. Miyake",Computer Science,325,35
33918669,Generating Realistic Facial Expressions with Wrinkles for Model-Based Coding,"Due to the limitations of current computer graphics technology mimicing realistic facial textures, such as wrinkles, is very difficult. Facial texture updating and compression are crucial to achieving realistic facial animation for low bit rate model-based coding. In this paper, we present a partial texture updating method for realistic facial expression synthesis with facial wrinkles. First, fiducial points on a face are estimated using a color-based deformable template matching method. Second, an extended dynamic mesh matching algorithm is developed for face tracking. Next, textures of interest (TOI) in the potential expressive wrinkles and mouth?eye texture areas are captured by the detected fiducial points. Among the TOI, the so-called active textures or expressive textures are extracted by exploring temporal correlation information. Finally, the entire facial texture is synthesized using the active texture. Compared to the entire texture updating scheme, partially updating and compressing facial textures significantly reduce the computational complexity and bit rates while still producing an acceptable visual quality. Experiments on the video sequences demonstrate the advantage of the proposed algorithm.",2001,"L. Yin,A. Basu",Computer Science,51,24
18593684,Face modeling for recognition,"3D human face models have been widely used in applications such as facial animation, video compression/coding, augmented reality, head tracking, facial expression recognition, human action recognition, and face recognition. Modeling human faces provides a potential solution to identifying faces with variations in illumination, pose, and facial expression. We propose a method of modeling human faces based on a generic face model (a triangular mesh model) and individual facial measurements containing both shape and texture information. The modeling method adapts a generic face model to the given facial features, extracted from registered range and color images, in a global-to-local fashion. It iteratively moves the vertices of the mesh model to smoothen the non-feature areas, and uses the 2.5D active contours to refine feature boundaries. The resultant face model has been shown to be visually similar to the true face. Initial results show that the constructed model is quite useful for recognizing nonfrontal views.",2001,"Rein-Lien Hsu,Anil K. Jain",Computer Science,67,23
14088925,Color Transfer between Images,We use a simple statistical analysis to impose one image's color characteristics on another. We can achieve color correction by choosing an appropriate source image and apply its characteristic to another image.,2001,"E. Reinhard,M. Ashikhmin,B. Gooch,P. Shirley",Computer Science,2639,14
2201072,Image analogies,"This paper describes a new framework for processing images by example, called “image analogies.” The framework involves two stages: a design phase, in which a pair of images, with one image purported to be a “filtered” version of the other, is presented as “training data”; and an application phase, in which the learned filter is applied to some new target image in order to create an “analogous” filtered result. Image analogies are based on a simple multi-scale autoregression, inspired primarily by recent results in texture synthesis. By choosing different types of source image pairs as input, the framework supports a wide variety of “image filter” effects, including traditional image filters, such as blurring or embossing; improved texture synthesis, in which some textures are synthesized with higher quality than by previous approaches; super-resolution, in which a higher-resolution image is inferred from a low-resolution source; texture transfer, in which images are “texturized” with some arbitrary source texture; artistic filters, in which various drawing and painting styles are synthesized based on scanned real-world examples; and texture-by-numbers, in which realistic scenes, composed of a variety of textures, are created using a simple painting interface.",2001,"Aaron Hertzmann,Charles E. Jacobs,Nuria Oliver,B. Curless,D. Salesin",Computer Science,1795,56
2480531,Real-time Photo-Realistic Physically Based Rendering of Fine Scale Human Skin Structure,"Skin is noticeably bumpy in character, which is clearly visible in close-up shots in a film or game. Methods that rely on simple texture-mapping of faces lack such high frequency shape detail, which makes them look non-realistic. More specifically, this detail is usually ignored in real-time applications, or is drawn in manually by an artist. In this paper, we present techniques for capturing and rendering the fine scale structure of human skin. First, we present a method for creating normal maps of skin with a high degree of accuracy from physical data. We also present techniques inspired by texture synthesis to ""grow"" skin normal maps to cover the face. Finally, we demonstrate how such skin models can be rendered in real-time on consumer-end graphics hardware.",2001,"A. Haro,Irfan Essa,B. Guenter",Computer Science,45,23
12248965,Automatic facial feature extraction by genetic algorithms,"An automatic facial feature extraction algorithm is presented in this paper. The algorithm is composed of two main stages: the face region estimation stage and the feature extraction stage. In the face region estimation stage, a second-chance region growing method is adopted to estimate the face region of a target image. In the feature extraction stage, genetic search algorithms are applied to extract the facial feature points within the face region. It is shown by simulation results that the proposed algorithm can automatically and exactly extract facial features with limited computational complexity.",1998,"Chun-Hung Lin,Ja-Ling Wu","Medicine,Engineering,Computer Science",94,14
196109879,FERET Evaluation Methodology for Face-Recognition Algorithms | NIST,,1998,"P. Phillips,Hyeonjoon Moon,Syed A. Rizvi,P. Rauss",Computer Science,17,0
61563242,Robust Regression and Outlier Detection,1. Introduction. 2. Simple Regression. 3. Multiple Regression. 4. The Special Case of One-Dimensional Location. 5. Algorithms. 6. Outlier Diagnostics. 7. Related Statistical Techniques. References. Table of Data Sets. Index.,2005,"P. Rousseeuw,A. Leroy",Computer Science,8320,0
14569112,Color Invariance,"This paper presents the measurement of colored object reflectance, under different, general assumptions regarding the imaging conditions. We exploit the Gaussian scale-space paradigm for color images to define a framework for the robust measurement of object reflectance from color images. Object reflectance is derived from a physical reflectance model based on the Kubelka-Munk theory for colorant layers. Illumination and geometrical invariant properties are derived from the reflectance model. Invariance and discriminative power of the color invariants is experimentally investigated, showing the invariants to be successful in discounting shadow, illumination, highlights, and noise. Extensive experiments show the different invariants to be highly discriminative, while maintaining invariance properties. The presented framework for color measurement is well-founded in the physics of color as well as in measurement science. Hence, the proposed invariants are considered more adequate for the measurement of invariant color features than existing methods.",2001,"J. Geusebroek,R. V. D. Boomgaard,A. Smeulders,H. Geerts","Mathematics,Computer Science",605,40
17032933,Hybrid image segmentation using watersheds and fast region merging,"A hybrid multidimensional image segmentation algorithm is proposed, which combines edge and region-based techniques through the morphological algorithm of watersheds. An edge-preserving statistical noise reduction approach is used as a preprocessing stage in order to compute an accurate estimate of the image gradient. Then, an initial partitioning of the image into primitive regions is produced by applying the watershed transform on the image gradient magnitude. This initial segmentation is the input to a computationally efficient hierarchical (bottom-up) region merging process that produces the final segmentation. The latter process uses the region adjacency graph (RAG) representation of the image regions. At each step, the most similar pair of regions is determined (minimum cost RAG edge), the regions are merged and the RAG is updated. Traditionally, the above is implemented by storing all RAG edges in a priority queue. We propose a significantly faster algorithm, which additionally maintains the so-called nearest neighbor graph, due to which the priority queue size and processing time are drastically reduced. The final segmentation provides, due to the RAG, one-pixel wide, closed, and accurately localized contours/surfaces. Experimental results obtained with two-dimensional/three-dimensional (2-D/3-D) magnetic resonance images are presented.",1998,"K. Haris,S. N. Efstratiadis,N. Maglaveras,A. Katsaggelos","Mathematics,Computer Science,Medicine",815,46
2479502,Anisotropic diffusion of multivalued images with applications to color filtering,"A general framework for anisotropic diffusion of multivalued images is presented. We propose an evolution equation where, at each point in time, the directions and magnitudes of the maximal and minimal rate of change in the vector-image are first evaluated. These are given by eigenvectors and eigenvalues of the first fundamental form in the given image metric. Then, the image diffuses via a system of coupled differential equations in the direction of minimal change. The diffusion ""strength"" is controlled by a function that measures the degree of dissimilarity between the eigenvalues. We apply the proposed framework to the filtering of color images represented in CIE-L*a*b* space.",1996,"G. Sapiro,D. Ringach","Mathematics,Medicine,Computer Science",486,27
35812367,Multiresolution Color Image Segmentation,"Image segmentation is the process by which an original image is partitioned into some homogeneous regions. In this paper, a novel multiresolution color image segmentation (MCIS) algorithm which uses Markov random fields (MRF's) is proposed. The proposed approach is a relaxation process that converges to the MAP (maximum a posteriori) estimate of the segmentation. The quadtree structure is used to implement the multiresolution framework, and the simulated annealing technique is employed to control the splitting and merging of nodes so as to minimize an energy function and therefore, maximize the MAP estimate. The multiresolution scheme enables the use of different dissimilarity measures at different resolution levels. Consequently, the proposed algorithm is noise resistant. Since the global clustering information of the image is required in the proposed approach, the scale space filter (SSF) is employed as the first step. The multiresolution approach is used to refine the segmentation. Experimental results of both the synthesized and real images are very encouraging. In order to evaluate experimental results of both synthesized images and real images quantitatively, a new evaluation criterion is proposed and developed. >",1994,"Jianqing Liu,Herbert Yang","Mathematics,Computer Science",563,16
37015873,Adaptive Split-and-Merge Segmentation Based on Piecewise Least-Square Approximation,"The performance of the classic split-and-merge segmentation algorithm is severely hampered by its rigid split-and-merge processes, which are insensitive to the image semantics. The author proposes efficient algorithms and data structures to optimize the split-and-merge processes by piecewise least-square approximation of image intensity functions. This optimization aims at the unification of segment finding and edge detection. The optimized split-and-merge algorithm is shown to be adaptive to the image semantics and, hence, improves the segmentation validity of the previous algorithms. This algorithm also appears to work well on noisy sources. Since the optimization is done within the split-and-merge framework, the better segmentation performance is achieved at the same order of time complexity as the previous algorithms. >",1993,Xiaolin Wu,"Mathematics,Computer Science",102,5
63796669,A framework for the construction of reflectance maps for machine vision,"Abstract A reflectance map is the transfer function from surface orientation and illumination geometry to the surface normal, and in machine vision it plays a fundamental role in the reconstruction of surface by shape-from-shading and photometric stereo algorithms. While reflectance maps for Lambertain and specular surfaces are well understood, maps for real-world diffusely reflecting surfaces are scant. In this paper, the fundamental mechanisms of reflection from such surfaces are reviewed. Based on this, it is proposed that for point light source illumination, the diffuse component of the reflectance map has three terms: a forescatter term, a normal term, and a backscatter term. The physical origin of the three terms is discussed in detail and useful mathematical expressions are obtained for them. The range of applicability of the proposed reflectance maps is established, and an example of their use in photometric stereo is provided. The mathematical form of the reflectance map obtained from physical theories is amenable to generalization and such a generalization is called the m-lobed reflectance map is proposed.",1993,"H. Tagare,R. Defigueiredo","Mathematics,Computer Science",25,0
17689134,Color Space Analysis of Mutual Illumination,"Mutual illumination occurs when light reflected from one surface impinges on a second one. The resulting additional illumination incident on the second surface affects both the color and intensity of the light reflected from it. As a consequence, the image of a surface in the presence of mutual illumination differs from what it otherwise would have been in the absence of mutual illumination. Unaccounted for mutual illumination can easily confuse methods that rely on intensity or color such as shape-from-shading or color-based object recognition. In this correspondence, we introduce an algorithm that removes mutual illumination effects from images. The domain is that of previously-segmented images of convex surfaces of uniform color and diffuse reflectance where for each surface the interreflection occurs mainly from one other surface and can be accurately accounted for within a one-bounce model. The algorithm is based on a singular value decomposition of the colors coming from each surface. Geometrical information about where on the surface the colors emanate from is not required. The RGB triples from a single convex surface experiencing interreflection fall in a plane; intersecting the planes generated from two interreflecting surfaces results in a unique interreflection color. Each pixel can then be factored into its interreflection and no-interreflection components so that a complete no-interreflection image is produced. >",1992,"B. Funt,M. S. Drew","Mathematics,Computer Science",94,25
31986847,Segmenting images using normalized color,"An algorithm for segmenting images of 3-D scenes is presented. From an input color image, the algorithm determines the number of materials in the scene and labels each pixel according to the corresponding material. This segmentation is useful for many visual tasks including 3-D inspection and 3-D object recognition. The segmentation algorithm is based on a detailed analysis of the physics underlying color image formation and may be applied to images of a wide range of materials and surface textures. An initial edge detection on the intensity image is used to guide the segmentation process and to ensure accurate localization of region boundaries. The algorithm is based on the computation of local image features and can be mapped effectively onto high-performance parallel hardware. Issues related to illumination and sensors are addressed. Experimental results obtained for several images are presented. >",1992,G. Healey,Computer Science,194,22
219305183,COMET: Context-Aware IoU-Guided Network for Small Object Tracking,,2020,"S. M. Marvasti-Zadeh,Javad Khaghani,Hossein Ghanei-Yakhdan,S. Kasaei,Li Cheng","Computer Science,Engineering",20,81
216398541,Recent advances in small object detection based on deep learning: A review,,2020,"Kang Tong,Yiquan Wu,Fei Zhou",Computer Science,294,90
58341840,Robust Visual Tracking via Hierarchical Particle Filter and Ensemble Deep Features,"Particle filter algorithms are a very important branch for visual object tracking in the past decades, showing strong robustness to challenging scenarios with partial occlusion and large-scale variations. However, since a large number of particles need to be extracted for the accurate target state estimation, their tracking efficiency typically suffers especially when meeting deep convolutional features, which have been developed for handling significant variations of the target appearance in the visual tracking community. In this paper, we propose to elegantly exploit deep convolutional features with few particles in a novel hierarchical particle filter, which formulates correlation filters as observation models and breaks the standard particle filter framework down into two constituent particle layers, namely, particle translation layer and particle scale layer. The particle translation layer focuses on the object location with the deep convolutional features capturing semantics but failing to precisely estimate the object scale, while the particle scale layer pays attention to large-scale variations with the lightweight hand-crafted features handling spatial details of the object size. Moreover, an efficient ensemble method is proposed to help explore deeper convolutional features with more semantics in the particle translation layer. Extensive experiments on four challenging tracking datasets, including OTB-2013, OTB-2015, VOT2014, and VOT2015 demonstrate that the proposed method performs favorably against a number of state-of-the-art trackers.",2020,"Shengjie Li,Shuai Zhao,B. Cheng,Erhu Zhao,Junliang Chen",Computer Science,15,57
208527176,Deep Learning for Visual Tracking: A Comprehensive Survey,"Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years – predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.",2019,"S. M. Marvasti-Zadeh,Li Cheng,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",205,272
192534743,ROI Pooled Correlation Filters for Visual Tracking,"The ROI (region-of-interest) based pooling method performs pooling operations on the cropped ROI regions for various samples and has shown great success in the object detection methods. It compresses the model size while preserving the localization accuracy, thus it is useful in the visual tracking field. Though being effective, the ROI-based pooling operation is not yet considered in the correlation filter formula. In this paper, we propose a novel ROI pooled correlation filter (RPCF) algorithm for robust visual tracking. Through mathematical derivations, we show that the ROI-based pooling can be equivalently achieved by enforcing additional constraints on the learned filter weights, which makes the ROI-based pooling feasible on the virtual circular samples. Besides, we develop an efficient joint training formula for the proposed correlation filter algorithm, and derive the Fourier solvers for efficient model training. Finally, we evaluate our RPCF tracker on OTB-2013, OTB-2015 and VOT-2017 benchmark datasets. Experimental results show that our tracker performs favourably against other state-of-the-art trackers.",2019,"Yuxuan Sun,Chong Sun,Dong Wang,You He,Huchuan Lu",Computer Science,73,39
198162846,Argoverse: 3D Tracking and Forecasting With Rich Maps,"We present Argoverse, a dataset designed to support autonomous vehicle perception tasks including 3D tracking and motion forecasting. Argoverse includes sensor data collected by a fleet of autonomous vehicles in Pittsburgh and Miami as well as 3D tracking annotations, 300k extracted interesting vehicle trajectories, and rich semantic maps. The sensor data consists of 360 degree images from 7 cameras with overlapping fields of view, forward-facing stereo imagery, 3D point clouds from long range LiDAR, and 6-DOF pose. Our 290km of mapped lanes contain rich geometric and semantic metadata which are not currently available in any public dataset. All data is released under a Creative Commons license at Argoverse.org. In baseline experiments, we use map information such as lane direction, driveable area, and ground height to improve the accuracy of 3D object tracking. We use 3D object tracking to mine for more than 300k interesting vehicle trajectories to create a trajectory forecasting benchmark. Motion forecasting experiments ranging in complexity from classical methods (k-NN) to LSTMs demonstrate that using detailed vector maps with lane-level information substantially reduces prediction error. Our tracking and forecasting experiments represent only a superficial exploration of the potential of rich maps in robotic perception. We hope that Argoverse will enable the research community to explore these problems in greater depth.",2019,"Ming-Fang Chang,John Lambert,Patsorn Sangkloy,Jagjeet Singh,Sławomir Bąk,Andrew Hartnett,De Wang,Peter Carr,S. Lucey,Deva Ramanan,James Hays",Computer Science,914,64
198186194,DeFusionNET: Defocus Blur Detection via Recurrently Fusing and Refining Multi-Scale Deep Features,"Defocus blur detection aims to detect out-of-focus regions from an image. Although attracting more and more attention due to its widespread applications, defocus blur detection still confronts several challenges such as the interference of background clutter, sensitivity to scales and missing boundary details of defocus blur regions. To deal with these issues, we propose a deep neural network which recurrently fuses and refines multi-scale deep features (DeFusionNet) for defocus blur detection. We firstly utilize a fully convolutional network to extract multi-scale deep features. The features from bottom layers are able to capture rich low-level features for details preservation, while the features from top layers can characterize the semantic information to locate blur regions. These features from different layers are fused as shallow features and semantic features, respectively. After that, the fused shallow features are propagated to top layers for refining the fine details of detected defocus blur regions, and the fused semantic features are propagated to bottom layers to assist in better locating the defocus regions. The feature fusing and refining are carried out in a recurrent manner. Also, we finally fuse the output of each layer at the last recurrent step to obtain the final defocus blur map by considering the sensitivity to scales of the defocus degree. Experiments on two commonly used defocus blur detection benchmark datasets are conducted to demonstrate the superority of DeFusionNet when compared with other 10 competitors. Code and more results can be found at: http://tangchang.net",2019,"Chang Tang,Xinzhong Zhu,Xinwang Liu,Lizhe Wang,Albert Y. Zomaya",Computer Science,60,48
196700924,Graph Convolutional Tracking,"Tracking by siamese networks has achieved favorable performance in recent years. However, most of existing siamese methods do not take full advantage of spatial-temporal target appearance modeling under different contextual situations. In fact, the spatial-temporal information can provide diverse features to enhance the target representation, and the context information is important for online adaption of target localization. To comprehensively leverage the spatial-temporal structure of historical target exemplars and get benefit from the context information, in this work, we present a novel Graph Convolutional Tracking (GCT) method for high-performance visual tracking. Specifically, the GCT jointly incorporates two types of Graph Convolutional Networks (GCNs) into a siamese framework for target appearance modeling. Here, we adopt a spatial-temporal GCN to model the structured representation of historical target exemplars. Furthermore, a context GCN is designed to utilize the context of the current frame to learn adaptive features for target localization. Extensive results on 4 challenging benchmarks show that our GCT method performs favorably against state-of-the-art trackers while running around 50 frames per second.",2019,"Junyu Gao,Tianzhu Zhang,Changsheng Xu",Computer Science,212,88
145966650,Robust Visual Tracking via Adaptive Occlusion Detection,"Occlusion is a special challenge in visual tracking, which may cause target template corrupted by background information. In this paper, we propose an adaptive occlusion detection framework for robust tracking against occlusion. The framework consists of a patch tracker, an occlusion detector, a template updater and a search window predictor. The patch tracker applies KCF-based method to track background patch individually, which may occlude target. The occlusion detector searches for background patches occluding target with an adaptive threshold. The template updater evaluates the occlusion state and applies appropriate target template update strategy. The search window predictor adaptively rescales the size of search window based on occlusion state. Experiments in OTB50 demonstrate that our tracker achieves comparable performance compared with other state-of-art trackers and outperforms them in cases of occlusion.",2019,"Yueyang Gu,Xiaoguang Niu,Yu Qiao",Computer Science,6,19
102486909,Target-Aware Deep Tracking,"Existing deep trackers mainly use convolutional neural networks pre-trained for the generic object recognition task for representations. Despite demonstrated successes for numerous vision tasks, the contributions of using pre-trained deep features for visual tracking are not as significant as that for object recognition. The key issue is that in visual tracking the targets of interest can be arbitrary object class with arbitrary forms. As such, pre-trained deep features are less effective in modeling these targets of arbitrary forms for distinguishing them from the background. In this paper, we propose a novel scheme to learn target-aware features, which can better recognize the targets undergoing significant appearance variations than pre-trained deep features. To this end, we develop a regression loss and a ranking loss to guide the generation of target-active and scale-sensitive features. We identify the importance of each convolutional filter according to the back-propagated gradients and select the target-aware features based on activations for representing the targets. The target-aware features are integrated with a Siamese matching network for visual tracking. Extensive experimental results show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of accuracy and speed.",2019,"Xin Li,Chao Ma,Baoyuan Wu,Zhenyu He,Ming-Hsuan Yang",Computer Science,306,54
219793067,Ocean: Object-aware Anchor-free Tracking,,2020,"Zhipeng Zhang,Houwen Peng",Computer Science,439,50
216398541,Recent advances in small object detection based on deep learning: A review,,2020,"Kang Tong,Yiquan Wu,Fei Zhou",Computer Science,294,90
214714187,AutoTrack: Towards High-Performance Visual Tracking for UAV With Automatic Spatio-Temporal Regularization,"Most existing trackers based on discriminative correlation filters (DCF) try to introduce predefined regularization term to improve the learning of target objects, e.g., by suppressing background learning or by restricting change rate of correlation filters. However, predefined parameters introduce much effort in tuning them and they still fail to adapt to new situations that the designer did not think of. In this work, a novel approach is proposed to online automatically and adaptively learn spatio-temporal regularization term. Spatially local response map variation is introduced as spatial regularization to make DCF focus on the learning of trust-worthy parts of the object, and global response map variation determines the updating rate of the filter. Extensive experiments on four UAV benchmarks have proven the superiority of our method compared to the state-of-the-art CPU- and GPU-based trackers, with a speed of ~60 frames per second running on a single CPU. Our tracker is additionally proposed to be applied in UAV localization. Considerable tests in the indoor practical scenarios have proven the effectiveness and versatility of our localization method. The code is available at https://github.com/vision4robotics/AutoTrack.",2020,"Yiming Li,Changhong Fu,Fangqiang Ding,Ziyuan Huang,Geng Lu",Computer Science,222,59
214693026,Probabilistic Regression for Visual Tracking,"Visual tracking is fundamentally the problem of regressing the state of the target in each video frame. While significant progress has been achieved, trackers are still prone to failures and inaccuracies. It is therefore crucial to represent the uncertainty in the target estimation. Although current prominent paradigms rely on estimating a state-dependent confidence score, this value lacks a clear probabilistic interpretation, complicating its use. In this work, we therefore propose a probabilistic regression formulation and apply it to tracking. Our network predicts the conditional probability density of the target state given an input image. Crucially, our formulation is capable of modeling label noise stemming from inaccurate annotations and ambiguities in the task. The regression network is trained by minimizing the Kullback-Leibler divergence. When applied for tracking, our formulation not only allows a probabilistic representation of the output, but also substantially improves the performance. Our tracker sets a new state-of-the-art on six datasets, achieving 59.8% AUC on LaSOT and 75.8% Success on TrackingNet. The code and models are available at https://github.com/visionml/pytracking.",2020,"Martin Danelljan,L. Gool,R. Timofte",Computer Science,350,53
212657812,Training-Set Distillation for Real-Time UAV Object Tracking,"Correlation filter (CF) has recently exhibited promising performance in visual object tracking for unmanned aerial vehicle (UAV). Such online learning method heavily depends on the quality of the training-set, yet complicated aerial scenarios like occlusion or out of view can reduce its reliability. In this work, a novel time slot-based distillation approach is proposed to efficiently and effectively optimize the training-set's quality on the fly. A cooperative energy minimization function is established to score the historical samples adaptively. To accelerate the scoring process, frames with high confident tracking results are employed as the keyframes to divide the tracking process into multiple time slots. After the establishment of a new slot, the weighted fusion of the previous samples generates one key-sample, in order to reduce the number of samples to be scored. Besides, when the current time slot exceeds the maximum frame number, which can be scored, the sample with the lowest score will be discarded. Consequently, the training-set can be efficiently and reliably distilled. Comprehensive tests on two well-known UAV benchmarks prove the effectiveness of our method with real-time speed on single CPU.",2020,"Fan Li,Changhong Fu,Fuling Lin,Yiming Li,Peng Lu",Computer Science,20,33
212657491,Keyfilter-Aware Real-Time UAV Object Tracking,"Correlation filter-based tracking has been widely applied in unmanned aerial vehicle (UAV) with high efficiency. However, it has two imperfections, i.e., boundary effect and filter corruption. Several methods enlarging the search area can mitigate boundary effect, yet introducing undesired background distraction. Existing frame-by-frame context learning strategies for repressing background distraction nevertheless lower the tracking speed. Inspired by keyframe-based simultaneous localization and mapping, keyfilter is proposed in visual tracking for the first time, in order to handle the above issues efficiently and effectively. Keyfilters generated by periodically selected keyframes learn the context intermittently and are used to restrain the learning of filters, so that 1) context awareness can be transmitted to all the filters via keyfilter restriction, and 2) filter corruption can be repressed. Compared to the state-of-the-art results, our tracker performs better on two challenging benchmarks, with enough speed for UAV real-time applications.",2020,"Yiming Li,Changhong Fu,Ziyuan Huang,Yinqiang Zhang,Jia Pan",Computer Science,34,40
210714230,"Vision Meets Drones: Past, Present and Future","Drones, or general UAVs, equipped with cameras have been fast deployed with a wide range of applications, including agriculture, aerial photography, and surveillance. Consequently, automatic understanding of visual data collected from drones becomes highly demanding, bringing computer vision and drones more and more closely. To promote and track the evelopments of object detection and tracking algorithms, we have organized two challenge workshops in conjunction with ECCV 2018, and ICCV 2019, attracting more than 100 teams around the world. We provide a large-scale drone captured dataset, VisDrone, which includes four tracks, i.e., (1) image object detection, (2) video object detection, (3) single object tracking, and (4) multi-object tracking. In this paper, we first presents a thorough review of object detection and tracking datasets and benchmarks, and discuss the challenges of collecting large-scale drone-based object detection and tracking datasets with fully manual annotations. After that, we describe our VisDrone dataset, which is captured over various urban/suburban areas of 14 different cities across China from North to South. Being the largest such dataset ever published, VisDrone enables extensive evaluation and investigation of visual analysis algorithms on the drone platform. We provide a detailed analysis of the current state of the field of large-scale object detection and tracking on drones, and conclude the challenge as well as propose future directions. We expect the benchmark largely boost the research and development in video analysis on drone platforms. All the datasets and experimental results can be downloaded from the website: this https URL",2020,"Pengfei Zhu,Longyin Wen,Dawei Du,Xiao Bian,Q. Hu,Haibin Ling",Computer Science,145,189
209370511,Small Object Detection using Context and Attention,"There are many limitations applying object detection algorithm on various environments. Specifically, detecting small objects is still challenging because they have low-resolution and limited information. We propose an object detection method using context for improving accuracy of detecting small objects. The proposed method uses additional features from different layers as context by concatenating multi-scale features. We also propose object detection with attention mechanism which can focus on the object in image, and it can include contextual information from target layer. Experimental results shows that proposed method also has higher accuracy than conventional SSD on detecting small objects. Moreover, for $300 \times 300$ input, we achieved 78.1% Mean Average Precision (mAP) on the PASCAL VOC2007 test set.",2019,"Jeong-Seon Lim,M. Astrid,Hyungjin Yoon,Seung-Ik Lee",Computer Science,124,19
212927782,"The Unmanned Aerial Vehicle Benchmark: Object Detection, Tracking and Baseline",,2019,"Hongyang Yu,Guorong Li,Weigang Zhang,Qingming Huang,Dawei Du,Q. Tian,N. Sebe",Computer Science,98,78
208527176,Deep Learning for Visual Tracking: A Comprehensive Survey,"Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years – predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.",2019,"S. M. Marvasti-Zadeh,Li Cheng,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",205,272
201070350,RANet: Ranking Attention Network for Fast Video Object Segmentation,"Despite online learning (OL) techniques have boosted the performance of semi-supervised video object segmentation (VOS) methods, the huge time costs of OL greatly restricts their practicality. Matching based and propagation based methods run at a faster speed by avoiding OL techniques. However, they are limited by sub-optimal accuracy, due to mismatching and drifting problems. In this paper, we develop a real-time yet very accurate Ranking Attention Network (RANet) for VOS. Specifically, to integrate the insights of matching based and propagation based methods, we employ an encoder-decoder framework to learn pixel-level similarity and segmentation in an end-to-end manner. To better utilize the similarity maps, we propose a novel ranking attention module, which automatically ranks and selects these maps for fine-grained VOS performance. Experiments on DAVIS16 and DAVIS17 datasets show that our RANet achieves the best speed-accuracy trade-off, e.g., with 33 milliseconds per frame and J&F=85.5% on DAVIS16. With OL, our RANet reaches J&F=87.1% on DAVIS16, exceeding state-of-the-art VOS methods. The code can be found at https://github.com/Storife/RANet.",2019,"Ziqin Wang,Jun Xu,Li Liu,Fan Zhu,Ling Shao",Computer Science,177,61
199001006,Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking,"We propose a new Group Feature Selection method for Discriminative Correlation Filters (GFS-DCF) based visual object tracking. The key innovation of the proposed method is to perform group feature selection across both channel and spatial dimensions, thus to pinpoint the structural relevance of multi-channel features to the filtering system. In contrast to the widely used spatial regularisation or feature selection methods, to the best of our knowledge, this is the first time that channel selection has been advocated for DCF-based tracking. We demonstrate that our GFS-DCF method is able to significantly improve the performance of a DCF tracker equipped with deep neural network features. In addition, our GFS-DCF enables joint feature selection and filter learning, achieving enhanced discrimination and interpretability of the learned filters. To further improve the performance, we adaptively integrate historical information by constraining filters to be smooth across temporal frames, using an efficient low-rank approximation. By design, specific temporal-spatial-channel configurations are dynamically learned in the tracking process, highlighting the relevant features, and alleviating the performance degrading impact of less discriminative representations and reducing information redundancy. The experimental results obtained on OTB2013, OTB2015, VOT2017, VOT2018 and TrackingNet demonstrate the merits of our GFS-DCF and its superiority over the state-of-the-art trackers. The code is publicly available at \url{https://github.com/XU-TIANYANG/GFS-DCF}.",2019,"Tianyang Xu,Zhenhua Feng,Xiaojun Wu,J. Kittler",Computer Science,140,93
128358415,Siamese Attentional Keypoint Network for High Performance Visual Tracking,,2019,"Peng Gao,Yipeng Ma,Ruyue Yuan,Liyi Xiao,Fei Wang",Computer Science,95,73
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
102351480,FoveaBox: Beyond Anchor-based Object Detector,"We present FoveaBox, an accurate, flexible and completely anchor-free framework for object detection. While almost all state-of-the-art object detectors utilize the predefined anchors to enumerate possible locations, scales and aspect ratios for the search of the objects, their performance and generalization ability are also limited to the design of anchors. Instead, FoveaBox directly learns the object existing possibility and the bounding box coordinates without anchor reference. This is achieved by: (a) predicting category-sensitive semantic maps for the object existing possibility, and (b) producing category-agnostic bounding box for each position that potentially contains an object. The scales of target boxes are naturally associated with feature pyramid representations for each input image. Without bells and whistles, FoveaBox achieves state-of-the-art single model performance of 42.1 AP on the standard COCO detection benchmark. Specially for the objects with arbitrary aspect ratios, FoveaBox brings in significant improvement compared to the anchor-based detectors. More surprisingly, when it is challenged by the stretched testing images, FoveaBox shows great robustness and generalization ability to the changed distribution of bounding box shapes. The code will be made publicly available.",2019,"Tao Kong,F. Sun,Huaping Liu,Yuning Jiang,Jianbo Shi",Computer Science,176,53
104291974,SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking,"The greatest challenge facing visual object tracking is the simultaneous requirements on robustness and discrimination power. In this paper, we propose a SiamFC-based tracker, named SPM-Tracker, to tackle this challenge. The basic idea is to address the two requirements in two separate matching stages. Robustness is strengthened in the coarse matching (CM) stage through generalized training while discrimination power is enhanced in the fine matching (FM) stage through a distance learning network. The two stages are connected in series as the input proposals of the FM stage are generated by the CM stage. They are also connected in parallel as the matching scores and box location refinements are fused to generate the final results. This innovative series-parallel structure takes advantage of both stages and results in superior performance. The proposed SPM-Tracker, running at 120fps on GPU, achieves an AUC of 0.687 on OTB-100 and an EAO of 0.434 on VOT-16, exceeding other real-time trackers by a notable margin.",2019,"Guangting Wang,Chong Luo,Zhiwei Xiong,Wenjun Zeng",Computer Science,160,60
57189581,SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks,"Siamese network based trackers formulate tracking as convolutional feature cross-correlation between target template and searching region. However, Siamese trackers still have accuracy gap compared with state-of-the-art algorithms and they cannot take advantage of feature from deep networks, such as ResNet-50 or deeper. In this work we prove the core reason comes from the lack of strict translation invariance. By comprehensive theoretical analysis and experimental validations, we break this restriction through a simple yet effective spatial aware sampling strategy and successfully train a ResNet-driven Siamese tracker with significant performance gain. Moreover, we propose a new model architecture to perform depth-wise and layer-wise aggregations, which not only further improves the accuracy but also reduces the model size. We conduct extensive ablation studies to demonstrate the effectiveness of the proposed tracker, which obtains currently the best results on four large tracking benchmarks, including OTB2015, VOT2018, UAV123, and LaSOT. Our model will be released to facilitate further studies based on this problem.",2018,"Bo Li,Wei Wu,Qiang Wang,Fangyi Zhang,Junliang Xing,Junjie Yan",Computer Science,1396,55
56305074,Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking,"Recently, the region proposal networks (RPN) have been combined with the Siamese network for tracking, and shown excellent accuracy with high efficiency. Nevertheless, previously proposed one-stage Siamese-RPN trackers degenerate in presence of similar distractors and large scale variation. Addressing these issues, we propose a multi-stage tracking framework, Siamese Cascaded RPN (C-RPN), which consists of a sequence of RPNs cascaded from deep high-level to shallow low-level layers in a Siamese network. Compared to previous solutions, C-RPN has several advantages: (1) Each RPN is trained using the outputs of RPN in the previous stage. Such process stimulates hard negative sampling, resulting in more balanced training samples. Consequently, the RPNs are sequentially more discriminative in distinguishing difficult background (i.e.,, similar distractors). (2) Multi-level features are fully leveraged through a novel feature transfer block (FTB) for each RPN, further improving the discriminability of C-RPN using both high-level semantic and low-level spatial information. (3) With multiple steps of regressions, C-RPN progressively refines the location and shape of the target in each RPN with adjusted anchor boxes in the previous stage, which makes localization more accurate. C-RPN is trained end-to-end with the multi-task loss function. In inference, C-RPN is deployed as it is, without any temporal adaption, for real-time tracking. In extensive experiments on OTB-2013, OTB-2015, VOT-2016, VOT-2017, LaSOT and TrackingNet, C-RPN consistently achieves state-of-the-art results and runs in real-time.",2018,"Heng Fan,Haibin Ling",Computer Science,317,61
54475412,Fast Online Object Tracking and Segmentation: A Unifying Approach,"In this paper we illustrate how to perform both visual object tracking and semi-supervised video object segmentation, in real-time, with a single simple approach. Our method, dubbed SiamMask, improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task. Once trained, SiamMask solely relies on a single bounding box initialisation and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 55 frames per second. Despite its simplicity, versatility and fast speed, our strategy allows us to establish a new state-of-the-art among real-time trackers on VOT-2018, while at the same time demonstrating competitive performance and the best speed for the semi-supervised video object segmentation task on DAVIS-2016 and DAVIS-2017.",2018,"Qiang Wang,Li Zhang,Luca Bertinetto,Weiming Hu,Philip H. S. Torr",Computer Science,1039,78
53961460,Grid R-CNN,"This paper proposes a novel object detection framework named Grid R-CNN, which adopts a grid guided localization mechanism for accurate object detection. Different from the traditional regression based methods, the Grid R-CNN captures the spatial information explicitly and enjoys the position sensitive property of fully convolutional architecture. Instead of using only two independent points, we design a multi-point supervision formulation to encode more clues in order to reduce the impact of inaccurate prediction of specific points. To take the full advantage of the correlation of points in a grid, we propose a two-stage information fusion strategy to fuse feature maps of neighbor grid points. The grid guided localization approach is easy to be extended to different state-of-the-art detection frameworks. Grid R-CNN leads to high quality object localization, and experiments demonstrate that it achieves a 4.1% AP gain at IoU=0.8 and a 10.0% AP gain at IoU=0.9 on COCO benchmark compared to Faster R-CNN with Res50 backbone and FPN architecture.",2018,"Xin Lu,Buyu Li,Yuxin Yue,Quanquan Li,Junjie Yan",Computer Science,288,33
104291974,SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking,"The greatest challenge facing visual object tracking is the simultaneous requirements on robustness and discrimination power. In this paper, we propose a SiamFC-based tracker, named SPM-Tracker, to tackle this challenge. The basic idea is to address the two requirements in two separate matching stages. Robustness is strengthened in the coarse matching (CM) stage through generalized training while discrimination power is enhanced in the fine matching (FM) stage through a distance learning network. The two stages are connected in series as the input proposals of the FM stage are generated by the CM stage. They are also connected in parallel as the matching scores and box location refinements are fused to generate the final results. This innovative series-parallel structure takes advantage of both stages and results in superior performance. The proposed SPM-Tracker, running at 120fps on GPU, achieves an AUC of 0.687 on OTB-100 and an EAO of 0.434 on VOT-16, exceeding other real-time trackers by a notable margin.",2019,"Guangting Wang,Chong Luo,Zhiwei Xiong,Wenjun Zeng",Computer Science,160,60
53712235,ATOM: Accurate Tracking by Overlap Maximization,"While recent years have witnessed astonishing improvements in visual tracking robustness, the advancements in tracking accuracy have been limited. As the focus has been directed towards the development of powerful classifiers, the problem of accurate target state estimation has been largely overlooked. In fact, most trackers resort to a simple multi-scale search in order to estimate the target bounding box. We argue that this approach is fundamentally limited since target estimation is a complex task, requiring high-level knowledge about the object. We address this problem by proposing a novel tracking architecture, consisting of dedicated target estimation and classification components. High level knowledge is incorporated into the target estimation through extensive offline learning. Our target estimation component is trained to predict the overlap between the target object and an estimated bounding box. By carefully integrating target-specific information, our approach achieves previously unseen bounding box accuracy. We further introduce a classification component that is trained online to guarantee high discriminative power in the presence of distractors. Our final tracking framework sets a new state-of-the-art on five challenging benchmarks. On the new large-scale TrackingNet dataset, our tracker ATOM achieves a relative gain of 15% over the previous best approach, while running at over 30 FPS. Code and models are available at https://github.com/visionml/pytracking.",2018,"Martin Danelljan,Goutam Bhat,F. Khan,M. Felsberg",Computer Science,838,43
52908642,Continual learning of context-dependent processing in neural networks,,2018,"Guanxiong Zeng,Yang Chen,Bo Cui,Shan Yu",Computer Science,196,63
53104061,Three Mechanisms of Weight Decay Regularization,"Weight decay is one of the standard tricks in the neural network toolbox, but the reasons for its regularization effect are poorly understood, and recent results have cast doubt on the traditional interpretation in terms of $L_2$ regularization. Literal weight decay has been shown to outperform $L_2$ regularization for optimizers for which they differ. We empirically investigate weight decay for three optimization algorithms (SGD, Adam, and K-FAC) and a variety of network architectures. We identify three distinct mechanisms by which weight decay exerts a regularization effect, depending on the particular optimization algorithm and architecture: (1) increasing the effective learning rate, (2) approximately regularizing the input-output Jacobian norm, and (3) reducing the effective damping coefficient for second-order optimization. Our results provide insight into how to improve the regularization of neural networks.",2018,"Guodong Zhang,Chaoqi Wang,Bowen Xu,R. Grosse","Computer Science,Mathematics",210,33
52097928,Real-Time MDNet,,2018,"Ilchae Jung,J. Son,Mooyeol Baek,Bohyung Han",Computer Science,230,34
52045903,Distractor-aware Siamese Networks for Visual Object Tracking,,2018,"Zheng Zhu,Qiang Wang,Bo Li,Wei Wu,Junjie Yan,Weiming Hu",Computer Science,966,40
52255840,High Performance Visual Tracking with Siamese Region Proposal Network,"Visual object tracking has been a fundamental topic in recent years and many deep learning based trackers have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers can hardly get top performance with real-time speed. In this paper, we propose the Siamese region proposal network (Siamese-RPN) which is end-to-end trained off-line with large-scale image pairs. Specifically, it consists of Siamese subnetwork for feature extraction and region proposal subnetwork including the classification branch and regression branch. In the inference phase, the proposed framework is formulated as a local one-shot detection task. We can pre-compute the template branch of the Siamese subnetwork and formulate the correlation layers as trivial convolution layers to perform online tracking. Benefit from the proposal refinement, traditional multi-scale test and online fine-tuning can be discarded. The Siamese-RPN runs at 160 FPS while achieving leading performance in VOT2015, VOT2016 and VOT2017 real-time challenges.",2018,"Bo Li,Junjie Yan,Wei Wu,Zheng Zhu,Xiaolin Hu",Computer Science,1808,40
4321186,Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking,"Discriminative Correlation Filters (DCF) are efficient in visual tracking but suffer from unwanted boundary effects. Spatially Regularized DCF (SRDCF) has been suggested to resolve this issue by enforcing spatial penalty on DCF coefficients, which, inevitably, improves the tracking performance at the price of increasing complexity. To tackle online updating, SRDCF formulates its model on multiple training images, further adding difficulties in improving efficiency. In this work, by introducing temporal regularization to SRDCF with single sample, we present our spatial-temporal regularized correlation filters (STRCF). The STRCF formulation can not only serve as a reasonable approximation to SRDCF with multiple training samples, but also provide a more robust appearance model than SRDCF in the case of large appearance variations. Besides, it can be efficiently solved via the alternating direction method of multipliers (ADMM). By incorporating both temporal and spatial regularization, our STRCF can handle boundary effects without much loss in efficiency and achieve superior performance over SRDCF in terms of accuracy and speed. Compared with SRDCF, STRCF with hand-crafted features provides a 5Ã— speedup and achieves a gain of 5.4% and 3.6% AUC score on OTB-2015 and Temple-Color, respectively. Moreover, STRCF with deep features also performs favorably against state-of-the-art trackers and achieves an AUC score of 68.3% on OTB-2015.",2018,"Feng Li,Cheng Tian,W. Zuo,Lei Zhang,Ming-Hsuan Yang",Computer Science,614,42
73497737,Continual Lifelong Learning with Neural Networks: A Review,,2018,"G. I. Parisi,Ronald Kemker,Jose L. Part,Christopher Kanan,S. Wermter","Computer Science,Biology,Mathematics,Medicine",2158,208
93001666,Overcoming Catastrophic Interference using Conceptor-Aided Backpropagation,,2018,"Xu He,H. Jaeger",Computer Science,100,0
208291472,SPARK: Spatial-Aware Online Incremental Attack Against Visual Tracking,,2019,"Qing Guo,Xiaofei Xie,Felix Juefei-Xu,L. Ma,Zhongguo Li,Wanli Xue,Wei Feng,Yang Liu",Computer Science,61,66
191525888,Feature Space Perturbations Yield More Transferable Adversarial Examples,"Many recent works have shown that deep learning models are vulnerable to quasi-imperceptible input perturbations, yet practitioners cannot fully explain this behavior. This work describes a transfer-based blackbox targeted adversarial attack of deep feature space representations that also provides insights into cross-model class representations of deep CNNs. The attack is explicitly designed for transferability and drives feature space representation of a source image at layer L towards the representation of a target image at L. The attack yields highly transferable targeted examples, which outperform competition winning methods by over 30\% in targeted attack metrics. We also show the choice of L to generate examples from is important, transferability characteristics are blackbox model agnostic, and indicate that well trained deep models have similar highly-abstract representations.",2019,"Nathan Inkawhich,W. Wen,Hai Helen Li,Yiran Chen",Computer Science,146,29
131775150,Physical Adversarial Textures That Fool Visual Object Tracking,"We present a method for creating inconspicuous-looking textures that, when displayed as posters in the physical world, cause visual object tracking systems to become confused. As a target being visually tracked moves in front of such a poster, its adversarial texture makes the tracker lock onto it, thus allowing the target to evade. This adversarial attack evaluates several optimization strategies for fooling seldom-targeted regression models: non-targeted, targeted, and a newly-coined family of guided adversarial losses. Also, while we use the Expectation Over Transformation (EOT) algorithm to generate physical adversaries that fool tracking models when imaged under diverse conditions, we compare the impacts of different scene variables to find practical attack setups with high resulting adversarial strength and convergence speed. We further showcase that textures optimized using simulated scenes can confuse real-world tracking systems for cameras and robots.",2019,"R. Wiyatno,Anqi Xu","Computer Science,Engineering",61,33
121124946,Fooling Automated Surveillance Cameras: Adversarial Patches to Attack Person Detection,"Adversarial attacks on machine learning models have seen increasing interest in the past years. By making only subtle changes to the input of a convolutional neural network, the output of the network can be swayed to output a completely different result. The first attacks did this by changing pixel values of an input image slightly to fool a classifier to output the wrong class. Other approaches have tried to learn ""patches"" that can be applied to an object to fool detectors and classifiers. Some of these approaches have also shown that these attacks are feasible in the real-world, i.e. by modifying an object and filming it with a video camera. However, all of these approaches target classes that contain almost no intra-class variety (e.g. stop signs). The known structure of the object is then used to generate an adversarial patch on top of it. In this paper, we present an approach to generate adversarial patches to targets with lots of intra-class variety, namely persons. The goal is to generate a patch that is able successfully hide a person from a person detector. An attack that could for instance be used maliciously to circumvent surveillance systems, intruders can sneak around undetected by holding a small cardboard plate in front of their body aimed towards the surveilance camera. From our results we can see that our system is able significantly lower the accuracy of a person detector. Our approach also functions well in real-life scenarios where the patch is filmed by a camera. To the best of our knowledge we are the first to attempt this kind of attack on targets with a high level of intra-class variety like persons.",2019,"Simen Thys,W. V. Ranst,T. Goedemé",Computer Science,432,20
57189581,SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks,"Siamese network based trackers formulate tracking as convolutional feature cross-correlation between target template and searching region. However, Siamese trackers still have accuracy gap compared with state-of-the-art algorithms and they cannot take advantage of feature from deep networks, such as ResNet-50 or deeper. In this work we prove the core reason comes from the lack of strict translation invariance. By comprehensive theoretical analysis and experimental validations, we break this restriction through a simple yet effective spatial aware sampling strategy and successfully train a ResNet-driven Siamese tracker with significant performance gain. Moreover, we propose a new model architecture to perform depth-wise and layer-wise aggregations, which not only further improves the accuracy but also reduces the model size. We conduct extensive ablation studies to demonstrate the effectiveness of the proposed tracker, which obtains currently the best results on four large tracking benchmarks, including OTB2015, VOT2018, UAV123, and LaSOT. Our model will be released to facilitate further studies based on this problem.",2018,"Bo Li,Wei Wu,Qiang Wang,Fangyi Zhang,Junliang Xing,Junjie Yan",Computer Science,1396,55
54475412,Fast Online Object Tracking and Segmentation: A Unifying Approach,"In this paper we illustrate how to perform both visual object tracking and semi-supervised video object segmentation, in real-time, with a single simple approach. Our method, dubbed SiamMask, improves the offline training procedure of popular fully-convolutional Siamese approaches for object tracking by augmenting their loss with a binary segmentation task. Once trained, SiamMask solely relies on a single bounding box initialisation and operates online, producing class-agnostic object segmentation masks and rotated bounding boxes at 55 frames per second. Despite its simplicity, versatility and fast speed, our strategy allows us to establish a new state-of-the-art among real-time trackers on VOT-2018, while at the same time demonstrating competitive performance and the best speed for the semi-supervised video object segmentation task on DAVIS-2016 and DAVIS-2017.",2018,"Qiang Wang,Li Zhang,Luca Bertinetto,Weiming Hu,Philip H. S. Torr",Computer Science,1039,78
53102207,GOT-10k: A Large High-Diversity Benchmark for Generic Object Tracking in the Wild,"We introduce here a large tracking database that offers an unprecedentedly wide coverage of common moving objects in the wild, called GOT-10k. Specifically, GOT-10k is built upon the backbone of WordNet structure <xref ref-type=""bibr"" rid=""ref1"">[1]</xref> and it populates the majority of over 560 classes of moving objects and 87 motion patterns, magnitudes wider than the most recent similar-scale counterparts <xref ref-type=""bibr"" rid=""ref19"">[19]</xref>, <xref ref-type=""bibr"" rid=""ref20"">[20]</xref>, <xref ref-type=""bibr"" rid=""ref23"">[23]</xref>, <xref ref-type=""bibr"" rid=""ref26"">[26]</xref>. By releasing the large high-diversity database, we aim to provide a unified training and evaluation platform for the development of class-agnostic, generic purposed short-term trackers. The features of GOT-10k and the contributions of this article are summarized in the following. (1) GOT-10k offers over 10,000 video segments with more than 1.5 million manually labeled bounding boxes, enabling unified training and stable evaluation of deep trackers. (2) GOT-10k is by far the first video trajectory dataset that uses the semantic hierarchy of WordNet to guide class population, which ensures a comprehensive and relatively unbiased coverage of diverse moving objects. (3) For the first time, GOT-10k introduces the <italic>one-shot</italic> protocol for tracker evaluation, where the training and test classes are <italic>zero-overlapped</italic>. The protocol avoids biased evaluation results towards familiar objects and it promotes generalization in tracker development. (4) GOT-10k offers additional labels such as motion classes and object visible ratios, facilitating the development of motion-aware and occlusion-aware trackers. (5) We conduct extensive tracking experiments with 39 typical tracking algorithms and their variants on GOT-10k and analyze their results in this paper. (6) Finally, we develop a comprehensive platform for the tracking community that offers full-featured evaluation toolkits, an online evaluation server, and a responsive leaderboard. The annotations of GOT-10k’s test data are kept private to avoid tuning parameters on it.",2018,"Lianghua Huang,Xin Zhao,Kaiqi Huang","Computer Science,Medicine",906,104
52350875,LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking,"In this paper, we present LaSOT, a high-quality benchmark for Large-scale Single Object Tracking. LaSOT consists of 1,400 sequences with more than 3.5M frames in total. Each frame in these sequences is carefully and manually annotated with a bounding box, making LaSOT the largest, to the best of our knowledge, densely annotated tracking benchmark. The average video length of LaSOT is more than 2,500 frames, and each sequence comprises various challenges deriving from the wild where target objects may disappear and re-appear again in the view. By releasing LaSOT, we expect to provide the community with a large-scale dedicated benchmark with high quality for both the training of deep trackers and the veritable evaluation of tracking algorithms. Moreover, considering the close connections of visual appearance and natural language, we enrich LaSOT by providing additional language specification, aiming at encouraging the exploration of natural linguistic feature for tracking. A thorough experimental evaluation of 35 tracking algorithms on LaSOT is presented with detailed analysis, and the results demonstrate that there is still a big room for improvements.",2018,"Heng Fan,Liting Lin,Fan Yang,Peng Chu,Ge Deng,Sijia Yu,Hexin Bai,Yong Xu,Chunyuan Liao,Haibin Ling",Computer Science,849,60
59222267,The Sixth Visual Object Tracking VOT2018 Challenge Results,,2018,"M. Kristan,A. Leonardis,Jiri Matas,M. Felsberg,R. Pflugfelder,L. Č. Zajc,Tomás Vojír,Goutam Bhat,A. Lukežič,Abdelrahman Eldesokey,G. Fernandez,Álvaro García-Martín,Álvaro Iglesias-Arias,Aydin Alatan,Abel Gonzalez-Garcia,A. Petrosino,Alireza Memarmoghadam,A. Vedaldi,A. Muhic,Anfeng He,A. Smeulders,Asanka G. Perera,Bo Li,Boyu Chen,Changick Kim,Changsheng Xu,Changzhen Xiong,Cheng Tian,Chong Luo,Chong Sun,Cong Hao,Daijin Kim,Deepak Mishra,Deming Chen,Dong Wang,Dongyoon Wee,E. Gavves,Erhan Gundogdu,Erik Velasco-Salido,F. Khan,Fan Yang,Fei Zhao,Feng Li,Francesco Battistone,George De Ath,G. R. S. Subrahmanyam,G. Bastos,Haibin Ling,Hamed Kiani Galoogahi,Hankyeol Lee,Haojie Li,Haojie Zhao,Heng Fan,Honggang Zhang,Horst Possegger,Houqiang Li,Huchuan Lu,Hui Zhi,Huiyun Li,Hyemin Lee,H. Chang,I. Drummond,Jack Valmadre,Jaime Spencer Martin,J. Chahl,J. Choi,Jing Li,Jinqiao Wang,Jinqing Qi,Jinyoung Sung,Joakim Johnander,João F. Henriques,Jongwon Choi,Joost van de Weijer,J. Herranz,J. Sanchez,J. Kittler,Junfei Zhuang,Junyu Gao,Klemen Grm,Lichao Zhang,Lijun Wang,Lingxiao Yang,Litu Rout,Liu Si,Luca Bertinetto,Lutao Chu,Manqiang Che,M. Maresca,Martin Danelljan,Ming-Hsuan Yang,Mohamed H. Abdelpakey,M. Shehata,M. Kang,Namhoon Lee,Ning Wang,O. Mikšík,P. Moallem,Pablo Vicente-Moñivar,P. Senna,Peixia Li,Philip H. S. Torr,Priya Mariam Raju,Ruihe Qian,Qiang Wang,Qin Zhou,Qing Guo,Rafael Martin Nieto,Rama Krishna Sai Subrahmanyam Gorthi,R. Tao,R. Bowden,R. Everson,Runling Wang,Sangdoo Yun,Seokeon Choi,Sergio Vivas,Shuai Bai,Shuangping Huang,Sihang Wu,Simon Hadfield,Siwen Wang,S. Golodetz,Ming Tang,Tianyang Xu,Tianzhu Zhang,Tobias Fischer,V. Santopietro,V. Štruc,Wei Wang,W. Zuo,Wei Feng,Wei Wu,Wei Zou,Weiming Hu,Wen-gang Zhou,W. Zeng,Xiaofan Zhang,Xiaohe Wu,Xiaojun Wu,Xinmei Tian,Yan Li,Yan Lu,Yee Wei Law,Yi Wu,Y. Demiris,Yicai Yang,Yifan Jiao,Yuhong Li,Yunhua Zhang,Yuxuan Sun,Zheng Zhang,Zhengyu Zhu,Zhenhua Feng,Zhihui Wang,Zhiqun He",Computer Science,656,100
52036921,Deep Regression Tracking with Shrinkage Loss,,2018,"Xiankai Lu,Chao Ma,Bingbing Ni,Xiaokang Yang,I. Reid,Ming-Hsuan Yang",Computer Science,212,64
212657491,Keyfilter-Aware Real-Time UAV Object Tracking,"Correlation filter-based tracking has been widely applied in unmanned aerial vehicle (UAV) with high efficiency. However, it has two imperfections, i.e., boundary effect and filter corruption. Several methods enlarging the search area can mitigate boundary effect, yet introducing undesired background distraction. Existing frame-by-frame context learning strategies for repressing background distraction nevertheless lower the tracking speed. Inspired by keyframe-based simultaneous localization and mapping, keyfilter is proposed in visual tracking for the first time, in order to handle the above issues efficiently and effectively. Keyfilters generated by periodically selected keyframes learn the context intermittently and are used to restrain the learning of filters, so that 1) context awareness can be transmitted to all the filters via keyfilter restriction, and 2) filter corruption can be repressed. Compared to the state-of-the-art results, our tracker performs better on two challenging benchmarks, with enough speed for UAV real-time applications.",2020,"Yiming Li,Changhong Fu,Ziyuan Huang,Yinqiang Zhang,Jia Pan",Computer Science,34,40
199543536,Boundary Effect-Aware Visual Tracking for UAV with Online Enhanced Background Learning and Multi-Frame Consensus Verification,"Due to implicitly introduced periodic shifting of limited searching area, visual object tracking using correlation filters often has to confront undesired boundary effect. As boundary effect severely degrade the quality of object model, it has made it a challenging task for unmanned aerial vehicles (UAV) to perform robust and accurate object following. Traditional hand-crafted features are also not precise and robust enough to describe the object in the viewing point of UAV. In this work, a novel tracker with online enhanced background learning is specifically proposed to tackle boundary effects. Real background samples are densely extracted to learn as well as update correlation filters. Spatial penalization is introduced to offset the noise introduced by exceedingly more background information so that a more accurate appearance model can be established. Meanwhile, convolutional features are extracted to provide a more comprehensive representation of the object. In order to mitigate changes of objects’ appearances, multi-frame technique is applied to learn an ideal response map and verify the generated one in each frame. Exhaustive experiments were conducted on 100 challenging UAV image sequences and the proposed tracker has achieved state-of-the-art performance.",2019,"Changhong Fu,Ziyuan Huang,Yiming Li,Ran Duan,Peng Lu",Computer Science,20,30
199453091,Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking,"Traditional framework of discriminative correlation filters (DCF) is often subject to undesired boundary effects. Several approaches to enlarge search regions have been already proposed in the past years to make up for this shortcoming. However, with excessive background information, more background noises are also introduced and the discriminative filter is prone to learn from the ambiance rather than the object. This situation, along with appearance changes of objects caused by full/partial occlusion, illumination variation, and other reasons has made it more likely to have aberrances in the detection process, which could substantially degrade the credibility of its result. Therefore, in this work, a novel approach to repress the aberrances happening during the detection process is proposed, i.e., aberrance repressed correlation filter (ARCF). By enforcing restriction to the rate of alteration in response maps generated in the detection phase, the ARCF tracker can evidently suppress aberrances and is thus more robust and accurate to track objects. Considerable experiments are conducted on different UAV datasets to perform object tracking from an aerial view, i.e., UAV123, UAVDT, and DTB70, with 243 challenging image sequences containing over 90K frames to verify the performance of the ARCF tracker and it has proven itself to have outperformed other 20 state-of-the-art trackers based on DCF and deep-based frameworks with sufficient speed for real-time applications.",2019,"Ziyuan Huang,Changhong Fu,Yiming Li,Fuling Lin,Peng Lu",Computer Science,240,31
198347261,Visual Tracking via Adaptive Spatially-Regularized Correlation Filters,"In this work, we propose a novel adaptive spatially-regularized correlation filters (ASRCF) model to simultaneously optimize the filter coefficients and the spatial regularization weight. First, this adaptive spatial regularization scheme could learn an effective spatial weight for a specific object and its appearance variations, and therefore result in more reliable filter coefficients during the tracking process. Second, our ASRCF model can be effectively optimized based on the alternating direction method of multipliers, where each subproblem has the closed-from solution. Third, our tracker applies two kinds of CF models to estimate the location and scale respectively. The location CF model exploits ensembles of shallow and deep features to determine the optimal position accurately. The scale CF model works on multi-scale shallow features to estimate the optimal scale efficiently. Extensive experiments on five recent benchmarks show that our tracker performs favorably against many state-of-the-art algorithms, with real-time performance of 28fps.",2019,"Kenan Dai,D. Wang,Huchuan Lu,Chong Sun,Jianhua Li",Computer Science,255,40
133604052,Multi-Correlation Filters With Triangle-Structure Constraints for Object Tracking,"Correlation filters (CFs) have been extensively used in tracking tasks due to their high efficiency although most of them regard the tracked target as a whole and are minimally effective in handling partial occlusion. In this study, we incorporate a part-based strategy into the framework of CFs and propose a novel multipart correlation tracker with triangle-structure constraints. Specifically, we train multiple CFs for the global object and local parts, which are then jointly applied to obtain the correlation response of any candidate during tracking. The tracker is robust in handling partial occlusion because of the use of part-based representation. The remaining global representation can contribute reliable cues in cases wherein several local filters drift away in a specific scene. We further propose a triangle-structure model to measure the structural similarity of candidates. The model employs multiple triangles to determine the spatial relationship among parts and helps constrain the location of the target. Moreover, we introduce an effective part selection scheme based on energy and integrity, which is generally applicable to part-tracking models. Extensive experiments on two public benchmarks demonstrate the superiority of the proposed method over the state-of-the-art approaches.",2019,"Weijian Ruan,Jun Chen,Yi Wu,Jinqiao Wang,Chao Liang,R. Hu,Junjun Jiang",Computer Science,50,57
102353279,Towards a Robust Aerial Cinematography Platform: Localizing and Tracking Moving Targets in Unstructured Environments,"The use of drones for aerial cinematography has revolutionized several applications and industries that require live and dynamic camera viewpoints such as entertainment, sports, and security. However, safely controlling a drone while filming a moving target usually requires multiple expert human operators; hence the need for an autonomous cinematographer. Current approaches have severe real-life limitations such as requiring fully scripted scenes, high-precision motion-capture systems or GPS tags to localize targets, and prior maps of the environment to avoid obstacles and plan for occlusion.In this work, we overcome such limitations and propose a complete system for aerial cinematography that combines: (1) a vision-based algorithm for target localization; (2) a real-time incremental 3D signed-distance map algorithm for occlusion and safety computation; and (3) a real-time camera motion planner that optimizes smoothness, collisions, occlusions and artistic guidelines. We evaluate robustness and real-time performance in series of field experiments and simulations by tracking dynamic targets moving through unknown, unstructured environments. Finally, we verify that despite removing previous limitations, our system achieves state-of-the-art performance.",2019,"Rogerio Bonatti,Cherie Ho,Wenshan Wang,Sanjiban Choudhury,S. Scherer",Computer Science,68,43
102487133,Unsupervised Deep Tracking,"We propose an unsupervised visual tracking method in this paper. Different from existing approaches using extensive annotated data for supervised learning, our CNN model is trained on large-scale unlabeled videos in an unsupervised manner. Our motivation is that a robust tracker should be effective in both the forward and backward predictions (i.e., the tracker can forward localize the target object in successive frames and backtrace to its initial position in the first frame). We build our framework on a Siamese correlation filter network, which is trained using unlabeled raw videos. Meanwhile, we propose a multiple-frame validation method and a cost-sensitive loss to facilitate unsupervised learning. Without bells and whistles, the proposed unsupervised tracker achieves the baseline accuracy of fully supervised trackers, which require complete and accurate labels during training. Furthermore, unsupervised framework exhibits a potential in leveraging unlabeled or weakly labeled data to further improve the tracking accuracy.",2019,"Ning Wang,Yibing Song,Chao Ma,Wen-gang Zhou,W. Liu,Houqiang Li",Computer Science,291,59
51993386,Multi-cue Correlation Filters for Robust Visual Tracking,"In recent years, many tracking algorithms achieve impressive performance via fusing multiple types of features, however, most of them fail to fully explore the context among the adopted multiple features and the strength of them. In this paper, we propose an efficient multi-cue analysis framework for robust visual tracking. By combining different types of features, our approach constructs multiple experts through Discriminative Correlation Filter (DCF) and each of them tracks the target independently. With the proposed robustness evaluation strategy, the suitable expert is selected for tracking in each frame. Furthermore, the divergence of multiple experts reveals the reliability of the current tracking, which is quantified to update the experts adaptively to keep them from corruption. Through the proposed multi-cue analysis, our tracker with standard DCF and deep features achieves outstanding results on several challenging benchmarks: OTB-2013, OTB-2015, Temple-Color and VOT 2016. On the other hand, when evaluated with only simple hand-crafted features, our method demonstrates comparable performance amongst complex non-realtime trackers, but exhibits much better efficiency, with a speed of 45 FPS on a CPU.",2018,"Ning Wang,Wen-gang Zhou,Q. Tian,Richang Hong,Meng Wang,Houqiang Li",Computer Science,299,58
4803532,VITAL: VIsual Tracking via Adversarial Learning,"The tracking-by-detection framework consists of two stages, i.e., drawing samples around the target object in the first stage and classifying each sample as the target object or as background in the second stage. The performance of existing trackers using deep classification networks is limited by two aspects. First, the positive samples in each frame are highly spatially overlapped, and they fail to capture rich appearance variations. Second, there exists extreme class imbalance between positive and negative samples. This paper presents the VITAL algorithm to address these two problems via adversarial learning. To augment positive samples, we use a generative network to randomly generate masks, which are applied to adaptively dropout input features to capture a variety of appearance changes. With the use of adversarial learning, our network identifies the mask that maintains the most robust features of the target objects over a long temporal span. In addition, to handle the issue of class imbalance, we propose a high-order cost sensitive loss to decrease the effect of easy negative samples to facilitate training the classification network. Extensive experiments on benchmark datasets demonstrate that the proposed tracker performs favorably against state-of-the-art approaches.",2018,"Yibing Song,Chao Ma,Xiaohe Wu,Lijun Gong,Linchao Bao,W. Zuo,Chunhua Shen,Rynson W. H. Lau,Ming-Hsuan Yang",Computer Science,469,64
4321186,Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking,"Discriminative Correlation Filters (DCF) are efficient in visual tracking but suffer from unwanted boundary effects. Spatially Regularized DCF (SRDCF) has been suggested to resolve this issue by enforcing spatial penalty on DCF coefficients, which, inevitably, improves the tracking performance at the price of increasing complexity. To tackle online updating, SRDCF formulates its model on multiple training images, further adding difficulties in improving efficiency. In this work, by introducing temporal regularization to SRDCF with single sample, we present our spatial-temporal regularized correlation filters (STRCF). The STRCF formulation can not only serve as a reasonable approximation to SRDCF with multiple training samples, but also provide a more robust appearance model than SRDCF in the case of large appearance variations. Besides, it can be efficiently solved via the alternating direction method of multipliers (ADMM). By incorporating both temporal and spatial regularization, our STRCF can handle boundary effects without much loss in efficiency and achieve superior performance over SRDCF in terms of accuracy and speed. Compared with SRDCF, STRCF with hand-crafted features provides a 5Ã— speedup and achieves a gain of 5.4% and 3.6% AUC score on OTB-2015 and Temple-Color, respectively. Moreover, STRCF with deep features also performs favorably against state-of-the-art trackers and achieves an AUC score of 68.3% on OTB-2015.",2018,"Feng Li,Cheng Tian,W. Zuo,Lei Zhang,Ming-Hsuan Yang",Computer Science,614,42
202578069,GradNet: Gradient-Guided Network for Visual Object Tracking,"The fully-convolutional siamese network based on template matching has shown great potentials in visual tracking. During testing, the template is fixed with the initial target feature and the performance totally relies on the general matching ability of the siamese network. However, this manner cannot capture the temporal variations of targets or background clutter. In this work, we propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations. To be specific, the algorithm can utilize the information from the gradient to update the template in the current frame. In addition, a template generalization training method is proposed to better use gradient information and avoid overfitting. To our knowledge, this work is the first attempt to exploit the information in the gradient for template update in siamese-based trackers. Extensive experiments on recent benchmarks demonstrate that our method achieves better performance than other state-of-the-art trackers.",2019,"Peixia Li,Boyu Chen,Wanli Ouyang,Dong Wang,Xiaoyun Yang,Huchuan Lu",Computer Science,198,46
199453091,Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking,"Traditional framework of discriminative correlation filters (DCF) is often subject to undesired boundary effects. Several approaches to enlarge search regions have been already proposed in the past years to make up for this shortcoming. However, with excessive background information, more background noises are also introduced and the discriminative filter is prone to learn from the ambiance rather than the object. This situation, along with appearance changes of objects caused by full/partial occlusion, illumination variation, and other reasons has made it more likely to have aberrances in the detection process, which could substantially degrade the credibility of its result. Therefore, in this work, a novel approach to repress the aberrances happening during the detection process is proposed, i.e., aberrance repressed correlation filter (ARCF). By enforcing restriction to the rate of alteration in response maps generated in the detection phase, the ARCF tracker can evidently suppress aberrances and is thus more robust and accurate to track objects. Considerable experiments are conducted on different UAV datasets to perform object tracking from an aerial view, i.e., UAV123, UAVDT, and DTB70, with 243 challenging image sequences containing over 90K frames to verify the performance of the ARCF tracker and it has proven itself to have outperformed other 20 state-of-the-art trackers based on DCF and deep-based frameworks with sufficient speed for real-time applications.",2019,"Ziyuan Huang,Changhong Fu,Yiming Li,Fuling Lin,Peng Lu",Computer Science,240,31
199405431,Learning the Model Update for Siamese Trackers,"Siamese approaches address the visual tracking problem by extracting an appearance template from the current frame, which is used to localize the target in the next frame. In general, this template is linearly combined with the accumulated template from the previous frame, resulting in an exponential decay of information over time. While such an approach to updating has led to improved results, its simplicity limits the potential gain likely to be obtained by learning to update. Therefore, we propose to replace the handcrafted update function with a method which learns to update. We use a convolutional neural network, called UpdateNet, which given the initial template, the accumulated template and the template of the current frame aims to estimate the optimal template for the next frame. The UpdateNet is compact and can easily be integrated into existing Siamese trackers. We demonstrate the generality of the proposed approach by applying it to two Siamese trackers, SiamFC and DaSiamRPN. Extensive experiments on VOT2016, VOT2018, LaSOT, and TrackingNet datasets demonstrate that our UpdateNet effectively predicts the new target template, outperforming the standard linear update. On the large-scale TrackingNet dataset, our UpdateNet improves the results of DaSiamRPN with an absolute gain of 3.9% in terms of success score.",2019,"Lichao Zhang,Abel Gonzalez-Garcia,Joost van de Weijer,Martin Danelljan,F. Khan",Computer Science,241,51
199001006,Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking,"We propose a new Group Feature Selection method for Discriminative Correlation Filters (GFS-DCF) based visual object tracking. The key innovation of the proposed method is to perform group feature selection across both channel and spatial dimensions, thus to pinpoint the structural relevance of multi-channel features to the filtering system. In contrast to the widely used spatial regularisation or feature selection methods, to the best of our knowledge, this is the first time that channel selection has been advocated for DCF-based tracking. We demonstrate that our GFS-DCF method is able to significantly improve the performance of a DCF tracker equipped with deep neural network features. In addition, our GFS-DCF enables joint feature selection and filter learning, achieving enhanced discrimination and interpretability of the learned filters. To further improve the performance, we adaptively integrate historical information by constraining filters to be smooth across temporal frames, using an efficient low-rank approximation. By design, specific temporal-spatial-channel configurations are dynamically learned in the tracking process, highlighting the relevant features, and alleviating the performance degrading impact of less discriminative representations and reducing information redundancy. The experimental results obtained on OTB2013, OTB2015, VOT2017, VOT2018 and TrackingNet demonstrate the merits of our GFS-DCF and its superiority over the state-of-the-art trackers. The code is publicly available at \url{https://github.com/XU-TIANYANG/GFS-DCF}.",2019,"Tianyang Xu,Zhenhua Feng,Xiaojun Wu,J. Kittler",Computer Science,140,93
118637813,Learning Discriminative Model Prediction for Tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",2019,"Goutam Bhat,Martin Danelljan,L. Gool,R. Timofte",Computer Science,761,50
104291974,SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking,"The greatest challenge facing visual object tracking is the simultaneous requirements on robustness and discrimination power. In this paper, we propose a SiamFC-based tracker, named SPM-Tracker, to tackle this challenge. The basic idea is to address the two requirements in two separate matching stages. Robustness is strengthened in the coarse matching (CM) stage through generalized training while discrimination power is enhanced in the fine matching (FM) stage through a distance learning network. The two stages are connected in series as the input proposals of the FM stage are generated by the CM stage. They are also connected in parallel as the matching scores and box location refinements are fused to generate the final results. This innovative series-parallel structure takes advantage of both stages and results in superior performance. The proposed SPM-Tracker, running at 120fps on GPU, achieves an AUC of 0.687 on OTB-100 and an EAO of 0.434 on VOT-16, exceeding other real-time trackers by a notable margin.",2019,"Guangting Wang,Chong Luo,Zhiwei Xiong,Wenjun Zeng",Computer Science,160,60
57573771,Deeper and Wider Siamese Networks for Real-Time Visual Tracking,"Siamese networks have drawn great attention in visual tracking because of their balanced accuracy and speed. However, the backbone networks used in Siamese trackers are relatively shallow, such as AlexNet, which does not fully take advantage of the capability of modern deep neural networks. In this paper, we investigate how to leverage deeper and wider convolutional neural networks to enhance tracking robustness and accuracy. We observe that direct replacement of backbones with existing powerful architectures, such as ResNet and Inception, does not bring improvements. The main reasons are that 1) large increases in the receptive field of neurons lead to reduced feature discriminability and localization precision; and 2) the network padding for convolutions induces a positional bias in learning. To address these issues, we propose new residual modules to eliminate the negative impact of padding, and further design new architectures using these modules with controlled receptive field size and network stride. The designed architectures are lightweight and guarantee real-time tracking speed when applied to SiamFC and SiamRPN. Experiments show that solely due to the proposed network architectures, our SiamFC+ and SiamRPN+ obtain up to 9.8%/6.3% (AUC), 23.3%/8.8% (EAO) and 24.4%/25.0% (EAO) relative improvements over the original versions on the OTB-15, VOT-16 and VOT-17 datasets, respectively.",2019,"Zhipeng Zhang,Houwen Peng,Qiang Wang",Computer Science,709,45
57189581,SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks,"Siamese network based trackers formulate tracking as convolutional feature cross-correlation between target template and searching region. However, Siamese trackers still have accuracy gap compared with state-of-the-art algorithms and they cannot take advantage of feature from deep networks, such as ResNet-50 or deeper. In this work we prove the core reason comes from the lack of strict translation invariance. By comprehensive theoretical analysis and experimental validations, we break this restriction through a simple yet effective spatial aware sampling strategy and successfully train a ResNet-driven Siamese tracker with significant performance gain. Moreover, we propose a new model architecture to perform depth-wise and layer-wise aggregations, which not only further improves the accuracy but also reduces the model size. We conduct extensive ablation studies to demonstrate the effectiveness of the proposed tracker, which obtains currently the best results on four large tracking benchmarks, including OTB2015, VOT2018, UAV123, and LaSOT. Our model will be released to facilitate further studies based on this problem.",2018,"Bo Li,Wei Wu,Qiang Wang,Fangyi Zhang,Junliang Xing,Junjie Yan",Computer Science,1396,55
56305074,Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking,"Recently, the region proposal networks (RPN) have been combined with the Siamese network for tracking, and shown excellent accuracy with high efficiency. Nevertheless, previously proposed one-stage Siamese-RPN trackers degenerate in presence of similar distractors and large scale variation. Addressing these issues, we propose a multi-stage tracking framework, Siamese Cascaded RPN (C-RPN), which consists of a sequence of RPNs cascaded from deep high-level to shallow low-level layers in a Siamese network. Compared to previous solutions, C-RPN has several advantages: (1) Each RPN is trained using the outputs of RPN in the previous stage. Such process stimulates hard negative sampling, resulting in more balanced training samples. Consequently, the RPNs are sequentially more discriminative in distinguishing difficult background (i.e.,, similar distractors). (2) Multi-level features are fully leveraged through a novel feature transfer block (FTB) for each RPN, further improving the discriminability of C-RPN using both high-level semantic and low-level spatial information. (3) With multiple steps of regressions, C-RPN progressively refines the location and shape of the target in each RPN with adjusted anchor boxes in the previous stage, which makes localization more accurate. C-RPN is trained end-to-end with the multi-task loss function. In inference, C-RPN is deployed as it is, without any temporal adaption, for real-time tracking. In extensive experiments on OTB-2013, OTB-2015, VOT-2016, VOT-2017, LaSOT and TrackingNet, C-RPN consistently achieves state-of-the-art results and runs in real-time.",2018,"Heng Fan,Haibin Ling",Computer Science,317,61
219305183,COMET: Context-Aware IoU-Guided Network for Small Object Tracking,,2020,"S. M. Marvasti-Zadeh,Javad Khaghani,Hossein Ghanei-Yakhdan,S. Kasaei,Li Cheng","Computer Science,Engineering",20,81
218502189,NTIRE 2020 Challenge on Real-World Image Super-Resolution: Methods and Results,"This paper reviews the NTIRE 2020 challenge on real world super-resolution. It focuses on the participating methods and final results. The challenge addresses the real world setting, where paired true high and low-resolution images are unavailable. For training, only one set of source input images is therefore provided along with a set of unpaired high-quality target images. In Track 1: Image Processing artifacts, the aim is to super-resolve images with synthetically generated image processing artifacts. This allows for quantitative benchmarking of the approaches w.r.t. a ground-truth image. In Track 2: Smartphone Images, real low-quality smart phone images have to be super-resolved. In both tracks, the ultimate goal is to achieve the best perceptual quality, evaluated using a human study. This is the second challenge on the subject, following AIM 2019, targeting to advance the state-of-the-art in super-resolution. To measure the performance we use the benchmark protocol from AIM 2019. In total 22 teams competed in the final testing phase, demonstrating new and innovative solutions to the problem.",2020,"Andreas Lugmayr,Martin Danelljan,R. Timofte,Namhyuk Ahn,Dongwoon Bai,Jie Cai,Yun Cao,Junyang Chen,Kaihua Cheng,SeYoung Chun,Wei Deng,Mostafa El-Khamy,C. Ho,Xiaozhong Ji,A. Kheradmand,Gwantae Kim,Hanseok Ko,Kanghyu Lee,Jungwon Lee,Hao Li,Ziluan Liu,Zhi-Song Liu,Shuai Liu,Yunhua Lu,Zibo Meng,Pablo Navarrete Michelini,C. Micheloni,Kalpesh P. Prajapati,Haoyu Ren,Yong Hyeok Seo,W. Siu,Kyung-ah Sohn,Ying Tai,Rao Muhammad Umer,Shuangquan Wang,Huibing Wang,Timothy Haoning Wu,Haoning Wu,Biao Yang,Fuzhi Yang,Jaejun Yoo,Tongtong Zhao,Yuanbo Zhou,Haijie Zhuo,Ziyao Zong,Xueyi Zou","Engineering,Computer Science",143,83
216398541,Recent advances in small object detection based on deep learning: A review,,2020,"Kang Tong,Yiquan Wu,Fei Zhou",Computer Science,294,90
215745370,Residual Attention U-Net for Automated Multi-Class Segmentation of COVID-19 Chest CT Images,"The novel coronavirus disease 2019 (COVID-19) has been spreading rapidly around the world and caused significant impact on the public health and economy. However, there is still lack of studies on effectively quantifying the lung infection caused by COVID-19. As a basic but challenging task of the diagnostic framework, segmentation plays a crucial role in accurate quantification of COVID-19 infection measured by computed tomography (CT) images. To this end, we proposed a novel deep learning algorithm for automated segmentation of multiple COVID-19 infection regions. Specifically, we use the Aggregated Residual Transformations to learn a robust and expressive feature representation and apply the soft attention mechanism to improve the capability of the model to distinguish a variety of symptoms of the COVID-19. With a public CT image dataset, we validate the efficacy of the proposed algorithm in comparison with other competing methods. Experimental results demonstrate the outstanding performance of our algorithm for automated segmentation of COVID-19 Chest CT images. Our study provides a promising deep leaning-based segmentation tool to lay a foundation to quantitative diagnosis of COVID-19 lung infection in CT images.",2020,"Xiaocong Chen,Lina Yao,Yu Zhang","Engineering,Computer Science,Biology",178,37
210834218,Convolution operators for visual tracking based on spatial–temporal regularization,,2020,"Peng Wang,Mengyu Sun,Haiyan Wang,Xiaoyan Li,Yongxia Yang",Computer Science,9,27
208527176,Deep Learning for Visual Tracking: A Comprehensive Survey,"Visual target tracking is one of the most sought-after yet challenging research topics in computer vision. Given the ill-posed nature of the problem and its popularity in a broad range of real-world scenarios, a number of large-scale benchmark datasets have been established, on which considerable methods have been developed and demonstrated with significant progress in recent years – predominantly by recent deep learning (DL)-based methods. This survey aims to systematically investigate the current DL-based visual tracking methods, benchmark datasets, and evaluation metrics. It also extensively evaluates and analyzes the leading visual tracking methods. First, the fundamental characteristics, primary motivations, and contributions of DL-based methods are summarized from nine key aspects of: network architecture, network exploitation, network training for visual tracking, network objective, network output, exploitation of correlation filter advantages, aerial-view tracking, long-term tracking, and online tracking. Second, popular visual tracking benchmarks and their respective properties are compared, and their evaluation metrics are summarized. Third, the state-of-the-art DL-based methods are comprehensively examined on a set of well-established benchmarks of OTB2013, OTB2015, VOT2018, LaSOT, UAV123, UAVDT, and VisDrone2019. Finally, by conducting critical analyses of these state-of-the-art trackers quantitatively and qualitatively, their pros and cons under various common scenarios are investigated. It may serve as a gentle use guide for practitioners to weigh when and under what conditions to choose which method(s). It also facilitates a discussion on ongoing issues and sheds light on promising research directions.",2019,"S. M. Marvasti-Zadeh,Li Cheng,Hossein Ghanei-Yakhdan,S. Kasaei","Computer Science,Engineering",205,272
196700924,Graph Convolutional Tracking,"Tracking by siamese networks has achieved favorable performance in recent years. However, most of existing siamese methods do not take full advantage of spatial-temporal target appearance modeling under different contextual situations. In fact, the spatial-temporal information can provide diverse features to enhance the target representation, and the context information is important for online adaption of target localization. To comprehensively leverage the spatial-temporal structure of historical target exemplars and get benefit from the context information, in this work, we present a novel Graph Convolutional Tracking (GCT) method for high-performance visual tracking. Specifically, the GCT jointly incorporates two types of Graph Convolutional Networks (GCNs) into a siamese framework for target appearance modeling. Here, we adopt a spatial-temporal GCN to model the structured representation of historical target exemplars. Furthermore, a context GCN is designed to utilize the context of the current frame to learn adaptive features for target localization. Extensive results on 4 challenging benchmarks show that our GCT method performs favorably against state-of-the-art trackers while running around 50 frames per second.",2019,"Junyu Gao,Tianzhu Zhang,Changsheng Xu",Computer Science,212,88
150373805,A Survey on Deep Learning based Brain Computer Interface: Recent Advances and New Frontiers,"Brain-Computer Interface (BCI) bridges the human's neural world and the outer physical world by decoding individuals' brain signals into commands recognizable by computer devices. Deep learning has lifted the performance of brain-computer interface systems significantly in recent years. In this article, we systematically investigate brain signal types for BCI and related deep learning concepts for brain signal analysis. We then present a comprehensive survey of deep learning techniques used for BCI, by summarizing over 230 contributions most published in the past five years. Finally, we discuss the applied areas, opening challenges, and future directions for deep learning-based BCI.",2019,"Xiang Zhang,Lina Yao,Xianzhi Wang,Jessica J. M. Monaghan,D. McAlpine","Computer Science,Engineering,Biology",118,254
199490651,Rotation-Aware Discriminative Scale Space Tracking,"Although discriminative correlation filters (DCF) based methods have achieved desirable performance in visual tracking, most existing methods still fail to cope with significant target rotations in challenging scenarios. This paper proposes a rotation-aware DCF-based tracking method that efficiently estimates the target rotation and exploits the estimated rotation in translation and scale models. The proposed method reformulates the discriminative scale space tracker (DSST) to estimate target location and rotation, simultaneously. Then, the estimated rotation integrates into the scale estimation process, effectively. While the proposed method can estimate all target rotations, it uses only three target models in each frame to have desirable tracking speed. Experimental results demonstrate that the proposed method outperforms the average precision and success rate of the DSST up to 3.9% and 5.3% on 21 relevant video sequences, respectively.",2019,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei",Computer Science,8,19
57573771,Deeper and Wider Siamese Networks for Real-Time Visual Tracking,"Siamese networks have drawn great attention in visual tracking because of their balanced accuracy and speed. However, the backbone networks used in Siamese trackers are relatively shallow, such as AlexNet, which does not fully take advantage of the capability of modern deep neural networks. In this paper, we investigate how to leverage deeper and wider convolutional neural networks to enhance tracking robustness and accuracy. We observe that direct replacement of backbones with existing powerful architectures, such as ResNet and Inception, does not bring improvements. The main reasons are that 1) large increases in the receptive field of neurons lead to reduced feature discriminability and localization precision; and 2) the network padding for convolutions induces a positional bias in learning. To address these issues, we propose new residual modules to eliminate the negative impact of padding, and further design new architectures using these modules with controlled receptive field size and network stride. The designed architectures are lightweight and guarantee real-time tracking speed when applied to SiamFC and SiamRPN. Experiments show that solely due to the proposed network architectures, our SiamFC+ and SiamRPN+ obtain up to 9.8%/6.3% (AUC), 23.3%/8.8% (EAO) and 24.4%/25.0% (EAO) relative improvements over the original versions on the OTB-15, VOT-16 and VOT-17 datasets, respectively.",2019,"Zhipeng Zhang,Houwen Peng,Qiang Wang",Computer Science,709,45
208337271,An improved correlation filter tracking method with occlusion and drift handling,,2019,"Jun Liu,Zhongqiang Luo,Xingzhong Xiong",Computer Science,5,52
207828448,A new TLD target tracking method based on improved correlation filter and adaptive scale,,2019,"Xin Yang,Songyan Zhu,Sijun Xia,Dake Zhou",Computer Science,9,33
102486909,Target-Aware Deep Tracking,"Existing deep trackers mainly use convolutional neural networks pre-trained for the generic object recognition task for representations. Despite demonstrated successes for numerous vision tasks, the contributions of using pre-trained deep features for visual tracking are not as significant as that for object recognition. The key issue is that in visual tracking the targets of interest can be arbitrary object class with arbitrary forms. As such, pre-trained deep features are less effective in modeling these targets of arbitrary forms for distinguishing them from the background. In this paper, we propose a novel scheme to learn target-aware features, which can better recognize the targets undergoing significant appearance variations than pre-trained deep features. To this end, we develop a regression loss and a ranking loss to guide the generation of target-active and scale-sensitive features. We identify the importance of each convolutional filter according to the back-propagated gradients and select the target-aware features based on activations for representing the targets. The target-aware features are integrated with a Siamese matching network for visual tracking. Extensive experimental results show that the proposed algorithm performs favorably against the state-of-the-art methods in terms of accuracy and speed.",2019,"Xin Li,Chao Ma,Baoyuan Wu,Zhenyu He,Ming-Hsuan Yang",Computer Science,306,54
61156483,Part-based visual tracking with spatially regularized correlation filters,,2019,"Dejun Zhang,Zhao Zhang,Lu Zou,Zhuyang Xie,Fazhi He,Yiqi Wu,Zhigang Tu",Computer Science,21,55
59307502,Long-term correlation tracking via spatial–temporal context,,2019,"Zhi Chen,Peizhong Liu,Yongzhao Du,Yanmin Luo,Jing-Ming Guo",Computer Science,6,47
53697865,Multiple Context Features in Siamese Networks for Visual Object Tracking,,2018,Henrique Morimitsu,Computer Science,11,35
52952498,Real-Time 'Actor-Critic' Tracking,,2018,"Boyu Chen,D. Wang,Peixia Li,Shuang Wang,Huchuan Lu",Computer Science,123,56
3520436,A Twofold Siamese Network for Real-Time Object Tracking,"Observing that Semantic features learned in an image classification task and Appearance features learned in a similarity matching task complement each other, we build a twofold Siamese network, named SA-Siam, for real-time object tracking. SA-Siam is composed of a semantic branch and an appearance branch. Each branch is a similaritylearning Siamese network. An important design choice in SA-Siam is to separately train the two branches to keep the heterogeneity of the two types of features. In addition, we propose a channel attention mechanism for the semantic branch. Channel-wise weights are computed according to the channel activations around the target position. While the inherited architecture from SiamFC [3] allows our tracker to operate beyond real-time, the twofold design and the attention mechanism significantly improve the tracking performance. The proposed SA-Siam outperforms all other real-time trackers by a large margin on OTB-2013/50/100 benchmarks.",2018,"Anfeng He,Chong Luo,Xinmei Tian,Wenjun Zeng",Computer Science,512,41
5048038,Adaptive spatio-temporal context learning for visual target tracking,"While visual target tracking is one of the noteworthy and the most active research areas in computer vision and machine learning, many challenges are still unresolved. In this paper, an adaptive generic target tracker is proposed that includes the adaptive determination of learning parameters from spatio-temporal context model, analysis of prior targets and confidence map for accurate target localization, and modified scale estimation scheme based on confidence map. According to spatio-temporal context model, the learning parameters are adaptively determined for achieving confidence map and target scale robustly. Moreover, analysis of the confidence map helps our tracker to change context feature set and accurately estimate target location in critical situations such as occlusion, appearance changes, and pose variation. Finally, we propose a modified scale estimation scheme based on confidence map that corrects adopted scale when the confidence map is not reliable. Experimental results on numerous video sequences show that the proposed adaptive generic tracker outperforms both the accuracy and robustness compared to the dense spatio-temporal context learning (STC) tracker effectively.",2017,"S. M. Marvasti-Zadeh,Hossein Ghanei-Yakhdan,S. Kasaei",Computer Science,4,16
22947351,Robust Visual Tracking via Hierarchical Convolutional Features,"Visual tracking is challenging as target objects often undergo significant appearance changes caused by deformation, abrupt motion, background clutter and occlusion. In this paper, we propose to exploit the rich hierarchical features of deep convolutional neural networks to improve the accuracy and robustness of visual tracking. Deep neural networks trained on object recognition datasets consist of multiple convolutional layers. These layers encode target appearance with different levels of abstraction. For example, the outputs of the last convolutional layers encode the semantic information of targets and such representations are invariant to significant appearance variations. However, their spatial resolutions are too coarse to precisely localize the target. In contrast, features from earlier convolutional layers provide more precise localization but are less invariant to appearance changes. We interpret the hierarchical features of convolutional layers as a nonlinear counterpart of an image pyramid representation and explicitly exploit these multiple levels of abstraction to represent target objects. Specifically, we learn adaptive correlation filters on the outputs from each convolutional layer to encode the target appearance. We infer the maximum response of each layer to locate targets in a coarse-to-fine manner. To further handle the issues with scale estimation and re-detecting target objects from tracking failures caused by heavy occlusion or out-of-the-view movement, we conservatively learn another correlation filter, that maintains a long-term memory of target appearance, as a discriminative classifier. We apply the classifier to two types of object proposals: (1) proposals with a small step size and tightly around the estimated location for scale estimation; and (2) proposals with large step size and across the whole image for target re-detection. Extensive experimental results on large-scale benchmark datasets show that the proposed algorithm performs favorably against the state-of-the-art tracking methods.",2017,"Chao Ma,Jia-Bin Huang,Xiaokang Yang,Ming-Hsuan Yang","Computer Science,Medicine",174,82
219305183,COMET: Context-Aware IoU-Guided Network for Small Object Tracking,,2020,"S. M. Marvasti-Zadeh,Javad Khaghani,Hossein Ghanei-Yakhdan,S. Kasaei,Li Cheng","Computer Science,Engineering",20,81
216398541,Recent advances in small object detection based on deep learning: A review,,2020,"Kang Tong,Yiquan Wu,Fei Zhou",Computer Science,294,90
213271246,End-to-end multitask Siamese network with residual hierarchical attention for real-time object tracking,,2020,"Wenhui Huang,J. Gu,Xin Ma,Yibin Li",Computer Science,22,54
58341840,Robust Visual Tracking via Hierarchical Particle Filter and Ensemble Deep Features,"Particle filter algorithms are a very important branch for visual object tracking in the past decades, showing strong robustness to challenging scenarios with partial occlusion and large-scale variations. However, since a large number of particles need to be extracted for the accurate target state estimation, their tracking efficiency typically suffers especially when meeting deep convolutional features, which have been developed for handling significant variations of the target appearance in the visual tracking community. In this paper, we propose to elegantly exploit deep convolutional features with few particles in a novel hierarchical particle filter, which formulates correlation filters as observation models and breaks the standard particle filter framework down into two constituent particle layers, namely, particle translation layer and particle scale layer. The particle translation layer focuses on the object location with the deep convolutional features capturing semantics but failing to precisely estimate the object scale, while the particle scale layer pays attention to large-scale variations with the lightweight hand-crafted features handling spatial details of the object size. Moreover, an efficient ensemble method is proposed to help explore deeper convolutional features with more semantics in the particle translation layer. Extensive experiments on four challenging tracking datasets, including OTB-2013, OTB-2015, VOT2014, and VOT2015 demonstrate that the proposed method performs favorably against a number of state-of-the-art trackers.",2020,"Shengjie Li,Shuai Zhao,B. Cheng,Erhu Zhao,Junliang Chen",Computer Science,15,57
208337271,An improved correlation filter tracking method with occlusion and drift handling,,2019,"Jun Liu,Zhongqiang Luo,Xingzhong Xiong",Computer Science,5,52
207828448,A new TLD target tracking method based on improved correlation filter and adaptive scale,,2019,"Xin Yang,Songyan Zhu,Sijun Xia,Dake Zhou",Computer Science,9,33
189927699,A multiple feature fused model for visual object tracking via correlation filters,,2019,"Di Yuan,Xinming Zhang,Jiaqi Liu,Donghao Li",Computer Science,46,64
199542086,Visual object tracking with discriminative correlation filtering and hybrid color feature,,2019,"Y. Huang,Zhiqiang Zhao,Bin Wu,Zhuolin Mei,Zongmin Cui,Guangyong Gao",Computer Science,11,46
199528053,Robust visual tracking using self-adaptive strategy,,2019,"Zhi Chen,Peizhong Liu,Yongzhao Du,Yanmin Luo,Jing-Ming Guo",Computer Science,3,52
199586139,Robust visual tracking via a hybrid correlation filter,,2019,"Yong Wang,Xinbin Luo,Lu Ding,Jingjing Wu,Shan Fu",Computer Science,10,52
16742062,Sparse Unmixing of Hyperspectral Data,"Linear spectral unmixing is a popular tool in remotely sensed hyperspectral data interpretation. It aims at estimating the fractional abundances of pure spectral signatures (also called as endmembers) in each mixed pixel collected by an imaging spectrometer. In many situations, the identification of the end-member signatures in the original data set may be challenging due to insufficient spatial resolution, mixtures happening at different scales, and unavailability of completely pure spectral signatures in the scene. However, the unmixing problem can also be approached in semisupervised fashion, i.e., by assuming that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In practice, this is a combinatorial problem which calls for efficient linear sparse regression (SR) techniques based on sparsity-inducing regularizers, since the number of endmembers participating in a mixed pixel is usually very small compared with the (ever-growing) dimensionality (and availability) of spectral libraries. Linear SR is an area of very active research, with strong links to compressed sensing, basis pursuit (BP), BP denoising, and matching pursuit. In this paper, we study the linear spectral unmixing problem under the light of recent theoretical results published in those referred to areas. Furthermore, we provide a comparison of several available and new linear SR algorithms, with the ultimate goal of analyzing their potential in solving the spectral unmixing problem by resorting to available spectral libraries. Our experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. This opens new perspectives for spectral unmixing, since the abundance estimation process no longer depends on the availability of pure spectral signatures in the input data nor on the capacity of a certain endmember extraction algorithm to identify such pure signatures.",2011,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,914,50
11927662,Alternating direction algorithms for constrained sparse regression: Application to hyperspectral unmixing,"Convex optimization problems are common in hyperspectral unmixing. Examples are the constrained least squares (CLS) problem used to compute the fractional abundances in a linear mixture of known spectra, the constrained basis pursuit (CBP) to find sparse (i.e., with a small number of terms) linear mixtures of spectra, selected from large libraries, and the constrained basis pursuit denoising (CBPDN), which is a generalization of BP to admit modeling errors. In this paper, we introduce two new algorithms to efficiently solve these optimization problems, based on the alternating direction method of multipliers, a method from the augmented Lagrangian family. The algorithms are termed SUnSAL (sparse unmixing by variable splitting and augmented Lagrangian) and C-SUnSAL (constrained SUnSAL). C-SUnSAL solves the CBP and CBPDN problems, while SUnSAL solves CLS as well as a more general version thereof, called constrained sparse regression (CSR). C-SUnSAL and SUnSAL are shown to outperform off-the-shelf methods in terms of speed and accuracy.",2010,"J. Bioucas-Dias,Mário A. T. Figueiredo","Mathematics,Computer Science",570,25
1072704,An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems,"We propose a new fast algorithm for solving one of the standard approaches to ill-posed linear inverse problems (IPLIP), where a (possibly nonsmooth) regularizer is minimized under the constraint that the solution explains the observations sufficiently well. Although the regularizer and constraint are usually convex, several particular features of these problems (huge dimensionality, nonsmoothness) preclude the use of off-the-shelf optimization tools and have stimulated a considerable amount of research. In this paper, we propose a new efficient algorithm to handle one class of constrained problems (often known as basis pursuit denoising) tailored to image recovery applications. The proposed algorithm, which belongs to the family of augmented Lagrangian methods, can be used to deal with a variety of imaging IPLIP, including deconvolution and reconstruction from compressive observations (such as MRI), using either total-variation or wavelet-based (or, more generally, frame-based) regularization. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence sufficient conditions are known; we show that these conditions are satisfied by the proposed algorithm. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is a strong contender for the state-of-the-art.",2009,"M. Afonso,J. Bioucas-Dias,Mário A. T. Figueiredo","Computer Science,Mathematics,Medicine",1039,62
1549791,Average Case Analysis of Multichannel Sparse Recovery Using Convex Relaxation,"This paper considers recovery of jointly sparse multichannel signals from incomplete measurements. Several approaches have been developed to recover the unknown sparse vectors from the given observations, including thresholding, simultaneous orthogonal matching pursuit (SOMP), and convex relaxation based on a mixed matrix norm. Typically, worst case analysis is carried out in order to analyze conditions under which the algorithms are able to recover any jointly sparse set of vectors. However, such an approach is not able to provide insights into why joint sparse recovery is superior to applying standard sparse reconstruction methods to each channel individually. Previous work considered an average case analysis of thresholding and SOMP by imposing a probability model on the measured signals. Here, the main focus is on analysis of convex relaxation techniques. In particular, the mixed l 2,1 approach to multichannel recovery is investigated. Under a very mild condition on the sparsity and on the dictionary characteristics, measured for example by the coherence, it is shown that the probability of recovery failure decays exponentially in the number of channels. This demonstrates that most of the time, multichannel sparse recovery is indeed superior to single channel methods. The probability bounds are valid and meaningful even for a small number of signals. Using the tools developed to analyze the convex relaxation technique, also previous bounds for thresholding and SOMP recovery are tightened.",2009,"Yonina C. Eldar,H. Rauhut","Mathematics,Computer Science",332,57
11964764,From Sparse Solutions of Systems of Equations to Sparse Modeling of Signals and Images,"A full-rank matrix ${\bf A}\in \mathbb{R}^{n\times m}$ with $n<m$ generates an underdetermined system of linear equations ${\bf Ax} = {\bf b}$ having infinitely many solutions. Suppose we seek the sparsest solution, i.e., the one with the fewest nonzero entries. Can it ever be unique? If so, when? As optimization of sparsity is combinatorial in nature, are there efficient methods for finding the sparsest solution? These questions have been answered positively and constructively in recent years, exposing a wide variety of surprising phenomena, in particular the existence of easily verifiable conditions under which optimally sparse solutions can be found by concrete, effective computational methods.

Such theoretical results inspire a bold perspective on some important practical problems in signal and image processing. Several well-known signal and image processing problems can be cast as demanding solutions of undetermined systems of equations. Such problems have previously seemed, to many, intractable, but there is considerable evidence that these problems often have sparse solutions. Hence, advances in finding sparse solutions to underdetermined systems have energized research on such signal and image processing problems—to striking effect.

In this paper we review the theoretical results on sparse solutions of linear systems, empirical results on sparse modeling of signals and images, and recent applications in inverse problems and compression in image processing. This work lies at the intersection of signal processing and applied mathematics, and arose initially from the wavelets and harmonic analysis research communities. The aim of this paper is to introduce a few key notions and applications connected to sparsity, targeting newcomers interested in either the mathematical aspects of this area or its applications.",2009,"A. Bruckstein,D. Donoho,Michael Elad","Mathematics,Computer Science",2325,177
8906918,On the Uniqueness of Nonnegative Sparse Solutions to Underdetermined Systems of Equations,"An underdetermined linear system of equations Ax = b with nonnegativity constraint x ges 0 is considered. It is shown that for matrices A with a row-span intersecting the positive orthant, if this problem admits a sufficiently sparse solution, it is necessarily unique. The bound on the required sparsity depends on a coherence property of the matrix A. This coherence measure can be improved by applying a conditioning stage on A, thereby strengthening the claimed result. The obtained uniqueness theorem relies on an extended theoretical analysis of the lscr0 - lscr1 equivalence developed here as well, considering a matrix A with arbitrary column norms, and an arbitrary monotone element-wise concave penalty replacing the lscr1-norm objective function. Finally, from a numerical point of view, a greedy algorithm-a variant of the matching pursuit-is presented, such that it is guaranteed to find this sparse solution. It is further shown how this algorithm can benefit from well-designed conditioning of A .",2008,"A. Bruckstein,Michael Elad,M. Zibulevsky","Mathematics,Computer Science",298,42
281928,Reduce and Boost: Recovering Arbitrary Sets of Jointly Sparse Vectors,"The rapid developing area of compressed sensing suggests that a sparse vector lying in a high dimensional space can be accurately and efficiently recovered from only a small set of nonadaptive linear measurements, under appropriate conditions on the measurement matrix. The vector model has been extended both theoretically and practically to a finite set of sparse vectors sharing a common sparsity pattern. In this paper, we treat a broader framework in which the goal is to recover a possibly infinite set of jointly sparse vectors. Extending existing algorithms to this model is difficult due to the infinite structure of the sparse vector set. Instead, we prove that the entire infinite set of sparse vectors can be recovered by solving a single, reduced-size finite-dimensional problem, corresponding to recovery of a finite set of sparse vectors. We then show that the problem can be further reduced to the basic model of a single sparse vector by randomly combining the measurements. Our approach is exact for both countable and uncountable sets, as it does not rely on discretization or heuristic techniques. To efficiently find the single sparse vector produced by the last reduction step, we suggest an empirical boosting strategy that improves the recovery ability of any given suboptimal method for recovering a sparse vector. Numerical experiments on random data demonstrate that, when applied to infinite sets, our strategy outperforms discretization techniques in terms of both run time and empirical recovery rate. In the finite model, our boosting algorithm has fast run time and much higher recovery rate than known popular methods.",2008,"M. Mishali,Yonina C. Eldar","Physics,Mathematics,Computer Science",365,29
2478002,Algorithms for simultaneous sparse approximation. Part II: Convex relaxation,,2006,J. Tropp,"Mathematics,Computer Science",799,23
121097971,Simultaneous Variable Selection,"We propose a new method for selecting a common subset of explanatory variables where the aim is to model several response variables. The idea is a natural extension of the LASSO technique proposed by Tibshirani (1996) and is based on the (joint) residual sum of squares while constraining the parameter estimates to lie within a suitable polyhedral region. The properties of the resulting convex programming problem are analyzed for the special case of an orthonormal design. For the general case, we develop an efficient interior point algorithm. The method is illustrated on a dataset with infrared spectrometry measurements on 14 qualitatively different but correlated responses using 770 wavelengths. The aim is to select a subset of the wavelengths suitable for use as predictors for as many of the responses as possible.",2005,"B. Turlach,W. Venables,Stephen J. Wright","Computer Science,Mathematics",410,52
119159284,Stable signal recovery from incomplete and inaccurate measurements,"Suppose we wish to recover a vector x0 ∈ ℝ𝓂 (e.g., a digital signal or image) from incomplete and contaminated observations y = A x0 + e; A is an 𝓃 × 𝓂 matrix with far fewer rows than columns (𝓃 ≪ 𝓂) and e is an error term. Is it possible to recover x0 accurately based on the data y?",2005,"E. Candès,J. Romberg,T. Tao","Mathematics,Physics",7351,25
10285860,Hyperspectral Unmixing Based on Mixtures of Dirichlet Components,"This paper introduces a new unsupervised hyperspectral unmixing method conceived to linear but highly mixed hyperspectral data sets, in which the simplex of minimum volume, usually estimated by the purely geometrically based algorithms, is far way from the true simplex associated with the endmembers. The proposed method, an extension of our previous studies, resorts to the statistical framework. The abundance fraction prior is a mixture of Dirichlet densities, thus automatically enforcing the constraints on the abundance fractions imposed by the acquisition process, namely, nonnegativity and sum-to-one. A cyclic minimization algorithm is developed where the following are observed: 1) The number of Dirichlet modes is inferred based on the minimum description length principle; 2) a generalized expectation maximization algorithm is derived to infer the model parameters; and 3) a sequence of augmented Lagrangian-based optimizations is used to compute the signatures of the endmembers. Experiments on simulated and real data are presented to show the effectiveness of the proposed algorithm in unmixing problems beyond the reach of the geometrically based state-of-the-art competitors.",2012,"J. Nascimento,J. Bioucas-Dias","Mathematics,Computer Science",144,69
12521016,"Learning Discriminative Sparse Representations for Modeling, Source Separation, and Mapping of Hyperspectral Imagery","A method is presented for subpixel modeling, mapping, and classification in hyperspectral imagery using learned block-structured discriminative dictionaries, where each block is adapted and optimized to represent a material in a compact and sparse manner. The spectral pixels are modeled by linear combinations of subspaces defined by the learned dictionary atoms, allowing for linear mixture analysis. This model provides flexibility in source representation and selection, thus accounting for spectral variability, small-magnitude errors, and noise. A spatial-spectral coherence regularizer in the optimization allows pixel classification to be influenced by similar neighbors. We extend the proposed approach for cases for which there is no knowledge of the materials in the scene, unsupervised classification, and provide experiments and comparisons with simulated and real data. We also present results when the data have been significantly undersampled and then reconstructed, still retaining high-performance classification, showing the potential role of compressive sensing and sparse modeling techniques in efficient acquisition/transmission missions for hyperspectral imagery.",2011,"Alexey Castrodad,Zhengming Xing,J. Greer,E. Bosch,L. Carin,G. Sapiro",Computer Science,129,69
206690151,Hyperspectral Unmixing via $L_{1/2}$ Sparsity-Constrained Nonnegative Matrix Factorization,"Hyperspectral unmixing is a crucial preprocessing step for material classification and recognition. In the last decade, nonnegative matrix factorization (NMF) and its extensions have been intensively studied to unmix hyperspectral imagery and recover the material end-members. As an important constraint for NMF, sparsity has been modeled making use of the <i>L</i><sub>1</sub> regularizer. Unfortunately, the <i>L</i><sub>1</sub> regularizer cannot enforce further sparsity when the full additivity constraint of material abundances is used, hence limiting the practical efficacy of NMF methods in hyperspectral unmixing. In this paper, we extend the NMF method by incorporating the <i>L</i><sub>1/2</sub> sparsity constraint, which we name <i>L</i><sub>1/2</sub> -NMF. The <i>L</i><sub>1/2</sub> regularizer not only induces sparsity but is also a better choice among <i>Lq</i>(0 <; <i>q</i> <; 1) regularizers. We propose an iterative estimation algorithm for <i>L</i><sub>1/2</sub>-NMF, which provides sparser and more accurate results than those delivered using the <i>L</i><sub>1</sub> norm. We illustrate the utility of our method on synthetic and real hyperspectral data and compare our results to those yielded by other state-of-the-art methods.",2011,"Y. Qian,Sen Jia,J. Zhou,A. Robles-Kelly","Mathematics,Computer Science",458,57
12428827,Learning Sparse Codes for Hyperspectral Imagery,"The spectral features in hyperspectral imagery (HSI) contain significant structure that, if properly characterized, could enable more efficient data acquisition and improved data analysis. Because most pixels contain reflectances of just a few materials, we propose that a sparse coding model is well-matched to HSI data. Sparsity models consider each pixel as a combination of just a few elements from a larger dictionary, and this approach has proven effective in a wide range of applications. Furthermore, previous work has shown that optimal sparse coding dictionaries can be learned from a dataset with no other a priori information (in contrast to many HSI “endmember” discovery algorithms that assume the presence of pure spectra or side information). We modified an existing unsupervised learning approach and applied it to HSI data (with significant ground truth labeling) to learn an optimal sparse coding dictionary. Using this learned dictionary, we demonstrate three main findings: 1) the sparse coding model learns spectral signatures of materials in the scene and locally approximates nonlinear manifolds for individual materials; 2) this learned dictionary can be used to infer HSI-resolution data with very high accuracy from simulated imagery collected at multispectral-level resolution, and 3) this learned dictionary improves the performance of a supervised classification algorithm, both in terms of the classifier complexity and generalization from very small training sets.",2011,"Adam S. Charles,B. Olshausen,C. Rozell",Computer Science,196,57
6713715,A Quantitative Analysis of Virtual Endmembers' Increased Impact on the Collinearity Effect in Spectral Unmixing,"In the past decades, spectral unmixing has been studied for deriving the fractions of spectrally pure materials in a mixed pixel. However, limited attention has been given to the collinearity problem in spectral mixture analysis. In this paper, quantitative analysis and detailed simulations are provided, which show that the high correlation between the endmembers, including the virtual endmembers introduced in a nonlinear model, has a strong impact on unmixing errors through inflating the Gaussian noise. While distinctive spectra with low correlations are often selected as true endmembers, the virtual endmembers formed by their product terms can be highly correlated. It is found that a virtual-endmember-based nonlinear model generally suffers more from collinearity problems compared to linear models and may not perform as expected when the Gaussian noise is high, despite its higher modeling power. Experiments were conducted on a set of in situ measured data, and the results show that the linear mixture model performs better in 61.5% of the cases.",2011,"Xuehong Chen,Jin Chen,X. Jia,B. Somers,Jin Wu,P. Coppin","Mathematics,Computer Science",72,58
24500103,Endmember Extraction of Hyperspectral Remote Sensing Images Based on the Ant Colony Optimization (ACO) Algorithm,"Spectral mixture analysis has been an important research topic in remote sensing applications, particularly for hyperspectral remote sensing data processing. On the basis of linear spectral mixture models, this paper applied directed and weighted graphs to describe the relationship between pixels. In particular, we transformed the endmember extraction problem in the decomposition of mixed pixels into an issue of optimization and built feasible solution space to evaluate the practical significance of the objective function, thereby establishing two ant colony optimization algorithms for endmember extraction. In addition to the detailed process of calculation, we also addressed the effects of different operating parameters on algorithm performance. Finally we designed two sets of simulation data experiments and one set of actual data experiments, and the results of those experiments prove that endmember extraction based on ant colony algorithms can avoid some defects of N-FINDR, VCA and other algorithms, improve the representation of endmembers for all image pixels, decrease the average value of root-mean-square error, and therefore achieve better endmember extraction results than the N-FINDR and VCA algorithms.",2011,"Bing Zhang,Xun Sun,Lianru Gao,Lina Yang",Computer Science,101,29
36718629,An Iterative Search in End-Member Fraction Space for Spectral Unmixing,"A novel unmixing methodology is presented, searching for a fraction combination of end-members (EMs) that reconstructs the integrated source signal. The search starts with computing an initially estimated unmixing solution and then assesses combinations selected at random within an envelope surrounding this estimated solution. From each of these combinations, it then progresses iteratively along a path of neighboring combinations, so as to minimize the spectral angle between the corresponding (integrated) signatures and the source signal, until reaching a satisfactory solution. The new iterative fraction combination search (IFCS) was compared to the standard least squares unmixing (LSU). An assessment of both methods was conducted with a real Airborne Visible/Infrared Imaging Spectrometer image and nine synthetic images generated by randomly selecting fractions for two up to ten EMs derived from this real image. Considering all these EMs for the unmixing solution (not knowing specifically which or how many of them are actually mixed at each pixel), the IFCS method performed considerably better than LSU.",2011,"M. Shoshany,F. Kizel,N. Netanyahu,Naftali Goldshlager,T. Jarmer,G. Even-Tzur","Mathematics,Computer Science",20,9
23944119,An approach based on constrained nonnegative matrix factorization to unmix hyperspectral data,"Nonnegative matrix factorization (NMF) has been recently applied to solve the hyperspectral unmixing problem because it ensures nonnegativity and needs no assumption for the presence of pure pixels. However, the algorithm has a large amount of local minima due to the obvious nonconvexity of the objective function. In order to improve its performance, auxiliary constraints can be introduced into the algorithm. In this paper, we propose a new approach named abundance separation and smoothness constrained NMF by introducing two constraints, namely, abundance separation and smoothness, into the NMF algorithm. These constraints are based on two properties of hyperspectral imagery. First, usually, every ground object presents dominance in a specific region of the entire image scene and the correlation is weak between different endmembers. Second, moving through various regions, ground objects usually vary slowly and abrupt changes rarely appear. We also propose a learning algorithm to further improve the performance of our method, from which the auxiliary constraints are removed at an appropriate time. The proposed algorithm retains all the advantages of NMF and effectively overcomes the shortcoming of local minima at the same time. Experimental results based on synthetic and real hyperspectral data show the superiority of the proposed algorithm with respect to other state-of-the-art approaches.",2011,"Xuesong Liu,W. Xia,Bin Wang,Liming Zhang","Mathematics,Computer Science",156,49
16742062,Sparse Unmixing of Hyperspectral Data,"Linear spectral unmixing is a popular tool in remotely sensed hyperspectral data interpretation. It aims at estimating the fractional abundances of pure spectral signatures (also called as endmembers) in each mixed pixel collected by an imaging spectrometer. In many situations, the identification of the end-member signatures in the original data set may be challenging due to insufficient spatial resolution, mixtures happening at different scales, and unavailability of completely pure spectral signatures in the scene. However, the unmixing problem can also be approached in semisupervised fashion, i.e., by assuming that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In practice, this is a combinatorial problem which calls for efficient linear sparse regression (SR) techniques based on sparsity-inducing regularizers, since the number of endmembers participating in a mixed pixel is usually very small compared with the (ever-growing) dimensionality (and availability) of spectral libraries. Linear SR is an area of very active research, with strong links to compressed sensing, basis pursuit (BP), BP denoising, and matching pursuit. In this paper, we study the linear spectral unmixing problem under the light of recent theoretical results published in those referred to areas. Furthermore, we provide a comparison of several available and new linear SR algorithms, with the ultimate goal of analyzing their potential in solving the spectral unmixing problem by resorting to available spectral libraries. Our experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. This opens new perspectives for spectral unmixing, since the abundance estimation process no longer depends on the availability of pure spectral signatures in the input data nor on the capacity of a certain endmember extraction algorithm to identify such pure signatures.",2011,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,914,50
5503997,Nonlinear Spectral Mixture Analysis for Hyperspectral Imagery in an Unknown Environment,"Nonlinear spectral mixture analysis for hyperspectral imagery is investigated without prior information about the image scene. A simple but effective nonlinear mixture model is adopted, where the multiplication of each pair of endmembers results in a virtual endmember representing multiple scattering effect during pixel construction process. The analysis is followed by linear unmixing for abundance estimation. Due to a large number of nonlinear terms being added in an unknown environment, the following abundance estimation may contain some errors if most of the endmembers do not really participate in the mixture of a pixel. We take advantage of the developed endmember variable linear mixture model (EVLMM) to search the actual endmember set for each pixel, which yields more accurate abundance estimation in terms of smaller pixel reconstruction error, smaller residual counts, and more pixel abundances satisfying sum-to-one and nonnegativity constraints.",2010,"N. Raksuntorn,Q. Du","Computer Science,Mathematics",71,27
238301149,Chemometric Tools for Image Analysis,,2014,"A. Juan,S. Piqueras,M. Maeder,T. Hancewicz,L. Duponchel,R. Tauler",Mathematics,83,118
18103428,Crop Stage Classification of Hyperspectral Data Using Unsupervised Techniques,"The presence of a large number of spectral bands in the hyperspectral images increases the capability to distinguish between various physical structures. However, they suffer from the high dimensionality of the data. Hence, the processing of hyperspectral images is applied in two stages: dimensionality reduction and unsupervised classification techniques. The high dimensionality of the data has been reduced with the help of Principal Component Analysis (PCA). The selected dimensions are classified using Niche Hierarchical Artificial Immune System (NHAIS). The NHAIS combines the splitting method to search for the optimal cluster centers using niching procedure and the merging method is used to group the data points based on majority voting. Results are presented for two hyperspectral images namely EO-1 Hyperion image and Indian pines image. A performance comparison of this proposed hierarchical clustering algorithm with the earlier three unsupervised algorithms is presented. From the results obtained, we deduce that the NHAIS is efficient.",2013,"J. Senthilnath,S. N. Omkar,V. Mani,N. Karnwal,S. P. B.",Computer Science,74,35
2775724,Collaborative nonnegative matrix factorization for remotely sensed hyperspectral unmixing,"In this paper, we develop a new algorithm for hyperspectral unmixing which can provide suitable endmembers (and their corresponding abundances) in a single step. Hence, the algorithm does not require a previous subspace identification step to estimate the number of endmembers as it can cope with the two most likely scenarios in practice (i.e., the number of endmembers is correctly determined or overestimated a priori). The proposed approach, termed collaborative NMF (CoNMF), uses a collaborative regularization prior which forces the abundances corresponding to the overestimated endmembers to zero, such that it is guaranteed that only the true endmembers have fractional abundance contributions and the estimation of the number of endmembers is not required in advance. The obtained experimental results demonstrate that the proposed method exhibits very good performance in case the number of endmember is not available a priori.",2012,"Jun Li,J. Bioucas-Dias,A. Plaza",Computer Science,38,20
3731487,Supervised Nonlinear Spectral Unmixing Using a Postnonlinear Mixing Model for Hyperspectral Imagery,This paper presents a nonlinear mixing model for hyperspectral image unmixing. The proposed model assumes that the pixel reflectances are nonlinear functions of pure spectral components contaminated by an additive white Gaussian noise. These nonlinear functions are approximated using polynomial functions leading to a polynomial postnonlinear mixing model. A Bayesian algorithm and optimization methods are proposed to estimate the parameters involved in the model. The performance of the unmixing strategies is evaluated by simulations conducted on synthetic and real data.,2012,"Y. Altmann,Abderrahim Halimi,N. Dobigeon,J. Tourneret","Computer Science,Medicine,Mathematics",210,40
178457,Total Variation Spatial Regularization for Sparse Hyperspectral Unmixing,"Spectral unmixing aims at estimating the fractional abundances of pure spectral signatures (also called endmembers) in each mixed pixel collected by a remote sensing hyperspectral imaging instrument. In recent work, the linear spectral unmixing problem has been approached in semisupervised fashion as a sparse regression one, under the assumption that the observed image signatures can be expressed as linear combinations of pure spectra, known a priori and available in a library. It happens, however, that sparse unmixing focuses on analyzing the hyperspectral data without incorporating spatial information. In this paper, we include the total variation (TV) regularization to the classical sparse regression formulation, thus exploiting the spatial-contextual information present in the hyperspectral images and developing a new algorithm called sparse unmixing via variable splitting augmented Lagrangian and TV. Our experimental results, conducted with both simulated and real hyperspectral data sets, indicate the potential of including spatial information (through the TV term) on sparse unmixing formulations for improved characterization of mixed pixels in hyperspectral imagery.",2012,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,609,72
2651051,Linear Versus Nonlinear PCA for the Classification of Hyperspectral Data Based on the Extended Morphological Profiles,"Morphological profiles (MPs) have been proposed in recent literature as aiding tools to achieve better results for classification of remotely sensed data. MPs are in general built using features containing most of the information content of the data, such as the components derived from principal component analysis (PCA). Recently, nonlinear PCA (NLPCA), performed by autoassociative neural network, has emerged as a good unsupervised technique to fit the information content of hyperspectral data into few components. The aim of this letter is to investigate the classification accuracies obtained using extended MPs built from the features of NPCA. A comparison of the two approaches has been validated on two different data sets having different spatial and spectral resolutions/coverages, over the same ground truth, and also using two different classification algorithms. The results show that NLPCA permits one to obtain better classification accuracies than using linear PCA.",2012,"G. Licciardi,P. Marpu,J. Chanussot,J. Benediktsson",Computer Science,257,15
2114665,Hyperspectral Image Unmixing Using a Multiresolution Sticky HDP,"This paper is concerned with joint Bayesian endmember extraction and linear unmixing of hyperspectral images using a spatial prior on the abundance vectors. We propose a generative model for hyperspectral images in which the abundances are sampled from a Dirichlet distribution (DD) mixture model, whose parameters depend on a latent label process. The label process is then used to enforces a spatial prior which encourages adjacent pixels to have the same label. A Gibbs sampling framework is used to generate samples from the posterior distributions of the abundances and the parameters of the DD mixture model. The spatial prior that is used is a tree-structured sticky hierarchical Dirichlet process (SHDP) and, when used to determine the posterior endmember and abundance distributions, results in a new unmixing algorithm called spatially constrained unmixing (SCU). The directed Markov model facilitates the use of scale-recursive estimation algorithms, and is therefore more computationally efficient as compared to standard Markov random field (MRF) models. Furthermore, the proposed SCU algorithm estimates the number of regions in the image in an unsupervised fashion. The effectiveness of the proposed SCU algorithm is illustrated using synthetic and real data.",2012,"Roni Mittelman,N. Dobigeon,A. Hero","Mathematics,Computer Science",29,47
10285860,Hyperspectral Unmixing Based on Mixtures of Dirichlet Components,"This paper introduces a new unsupervised hyperspectral unmixing method conceived to linear but highly mixed hyperspectral data sets, in which the simplex of minimum volume, usually estimated by the purely geometrically based algorithms, is far way from the true simplex associated with the endmembers. The proposed method, an extension of our previous studies, resorts to the statistical framework. The abundance fraction prior is a mixture of Dirichlet densities, thus automatically enforcing the constraints on the abundance fractions imposed by the acquisition process, namely, nonnegativity and sum-to-one. A cyclic minimization algorithm is developed where the following are observed: 1) The number of Dirichlet modes is inferred based on the minimum description length principle; 2) a generalized expectation maximization algorithm is derived to infer the model parameters; and 3) a sequence of augmented Lagrangian-based optimizations is used to compute the signatures of the endmembers. Experiments on simulated and real data are presented to show the effectiveness of the proposed algorithm in unmixing problems beyond the reach of the geometrically based state-of-the-art competitors.",2012,"J. Nascimento,J. Bioucas-Dias","Mathematics,Computer Science",144,69
15904801,FPGA Implementation of the N-FINDR Algorithm for Remotely Sensed Hyperspectral Image Analysis,"Hyperspectral remote sensing attempts to identify features in the surface of the Earth using sensors that generally provide large amounts of data. The data are usually collected by a satellite or an airborne instrument and sent to a ground station that processes it. The main bottleneck of this approach is the (often reduced) bandwidth connection between the satellite and the station, which drastically limits the information that can be sent and processed in real time. A possible way to overcome this problem is to include onboard computing resources able to preprocess the data, reducing its size by orders of magnitude. Reconfigurable field-programmable gate arrays (FPGAs) are a promising platform that allows hardware/software codesign and the potential to provide powerful onboard computing capability and flexibility at the same time. Since FPGAs can implement custom hardware solutions, they can reach very high performance levels. Moreover, using run-time reconfiguration, the functionality of the FPGA can be updated at run time as many times as needed to perform different computations. Hence, the FPGA can be reused for several applications reducing the number of computing resources needed. One of the most popular and widely used techniques for analyzing hyperspectral data is linear spectral unmixing, which relies on the identification of pure spectral signatures via a so-called endmember extraction algorithm. In this paper, we present the first FPGA design for N-FINDR, a widely used endmember extraction algorithm in the literature. Our system includes a direct memory access module and implements a prefetching technique to hide the latency of the input/output communications. The proposed method has been implemented on a Virtex-4 XC4VFX60 FPGA (a model that is similar to radiation-hardened FPGAs certified for space operation) and tested using real hyperspectral data collected by NASA's Earth Observing-1 Hyperion (a satellite instrument) and the Airborne Visible Infra-Red Imaging Spectrometer over the Cuprite mining district in Nevada and the Jasper Ridge Biological Preserve in California. Experimental results demonstrate that our hardware version of the N-FINDR algorithm can significantly outperform an equivalent software version and is able to provide accurate results in near real time, which makes our reconfigurable system appealing for onboard hyperspectral data processing.",2012,"Carlos González,D. Mozos,J. Resano,A. Plaza",Computer Science,74,33
25772266,FPGA Implementation of Abundance Estimation for Spectral Unmixing of Hyperspectral Data Using the Image Space Reconstruction Algorithm,"One of the most popular and widely used techniques for analyzing remotely sensed hyperspectral data is spectral unmixing, which relies on two stages: (i) identification of pure spectral signatures (endmembers) in the data, and (ii) estimation of the abundance of each endmember in each (possibly mixed) pixel. Due to the high dimensionality of the hyperspectral data, spectral unmixing is a very time-consuming task. With recent advances in reconfigurable computing, especially using field programmable gate arrays (FPGAs), hyperspectral image processing algorithms can now be accelerated for on-board exploitation using compact hardware components with small size and cost. Although in previous work several efforts have been directed towards FPGA implementation of endmember extraction algorithms, the abundance estimation step has received comparatively much less attention. In this work, we develop a parallel FPGA-based design of the image space reconstruction algorithm (ISRA), a technique for solving linear inverse problems with positive constraints that has been used to estimate the abundance of each endmember in each pixel of a hyperspectral image. It is an iterative algorithm that guarantees convergence (after a certain number of iterations) and positive values in the results of the abundances (an important consideration in unmixing applications). Our system includes a direct memory access (DMA) module and implements a pre-fetching technique to hide the latency of the input/output communications. The method has been implemented on a Virtex-4 XC4VFX60 FPGA (a model that is similar to radiation-hardened FPGAs certified for space operation) and tested using real hyperspectral data sets collected by the Airborne Visible Infra-Red Imaging Spectrometer (AVIRIS) over the Cuprite mining district in Nevada and the Jasper Ridge Biological Preserve in California. Experimental results demonstrate that our hardware version can significantly outperform an equivalent software version, thus being able to provide abundance estimation results in near real-time, which makes our reconfigurable system appealing for on-board hyperspectral data processing.",2012,"Carlos González,J. Resano,A. Plaza,D. Mozos",Computer Science,53,35
7241355,Subspace clustering,"Subspace clustering refers to the task of identifying clusters of similar objects or data records (vectors) where the similarity is defined with respect to a subset of the attributes (i.e., a subspace of the data space). The subspace is not necessarily (and actually is usually not) the same for different clusters within one clustering solution. In this article, the problems motivating subspace clustering are sketched, different definitions and usages of subspaces for clustering are described, and exemplary algorithmic solutions are discussed. Finally, we sketch current research directions. © 2012 Wiley Periodicals, Inc.",2012,"H. Kriegel,Peer Kröger,Arthur Zimek",Computer Science,789,107
7611523,Translated Poisson Mixture Model for Stratification Learning,,2008,"G. Haro,G. Randall,G. Sapiro","Mathematics,Computer Science",54,40
14571052,Clustering and dimensionality reduction on Riemannian manifolds,"We propose a novel algorithm for clustering data sampled from multiple submanifolds of a Riemannian manifold. First, we learn a representation of the data using generalizations of local nonlinear dimensionality reduction algorithms from Euclidean to Riemannian spaces. Such generalizations exploit geometric properties of the Riemannian space, particularly its Riemannian metric. Then, assuming that the data points from different groups are separated, we show that the null space of a matrix built from the local representation gives the segmentation of the data. Our method is computationally simple and performs automatic segmentation without requiring user initialization. We present results on 2-D motion segmentation and diffusion tensor imaging segmentation.",2008,"A. Goh,R. Vidal","Computer Science,Mathematics",150,21
3264198,A tutorial on spectral clustering,,2007,U. V. Luxburg,Computer Science,9585,80
3172398,Segmenting Motions of Different Types by Unsupervised Manifold Clustering,"We propose a novel algorithm for segmenting multiple motions of different types from point correspondences in multiple affine or perspective views. Since point trajectories associated with different motions live in different manifolds, traditional approaches deal with only one manifold type: linear subspaces for affine views, and homographic, bilinear and trilinear varieties for two and three perspective views. As real motion sequences contain motions of different types, we cast motion segmentation as a problem of clustering manifolds of different types. Rather than explicitly modeling each manifold as a linear, bilinear or multilinear variety, we use nonlinear dimensionality reduction to learn a low-dimensional representation of the union of all manifolds. We show that for a union of separated manifolds, the LLE algorithm computes a matrix whose null space contains vectors giving the segmentation of the data. An analysis of the variance of these vectors allows us to distinguish them from other vectors in the null space. This leads to a new algorithm for clustering both linear and nonlinear manifolds. Although this algorithm is theoretically designed for separated manifolds, our experiments demonstrate its performance on real data where this assumption does not hold. We test our algorithm on the Hopkins 155 motion segmentation database and achieve an average classification error of 4.8%, which compares favorably against state-of-the art multiframe motion segmentation methods.",2007,"A. Goh,R. Vidal","Computer Science,Mathematics",212,23
16286609,Minimum Volume Embedding,"Minimum Volume Embedding (MVE) is an algorithm for non-linear dimensionality reduction that uses semidefinite programming (SDP) and matrix factorization to find a low-dimensional embedding that preserves local distances between points while representing the dataset in many fewer dimensions. MVE follows an approach similar to algorithms such as Semidefinite Embedding (SDE), in that it learns a kernel matrix using an SDP before applying Kernel Principal Component Analysis (KPCA). However, the objective function for MVE directly optimizes the eigenspectrum of the data to preserve as much of its energy as possible within the few dimensions available to the embedding. Simultaneously, remaining eigenspectrum energy is minimized in directions orthogonal to the embedding thereby keeping data in a so-called minimum volume manifold. We show how MVE improves upon SDE in terms of the volume of the preserved embedding and the resulting eigenspectrum, producing better visualizations for a variety of synthetic and real-world datasets, including simple toy examples, face images, handwritten digits, phylogenetic trees, and social networks.",2007,"B. Shaw,T. Jebara","Mathematics,Computer Science",68,12
2375559,Dimension induced clustering,"It is commonly assumed that high-dimensional datasets contain points most of which are located in low-dimensional manifolds. Detection of low-dimensional clusters is an extremely useful task for performing operations such as clustering and classification, however, it is a challenging computational problem. In this paper we study the problem of finding subsets of points with low intrinsic dimensionality. Our main contribution is to extend the definition of fractal correlation dimension, which measures average volume growth rate, in order to estimate the intrinsic dimensionality of the data in local neighborhoods. We provide a careful analysis of several key examples in order to demonstrate the properties of our measure. Based on our proposed measure, we introduce a novel approach to discover clusters with low dimensionality. The resulting algorithms extend previous density based measures, which have been successfully used for clustering. We demonstrate the effectiveness of our algorithms for discovering low-dimensional m-flats embedded in high dimensional spaces, and for detecting low-rank sub-matrices.",2005,"A. Gionis,Alexander Hinneburg,S. Papadimitriou,Panayiotis Tsaparas","Computer Science,Mathematics",59,22
7591229,Unsupervised Dimensionality Estimation and Manifold Learning in high-dimensional Spaces by Tensor Voting,"We address dimensionality estimation and nonlinear manifold inference starting from point inputs in high dimensional spaces using tensor voting. The proposed method operates locally in neighborhoods and does not involve any global computations. It is based on information propagation among neighboring points implemented as a voting process. Unlike other local approaches for manifold learning, the quantity propagated from one point to another is not a scalar, but is in the form of a tensor that provides considerably richer information. The accumulation of votes at each point provides a reliable estimate of local dimensionality, as well as of the orientation of a potential manifold going through the point. Reliable dimensionality estimation at the point level is a major advantage over competing methods. Moreover, the absence of global operations allows us to process significantly larger datasets. We demonstrate the effectiveness of our method on a variety of challenging datasets.",2005,"Philippos Mordohai,G. Medioni","Mathematics,Computer Science",41,16
2458350,Acquiring linear subspaces for face recognition under variable lighting,"Previous work has demonstrated that the image variation of many objects (human faces in particular) under variable lighting can be effectively modeled by low-dimensional linear spaces, even when there are multiple light sources and shadowing. Basis images spanning this space are usually obtained in one of three ways: a large set of images of the object under different lighting conditions is acquired, and principal component analysis (PCA) is used to estimate a subspace. Alternatively, synthetic images are rendered from a 3D model (perhaps reconstructed from images) under point sources and, again, PCA is used to estimate a subspace. Finally, images rendered from a 3D model under diffuse lighting based on spherical harmonics are directly used as basis images. In this paper, we show how to arrange physical lighting so that the acquired images of each object can be directly used as the basis vectors of a low-dimensional linear space and that this subspace is close to those acquired by the other methods. More specifically, there exist configurations of k point light source directions, with k typically ranging from 5 to 9, such that, by taking k images of an object under these single sources, the resulting subspace is an effective representation for recognition under a wide range of lighting conditions. Since the subspace is generated directly from real images, potentially complex and/or brittle intermediate steps such as 3D reconstruction can be completely avoided; nor is it necessary to acquire large numbers of training images or to physically construct complex diffuse (harmonic) light fields. We validate the use of subspaces constructed in this fashion within the context of face recognition.",2005,"Kuang-chih Lee,J. Ho,D. Kriegman","Mathematics,Medicine,Computer Science",2455,27
8750179,Hamiltonian Annealed Importance Sampling for partition function estimation,"We introduce an extension to annealed importance sampling that uses Hamiltonian dynamics to rapidly estimate normalization constants. We demonstrate this method by computing log likelihoods in directed and undirected probabilistic image models. We compare the performance of linear generative models with both Gaussian and Laplace priors, product of experts models with Laplace and Student's t experts, the mc-RBM, and a bilinear generative model. We provide code to compare additional models.",2012,"Jascha Narain Sohl-Dickstein,B. J. Culpepper","Computer Science,Physics,Mathematics",39,20
2194647,A Spike and Slab Restricted Boltzmann Machine,"We introduce the spike and slab Restricted Boltzmann Machine, characterized by having both a real-valued vector, the slab, and a binary variable, the spike, associated with each unit in the hidden layer. The model possesses some practical properties such as being amenable to Block Gibbs sampling as well as being capable of generating similar latent representations of the data to the recently introduced mean and covariance Restricted Boltzmann Machine. We illustrate how the spike and slab Restricted Boltzmann Machine achieves competitive performance on the CIFAR-10 object recognition task.",2011,"Aaron C. Courville,J. Bergstra,Yoshua Bengio","Mathematics,Computer Science",95,28
1048042,Handbook of Markov Chain Monte Carlo,"Foreword Stephen P. Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng Introduction to MCMC, Charles J. Geyer A short history of Markov chain Monte Carlo: Subjective recollections from in-complete data, Christian Robert and George Casella Reversible jump Markov chain Monte Carlo, Yanan Fan and Scott A. Sisson Optimal proposal distributions and adaptive MCMC, Jeffrey S. Rosenthal MCMC using Hamiltonian dynamics, Radford M. Neal Inference and Monitoring Convergence, Andrew Gelman and Kenneth Shirley Implementing MCMC: Estimating with confidence, James M. Flegal and Galin L. Jones Perfection within reach: Exact MCMC sampling, Radu V. Craiu and Xiao-Li Meng Spatial point processes, Mark Huber The data augmentation algorithm: Theory and methodology, James P. Hobert Importance sampling, simulated tempering and umbrella sampling, Charles J.Geyer Likelihood-free Markov chain Monte Carlo, Scott A. Sisson and Yanan Fan MCMC in the analysis of genetic data on related individuals, Elizabeth Thompson A Markov chain Monte Carlo based analysis of a multilevel model for functional MRI data, Brian Caffo, DuBois Bowman, Lynn Eberly, and Susan Spear Bassett Partially collapsed Gibbs sampling & path-adaptive Metropolis-Hastings in high-energy astrophysics, David van Dyk and Taeyoung Park Posterior exploration for computationally intensive forward models, Dave Higdon, C. Shane Reese, J. David Moulton, Jasper A. Vrugt and Colin Fox Statistical ecology, Ruth King Gaussian random field models for spatial data, Murali Haran Modeling preference changes via a hidden Markov item response theory model, Jong Hee Park Parallel Bayesian MCMC imputation for multiple distributed lag models: A case study in environmental epidemiology, Brian Caffo, Roger Peng, Francesca Dominici, Thomas A. Louis, and Scott Zeger MCMC for state space models, Paul Fearnhead MCMC in educational research, Roy Levy, Robert J. Mislevy, and John T. Behrens Applications of MCMC in fisheries science, Russell B. Millar Model comparison and simulation for hierarchical models: analyzing rural-urban migration in Thailand, Filiz Garip and Bruce Western",2011,Radford M. Neal,"Computer Science,Mathematics,Physics",2693,51
961425,LIBSVM: A library for support vector machines,"LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",2011,"Chih-Chung Chang,Chih-Jen Lin",Computer Science,42944,59
2118934,Group Sparse Coding with a Laplacian Scale Mixture Prior,"We propose a class of sparse coding models that utilizes a Laplacian Scale Mixture (LSM) prior to model dependencies among coefficients. Each coefficient is modeled as a Laplacian distribution with a variable scale parameter, with a Gamma distribution prior over the scale parameter. We show that, due to the conjugacy of the Gamma prior, it is possible to derive efficient inference procedures for both the coefficients and the scale parameter. When the scale parameters of a group of coefficients are combined into a single variable, it is possible to describe the dependencies that occur due to common amplitude fluctuations among coefficients, which have been shown to constitute a large fraction of the redundancy in natural images [1]. We show that, as a consequence of this group sparse coding, the resulting inference of the coefficients follows a divisive normalization rule, and that this may be efficiently implemented in a network architecture similar to that which has been proposed to occur in primary visual cortex. We also demonstrate improvements in image coding and compressive sensing recovery using the LSM model.",2010,"Pierre Garrigues,B. Olshausen","Computer Science,Mathematics",122,32
1302462,Learning Convolutional Feature Hierarchies for Visual Recognition,"We propose an unsupervised method for learning multi-stage hierarchies of sparse convolutional features. While sparse coding has become an increasingly popular method for learning visual features, it is most often trained at the patch level. Applying the resulting filters convolutionally results in highly redundant codes because overlapping patches are encoded in isolation. By training convolutionally over large image windows, our method reduces the redudancy between feature vectors at neighboring locations and improves the efficiency of the overall representation. In addition to a linear decoder that reconstructs the image from sparse features, our method trains an efficient feed-forward encoder that predicts quasi-sparse features from the input. While patch-based training rarely produces anything but oriented edge detectors, we show that convolutional training produces highly diverse filters, including center-surround filters, corner detectors, cross detectors, and oriented grating detectors. We show that using these filters in multistage convolutional network architecture improves performance on a number of visual recognition and detection tasks.",2010,"K. Kavukcuoglu,P. Sermanet,Y-Lan Boureau,Karol Gregor,Michaël Mathieu,Yann LeCun",Computer Science,575,29
14013706,Supervised translation-invariant sparse coding,"In this paper, we propose a novel supervised hierarchical sparse coding model based on local image descriptors for classification tasks. The supervised dictionary training is performed via back-projection, by minimizing the training error of classifying the image level features, which are extracted by max pooling over the sparse codes within a spatial pyramid. Such a max pooling procedure across multiple spatial scales offer the model translation invariant properties, similar to the Convolutional Neural Network (CNN). Experiments show that our supervised dictionary improves the performance of the proposed model significantly over the unsupervised dictionary, leading to state-of-the-art performance on diverse image databases. Further more, our supervised model targets learning linear features, implying its great potential in handling large scale datasets in real applications.",2010,"Jianchao Yang,Kai Yu,Thomas S. Huang",Computer Science,362,29
90113,Learning mid-level features for recognition,"Many successful models for scene or object recognition transform low-level descriptors (such as Gabor filter responses, or SIFT descriptors) into richer representations of intermediate complexity. This process can often be broken down into two steps: (1) a coding step, which performs a pointwise transformation of the descriptors into a representation better adapted to the task, and (2) a pooling step, which summarizes the coded features over larger neighborhoods. Several combinations of coding and pooling schemes have been proposed in the literature. The goal of this paper is threefold. We seek to establish the relative importance of each step of mid-level feature extraction through a comprehensive cross evaluation of several types of coding modules (hard and soft vector quantization, sparse coding) and pooling schemes (by taking the average, or the maximum), which obtains state-of-the-art performance or better on several recognition benchmarks. We show how to improve the best performing coding scheme by learning a supervised discriminative dictionary for sparse coding. We provide theoretical and empirical insight into the remarkable performance of max pooling. By teasing apart components shared by modern mid-level feature extractors, our approach aims to facilitate the design of better recognition architectures.",2010,"Y-Lan Boureau,F. Bach,Yann LeCun,J. Ponce","Computer Science,Mathematics",1140,32
9068522,Modeling pixel means and covariances using factorized third-order boltzmann machines,"Learning a generative model of natural images is a useful way of extracting features that capture interesting regularities. Previous work on learning such models has focused on methods in which the latent features are used to determine the mean and variance of each pixel independently, or on methods in which the hidden units determine the covariance matrix of a zero-mean Gaussian distribution. In this work, we propose a probabilistic model that combines these two approaches into a single framework. We represent each image using one set of binary latent features that model the image-specific covariance and a separate set that model the mean. We show that this approach provides a probabilistic framework for the widely used simple-cell complex-cell architecture, it produces very realistic samples of natural images and it extracts features that yield state-of-the-art recognition accuracy on the challenging CIFAR 10 dataset.",2010,"Marc'Aurelio Ranzato,Geoffrey E. Hinton","Computer Science,Mathematics",261,35
1413690,Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines,"To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric weight between a pixel in the second image and a hidden unit. This creates cubically many parameters, which form a three-dimensional interaction tensor. We describe a low-rank approximation to this interaction tensor that uses a sum of factors, each of which is a three-way outer product. This approximation allows efficient learning of transformations between larger image patches. Since each factor can be viewed as an image filter, the model as a whole learns optimal filter pairs for efficiently representing transformations. We demonstrate the learning of optimal filter pairs from various synthetic and real image sequences. We also show how learning about image transformations allows the model to perform a simple visual analogy task, and we show how a completely unsupervised network trained on transformations perceives multiple motions of transparent dot patterns in the same way as humans.",2010,"R. Memisevic,Geoffrey E. Hinton","Mathematics,Computer Science,Medicine",282,24
961425,LIBSVM: A library for support vector machines,"LIBSVM is a library for Support Vector Machines (SVMs). We have been actively developing this package since the year 2000. The goal is to help users to easily apply SVM to their applications. LIBSVM has gained wide popularity in machine learning and many other areas. In this article, we present all implementation details of LIBSVM. Issues such as solving SVM optimization problems theoretical convergence multiclass classification probability estimates and parameter selection are discussed in detail.",2011,"Chih-Chung Chang,Chih-Jen Lin",Computer Science,42944,59
123813417,Template matching via $l_1$ minimization and its application to hyperspectral data,"Detecting and identifying targets or objects that are present in 
hyperspectral ground images are of great interest. Applications 
include land and environmental monitoring, mining, military, civil 
search-and-rescue operations, and so on. We propose and analyze an 
extremely simple and efficient idea for template matching based on 
$l_1$ minimization. The designed algorithm can be applied in 
hyperspectral classification and target detection. Synthetic image 
data and real hyperspectral image (HSI) data are used to assess the 
performance, with comparisons to other approaches, e.g. spectral 
angle map (SAM), adaptive coherence estimator (ACE), 
generalized-likelihood ratio test (GLRT) and matched filter. We 
demonstrate that this algorithm achieves excellent results with both 
high speed and accuracy by using Bregman iteration.",2011,"Zhaohui Guo,S. Osher",Mathematics,27,37
16742062,Sparse Unmixing of Hyperspectral Data,"Linear spectral unmixing is a popular tool in remotely sensed hyperspectral data interpretation. It aims at estimating the fractional abundances of pure spectral signatures (also called as endmembers) in each mixed pixel collected by an imaging spectrometer. In many situations, the identification of the end-member signatures in the original data set may be challenging due to insufficient spatial resolution, mixtures happening at different scales, and unavailability of completely pure spectral signatures in the scene. However, the unmixing problem can also be approached in semisupervised fashion, i.e., by assuming that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In practice, this is a combinatorial problem which calls for efficient linear sparse regression (SR) techniques based on sparsity-inducing regularizers, since the number of endmembers participating in a mixed pixel is usually very small compared with the (ever-growing) dimensionality (and availability) of spectral libraries. Linear SR is an area of very active research, with strong links to compressed sensing, basis pursuit (BP), BP denoising, and matching pursuit. In this paper, we study the linear spectral unmixing problem under the light of recent theoretical results published in those referred to areas. Furthermore, we provide a comparison of several available and new linear SR algorithms, with the ultimate goal of analyzing their potential in solving the spectral unmixing problem by resorting to available spectral libraries. Our experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. This opens new perspectives for spectral unmixing, since the abundance estimation process no longer depends on the availability of pure spectral signatures in the input data nor on the capacity of a certain endmember extraction algorithm to identify such pure signatures.",2011,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,914,50
12352708,Sparse coding and dictionary learning based on the MDL principle,"The power of sparse signal coding with learned overcomplete dictionaries has been demonstrated in a variety of applications and fields, from signal processing to statistical inference and machine learning. However, the statistical properties of these models, such as underfitting or overfitting given sets of data, are still not well characterized in the literature. This work aims at filling this gap by means of the Minimum Description Length (MDL) principle - a well established information-theoretic approach to statistical inference. The resulting framework derives a family of efficient sparse coding and modeling (dictionary learning) algorithms, which by virtue of the MDL principle, are completely parameter free. Furthermore, such framework allows to incorporate additional prior information in the model, such as Markovian dependencies, in a natural way. We demonstrate the performance of the proposed framework with results for image denoising and classification tasks.",2010,"Ignacio Francisco Ramírez Paulino,G. Sapiro","Computer Science,Mathematics",6,21
42167648,Spatio-Spectral Remote Sensing Image Classification With Graph Kernels,This letter presents a graph kernel for spatio-spectral remote sensing image classification with support vector machines (SVMs). The method considers higher order relations in the neighborhood (beyond pairwise spatial relations) to iteratively compute a kernel matrix for SVM learning. The proposed kernel is easy to compute and constitutes a powerful alternative to existing approaches. The capabilities of the method are illustrated in several multi- and hyperspectral remote sensing images acquired over both urban and agricultural areas.,2010,"Gustau Camps-Valls,N. Shervashidze,K. Borgwardt",Computer Science,129,31
7803097,Dictionary learning and sparse coding for unsupervised clustering,"A clustering framework within the sparse modeling and dictionary learning setting is introduced in this work. Instead of searching for the set of centroid that best fit the data, as in k-means type of approaches that model the data as distributions around discrete points, we optimize for a set of dictionaries, one for each cluster, for which the signals are best reconstructed in a sparse coding manner. Thereby, we are modeling the data as the of union of learned low dimensional subspaces, and data points associated to subspaces spanned by just a few atoms of the same learned dictionary are clustered together. Using learned dictionaries makes this method robust and well suited to handle large datasets. The proposed clustering algorithm uses a novel measurement for the quality of the sparse representation, inspired by the robustness of the ℓ1 regularization term in sparse coding. We first illustrate this measurement with examples on standard image and speech datasets in the supervised classification setting, showing with a simple approach its discriminative power and obtaining results comparable to the state-of-the-art. We then conclude with experiments for fully unsupervised clustering on extended standard datasets and texture images, obtaining excellent performance.",2010,"P. Sprechmann,G. Sapiro",Computer Science,136,19
29305173,Minimum Dispersion Constrained Nonnegative Matrix Factorization to Unmix Hyperspectral Data,"This paper considers the problem of unsupervised spectral unmixing for hyperspectral image analysis. Each observed pixel is assumed to be a noisy linear mixture of pure material spectra, namely, endmembers. The mixing coefficients, usually called abundances, are constrained to positive and summed to unity. The proposed unmixing approach is based on the nonnegative matrix factorization (NMF) framework, which considers the physical constraints of the problem, including the positivity of the endmember spectra and abundances. However, the basic NMF formulation has degenerated solutions and suffers from nonconvexity limitations. We consider here a regularization function, called dispersion, which favors the solution such that the endmember spectra have minimum variances. Such a solution encourages the recovered spectra to be flat, preserving the possible spectral singularities (peaks and sharp variations). The regularized criterion is minimized with a projected gradient (PG) scheme, and we propose a new step-size estimation technique to fasten the PG convergence. The derived algorithm is called MiniDisCo, for minimum dispersion constrained NMF. We experimentally compare MiniDisCo with the recently proposed algorithm. It is shown to be particularly robust to the presence of flat spectra, to a possible a priori overestimation of the number of endmembers, or if the amount of observed spectral pixels is low. In addition, experiments show that the considered regularization correctly overcomes the degeneracy and nonconvexity problems, leading to satisfactory unmixing accuracy. We include a comparative analysis of a real-world scene.",2010,"A. Huck,M. Guillaume,J. Blanc-Talon","Mathematics,Computer Science",129,41
13513061,Non-Parametric Bayesian Dictionary Learning for Sparse Image Representations,"Non-parametric Bayesian techniques are considered for learning dictionaries for sparse image representations, with applications in denoising, inpainting and compressive sensing (CS). The beta process is employed as a prior for learning the dictionary, and this non-parametric method naturally infers an appropriate dictionary size. The Dirichlet process and a probit stick-breaking process are also considered to exploit structure within an image. The proposed method can learn a sparse dictionary in situ; training images may be exploited if available, but they are not required. Further, the noise variance need not be known, and can be non-stationary. Another virtue of the proposed method is that sequential inference can be readily employed, thereby allowing scaling to large images. Several example results are presented, using both Gibbs and variational Bayesian inference, with comparisons to other state-of-the-art approaches.",2009,"Mingyuan Zhou,Haojun Chen,J. Paisley,Lu Ren,G. Sapiro,L. Carin",Computer Science,273,27
16781983,Universal priors for sparse modeling,"Sparse data models, where data is assumed to be well represented as a linear combination of a few elements from a dictionary, have gained considerable attention in recent years, and their use has led to state-of-the-art results in many signal and image processing tasks. It is now well understood that the choice of the sparsity regularization term is critical in the success of such models. In this work, we use tools from information theory to propose a sparsity regularization term which has several theoretical and practical advantages over the more standard ¿0 or ¿1 ones, and which leads to improved coding performance and accuracy in reconstruction tasks. We also briefly report on further improvements obtained by imposing low mutual coherence and Gram matrix norm on the learned dictionaries.",2009,"Ignacio Francisco Ramírez Paulino,F. Lecumberry,G. Sapiro",Computer Science,31,30
995282,Discovering Sociolinguistic Associations with Structured Sparsity,"We present a method to discover robust and interpretable sociolinguistic associations from raw geotagged text data. Using aggregate demographic statistics about the authors' geographic communities, we solve a multi-output regression problem between demographics and lexical frequencies. By imposing a composite e1,∞ regularizer, we obtain structured sparsity, driving entire rows of coefficients to zero. We perform two regression studies. First, we use term frequencies to predict demographic attributes; our method identifies a compact set of words that are strongly associated with author demographics. Next, we conjoin demographic attributes into features, which we use to predict term frequencies. The composite regularizer identifies a small number of features, which correspond to communities of authors united by shared demographic and linguistic properties.",2011,"Jacob Eisenstein,Noah A. Smith,E. Xing",Computer Science,141,28
15001936,Online Learning of Structured Predictors with Multiple Kernels,"Training structured predictors often requires a considerable time selecting features or tweaking the kernel. Multiple kernel learning (MKL) sidesteps this issue by embedding the kernel learning into the training procedure. Despite the recent progress towards efficiency of MKL algorithms, the structured output case remains an open research front. We propose a family of online algorithms able to tackle variants of MKL and group-LASSO, for which we show regret, convergence, and generalization bounds. Experiments on handwriting recognition and dependency parsing attest the success of the approach.",2011,"André F. T. Martins,Noah A. Smith,E. Xing,P. Aguiar,Mário A. T. Figueiredo",Computer Science,38,51
15497435,Moreau-Yosida Regularization for Grouped Tree Structure Learning,"We consider the tree structured group Lasso where the structure over the features can be represented as a tree with leaf nodes as features and internal nodes as clusters of the features. The structured regularization with a pre-defined tree structure is based on a group-Lasso penalty, where one group is defined for each node in the tree. Such a regularization can help uncover the structured sparsity, which is desirable for applications with some meaningful tree structures on the features. However, the tree structured group Lasso is challenging to solve due to the complex regularization. In this paper, we develop an efficient algorithm for the tree structured group Lasso. One of the key steps in the proposed algorithm is to solve the Moreau-Yosida regularization associated with the grouped tree structure. The main technical contributions of this paper include (1) we show that the associated Moreau-Yosida regularization admits an analytical solution, and (2) we develop an efficient algorithm for determining the effective interval for the regularization parameter. Our experimental results on the AR and JAFFE face data sets demonstrate the efficiency and effectiveness of the proposed algorithm.",2010,"Jun Liu,Jieping Ye","Computer Science,Mathematics",181,28
2997001,Turbo Parsers: Dependency Parsing by Approximate Variational Inference,"We present a unified view of two state-of-the-art non-projective dependency parsers, both approximate: the loopy belief propagation parser of Smith and Eisner (2008) and the relaxed linear program of Martins et al. (2009). By representing the model assumptions with a factor graph, we shed light on the optimization problems tackled in each method. We also propose a new aggressive online algorithm to learn the model parameters, which makes use of the underlying variational representation. The algorithm does not require a learning rate parameter and provides a single framework for a wide family of convex loss functions, including CRFs and structured SVMs. Experiments show state-of-the-art performance for 14 languages.",2010,"André F. T. Martins,Noah A. Smith,E. Xing,P. Aguiar,Mário A. T. Figueiredo",Computer Science,149,43
10181055,Practical Very Large Scale CRFs,"Conditional Random Fields (CRFs) are a widely-used approach for supervised sequence labelling, notably due to their ability to handle large description spaces and to integrate structural dependency between labels. Even for the simple linear-chain model, taking structure into account implies a number of parameters and a computational effort that grows quadratically with the cardinality of the label set. In this paper, we address the issue of training very large CRFs, containing up to hundreds output labels and several billion features. Efficiency stems here from the sparsity induced by the use of a l penalty term. Based on our own implementation, we compare three recent proposals for implementing this regularization strategy. Our experiments demonstrate that very large CRFs can be trained efficiently and that very large models are able to improve the accuracy, while delivering compact parameter sets.",2010,"T. Lavergne,O. Cappé,François Yvon",Computer Science,421,34
10636317,Proximal Methods for Sparse Hierarchical Dictionary Learning,"We propose to combine two approaches for modeling data admitting sparse representations: on the one hand, dictionary learning has proven effective for various signal processing tasks. On the other hand, recent work on structured sparsity provides a natural framework for modeling dependencies between dictionary elements. We thus consider a tree-structured sparse regularization to learn dictionaries embedded in a hierarchy. The involved proximal operator is computable exactly via a primal-dual method, allowing the use of accelerated gradient techniques. Experiments show that for natural image patches, learned dictionary elements organize themselves in such a hierarchical structure, leading to an improved performance for restoration tasks. When applied to text documents, our method learns hierarchies of topics, thus providing a competitive alternative to probabilistic topic models.",2010,"Rodolphe Jenatton,J. Mairal,G. Obozinski,F. Bach",Computer Science,393,25
6998485,Joint covariate selection and joint subspace selection for multiple classification problems,,2010,"G. Obozinski,B. Taskar,Michael I. Jordan","Computer Science,Mathematics",531,41
2395670,Convex Structure Learning in Log-Linear Models: Beyond Pairwise Potentials,"Previous work has examined structure learning in log-linear models with ‘1regularization, largely focusing on the case of pairwise potentials. In this work we consider the case of models with potentials of arbitrary order, but that satisfy a hierarchical constraint. We enforce the hierarchical constraint using group ‘1-regularization with overlapping groups. An active set method that enforces hierarchical inclusion allows us to tractably consider the exponential number of higher-order potentials. We use a spectral projected gradient method as a subroutine for solving the overlapping group ‘1regularization problem, and make use of a sparse version of Dykstra’s algorithm to compute the projection. Our experiments indicate that this model gives equal or better test set likelihood compared to previous models.",2010,"Mark W. Schmidt,Kevin P. Murphy","Mathematics,Computer Science",69,34
14601089,A note on the group lasso and a sparse group lasso,"We consider the group lasso penalty for the linear model. We note that the standard algorithm for solving the problem assumes that the model matrices in each group are orthonormal. Here we consider a more general penalty that blends the lasso (L1) with the group lasso (\two-norm""). This penalty yields solutions that are sparse at both the group and individual feature levels. We derive an ecien t algorithm for the resulting convex problem based on coordinate descent. This algorithm can also be used to solve the general form of the group lasso, with non-orthonormal model matrices.",2010,"J. Friedman,T. Hastie,R. Tibshirani",Mathematics,805,5
2166128,Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization,"We consider regularized stochastic learning and online optimization problems, where the objective function is the sum of two convex terms: one is the loss function of the learning task, and the other is a simple regularization term such as l1-norm for promoting sparsity. We develop a new online algorithm, the regularized dual averaging (RDA) method, that can explicitly exploit the regularization structure in an online setting. In particular, at each iteration, the learning variables are adjusted by solving a simple optimization problem that involves the running average of all past subgradients of the loss functions and the whole regularization term, not just its subgradient. Computational experiments show that the RDA method can be very effective for sparse online learning with l1-regularization.",2009,Lin Xiao,"Computer Science,Mathematics",842,74
16742062,Sparse Unmixing of Hyperspectral Data,"Linear spectral unmixing is a popular tool in remotely sensed hyperspectral data interpretation. It aims at estimating the fractional abundances of pure spectral signatures (also called as endmembers) in each mixed pixel collected by an imaging spectrometer. In many situations, the identification of the end-member signatures in the original data set may be challenging due to insufficient spatial resolution, mixtures happening at different scales, and unavailability of completely pure spectral signatures in the scene. However, the unmixing problem can also be approached in semisupervised fashion, i.e., by assuming that the observed image signatures can be expressed in the form of linear combinations of a number of pure spectral signatures known in advance (e.g., spectra collected on the ground by a field spectroradiometer). Unmixing then amounts to finding the optimal subset of signatures in a (potentially very large) spectral library that can best model each mixed pixel in the scene. In practice, this is a combinatorial problem which calls for efficient linear sparse regression (SR) techniques based on sparsity-inducing regularizers, since the number of endmembers participating in a mixed pixel is usually very small compared with the (ever-growing) dimensionality (and availability) of spectral libraries. Linear SR is an area of very active research, with strong links to compressed sensing, basis pursuit (BP), BP denoising, and matching pursuit. In this paper, we study the linear spectral unmixing problem under the light of recent theoretical results published in those referred to areas. Furthermore, we provide a comparison of several available and new linear SR algorithms, with the ultimate goal of analyzing their potential in solving the spectral unmixing problem by resorting to available spectral libraries. Our experimental results, conducted using both simulated and real hyperspectral data sets collected by the NASA Jet Propulsion Laboratory's Airborne Visible Infrared Imaging Spectrometer and spectral libraries publicly available from the U.S. Geological Survey, indicate the potential of SR techniques in the task of accurately characterizing the mixed pixels using the library spectra. This opens new perspectives for spectral unmixing, since the abundance estimation process no longer depends on the availability of pure spectral signatures in the input data nor on the capacity of a certain endmember extraction algorithm to identify such pure signatures.",2011,"Marian-Daniel Iordache,J. Bioucas-Dias,A. Plaza",Computer Science,914,50
11927662,Alternating direction algorithms for constrained sparse regression: Application to hyperspectral unmixing,"Convex optimization problems are common in hyperspectral unmixing. Examples are the constrained least squares (CLS) problem used to compute the fractional abundances in a linear mixture of known spectra, the constrained basis pursuit (CBP) to find sparse (i.e., with a small number of terms) linear mixtures of spectra, selected from large libraries, and the constrained basis pursuit denoising (CBPDN), which is a generalization of BP to admit modeling errors. In this paper, we introduce two new algorithms to efficiently solve these optimization problems, based on the alternating direction method of multipliers, a method from the augmented Lagrangian family. The algorithms are termed SUnSAL (sparse unmixing by variable splitting and augmented Lagrangian) and C-SUnSAL (constrained SUnSAL). C-SUnSAL solves the CBP and CBPDN problems, while SUnSAL solves CLS as well as a more general version thereof, called constrained sparse regression (CSR). C-SUnSAL and SUnSAL are shown to outperform off-the-shelf methods in terms of speed and accuracy.",2010,"J. Bioucas-Dias,Mário A. T. Figueiredo","Mathematics,Computer Science",570,25
14601089,A note on the group lasso and a sparse group lasso,"We consider the group lasso penalty for the linear model. We note that the standard algorithm for solving the problem assumes that the model matrices in each group are orthonormal. Here we consider a more general penalty that blends the lasso (L1) with the group lasso (\two-norm""). This penalty yields solutions that are sparse at both the group and individual feature levels. We derive an ecien t algorithm for the resulting convex problem based on coordinate descent. This algorithm can also be used to solve the general form of the group lasso, with non-orthonormal model matrices.",2010,"J. Friedman,T. Hastie,R. Tibshirani",Mathematics,805,5
1072704,An Augmented Lagrangian Approach to the Constrained Optimization Formulation of Imaging Inverse Problems,"We propose a new fast algorithm for solving one of the standard approaches to ill-posed linear inverse problems (IPLIP), where a (possibly nonsmooth) regularizer is minimized under the constraint that the solution explains the observations sufficiently well. Although the regularizer and constraint are usually convex, several particular features of these problems (huge dimensionality, nonsmoothness) preclude the use of off-the-shelf optimization tools and have stimulated a considerable amount of research. In this paper, we propose a new efficient algorithm to handle one class of constrained problems (often known as basis pursuit denoising) tailored to image recovery applications. The proposed algorithm, which belongs to the family of augmented Lagrangian methods, can be used to deal with a variety of imaging IPLIP, including deconvolution and reconstruction from compressive observations (such as MRI), using either total-variation or wavelet-based (or, more generally, frame-based) regularization. The proposed algorithm is an instance of the so-called alternating direction method of multipliers, for which convergence sufficient conditions are known; we show that these conditions are satisfied by the proposed algorithm. Experiments on a set of image restoration and reconstruction benchmark problems show that the proposed algorithm is a strong contender for the state-of-the-art.",2009,"M. Afonso,J. Bioucas-Dias,Mário A. T. Figueiredo","Computer Science,Mathematics,Medicine",1039,62
11964764,From Sparse Solutions of Systems of Equations to Sparse Modeling of Signals and Images,"A full-rank matrix ${\bf A}\in \mathbb{R}^{n\times m}$ with $n<m$ generates an underdetermined system of linear equations ${\bf Ax} = {\bf b}$ having infinitely many solutions. Suppose we seek the sparsest solution, i.e., the one with the fewest nonzero entries. Can it ever be unique? If so, when? As optimization of sparsity is combinatorial in nature, are there efficient methods for finding the sparsest solution? These questions have been answered positively and constructively in recent years, exposing a wide variety of surprising phenomena, in particular the existence of easily verifiable conditions under which optimally sparse solutions can be found by concrete, effective computational methods.

Such theoretical results inspire a bold perspective on some important practical problems in signal and image processing. Several well-known signal and image processing problems can be cast as demanding solutions of undetermined systems of equations. Such problems have previously seemed, to many, intractable, but there is considerable evidence that these problems often have sparse solutions. Hence, advances in finding sparse solutions to underdetermined systems have energized research on such signal and image processing problems—to striking effect.

In this paper we review the theoretical results on sparse solutions of linear systems, empirical results on sparse modeling of signals and images, and recent applications in inverse problems and compression in image processing. This work lies at the intersection of signal processing and applied mathematics, and arose initially from the wavelets and harmonic analysis research communities. The aim of this paper is to introduce a few key notions and applications connected to sparsity, targeting newcomers interested in either the mathematical aspects of this area or its applications.",2009,"A. Bruckstein,D. Donoho,Michael Elad","Mathematics,Computer Science",2325,177
8906918,On the Uniqueness of Nonnegative Sparse Solutions to Underdetermined Systems of Equations,"An underdetermined linear system of equations Ax = b with nonnegativity constraint x ges 0 is considered. It is shown that for matrices A with a row-span intersecting the positive orthant, if this problem admits a sufficiently sparse solution, it is necessarily unique. The bound on the required sparsity depends on a coherence property of the matrix A. This coherence measure can be improved by applying a conditioning stage on A, thereby strengthening the claimed result. The obtained uniqueness theorem relies on an extended theoretical analysis of the lscr0 - lscr1 equivalence developed here as well, considering a matrix A with arbitrary column norms, and an arbitrary monotone element-wise concave penalty replacing the lscr1-norm objective function. Finally, from a numerical point of view, a greedy algorithm-a variant of the matching pursuit-is presented, such that it is guaranteed to find this sparse solution. It is further shown how this algorithm can benefit from well-designed conditioning of A .",2008,"A. Bruckstein,Michael Elad,M. Zibulevsky","Mathematics,Computer Science",298,42
6162124,Model selection and estimation in regression with grouped variables,"Summary.  We consider the problem of selecting grouped variables (factors) for accurate prediction in regression. Such a problem arises naturally in many practical situations with the multifactor analysis‐of‐variance problem as the most important and well‐known example. Instead of selecting factors by stepwise backward elimination, we focus on the accuracy of estimation and consider extensions of the lasso, the LARS algorithm and the non‐negative garrotte for factor selection. The lasso, the LARS algorithm and the non‐negative garrotte are recently proposed regression methods that can be used to select individual variables. We study and propose efficient algorithms for the extensions of these methods for factor selection and show that these extensions give superior performance to the traditional stepwise backward elimination method in factor selection problems. We study the similarities and the differences between these methods. Simulations and real examples are used to illustrate the methods.",2006,"M. Yuan,Yi Lin",Mathematics,7089,18
119159284,Stable signal recovery from incomplete and inaccurate measurements,"Suppose we wish to recover a vector x0 ∈ ℝ𝓂 (e.g., a digital signal or image) from incomplete and contaminated observations y = A x0 + e; A is an 𝓃 × 𝓂 matrix with far fewer rows than columns (𝓃 ≪ 𝓂) and e is an error term. Is it possible to recover x0 accurately based on the data y?",2005,"E. Candès,J. Romberg,T. Tao","Mathematics,Physics",7351,25
12605120,Decoding by linear programming,"This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f/spl isin/R/sup n/ from corrupted measurements y=Af+e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y? We prove that under suitable conditions on the coding matrix A, the input f is the unique solution to the /spl lscr//sub 1/-minimization problem (/spl par/x/spl par//sub /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|) min(g/spl isin/R/sup n/) /spl par/y - Ag/spl par//sub /spl lscr/1/ provided that the support of the vector of errors is not too large, /spl par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl ne/ 0}|/spl les//spl rho//spl middot/m for some /spl rho/>0. In short, f can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; f is recovered exactly even in situations where a significant fraction of the output is corrupted. This work is related to the problem of finding sparse solutions to vastly underdetermined systems of linear equations. There are also significant connections with the problem of recovering signals from highly incomplete measurements. In fact, the results introduced in this paper improve on our earlier work. Finally, underlying the success of /spl lscr//sub 1/ is a crucial property we call the uniform uncertainty principle that we shall describe in detail.",2005,"E. Candès,T. Tao","Mathematics,Computer Science",7222,35
128543681,Imaging spectroscopy: Earth and planetary remote sensing with the USGS Tetracorder and expert systems,"[1] Imaging spectroscopy is a tool that can be used to spectrally identify and spatially map materials based on their specific chemical bonds. Spectroscopic analysis requires significantly more sophistication than has been employed in conventional broadband remote sensing analysis. We describe a new system that is effective at material identification and mapping: a set of algorithms within an expert system decision-making framework that we call Tetracorder. The expertise in the system has been derived from scientific knowledge of spectral identification. The expert system rules are implemented in a decision tree where multiple algorithms are applied to spectral analysis, additional expert rules and algorithms can be applied based on initial results, and more decisions are made until spectral analysis is complete. Because certain spectral features are indicative of specific chemical bonds in materials, the system can accurately identify and map those materials. In this paper we describe the framework of the decision making process used for spectral identification, describe specific spectral feature analysis algorithms, and give examples of what analyses and types of maps are possible with imaging spectroscopy data. We also present the expert system rules that describe which diagnostic spectral features are used in the decision making process for a set of spectra of minerals and other common materials. We demonstrate the applications of Tetracorder to identify and map surface minerals, to detect sources of acid rock drainage, and to map vegetation species, ice, melting snow, water, and water pollution, all with one set of expert system rules. Mineral mapping can aid in geologic mapping and fault detection and can provide a better understanding of weathering, mineralization, hydrothermal alteration, and other geologic processes. Environmental site assessment, such as mapping source areas of acid mine drainage, has resulted in the acceleration of site cleanup, saving millions of dollars and years in cleanup time. Imaging spectroscopy data and Tetracorder analysis can be used to study both terrestrial and planetary science problems. Imaging spectroscopy can be used to probe planetary systems, including their atmospheres, oceans, and land surfaces.",2003,"R. Clark,G. Swayze,K. Livo,R. Kokaly,S. J. Sutley,J. B. Dalton,Robert R. McDougal,C. Gent",Geology,755,51
3074570,$\ell_{p}-\ell_{q}$ Penalty for Sparse Linear and Sparse Multiple Kernel Multitask Learning,"Recently, there has been much interest around multitask learning (MTL) problem with the constraints that tasks should share a common sparsity profile. Such a problem can be addressed through a regularization framework where the regularizer induces a joint-sparsity pattern between task decision functions. We follow this principled framework and focus on ℓ<sub>p</sub>-ℓ<sub>q</sub> (with 0 ≤ <i>p</i> ≤ 1 and 1 ≤ <i>q</i> ≤ 2) mixed norms as sparsity-inducing penalties. Our motivation for addressing such a larger class of penalty is to adapt the penalty to a problem at hand leading thus to better performances and better sparsity pattern. For solving the problem in the general multiple kernel case, we first derive a variational formulation of the ℓ<sub>1</sub>-ℓ<sub>q</sub> penalty which helps us in proposing an alternate optimization algorithm. Although very simple, the latter algorithm provably converges to the global minimum of the ℓ<sub>1</sub>-ℓ<sub>q</sub> penalized problem. For the linear case, we extend existing works considering accelerated proximal gradient to this penalty. Our contribution in this context is to provide an efficient scheme for computing the ℓ<sub>1</sub>-ℓ<sub>q</sub> proximal operator. Then, for the more general case, when 0 <; <i>p</i> <; 1, we solve the resulting nonconvex problem through a majorization-minimization approach. The resulting algorithm is an iterative scheme which, at each iteration, solves a weighted ℓ<sub>1</sub>-ℓ<sub>q</sub> sparse MTL problem. Empirical evidences from toy dataset and real-word datasets dealing with brain-computer interface single-trial electroencephalogram classification and protein subcellular localization show the benefit of the proposed approaches and algorithms.",2011,"A. Rakotomamonjy,Rémi Flamary,G. Gasso,S. Canu","Computer Science,Medicine,Mathematics",89,58
6998485,Joint covariate selection and joint subspace selection for multiple classification problems,,2010,"G. Obozinski,B. Taskar,Michael I. Jordan","Computer Science,Mathematics",531,41
17188792,Iterative Reweighted 1 and 2 Methods for Finding Sparse Solutions,"A variety of practical methods have recently been introduced for finding maximally sparse representations from overcomplete dictionaries, a central computational task in compressive sensing applications as well as numerous others. Many of the underlying algorithms rely on iterative reweighting schemes that produce more focal estimates as optimization progresses. Two such variants are iterative reweighted l1 and l2 minimization; however, some properties related to convergence and sparse estimation, as well as possible generalizations, are still not clearly understood or fully exploited. In this paper, we make the distinction between separable and non-separable iterative reweighting algorithms. The vast majority of existing methods are separable, meaning the weighting of a given coefficient at each iteration is only a function of that individual coefficient from the previous iteration (as opposed to dependency on all coefficients). We examine two such separable reweighting schemes: an l2 method from Chartrand and Yin (2008) and an l1 approach from Cande's (2008), elaborating on convergence results and explicit connections between them. We then explore an interesting non-separable alternative that can be implemented via either l2 or l1 reweighting and maintains several desirable properties relevant to sparse recovery despite a highly non-convex underlying cost function. For example, in the context of canonical sparse estimation problems, we prove uniform superiority of this method over the minimum l1 solution in that, 1) it can never do worse when implemented with reweighted l1, and 2) for any dictionary and sparsity profile, there will always exist cases where it does better. These results challenge the prevailing reliance on strictly convex (and separable) penalty functions for finding sparse solutions. We then derive a new non-separable variant with similar properties that exhibits further performance improvements in empirical tests. Finally, we address natural extensions to group sparsity problems and non-negative sparse coding.",2010,"D. Wipf,S. Nagarajan","Mathematics,Computer Science",433,34
7854545,"Robust Bayesian estimation of the location, orientation, and time course of multiple correlated neural sources using MEG",,2010,"D. Wipf,J. Owen,H. Attias,K. Sekihara,S. Nagarajan","Computer Science,Medicine",197,41
9178122,Efficient Recovery of Jointly Sparse Vectors,"We consider the reconstruction of sparse signals in the multiple measurement vector (MMV) model, in which the signal, represented as a matrix, consists of a set of jointly sparse vectors. MMV is an extension of the single measurement vector (SMV) model employed in standard compressive sensing (CS). Recent theoretical studies focus on the convex relaxation of the MMV problem based on the (2,1)-norm minimization, which is an extension of the well-known 1-norm minimization employed in SMV. However, the resulting convex optimization problem in MMV is significantly much more difficult to solve than the one in SMV. Existing algorithms reformulate it as a second-order cone programming (SOCP) or semidefinite programming (SDP) problem, which is computationally expensive to solve for problems of moderate size. In this paper, we propose a new (dual) reformulation of the convex optimization problem in MMV and develop an efficient algorithm based on the prox-method. Interestingly, our theoretical analysis reveals the close connection between the proposed reformulation and multiple kernel learning. Our simulation studies demonstrate the scalability of the proposed algorithm.",2009,"Liang Sun,Jun Liu,Jianhui Chen,Jieping Ye","Computer Science,Mathematics",63,26
2145739,Model-based compressive sensing for signal ensembles,"Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for acquiring sparse or compressible signals. Instead of taking N periodic samples, we measure M ≪ N inner products with random vectors and then recover the signal via a sparsity-seeking optimization or greedy algorithm. A new framework for CS based on unions of subspaces can improve signal recovery by including dependencies between values and locations of the signal's significant coefficients. In this paper, we extend this framework to the acquisition of signal ensembles under a common sparse supports model. The new framework provides recovery algorithms with theoretical performance guarantees. Additionally, the framework scales naturally to large sensor networks: the number of measurements needed for each signal does not increase as the network becomes larger. Furthermore, the complexity of the recovery algorithm is only linear in the size of the network. We provide experimental results using synthetic and real-world signals that confirm these benefits.",2009,"Marco F. Duarte,V. Cevher,Richard Baraniuk",Computer Science,53,22
335122,Block-Sparse Signals: Uncertainty Relations and Efficient Recovery,"We consider efficient methods for the recovery of block-sparse signals-i.e., sparse signals that have nonzero entries occurring in clusters-from an underdetermined system of linear equations. An uncertainty relation for block-sparse signals is derived, based on a block-coherence measure, which we introduce. We then show that a block-version of the orthogonal matching pursuit algorithm recovers block -sparse signals in no more than steps if the block-coherence is sufficiently small. The same condition on block-coherence is shown to guarantee successful recovery through a mixed -optimization approach. This complements previous recovery results for the block-sparse case which relied on small block-restricted isometry constants. The significance of the results presented in this paper lies in the fact that making explicit use of block-sparsity can provably yield better reconstruction properties than treating the signal as being sparse in the conventional sense, thereby ignoring the additional structure in the problem.",2009,"Yonina C. Eldar,Patrick Kuppinger,H. Bölcskei","Computer Science,Mathematics",1261,53
2110798,A group bridge approach for variable selection,"Abstract In multiple regression problems when covariates can be naturally grouped, it is important to carry out feature selection at the group and within-group individual variable levels simultaneously. The existing methods, including the lasso and group lasso, are designed for either variable selection or group selection, but not for both. We propose a group bridge approach that is capable of simultaneous selection at both the group and within-group individual variable levels. The proposed approach is a penalized regularization method that uses a specially designed group bridge penalty. It has the oracle group selection property, in that it can correctly select important groups with probability converging to one. In contrast, the group lasso and group least angle regression methods in general do not possess such an oracle property in group selection. Simulation studies indicate that the group bridge has superior performance in group and individual variable selection relative to several existing methods.",2009,"Jian Huang,Shuange Ma,Huiliang Xie,Cun-Hui Zhang","Mathematics,Medicine",337,36
16293797,Sparsest solutions of underdetermined linear systems via ℓq-minimization for 0,,2009,"S. Foucart,M. Lai",Mathematics,756,17
168049,Model-Based Compressive Sensing,"Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for the acquisition of sparse or compressible signals that can be well approximated by just K ¿ N elements from an N -dimensional basis. Instead of taking periodic samples, CS measures inner products with M < N random vectors and then recovers the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS dictates that robust signal recovery is possible from M = O(K log(N/K)) measurements. It is possible to substantially decrease M without sacrificing robustness by leveraging more realistic signal models that go beyond simple sparsity and compressibility by including structural dependencies between the values and locations of the signal coefficients. This paper introduces a model-based CS theory that parallels the conventional theory and provides concrete guidelines on how to create model-based recovery algorithms with provable performance guarantees. A highlight is the introduction of a new class of structured compressible signals along with a new sufficient condition for robust structured compressible signal recovery that we dub the restricted amplification property, which is the natural counterpart to the restricted isometry property of conventional CS. Two examples integrate two relevant signal models-wavelet trees and block sparsity-into two state-of-the-art CS recovery algorithms and prove that they offer robust recovery from just M = O(K) measurements. Extensive numerical simulations demonstrate the validity and applicability of our new theory and algorithms.",2008,"Richard Baraniuk,V. Cevher,Marco F. Duarte,C. Hegde","Computer Science,Mathematics",2732,57
7845570,Fast ℓ1-minimization algorithms and an application in robust face recognition: A review,"We provide a comprehensive review of five representative ℓ1-minimization methods, i.e., gradient projection, homotopy, iterative shrinkage-thresholding, proximal gradient, and augmented Lagrange multiplier. The repository is intended to fill in a gap in the existing literature to systematically benchmark the performance of these algorithms using a consistent experimental setting. The experiment will be focused on the application of face recognition, where a sparse representation framework has recently been developed to recover human identities from facial images that may be affected by illumination change, occlusion, and facial disguise. The paper also provides useful guidelines to practitioners working in similar fields.",2010,"A. Yang,S. Sastry,Arvind Ganesh,Yi Ma","Computer Science,Mathematics",476,51
1024788,The Noise-Sensitivity Phase Transition in Compressed Sensing,"Consider the noisy underdetermined system of linear equations: y = Ax<sub>0</sub> + z, with A an n × N measurement matrix, n <; N, and z ~ N(0, σ<sup>2</sup>I) a Gaussian white noise. Both y and A are known, both x<sub>0</sub> and z are unknown, and we seek an approximation to x<sub>0</sub>. When x<sub>0</sub> has few nonzeros, useful approximations are often obtained by ℓ<sub>1</sub>-penalized ℓ<sub>2</sub> minimization, in which the reconstruction x̂<sup>1,λ</sup> solves min{||y - Ax||<sub>2</sub><sup>2</sup>/2 + λ||x||<sub>1</sub>}. Consider the reconstruction mean-squared error MSE = E|| x̂<sup>1,λ</sup> - x<sub>0</sub>||<sub>2</sub><sup>2</sup>/N, and define the ratio MSE/σ<sup>2</sup> as the noise sensitivity. Consider matrices A with i.i.d. Gaussian entries and a large-system limit in which n, N → ∞ with n/N → δ and k/n → ρ. We develop exact expressions for the asymptotic MSE of x̂<sup>1,λ</sup> , and evaluate its worst-case noise sensitivity over all types of k-sparse signals. The phase space 0 ≤ 8, ρ ≤ 1 is partitioned by the curve ρ = ρ<sub>MSE</sub>(δ) into two regions. Formal noise sensitivity is bounded throughout the region ρ = ρ<sub>MSE</sub>(δ) and is unbounded throughout the region ρ = ρ<sub>MSE</sub>(δ). The phase boundary ρ = ρ<sub>MSE</sub>(δ) is identical to the previously known phase transition curve for equivalence of ℓ<sub>1</sub> - ℓ<sub>0</sub> minimization in the k-sparse noiseless case. Hence, a single phase boundary describes the fundamental phase transitions both for the noise less and noisy cases. Extensive computational experiments validate these predictions, including the existence of game-theoretical structures underlying it (saddlepoints in the payoff, least-favorable signals and maximin penalization). Underlying our formalism is an approximate message passing soft thresholding algorithm (AMP) introduced earlier by the authors. Other papers by the authors detail expressions for the formal MSE of AMP and its close connection to ℓ<sub>1</sub>-penalized reconstruction. The focus of the present paper is on computing the minimax formal MSE within the class of sparse signals x<sup>0</sup>.",2010,"D. Donoho,A. Maleki,A. Montanari","Mathematics,Computer Science",371,41
14534974,Alternating Direction Algorithms for 1-Problems in Compressive Sensing,"In this paper, we propose and study the use of alternating direction algorithms for several $\ell_1$-norm minimization problems arising from sparse solution recovery in compressive sensing, including the basis pursuit problem, the basis pursuit denoising problems of both unconstrained and constrained forms, and others. We present and investigate two classes of algorithms derived from either the primal or the dual form of $\ell_1$-problems. The construction of the algorithms consists of two main steps: (1) to reformulate an $\ell_1$-problem into one having blockwise separable objective functions by adding new variables and constraints; and (2) to apply an exact or inexact alternating direction method to the augmented Lagrangian function of the resulting problem. The derived alternating direction algorithms can be regarded as first-order primal-dual algorithms because both primal and dual variables are updated at every iteration. Convergence properties of these algorithms are established or restated when they already exist. Extensive numerical experiments are performed, using randomized partial Walsh-Hadamard sensing matrices, to demonstrate the versatility and effectiveness of the proposed approach. Moreover, we present numerical results to emphasize two practically important but perhaps overlooked points: (i) that algorithm speed should be evaluated relative to appropriate solution accuracy; and (ii) that when erroneous measurements possibly exist, the $\ell_1$-fidelity should generally be preferable to the $\ell_2$-fidelity.",2009,"Junfeng Yang,Yin Zhang","Computer Science,Mathematics",1228,64
9178122,Efficient Recovery of Jointly Sparse Vectors,"We consider the reconstruction of sparse signals in the multiple measurement vector (MMV) model, in which the signal, represented as a matrix, consists of a set of jointly sparse vectors. MMV is an extension of the single measurement vector (SMV) model employed in standard compressive sensing (CS). Recent theoretical studies focus on the convex relaxation of the MMV problem based on the (2,1)-norm minimization, which is an extension of the well-known 1-norm minimization employed in SMV. However, the resulting convex optimization problem in MMV is significantly much more difficult to solve than the one in SMV. Existing algorithms reformulate it as a second-order cone programming (SOCP) or semidefinite programming (SDP) problem, which is computationally expensive to solve for problems of moderate size. In this paper, we propose a new (dual) reformulation of the convex optimization problem in MMV and develop an efficient algorithm based on the prox-method. Interestingly, our theoretical analysis reveals the close connection between the proposed reformulation and multiple kernel learning. Our simulation studies demonstrate the scalability of the proposed algorithm.",2009,"Liang Sun,Jun Liu,Jianhui Chen,Jieping Ye","Computer Science,Mathematics",63,26
6961958,Fast Solution of $\ell _{1}$ -Norm Minimization Problems When the Solution May Be Sparse,"The minimum lscr1-norm solution to an underdetermined system of linear equations y=Ax is often, remarkably, also the sparsest solution to that system. This sparsity-seeking property is of interest in signal processing and information transmission. However, general-purpose optimizers are much too slow for lscr1 minimization in many large-scale applications.In this paper, the Homotopy method, originally proposed by Osborne et al. and Efron et al., is applied to the underdetermined lscr1-minimization problem min parxpar1 subject to y=Ax. Homotopy is shown to run much more rapidly than general-purpose LP solvers when sufficient sparsity is present. Indeed, the method often has the following k-step solution property: if the underlying solution has only k nonzeros, the Homotopy method reaches that solution in only k iterative steps. This k-step solution property is demonstrated for several ensembles of matrices, including incoherent matrices, uniform spherical matrices, and partial orthogonal matrices. These results imply that Homotopy may be used to rapidly decode error-correcting codes in a stylized communication system with a computational budget constraint. The approach also sheds light on the evident parallelism in results on lscr1 minimization and orthogonal matching pursuit (OMP), and aids in explaining the inherent relations between Homotopy, least angle regression (LARS), OMP, and polytope faces pursuit.",2008,"D. Donoho,Yaakov Tsaig","Mathematics,Computer Science",872,65
3100731,Robust Recovery of Signals From a Structured Union of Subspaces,"Traditional sampling theories consider the problem of reconstructing an unknown signal x from a series of samples. A prevalent assumption which often guarantees recovery from the given measurements is that x lies in a known subspace. Recently, there has been growing interest in nonlinear but structured signal models, in which x lies in a union of subspaces. In this paper, we develop a general framework for robust and efficient recovery of such signals from a given set of samples. More specifically, we treat the case in which x lies in a sum of k subspaces, chosen from a larger set of m possibilities. The samples are modeled as inner products with an arbitrary set of sampling functions. To derive an efficient and robust recovery algorithm, we show that our problem can be formulated as that of recovering a block-sparse vector whose nonzero elements appear in fixed blocks. We then propose a mixed lscr2/lscr1 program for block sparse recovery. Our main result is an equivalence condition under which the proposed convex algorithm is guaranteed to recover the original signal. This result relies on the notion of block restricted isometry property (RIP), which is a generalization of the standard RIP used extensively in the context of compressed sensing. Based on RIP, we also prove stability of our approach in the presence of noise and modeling errors. A special case of our framework is that of recovering multiple measurement vectors (MMV) that share a joint sparsity pattern. Adapting our results to this context leads to new MMV recovery methods as well as equivalence conditions under which the entire set can be determined efficiently.",2008,"Yonina C. Eldar,M. Mishali","Computer Science,Physics,Mathematics",997,60
7399917,Sparse Reconstruction by Separable Approximation,"Finding sparse approximate solutions to large underdetermined linear systems of equations is a common problem in signal/image processing and statistics. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution and reconstruction, and compressed sensing (CS) are a few well-known areas in which problems of this type appear. One standard approach is to minimize an objective function that includes a quadratic (lscr 2) error term added to a sparsity-inducing (usually lscr1) regularizater. We present an algorithmic framework for the more general problem of minimizing the sum of a smooth convex function and a nonsmooth, possibly nonconvex regularizer. We propose iterative methods in which each step is obtained by solving an optimization subproblem involving a quadratic term with diagonal Hessian (i.e., separable in the unknowns) plus the original sparsity-inducing regularizer; our approach is suitable for cases in which this subproblem can be solved much more rapidly than the original problem. Under mild conditions (namely convexity of the regularizer), we prove convergence of the proposed iterative algorithm to a minimum of the objective function. In addition to solving the standard lscr2-lscr1 case, our framework yields efficient solution techniques for other regularizers, such as an lscrinfin norm and group-separable regularizers. It also generalizes immediately to the case in which the data is complex rather than real. Experiments with CS problems show that our approach is competitive with the fastest known methods for the standard lscr2-lscr1 problem, as well as being efficient on problems with other separable regularization terms.",2008,"Stephen J. Wright,R. Nowak,Mário A. T. Figueiredo","Computer Science,Mathematics",1947,90
16137430,On the Reconstruction of Block-Sparse Signals With an Optimal Number of Measurements,,2008,"M. Stojnic,F. Parvaresh,B. Hassibi","Computer Science,Mathematics,Chemistry,Medicine",493,75
675041,An Interior-Point Method for Large-Scale  $\ell_1$-Regularized Least Squares,"Recently, a lot of attention has been paid to regularization based methods for sparse signal reconstruction (e.g., basis pursuit denoising and compressed sensing) and feature selection (e.g., the Lasso algorithm) in signal processing, statistics, and related fields. These problems can be cast as -regularized least-squares programs (LSPs), which can be reformulated as convex quadratic programs, and then solved by several standard methods such as interior-point methods, at least for small and medium size problems. In this paper, we describe a specialized interior-point method for solving large-scale -regularized LSPs that uses the preconditioned conjugate gradients algorithm to compute the search direction. The interior-point method can solve large sparse problems, with a million variables and observations, in a few tens of minutes on a PC. It can efficiently solve large dense problems, that arise in sparse signal recovery with orthogonal transforms, by exploiting fast algorithms for these transforms. The method is illustrated on a magnetic resonance imaging data set.",2007,"Seung-Jean Kim,Kwangmoo Koh,M. Lustig,Stephen P. Boyd,D. Gorinevsky","Computer Science,Mathematics",1795,63
8510060,For most large underdetermined systems of linear equations the minimal 𝓁1‐norm solution is also the sparsest solution,"We consider linear equations y = Φx where y is a given vector in ℝn and Φ is a given n × m matrix with n < m ≤ τn, and we wish to solve for x ∈ ℝm. We suppose that the columns of Φ are normalized to the unit 𝓁2‐norm, and we place uniform measure on such Φ. We prove the existence of ρ = ρ(τ) > 0 so that for large n and for all Φ's except a negligible fraction, the following property holds: For every y having a representation y = Φx0 by a coefficient vector x0 ∈ ℝm with fewer than ρ · n nonzeros, the solution x1 of the 𝓁1‐minimization problem $${\rm min} \|x\|_{1} \;\;{subject \; to}\;\; \Phi x = y$$ is unique and equal to x0. In contrast, heuristic attempts to sparsely solve such systems—greedy algorithms and thresholding—perform poorly in this challenging setting. The techniques include the use of random proportional embeddings and almost‐spherical sections in Banach space theory, and deviation bounds for the eigenvalues of random Wishart matrices. © 2006 Wiley Periodicals, Inc.",2006,D. Donoho,Mathematics,2595,29
218595892,Jigsaw-VAE: Towards Balancing Features in Variational Autoencoders,"The latent variables learned by VAEs have seen considerable interest as an unsupervised way of extracting features, which can then be used for downstream tasks. There is a growing interest in the question of whether features learned on one environment will generalize across different environments. We demonstrate here that VAE latent variables often focus on some factors of variation at the expense of others - in this case we refer to the features as ``imbalanced''. Feature imbalance leads to poor generalization when the latent variables are used in an environment where the presence of features changes. Similarly, latent variables trained with imbalanced features induce the VAE to generate less diverse (i.e. biased towards dominant features) samples. To address this, we propose a regularization scheme for VAEs, which we show substantially addresses the feature imbalance problem. We also introduce a simple metric to measure the balance of features in generated images.",2020,"Saeid Asgari Taghanaki,Mohammad Havaei,Alex Lamb,Aditya Sanghi,Aram Danielyan,Tonya Custis","Computer Science,Mathematics",6,42
212675673,ARAE: Adversarially Robust Training of Autoencoders Improves Novelty Detection,,2020,"Mohammadreza Salehi,Atrin Arya,Barbod Pajoum,Mohammad Otoofi,Amirreza Shaeiri,M. Rohban,H. Rabiee","Computer Science,Medicine",42,49
210164926,Fast is better than free: Revisiting adversarial training,"Adversarial training, a method for learning robust deep networks, is typically assumed to be more expensive than traditional training due to the necessity of constructing adversarial examples via a first-order method like projected gradient decent (PGD). In this paper, we make the surprising discovery that it is possible to train empirically robust models using a much weaker and cheaper adversary, an approach that was previously believed to be ineffective, rendering the method no more costly than standard training in practice. Specifically, we show that adversarial training with the fast gradient sign method (FGSM), when combined with random initialization, is as effective as PGD-based training but has significantly lower cost. Furthermore we show that FGSM adversarial training can be further accelerated by using standard techniques for efficient training of deep networks, allowing us to learn a robust CIFAR10 classifier with 45% robust accuracy to PGD attacks with $\epsilon=8/255$ in 6 minutes, and a robust ImageNet classifier with 43% robust accuracy at $\epsilon=2/255$ in 12 hours, in comparison to past work based on ""free"" adversarial training which took 10 and 50 hours to reach the same respective thresholds. Finally, we identify a failure mode referred to as ""catastrophic overfitting"" which may have caused previous attempts to use FGSM adversarial training to fail. All code for reproducing the experiments in this paper as well as pretrained model weights are at this https URL.",2020,"Eric Wong,Leslie Rice,J. Z. Kolter","Computer Science,Mathematics",903,52
196622802,Exploring Deep Anomaly Detection Methods Based on Capsule Net,,2019,"Xiaoyan Li,I. Kiringa,T. Yeap,Xiaodan Zhu,Yifeng Li","Computer Science,Mathematics",19,36
195750576,Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty,"Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research.",2019,"Dan Hendrycks,Mantas Mazeika,Saurav Kadavath,D. Song","Computer Science,Mathematics",762,44
189857704,MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,"The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the ﬁeld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the ﬁrst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,747,29
146121358,"Adversarial Examples Are Not Bugs, They Are Features","Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.",2019,"Andrew Ilyas,Shibani Santurkar,Dimitris Tsipras,Logan Engstrom,Brandon Tran,A. Madry","Computer Science,Mathematics",1473,64
102353587,Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection,"Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder ""generalizes"" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",2019,"Dong Gong,Lingqiao Liu,Vuong Le,Budhaditya Saha,M. Mansour,S. Venkatesh,A. Hengel",Computer Science,853,54
84186723,OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations,"We present a novel model called OCGAN for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class. Our solution is based on learning latent representations of in-class examples using a de-noising auto-encoder network. The key contribution of our work is our proposal to explicitly constrain the latent space to exclusively represent the given class. In order to accomplish this goal, firstly, we force the latent space to have bounded support by introducing a tanh activation in the encoder's output layer. Secondly, using a discriminator in the latent space that is trained adversarially, we ensure that encoded representations of in-class examples resemble uniform random samples drawn from the same bounded space. Thirdly, using a second adversarial discriminator in the input space, we ensure all randomly drawn latent samples generate examples that look real. Finally, we introduce a gradient-descent based sampling technique that explores points in the latent space that generate potential out-of-class examples, which are fed back to the network to further train it to generate in-class examples from those points. The effectiveness of the proposed method is measured across four publicly available datasets using two one-class novelty detection protocols where we achieve state-of-the-art results.",2019,"Pramuditha Perera,Ramesh Nallapati,Bing Xiang",Computer Science,415,30
57825713,Deep Learning for Anomaly Detection: A Survey,"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.",2019,"Raghavendra Chalapathy,Sanjay Chawla","Computer Science,Mathematics,Geology",1201,477
207815138,IDRiD: Diabetic Retinopathy - Segmentation and Grading Challenge.,,2020,"Prasanna Porwal,S. Pachade,M. Kokare,Girish Deshmukh,Jaemin Son,Woong Bae,Lihong Liu,Jianzong Wang,Xinhui Liu,Liangxin Gao,Tianbo Wu,Jing Xiao,Fengyan Wang,Baocai Yin,Yunzhi Wang,Gopichandh Danala,Linsheng He,Y. Choi,Y. Lee,Sang-Hyuk Jung,Zhongyu Li,Xiaodan Sui,Junyan Wu,Xiaolong Li,Ting Zhou,János Tóth,Ágnes Baran,Avinash Kori,Sai Saketh Chennamsetty,M. Safwan,Varghese Alex,Xingzheng Lyu,Li Cheng,Qinhao Chu,Pengcheng Li,Xin Ji,Sanyuan Zhang,Yaxin Shen,Ling Dai,Oindrila Saha,R. Sathish,Tânia Melo,Teresa Araújo,B. Harangi,Bin Sheng,Ruogu Fang,D. Sheet,A. Hajdu,Yuanjie Zheng,A. Mendonça,Shaoting Zhang,A. Campilho,B. Zheng,Dinggang Shen,L. Giancardo,G. Quellec,F. Mériaudeau","Computer Science,Medicine",174,171
208513223,Sparse-Gan: Sparsity-Constrained Generative Adversarial Network for Anomaly Detection in Retinal OCT Image,"With the development of convolutional neural network, deep learning has shown its success for retinal disease detection from optical coherence tomography (OCT) images. However, deep learning often relies on large scale labelled data for training, which is oftentimes challenging especially for disease with low occurrence. Moreover, a deep learning system trained from data-set with one or a few diseases is unable to detect other unseen diseases, which limits the practical usage of the system in disease screening. To address the limitation, we propose a novel anomaly detection framework termed Sparsity-constrained Generative Adversarial Network (Sparse-GAN) for disease screening where only healthy data are available in the training set. The contributions of Sparse-GAN are two-folds: 1) The proposed Sparse-GAN predicts the anomalies in latent space rather than image-level; 2) Sparse-GAN is constrained by a novel Sparsity Regularization Net. Furthermore, in light of the role of lesions for disease screening, we present to leverage on an anomaly activation map to show the heatmap of lesions. We evaluate our proposed Sparse-GAN on a publicly available dataset, and the results show that the proposed method outperforms the state-of-the-art methods.",2019,"Kang Zhou,Shenghua Gao,Jun Cheng,Zaiwang Gu,H. Fu,Zhi Tu,Jianlong Yang,Yitian Zhao,Jiang Liu","Computer Science,Engineering,Physics",58,21
204837946,Perceptual-Assisted Adversarial Adaptation for Choroid Segmentation in Optical Coherence Tomography,"Accurate choroid segmentation in optical coherence tomography (OCT) image is vital because the choroid thickness is a major quantitative biomarker of many ocular diseases. Deep learning has shown its superiority in the segmentation of the choroid region but subjects to the performance degeneration caused by the domain discrepancies (e.g., noise level and distribution) among datasets obtained from the OCT devices of different manufacturers. In this paper, we present an unsupervised perceptual-assisted adversarial adaptation (PAAA) framework for efficiently segmenting the choroid area by narrowing the domain discrepancies between different domains. The adversarial adaptation module in the proposed framework encourages the prediction structure information of the target domain to be similar to that of the source domain. Besides, a perceptual loss is employed for matching their shape information (the curvatures of Bruch's membrane and choroid-sclera interface) which can result in a fine boundary prediction. The results of quantitative experiments show that the proposed PAAA segmentation framework outperforms other state-of-the-art methods.",2019,"Zhenjie Chai,Kang Zhou,Jianlong Yang,Yuhui Ma,Zhi Chen,Shenghua Gao,Jiang Liu","Computer Science,Engineering",13,17
208002298,EdgeConnect: Structure Guided Image Inpainting using Edge Prediction,"In recent years, many deep learning techniques have been applied to the image inpainting problem: the task of filling incomplete regions of an image. However, these models struggle to recover and/or preserve image structure especially when significant portions of the image are missing. We propose a two-stage model that separates the inpainting problem into structure prediction and image completion. Similar to sketch art, our model first predicts the image structure of the missing region in the form of edge maps. Predicted edge maps are passed to the second stage to guide the inpainting process. We evaluate our model end-to-end over publicly available datasets CelebA, CelebHQ, Places2, and Paris StreetView on images up to a resolution of 512 × 512. We demonstrate that this approach outperforms current state-of-the-art techniques quantitatively and qualitatively.",2019,"Kamyar Nazeri,Eric Ng,Tony Joseph,F. Qureshi,Mehran Ebrahimi",Computer Science,323,62
206769856,Video Anomaly Detection with Sparse Coding Inspired Deep Neural Networks,"This paper presents an anomaly detection method that is based on a sparse coding inspired Deep Neural Networks (DNN). Specifically, in light of the success of sparse coding based anomaly detection, we propose a Temporally-coherent Sparse Coding (TSC), where a temporally-coherent term is used to preserve the similarity between two similar frames. The optimization of sparse coefficients in TSC with the Sequential Iterative Soft-Thresholding Algorithm (SIATA) is equivalent to a special stacked Recurrent Neural Networks (sRNN) architecture. Further, to reduce the computational cost in alternatively updating the dictionary and sparse coefficients in TSC optimization and to alleviate hyperparameters selection in TSC, we stack one more layer on top of the TSC-inspired sRNN to reconstruct the inputs, and arrive at an sRNN-AE. We further improve sRNN-AE in the following aspects: i) rather than using a predefined similarity measurement between two frames, we propose to learn a data-dependent similarity measurement between neighboring frames in sRNN-AE to make it more suitable for anomaly detection; ii) to reduce computational costs in the inference stage, we reduce the depth of the sRNN in sRNN-AE and, consequently, our framework achieves real-time anomaly detection; iii) to improve computational efficiency, we conduct temporal pooling over the appearance features of several consecutive frames for summarizing information temporally, then we feed appearance features and temporally summarized features into a separate sRNN-AE for more robust anomaly detection. To facilitate anomaly detection evaluation, we also build a large-scale anomaly detection dataset which is even larger than the summation of all existing datasets for anomaly detection in terms of both the volume of data and the diversity of scenes. Extensive experiments on both a toy dataset under controlled settings and real datasets demonstrate that our method significantly outperforms existing methods, which validates the effectiveness of our sRNN-AE method for anomaly detection. Codes and data have been released at https://github.com/StevenLiuWen/sRNN_TSC_Anomaly_Detection.",2019,"Weixin Luo,Wen Liu,Dongze Lian,Jinhui Tang,Lixin Duan,Xi Peng,Shenghua Gao","Computer Science,Medicine",118,52
199543694,StructureFlow: Image Inpainting via Structure-Aware Appearance Flow,"Image inpainting techniques have shown significant improvements by using deep neural networks recently. However, most of them may either fail to reconstruct reasonable structures or restore fine-grained textures. In order to solve this problem, in this paper, we propose a two-stage model which splits the inpainting task into two parts: structure reconstruction and texture generation. In the first stage, edge-preserved smooth images are employed to train a structure reconstructor which completes the missing structures of the inputs. In the second stage, based on the reconstructed structures, a texture generator using appearance flow is designed to yield image details. Experiments on multiple publicly available datasets show the superior performance of the proposed network.",2019,"Yurui Ren,Xiaoming Yu,Ruonan Zhang,Thomas H. Li,Shan Liu,Ge Li",Computer Science,275,36
198986024,Attention Guided Network for Retinal Image Segmentation,,2019,"S. Zhang,H. Fu,Yuguang Yan,Yubing Zhang,Qingyao Wu,Ming Yang,Mingkui Tan,Yanwu Xu","Engineering,Computer Science",152,17
70122761,Oversampling for Imbalanced Data via Optimal Transport,"The issue of data imbalance occurs in many real-world applications especially in medical diagnosis, where normal cases are usually much more than the abnormal cases. To alleviate this issue, one of the most important approaches is the oversampling method, which seeks to synthesize minority class samples to balance the numbers of different classes. However, existing methods barely consider global geometric information involved in the distribution of minority class samples, and thus may incur distribution mismatching between real and synthetic samples. In this paper, relying on optimal transport (Villani 2008), we propose an oversampling method by exploiting global geometric information of data to make synthetic samples follow a similar distribution to that of minority class samples. Moreover, we introduce a novel regularization based on synthetic samples and shift the distribution of minority class samples according to loss information. Experiments on toy and real-world data sets demonstrate the efficacy of our proposed method in terms of multiple metrics.",2019,"Yuguang Yan,Mingkui Tan,Yanwu Xu,Jiezhang Cao,M. Ng,Huaqing Min,Qingyao Wu",Computer Science,34,35
157059377,Automated segmentation of macular edema in OCT using deep neural networks,,2019,"Junjie Hu,Yuanyuan Chen,Zhang Yi","Computer Science,Medicine",56,45
189857704,MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,"The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the ﬁeld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the ﬁrst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,747,29
54558282,Deep Anomaly Detection with Outlier Exposure,"It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.",2018,"Dan Hendrycks,Mantas Mazeika,Thomas G. Dietterich","Computer Science,Mathematics",1118,53
52273850,Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series,"Today's Cyber-Physical Systems (CPSs) are large, complex, and affixed with networked sensors and actuators that are targets for cyber-attacks. Conventional detection techniques are unable to deal with the increasingly dynamic and complex nature of the CPSs. On the other hand, the networked sensors and actuators generate large amounts of data streams that can be continuously monitored for intrusion events. Unsupervised machine learning techniques can be used to model the system behaviour and classify deviant behaviours as possible attacks. In this work, we proposed a novel Generative Adversarial Networks-based Anomaly Detection (GAN-AD) method for such complex networked CPSs. We used LSTM-RNN in our GAN to capture the distribution of the multivariate time series of the sensors and actuators under normal working conditions of a CPS. Instead of treating each sensor's and actuator's time series independently, we model the time series of multiple sensors and actuators in the CPS concurrently to take into account of potential latent interactions between them. To exploit both the generator and the discriminator of our GAN, we deployed the GAN-trained discriminator together with the residuals between generator-reconstructed data and the actual samples to detect possible anomalies in the complex CPS. We used our GAN-AD to distinguish abnormal attacked situations from normal working conditions for a complex six-stage Secure Water Treatment (SWaT) system. Experimental results showed that the proposed strategy is effective in identifying anomalies caused by various attacks with high detection rate and low false positive rate as compared to existing methods.",2018,"Dan Li,Dacheng Chen,Jonathan Goh,See-Kiong Ng","Mathematics,Computer Science",245,46
53694083,Image Anomaly Detection with Generative Adversarial Networks,,2018,"Lucas Deecke,Robert A. Vandermeulen,Lukas Ruff,S. Mandt,M. Kloft",Computer Science,182,52
49312162,Deep One-Class Classification,"Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objec-tive. In this paper we introduce a new anomaly detection method—Deep Support Vector Data Description—, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs.",2018,"Lukas Ruff,Nico Görnitz,Lucas Deecke,Shoaib Ahmed Siddiqui,Robert A. Vandermeulen,Alexander Binder,Emmanuel Müller,M. Kloft",Computer Science,1418,58
44108048,Deep Anomaly Detection Using Geometric Transformations,"We consider the problem of anomaly detection in images, and present a new detection technique. Given a sample of images, all known to belong to a ""normal"" class (e.g., dogs), we show how to train a deep neural model that can detect out-of-distribution images (i.e., non-dog objects). The main idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our algorithm improves state-of-the-art methods by a wide margin.",2018,"I. Golan,Ran El-Yaniv","Computer Science,Mathematics",512,45
3943864,Triplet-Center Loss for Multi-view 3D Object Retrieval,"Most existing 3D object recognition algorithms focus on leveraging the strong discriminative power of deep learning models with softmax loss for the classification of 3D data, while learning discriminative features with deep metric learning for 3D object retrieval is more or less neglected. In the paper, we study variants of deep metric learning losses for 3D object retrieval, which did not receive enough attention from this area. First, two kinds of representative losses, triplet loss and center loss, are introduced which could learn more discriminative features than traditional classification loss. Then, we propose a novel loss named triplet-center loss, which can further enhance the discriminative power of the features. The proposed triplet-center loss learns a center for each class and requires that the distances between samples and centers from the same class are closer than those from different classes. Extensive experimental results on two popular 3D object retrieval benchmarks and two widely-adopted sketch-based 3D shape retrieval benchmarks consistently demonstrate the effectiveness of our proposed loss, and significant improvements have been achieved compared with the state-of-the-arts.",2018,"Xinwei He,Yang Zhou,Zhichao Zhou,S. Bai,X. Bai",Computer Science,288,43
51805340,Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection,"Unsupervised anomaly detection on multior high-dimensional data is of great importance in both fundamental machine learning research and industrial applications, for which density estimation lies at the core. Although previous approaches based on dimensionality reduction followed by density estimation have made fruitful progress, they mainly suffer from decoupled model learning with inconsistent optimization goals and incapability of preserving essential information in the low-dimensional space. In this paper, we present a Deep Autoencoding Gaussian Mixture Model (DAGMM) for unsupervised anomaly detection. Our model utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). Instead of using decoupled two-stage training and the standard Expectation-Maximization (EM) algorithm, DAGMM jointly optimizes the parameters of the deep autoencoder and the mixture model simultaneously in an end-to-end fashion, leveraging a separate estimation network to facilitate the parameter learning of the mixture model. The joint optimization, which well balances autoencoding reconstruction, density estimation of latent representation, and regularization, helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding the need of pre-training. Experimental results on several public benchmark datasets show that, DAGMM significantly outperforms state-of-the-art anomaly detection techniques, and achieves up to 14% improvement based on the standard F1 score.",2018,"Bo Zong,Qi Song,Martin Renqiang Min,Wei Cheng,C. Lumezanu,Dae-ki Cho,Haifeng Chen",Computer Science,1212,34
4009713,Unsupervised Representation Learning by Predicting Image Rotations,"Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training ConvNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: this https URL .",2018,"Spyros Gidaris,Praveer Singh,N. Komodakis",Computer Science,2755,36
3488815,Towards Deep Learning Models Resistant to Adversarial Attacks,"Recent work has demonstrated that deep neural networks are vulnerable to adversarial examples---inputs that are almost indistinguishable from natural data and yet classified incorrectly by the network. In fact, some of the latest findings suggest that the existence of adversarial attacks may be an inherent weakness of deep learning models. To address this problem, we study the adversarial robustness of neural networks through the lens of robust optimization. This approach provides us with a broad and unifying view on much of the prior work on this topic. Its principled nature also enables us to identify methods for both training and attacking neural networks that are reliable and, in a certain sense, universal. In particular, they specify a concrete security guarantee that would protect against any adversary. These methods let us train networks with significantly improved resistance to a wide range of adversarial attacks. They also suggest the notion of security against a first-order adversary as a natural and broad security guarantee. We believe that robustness against such well-defined classes of adversaries is an important stepping stone towards fully resistant deep learning models. Code and pre-trained models are available at this https URL and this https URL.",2017,"A. Madry,Aleksandar Makelov,Ludwig Schmidt,Dimitris Tsipras,Adrian Vladu","Computer Science,Mathematics",9026,44
17427022,Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery,,2017,"T. Schlegl,Philipp Seeböck,S. Waldstein,U. Schmidt-Erfurth,G. Langs","Computer Science,Mathematics",1798,20
199511239,Image Synthesis with a Single (Robust) Classifier,"We show that the basic classification framework alone can be used to tackle some of the most challenging tasks in image synthesis. In contrast to other state-of-the-art approaches, the toolkit we develop is rather minimal: it uses a single, off-the-shelf classifier for all these tasks. The crux of our approach is that we train this classifier to be adversarially robust. It turns out that adversarial robustness is precisely what we need to directly manipulate salient features of the input. Overall, our findings demonstrate the utility of robustness in the broader machine learning context. Code and models for our experiments can be found at this https URL.",2019,"Shibani Santurkar,Andrew Ilyas,Dimitris Tsipras,Logan Engstrom,Brandon Tran,A. Madry",Computer Science,173,57
166228027,Adversarially-trained autoencoders for robust unsupervised new physics searches,,2019,"A. Blance,M. Spannowsky,Philip Waite",Physics,105,102
146121358,"Adversarial Examples Are Not Bugs, They Are Features","Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features derived from patterns in the data distribution that are highly predictive, yet brittle and incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a misalignment between the (human-specified) notion of robustness and the inherent geometry of the data.",2019,"Andrew Ilyas,Shibani Santurkar,Dimitris Tsipras,Logan Engstrom,Brandon Tran,A. Madry","Computer Science,Mathematics",1473,64
140311498,Adversarial Training and Robustness for Multiple Perturbations,"Defenses against adversarial examples, such as adversarial training, are typically tailored to a single perturbation type (e.g., small $\ell_\infty$-noise). For other perturbations, these defenses offer no guarantees and, at times, even increase the model's vulnerability. Our aim is to understand the reasons underlying this robustness trade-off, and to train models that are simultaneously robust to multiple perturbation types. We prove that a trade-off in robustness to different types of $\ell_p$-bounded and spatial perturbations must exist in a natural and simple statistical setting. We corroborate our formal analysis by demonstrating similar robustness trade-offs on MNIST and CIFAR10. Building upon new multi-perturbation adversarial training schemes, and a novel efficient attack for finding $\ell_1$-bounded adversarial examples, we show that no model trained against multiple attacks achieves robustness competitive with that of models trained on each attack individually. In particular, we uncover a pernicious gradient-masking phenomenon on MNIST, which causes adversarial training with first-order $\ell_\infty, \ell_1$ and $\ell_2$ adversaries to achieve merely $50\%$ accuracy. Our results question the viability and computational scalability of extending adversarial robustness, and adversarial training, to multiple perturbation types.",2019,"Florian Tramèr,D. Boneh","Computer Science,Mathematics",309,48
102353587,Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection,"Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder ""generalizes"" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",2019,"Dong Gong,Lingqiao Liu,Vuong Le,Budhaditya Saha,M. Mansour,S. Venkatesh,A. Hengel",Computer Science,853,54
84186723,OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations,"We present a novel model called OCGAN for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class. Our solution is based on learning latent representations of in-class examples using a de-noising auto-encoder network. The key contribution of our work is our proposal to explicitly constrain the latent space to exclusively represent the given class. In order to accomplish this goal, firstly, we force the latent space to have bounded support by introducing a tanh activation in the encoder's output layer. Secondly, using a discriminator in the latent space that is trained adversarially, we ensure that encoded representations of in-class examples resemble uniform random samples drawn from the same bounded space. Thirdly, using a second adversarial discriminator in the input space, we ensure all randomly drawn latent samples generate examples that look real. Finally, we introduce a gradient-descent based sampling technique that explores points in the latent space that generate potential out-of-class examples, which are fed back to the network to further train it to generate in-class examples from those points. The effectiveness of the proposed method is measured across four publicly available datasets using two one-class novelty detection protocols where we achieve state-of-the-art results.",2019,"Pramuditha Perera,Ramesh Nallapati,Bing Xiang",Computer Science,415,30
57825713,Deep Learning for Anomaly Detection: A Survey,"Anomaly detection is an important problem that has been well-studied within diverse research areas and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore, we review the adoption of these methods for anomaly across various application domains and assess their effectiveness. We have grouped state-of-the-art research techniques into different categories based on the underlying assumptions and approach adopted. Within each category we outline the basic anomaly detection technique, along with its variants and present key assumptions, to differentiate between normal and anomalous behavior. For each category, we present we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced while adopting these techniques.",2019,"Raghavendra Chalapathy,Sanjay Chawla","Computer Science,Mathematics,Geology",1201,477
54445285,Rare Event Detection Using Disentangled Representation Learning,"This paper presents a novel method for rare event detection from an image pair with class-imbalanced datasets. A straightforward approach for event detection tasks is to train a detection network from a large-scale dataset in an end-to-end manner. However, in many applications such as building change detection on satellite images, few positive samples are available for the training. Moreover, an image pair of scenes contains many trivial events, such as in illumination changes or background motions. These many trivial events and the class imbalance problem lead to false alarms for rare event detection. In order to overcome these difficulties, we propose a novel method to learn disentangled representations from only low-cost negative samples. The proposed method disentangles the different aspects in a pair of observations: variant and invariant factors that represent trivial events and image contents, respectively. The effectiveness of the proposed approach is verified by the quantitative evaluations on four change detection datasets, and the qualitative analysis shows that the proposed method can acquire the representations that disentangle rare events from trivial ones.",2018,"Ryuhei Hamaguchi,Ken Sakurada,R. Nakamura",Computer Science,32,35
49657108,Generative Probabilistic Novelty Detection with Adversarial Autoencoders,"Novelty detection is the problem of identifying whether a new data point is considered to be an inlier or an outlier. We assume that training data is available to describe only the inlier distribution. Recent approaches primarily leverage deep encoder-decoder network architectures to compute a reconstruction error that is used to either compute a novelty score or to train a one-class classifier. While we too leverage a novel network of that kind, we take a probabilistic approach and effectively compute how likely it is that a sample was generated by the inlier distribution. We achieve this with two main contributions. First, we make the computation of the novelty probability feasible because we linearize the parameterized manifold capturing the underlying structure of the inlier distribution, and show how the probability factorizes and can be computed with respect to local coordinates of the manifold tangent space. Second, we improve the training of the autoencoder network. An extensive set of results show that the approach achieves state-of-the-art performance on several benchmark datasets.",2018,"Stanislav Pidhorskyi,Ranya Almohsen,D. Adjeroh,Gianfranco Doretto",Computer Science,268,61
49567058,Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders,"Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.",2018,"Paul Bergmann,Sindy Löwe,Michael Fauser,David Sattlegger,C. Steger",Computer Science,442,27
49865868,ScaleNet: An Unsupervised Representation Learning Method for Limited Information,,2023,"Huili Huang,M. M. Roozbahani",Computer Science,1533,52
211549689,Classification-Based Anomaly Detection for General Data,"Anomaly detection, finding patterns that substantially deviate from those seen previously, is one of the fundamental problems of artificial intelligence. Recently, classification-based methods were shown to achieve superior results on this task. In this work, we present a unifying view and propose an open-set method to relax current generalization assumptions. Furthermore, we extend the applicability of transformation-based methods to non-image data using random affine transformations. Our method is shown to obtain state-of-the-art accuracy and is applicable to broad data types. The strong performance of our method is extensively validated on multiple datasets from different domains.",2020,"Liron Bergman,Yedid Hoshen","Computer Science,Mathematics",276,29
195848253,Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection,"Nearest-neighbor (NN) procedures are well studied and widely used in both supervised and unsupervised learning problems. In this paper we are concerned with investigating the performance of NN-based methods for anomaly detection. We first show through extensive simulations that NN methods compare favorably to some of the other state-of-the-art algorithms for anomaly detection based on a set of benchmark synthetic datasets. We further consider the performance of NN methods on real datasets, and relate it to the dimensionality of the problem. Next, we analyze the theoretical properties of NN-methods for anomaly detection by studying a more general quantity called distance-to-measure (DTM), originally developed in the literature on robust geometric and topological inference. We provide finite-sample uniform guarantees for the empirical DTM and use them to derive misclassification rates for anomalous observations under various settings. In our analysis we rely on Huber's contamination model and formulate mild geometric regularity assumptions on the underlying distribution of the data.",2019,"Xiaoyi Gu,L. Akoglu,A. Rinaldo","Computer Science,Mathematics",69,37
195750576,Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty,"Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research.",2019,"Dan Hendrycks,Mantas Mazeika,Saurav Kadavath,D. Song","Computer Science,Mathematics",762,44
174802612,Deep Semi-Supervised Anomaly Detection,"Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.",2019,"Lukas Ruff,Robert A. Vandermeulen,Nico Görnitz,Alexander Binder,Emmanuel Müller,K. Müller,M. Kloft","Computer Science,Mathematics",388,88
53681688,"FastGRNN: A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network","This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the ""Hey Cortana"" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at this https URL.",2018,"Aditya Kusupati,Manish Singh,K. Bhatia,A. Kumar,Prateek Jain,M. Varma","Computer Science,Mathematics",165,57
59316845,Anomaly Detection With Multiple-Hypotheses Predictions,"In one-class-learning tasks, only the normal case (foreground) can be modeled with data, whereas the variation of all possible anomalies is too erratic to be described by samples. Thus, due to the lack of representative data, the wide-spread discriminative approaches cannot cover such learning tasks, and rather generative models, which attempt to learn the input density of the foreground, are used. However, generative models suffer from a large input dimensionality (as in images) and are typically inefficient learners. We propose to learn the data distribution of the foreground more efficiently with a multi-hypotheses autoencoder. Moreover, the model is criticized by a discriminator, which prevents artificial data modes not supported by data, and enforces diversity across hypotheses. Our multiple-hypothesesbased anomaly detection framework allows the reliable identification of out-of-distribution samples. For anomaly detection on CIFAR-10, it yields up to 3.9% points improvement over previously reported results. On a real anomaly detection task, the approach reduces the error of the baseline models from 6.8% to 1.5%.",2018,"D. Nguyen,Zhongyu Lou,Michael Klar,T. Brox",Computer Science,55,33
54558282,Deep Anomaly Detection with Outlier Exposure,"It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.",2018,"Dan Hendrycks,Mantas Mazeika,Thomas G. Dietterich","Computer Science,Mathematics",1118,53
52298207,Active Anomaly Detection via Ensembles,"In critical applications of anomaly detection including computer security and fraud prevention, the anomaly detector must be configurable by the analyst to minimize the effort on false positives. One important way to configure the anomaly detector is by providing true labels for a few instances. We study the problem of label-efficient active learning to automatically tune anomaly detection ensembles and make four main contributions. First, we present an important insight into how anomaly detector ensembles are naturally suited for active learning. This insight allows us to relate the greedy querying strategy to uncertainty sampling, with implications for label-efficiency. Second, we present a novel formalism called compact description to describe the discovered anomalies and show that it can also be employed to improve the diversity of the instances presented to the analyst without loss in the anomaly discovery rate. Third, we present a novel data drift detection algorithm that not only detects the drift robustly, but also allows us to take corrective actions to adapt the detector in a principled manner. Fourth, we present extensive experiments to evaluate our insights and algorithms in both batch and streaming settings. Our results show that in addition to discovering significantly more anomalies than state-of-the-art unsupervised baselines, our active learning algorithms under the streaming-data setup are competitive with the batch setup.",2018,"S. Das,M. R. Islam,Nitthilan Kanappan Jayakodi,J. Doppa","Computer Science,Mathematics",12,38
52273850,Anomaly Detection with Generative Adversarial Networks for Multivariate Time Series,"Today's Cyber-Physical Systems (CPSs) are large, complex, and affixed with networked sensors and actuators that are targets for cyber-attacks. Conventional detection techniques are unable to deal with the increasingly dynamic and complex nature of the CPSs. On the other hand, the networked sensors and actuators generate large amounts of data streams that can be continuously monitored for intrusion events. Unsupervised machine learning techniques can be used to model the system behaviour and classify deviant behaviours as possible attacks. In this work, we proposed a novel Generative Adversarial Networks-based Anomaly Detection (GAN-AD) method for such complex networked CPSs. We used LSTM-RNN in our GAN to capture the distribution of the multivariate time series of the sensors and actuators under normal working conditions of a CPS. Instead of treating each sensor's and actuator's time series independently, we model the time series of multiple sensors and actuators in the CPS concurrently to take into account of potential latent interactions between them. To exploit both the generator and the discriminator of our GAN, we deployed the GAN-trained discriminator together with the residuals between generator-reconstructed data and the actual samples to detect possible anomalies in the complex CPS. We used our GAN-AD to distinguish abnormal attacked situations from normal working conditions for a complex six-stage Secure Water Treatment (SWaT) system. Experimental results showed that the proposed strategy is effective in identifying anomalies caused by various attacks with high detection rate and low false positive rate as compared to existing methods.",2018,"Dan Li,Dacheng Chen,Jonathan Goh,See-Kiong Ng","Mathematics,Computer Science",245,46
208527731,A Case for the Score: Identifying Image Anomalies using Variational Autoencoder Gradients,"Through training on unlabeled data, anomaly detection has the potential to impact computer-aided diagnosis by outlining suspicious regions. Previous work on deep-learning-based anomaly detection has primarily focused on the reconstruction error. We argue instead, that pixel-wise anomaly ratings derived from a Variational Autoencoder based score approximation yield a theoretically better grounded and more faithful estimate. In our experiments, Variational Autoencoder gradient-based rating outperforms other approaches on unsupervised pixel-wise tumor detection on the BraTS-2017 dataset with a ROC-AUC of 0.94.",2019,"David Zimmerer,Jens Petersen,Simon A. A. Kohl,Klaus Maier-Hein","Engineering,Computer Science,Mathematics",21,20
195820708,Unsupervised Anomaly Localization using Variational Auto-Encoders,,2019,"David Zimmerer,Fabian Isensee,Jens Petersen,Simon A. A. Kohl,Klaus Maier-Hein","Computer Science,Engineering,Mathematics",90,23
189857704,MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,"The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the ﬁeld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the ﬁrst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,747,29
166228599,Classification Accuracy Score for Conditional Generative Models,"Deep generative models (DGMs) of images are now sufficiently mature that they produce nearly photorealistic samples and obtain scores similar to the data distribution on heuristics such as Frechet Inception Distance (FID). These results, especially on large-scale datasets such as ImageNet, suggest that DGMs are learning the data distribution in a perceptually meaningful space and can be used in downstream tasks. To test this latter hypothesis, we use class-conditional generative models from a number of model classes---variational autoencoders, autoregressive models, and generative adversarial networks (GANs)---to infer the class labels of real data. We perform this inference by training an image classifier using only synthetic data and using the classifier to predict labels on real data. The performance on this task, which we call Classification Accuracy Score (CAS), reveals some surprising results not identified by traditional metrics and constitute our contributions. First, when using a state-of-the-art GAN (BigGAN-deep), Top-1 and Top-5 accuracy decrease by 27.9\% and 41.6\%, respectively, compared to the original data; and conditional generative models from other model classes, such as Vector-Quantized Variational Autoencoder-2 (VQ-VAE-2) and Hierarchical Autoregressive Models (HAMs), substantially outperform GANs on this benchmark. Second, CAS automatically surfaces particular classes for which generative models failed to capture the data distribution, and were previously unknown in the literature. Third, we find traditional GAN metrics such as Inception Score (IS) and FID neither predictive of CAS nor useful when evaluating non-GAN models. Furthermore, in order to facilitate better diagnoses of generative models, we open-source the proposed metric.",2019,"Suman V. Ravuri,O. Vinyals","Computer Science,Mathematics",168,48
73516151,f‐AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks,,2019,"T. Schlegl,Philipp Seeböck,S. Waldstein,G. Langs,U. Schmidt-Erfurth","Medicine,Computer Science",778,45
76666188,Diagnosing and Enhancing VAE Models,"Although variational autoencoders (VAEs) represent a widely influential deep generative model, many aspects of the underlying energy function remain poorly understood. In particular, it is commonly believed that Gaussian encoder/decoder assumptions reduce the effectiveness of VAEs in generating realistic samples. In this regard, we rigorously analyze the VAE objective, differentiating situations where this belief is and is not actually true. We then leverage the corresponding insights to develop a simple VAE enhancement that requires no additional hyperparameters or sensitive tuning. Quantitatively, this proposal produces crisp samples and stable FID scores that are actually competitive with a variety of GAN models, all while retaining desirable attributes of the original VAE architecture. A shorter version of this work will appear in the ICLR 2019 conference proceedings (Dai and Wipf, 2019). The code for our model is available at this https URL TwoStageVAE.",2019,"B. Dai,D. Wipf","Mathematics,Computer Science",314,45
49567058,Improving Unsupervised Defect Segmentation by Applying Structural Similarity to Autoencoders,"Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an $\ell^p$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.",2018,"Paul Bergmann,Sindy Löwe,Michael Fauser,David Sattlegger,C. Steger",Computer Science,442,27
49863126,Anomaly Machine Component Detection by Deep Generative Model with Unregularized Score,"One of the most common needs in manufacturing plants is rejecting products not coincident with the standards as anomalies. Accurate and automatic anomaly detection improves product reliability and reduces inspection cost. Probabilistic models have been employed to detect test samples with lower likelihoods as anomalies in unsupervised manner. Recently, a probabilistic model called deep generative model (DGM) has been proposed for end-to-end modeling of natural images and already achieved a certain success. However, anomaly detection of machine components with complicated structures is still challenging because they produce a wide variety of normal image patches with low likelihoods. For overcoming this difficulty, we propose unregularized score for the DGM. As its name implies, the unregularized score is the anomaly score of the DGM without the regularization terms. The unregularized score is robust to the inherent complexity of a sample and has a smaller risk of rejecting a sample appearing less frequently but being coincident with the standards.",2018,"Takashi Matsubara,Ryosuke Tachibana,K. Uehara","Computer Science,Mathematics",15,33
67855732,Variational Autoencoder with Arbitrary Conditioning,"We propose a single neural probabilistic model based on variational autoencoder that can be conditioned on an arbitrary subset of observed features and then sample the remaining features in ""one shot"". The features may be both real-valued and categorical. Training of the model is performed by stochastic variational Bayes. The experimental evaluation on synthetic data, as well as feature imputation and image inpainting problems, shows the effectiveness of the proposed approach and diversity of the generated samples.",2018,"Oleg Ivanov,Michael Figurnov,D. Vetrov","Mathematics,Computer Science",127,31
4792240,Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images,,2018,"Christoph Baur,B. Wiestler,Shadi Albarqouni,Nassir Navab",Computer Science,381,21
49657329,Glow: Generative Flow with Invertible 1x1 Convolutions,"Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at this https URL",2018,"Diederik P. Kingma,Prafulla Dhariwal","Computer Science,Mathematics",2452,29
49215526,Deep Generative Models in the Real-World: An Open Challenge from Medical Imaging,"Recent advances in deep learning led to novel generative modeling techniques that achieve unprecedented quality in generated samples and performance in learning complex distributions in imaging data. These new models in medical image computing have important applications that form clinically relevant and very challenging unsupervised learning problems. In this paper, we explore the feasibility of using state-of-the-art auto-encoder-based deep generative models, such as variational and adversarial auto-encoders, for one such task: abnormality detection in medical imaging. We utilize typical, publicly available datasets with brain scans from healthy subjects and patients with stroke lesions and brain tumors. We use the data from healthy subjects to train different auto-encoder based models to learn the distribution of healthy images and detect pathologies as outliers. Models that can better learn the data distribution should be able to detect outliers more accurately. We evaluate the detection performance of deep generative models and compare them with non-deep learning based approaches to provide a benchmark of the current state of research. We conclude that abnormality detection is a challenging task for deep generative models and large room exists for improvement. In order to facilitate further research, we aim to provide carefully pre-processed imaging data available to the research community.",2018,"Xiaoran Chen,Nick Pawlowski,Martin Rajchl,Ben Glocker,E. Konukoglu",Computer Science,45,46
4792240,Deep Autoencoding Models for Unsupervised Anomaly Segmentation in Brain MR Images,,2018,"Christoph Baur,B. Wiestler,Shadi Albarqouni,Nassir Navab",Computer Science,381,21
5022170,Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders,"Lesion detection in brain Magnetic Resonance Images (MRI) remains a challenging task. State-of-the-art approaches are mostly based on supervised learning making use of large annotated datasets. Human beings, on the other hand, even non-experts, can detect most abnormal lesions after seeing a handful of healthy brain images. Replicating this capability of using prior information on the appearance of healthy brain structure to detect lesions can help computers achieve human level abnormality detection, specifically reducing the need for numerous labeled examples and bettering generalization of previously unseen lesions. To this end, we study detection of lesion regions in an unsupervised manner by learning data distribution of brain MRI of healthy subjects using auto-encoder based methods. We hypothesize that one of the main limitations of the current models is the lack of consistency in latent representation. We propose a simple yet effective constraint that helps mapping of an image bearing lesion close to its corresponding healthy image in the latent space. We use the Human Connectome Project dataset to learn distribution of healthy-appearing brain MRI and report improved detection, in terms of AUC, of the lesions in the BRATS challenge dataset.",2018,"Xiaoran Chen,E. Konukoglu",Computer Science,230,23
13976945,Unsupervised Lesion Detection in Brain CT using Bayesian Convolutional Autoencoders,"Normally, lesions are detected using supervised learning techniques that require labelled training data. We explore the use of Bayesian autoencoders to learn the variability of healthy tissue and detect lesions as unlikely events under the normative model. As a proof-of-concept, we test our method on registered 2D mid-axial slices from CT imaging data. Our results indicate that our method achieves best performance in detecting lesions caused by bleeding compared to baselines.",2018,"Nick Pawlowski,M. J. Lee,Martin Rajchl,Steven G. McDonagh,Enzo Ferrante,K. Kamnitsas,Sam Cooke,Susan Stevenson,A. Khetani,Tom Newman,F. Zeiler,R. Digby,J. Coles,D. Rueckert,D. Menon,V. Newcombe,Ben Glocker",Computer Science,80,13
4097106,An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos,Videos represent the primary source of information for surveillance applications and are available in large amounts but in most cases contain little or no annotation for supervised learning. This article reviews the state-of-the-art deep learning based methods for video anomaly detection and categorizes them based on the type of model and criteria of detection. We also perform simple studies to understand the different approaches and provide the criteria of evaluation for spatio-temporal anomaly detection.,2018,"Dilip Ravi Kiran,Mathew Thomas,Ranjith Parakkal",Computer Science,388,87
3697707,Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features,,2017,"S. Bakas,H. Akbari,Aristeidis Sotiras,M. Bilello,Martin Rozycki,J. Kirby,J. Freymann,K. Farahani,C. Davatzikos","Medicine,Computer Science",1748,90
11695878,SmoothGrad: removing noise by adding noise,"Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.",2017,"D. Smilkov,Nikhil Thorat,Been Kim,F. Viégas,M. Wattenberg","Computer Science,Mathematics",1744,26
15895922,Detecting Cancer Metastases on Gigapixel Pathology Images,"Each year, the treatment decisions for more than 230,000 breast cancer patients in the U.S. hinge on whether the cancer has metastasized away from the breast. Metastasis detection is currently performed by pathologists reviewing large expanses of biological tissues. This process is labor intensive and error-prone. We present a framework to automatically detect and localize tumors as small as 100 x 100 pixels in gigapixel microscopy images sized 100,000 x 100,000 pixels. Our method leverages a convolutional neural network (CNN) architecture and obtains state-of-the-art results on the Camelyon16 dataset in the challenging lesion-level tumor detection task. At 8 false positives per image, we detect 92.4% of the tumors, relative to 82.7% by the previous best automated approach. For comparison, a human pathologist attempting exhaustive search achieved 73.2% sensitivity. We achieve image-level AUC scores above 97% on both the Camelyon16 test set and an independent set of 110 slides. In addition, we discover that two slides in the Camelyon16 training set were erroneously labeled normal. Our approach could considerably reduce false negative rates in metastasis detection.",2017,"Yun Liu,Krishna Gadepalli,Mohammad Norouzi,George E. Dahl,Timo Kohlberger,Aleksey Boyko,Subhashini Venugopalan,Aleksei Timofeev,Phil Q. Nelson,G. Corrado,J. Hipp,L. Peng,Martin C. Stumpe",Computer Science,587,25
12663716,PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications,"PixelCNNs are a recently proposed class of powerful generative models with tractable likelihood. Here we discuss our implementation of PixelCNNs which we make available at this https URL Our implementation contains a number of modifications to the original model that both simplify its structure and improve its performance. 1) We use a discretized logistic mixture likelihood on the pixels, rather than a 256-way softmax, which we find to speed up training. 2) We condition on whole pixels, rather than R/G/B sub-pixels, simplifying the model structure. 3) We use downsampling to efficiently capture structure at multiple resolutions. 4) We introduce additional short-cut connections to further speed up optimization. 5) We regularize the model using dropout. Finally, we present state-of-the-art log likelihood results on CIFAR-10 to demonstrate the usefulness of these modifications.",2017,"Tim Salimans,A. Karpathy,Xi Chen,Diederik P. Kingma","Computer Science,Mathematics",809,22
214688471,Adversarial Discriminative Attention for Robust Anomaly Detection,"Existing methods for visual anomaly detection predominantly rely on global level pixel comparisons for anomaly score computation without emphasizing on unique local features. However, images from real-world applications are susceptible to unwanted noise and distractions, that might jeopardize the robustness of such anomaly score. To alleviate this problem, we propose a self-supervised masking method that specifically focuses on discriminative parts of images to enable robust anomaly detection. Our experiments reveal that discriminator’s class activation map in adversarial training evolves in three stages and finally fixates on the foreground location in the images. Using this property of the activation map, we construct a mask that suppresses spurious signals from the background thus enabling robust anomaly detection by focusing on local discriminative attributes. Additionally, our method can further improve the accuracy by learning a semi-supervised discriminative classifier in cases where a few samples from anomaly classes are available during the training. Experimental evaluations on four different types of datasets demonstrate that our method outperforms previous state-of-the-art methods for each condition and in all domains.",2020,"Daiki Kimura,Subhajit Chaudhury,Minori Narita,Asim Munawar,Ryuki Tachibana",Computer Science,24,51
211068987,Iterative energy-based projection on a normal data manifold for anomaly localization,"Autoencoder reconstructions are widely used for the task of unsupervised anomaly localization. Indeed, an autoencoder trained on normal data is expected to only be able to reconstruct normal features of the data, allowing the segmentation of anomalous pixels in an image via a simple comparison between the image and its autoencoder reconstruction. In practice however, local defects added to a normal image can deteriorate the whole reconstruction, making this segmentation challenging. To tackle the issue, we propose in this paper a new approach for projecting anomalous data on a autoencoder-learned normal data manifold, by using gradient descent on an energy derived from the autoencoder's loss function. This energy can be augmented with regularization terms that model priors on what constitutes the user-defined optimal projection. By iteratively updating the input of the autoencoder, we bypass the loss of high-frequency information caused by the autoencoder bottleneck. This allows to produce images of higher quality than classic reconstructions. Our method achieves state-of-the-art results on various anomaly localization datasets. It also shows promising results at an inpainting task on the CelebA dataset.",2020,"David Dehaene,Oriel Frigo,Sébastien Combrexelle,P. Eline",Computer Science,107,29
208139191,Towards Visually Explaining Variational Autoencoders,"Recent advances in Convolutional Neural Network (CNN) model interpretability have led to impressive progress in visualizing and understanding model predictions. In particular, gradient-based visual attention methods have driven much recent effort in using visual attention maps as a means for visual explanations. A key problem, however, is these methods are designed for classification and categorization tasks, and their extension to explaining generative models, e.g., variational autoencoders (VAE) is not trivial. In this work, we take a step towards bridging this crucial gap, proposing the first technique to visually explain VAEs by means of gradient-based attention. We present methods to generate visual attention from the learned latent space, and also demonstrate such attention explanations serve more than just explaining VAE predictions. We show how these attention maps can be used to localize anomalies in images, demonstrating state-of-the-art performance on the MVTec-AD dataset. We also show how they can be infused into model training, helping bootstrap the VAE into learning improved latent space disentanglement, demonstrated on the Dsprites dataset.",2019,"Wenqian Liu,Runze Li,Meng Zheng,S. Karanam,Ziyan Wu,B. Bhanu,R. Radke,O. Camps",Computer Science,152,48
209696152,Inductive Multi-view Semi-Supervised Anomaly Detection via Probabilistic Modeling,"This paper considers anomaly detection with multi-view data. Unlike traditional detection on single-view data which identifies anomalies based on inconsistency between instances, multi-view anomaly detection identifies anomalies based on view inconsistency within each instance. Current multi-view detection approaches are mostly unsupervised and transductive. This may have limited performance in many applications, which have labeled normal data and prefer efficient detection on new data. In this paper, we propose an inductive semi-supervised multi-view anomaly detection approach. We design a probabilistic generative model for normal data, which assumes different views of a normal instance are generated from a shared latent factor, conditioned on which the views become independent. We estimate the model by maximizing its likelihood on normal data using the EM algorithm. Then, we apply the model to detect anomalies, which are instances generated with small probabilities. We experiment our approach on nine public data sets under different multi-view anomaly settings, and show it outperforms several state-of-the-art multi-view detection methods.",2019,"Zhen Wang,Maohong Fan,S. Muknahallipatna,Chao Lan",Computer Science,4,19
204027875,Pathology-Aware Deep Network Visualization and Its Application in Glaucoma Image Synthesis,,2019,"Xiaofei Wang,Mai Xu,Liu Li,Zulin Wang,Zhenyu Guan",Computer Science,9,13
207863715,Deep Variational Semi-Supervised Novelty Detection,"In anomaly detection (AD), one seeks to identify whether a test sample is abnormal, given a data set of normal samples. A recent and promising approach to AD relies on deep generative models, such as variational autoencoders (VAEs), for unsupervised learning of the normal data distribution. In semi-supervised AD (SSAD), the data also includes a small sample of labeled anomalies. In this work, we propose two variational methods for training VAEs for SSAD. The intuitive idea in both methods is to train the encoder to `separate' between latent vectors for normal and outlier data. We show that this idea can be derived from principled probabilistic formulations of the problem, and propose simple and effective algorithms. Our methods can be applied to various data types, as we demonstrate on SSAD datasets ranging from natural images to astronomy and medicine, and can be combined with any VAE model architecture. When comparing to state-of-the-art SSAD methods that are not specific to particular data types, we obtain marked improvement in outlier detection.",2019,"Tal Daniel,Thanard Kurutach,Aviv Tamar","Computer Science,Mathematics",17,57
196622802,Exploring Deep Anomaly Detection Methods Based on Capsule Net,,2019,"Xiaoyan Li,I. Kiringa,T. Yeap,Xiaodan Zhu,Yifeng Li","Computer Science,Mathematics",19,36
174802612,Deep Semi-Supervised Anomaly Detection,"Deep approaches to anomaly detection have recently shown promising results over shallow methods on large and complex datasets. Typically anomaly detection is treated as an unsupervised learning problem. In practice however, one may have---in addition to a large set of unlabeled samples---access to a small pool of labeled samples, e.g. a subset verified by some domain expert as being normal or anomalous. Semi-supervised approaches to anomaly detection aim to utilize such labeled samples, but most proposed methods are limited to merely including labeled normal samples. Only a few methods take advantage of labeled anomalies, with existing deep approaches being domain-specific. In this work we present Deep SAD, an end-to-end deep methodology for general semi-supervised anomaly detection. We further introduce an information-theoretic framework for deep anomaly detection based on the idea that the entropy of the latent distribution for normal data should be lower than the entropy of the anomalous distribution, which can serve as a theoretical interpretation for our method. In extensive experiments on MNIST, Fashion-MNIST, and CIFAR-10, along with other anomaly detection benchmark datasets, we demonstrate that our method is on par or outperforms shallow, hybrid, and deep competitors, yielding appreciable performance improvements even when provided with only little labeled data.",2019,"Lukas Ruff,Robert A. Vandermeulen,Nico Görnitz,Alexander Binder,Emmanuel Müller,K. Müller,M. Kloft","Computer Science,Mathematics",388,88
189857704,MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,"The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the ﬁeld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the ﬁrst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,747,29
102353587,Memorizing Normality to Detect Anomaly: Memory-Augmented Deep Autoencoder for Unsupervised Anomaly Detection,"Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder ""generalizes"" so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",2019,"Dong Gong,Lingqiao Liu,Vuong Le,Budhaditya Saha,M. Mansour,S. Venkatesh,A. Hengel",Computer Science,853,54
198162051,Not All Areas Are Equal: Transfer Learning for Semantic Segmentation via Hierarchical Region Selection,"The success of deep neural networks for semantic segmentation heavily relies on large-scale and well-labeled datasets, which are hard to collect in practice. Synthetic data offers an alternative to obtain ground-truth labels for free. However, models directly trained on synthetic data often struggle to generalize to real images. In this paper, we consider transfer learning for semantic segmentation that aims to mitigate the gap between abundant synthetic data (source domain) and limited real data (target domain). Unlike previous approaches that either learn mappings to target domain or finetune on target images, our proposed method jointly learn from real images and selectively from realistic pixels in synthetic images to adapt to the target domain. Our key idea is to have weighting networks to score how similar the synthetic pixels are to real ones, and learn such weighting at pixel-, region- and image-levels. We jointly learn these hierarchical weighting networks and segmentation network in an end-to-end manner. Extensive experiments demonstrate that our proposed approach significantly outperforms other existing baselines, and is applicable to scenarios with extremely limited real images.",2019,"Ruoqi Sun,Xinge Zhu,Chongruo Wu,Chen Huang,Jianping Shi,Lizhuang Ma",Computer Science,59,33
198185521,Where's Wally Now? Deep Generative and Discriminative Embeddings for Novelty Detection,"We develop a framework for novelty detection (ND) methods relying on deep embeddings, either discriminative or generative, and also propose a novel framework for assessing their performance. While much progress was made recently in these approaches, it has been accompanied by certain limitations: most methods were tested on relatively simple problems (low resolution images / small number of classes) or involved non-public data; comparative performance has often proven inconclusive because of lacking statistical significance; and evaluation has generally been done on non-canonical problem sets of differing complexity, making apples-to-apples comparative performance evaluation difficult. This has led to a relative confusing state of affairs. We address these challenges via the following contributions: We make a proposal for a novel framework to measure the performance of novelty detection methods using a trade-space demonstrating performance (measured by ROCAUC) as a function of problem complexity. We also make several proposals to formally characterize problem complexity. We conduct experiments with problems of higher complexity (higher image resolution / number of classes). To this end we design several canonical datasets built from CIFAR-10 and ImageNet (IN-125) which we make available to perform future benchmarks for novelty detection as well as other related tasks including semantic zero/adaptive shot and unsupervised learning. Finally, we demonstrate, as one of the methods in our ND framework, a generative novelty detection method whose performance exceeds that of all recent best-in-class generative ND methods.",2019,"P. Burlina,Neil J. Joshi,I-J. Wang",Computer Science,35,42
189857704,MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection,"The detection of anomalous structures in natural image data is of utmost importance for numerous tasks in the ﬁeld of computer vision. The development of methods for unsupervised anomaly detection requires data on which to train and evaluate new approaches and ideas. We introduce the MVTec Anomaly Detection (MVTec AD) dataset containing 5354 high-resolution color images of different object and texture categories. It contains normal, i.e., defect-free, images intended for training and images with anomalies intended for testing. The anomalies manifest themselves in the form of over 70 different types of defects such as scratches, dents, contaminations, and various structural changes. In addition, we provide pixel-precise ground truth regions for all anomalies. We also conduct a thorough evaluation of current state-of-the-art unsupervised anomaly detection methods based on deep architectures such as convolutional autoencoders, generative adversarial networks, and feature descriptors using pre-trained convolutional neural networks, as well as classical computer vision methods. This initial benchmark indicates that there is considerable room for improvement. To the best of our knowledge, this is the ﬁrst comprehensive, multi-object, multi-defect dataset for anomaly detection that provides pixel-accurate ground truth regions and focuses on real-world applications.",2019,"Paul Bergmann,Michael Fauser,David Sattlegger,C. Steger",Computer Science,747,29
170079187,Exploiting Epistemic Uncertainty of Anatomy Segmentation for Anomaly Detection in Retinal OCT,"Diagnosis and treatment guidance are aided by detecting relevant biomarkers in medical images. Although supervised deep learning can perform accurate segmentation of pathological areas, it is limited by requiring a priori definitions of these regions, large-scale annotations, and a representative patient cohort in the training set. In contrast, anomaly detection is not limited to specific definitions of pathologies and allows for training on healthy samples without annotation. Anomalous regions can then serve as candidates for biomarker discovery. Knowledge about normal anatomical structure brings implicit information for detecting anomalies. We propose to take advantage of this property using Bayesian deep learning, based on the assumption that epistemic uncertainties will correlate with anatomical deviations from a normal training set. A Bayesian U-Net is trained on a well-defined healthy environment using weak labels of healthy anatomy produced by existing methods. At test time, we capture epistemic uncertainty estimates of our model using Monte Carlo dropout. A novel post-processing technique is then applied to exploit these estimates and transfer their layered appearance to smooth blob-shaped segmentations of the anomalies. We experimentally validated this approach in retinal optical coherence tomography (OCT) images, using weak labels of retinal layers. Our method achieved a Dice index of 0.789 in an independent anomaly test set of age-related macular degeneration (AMD) cases. The resulting segmentations allowed very high accuracy for separating healthy and diseased cases with late wet AMD, dry geographic atrophy (GA), diabetic macular edema (DME) and retinal vein occlusion (RVO). Finally, we qualitatively observed that our approach can also detect other deviations in normal scans such as cut edge artifacts.",2019,"Philipp Seeböck,J. Orlando,T. Schlegl,S. Waldstein,H. Bogunović,S. Klimscha,G. Langs,U. Schmidt-Erfurth","Computer Science,Mathematics,Engineering,Medicine",103,47
73516151,f‐AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks,,2019,"T. Schlegl,Philipp Seeböck,S. Waldstein,G. Langs,U. Schmidt-Erfurth","Medicine,Computer Science",778,45
84186723,OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations,"We present a novel model called OCGAN for the classical problem of one-class novelty detection, where, given a set of examples from a particular class, the goal is to determine if a query example is from the same class. Our solution is based on learning latent representations of in-class examples using a de-noising auto-encoder network. The key contribution of our work is our proposal to explicitly constrain the latent space to exclusively represent the given class. In order to accomplish this goal, firstly, we force the latent space to have bounded support by introducing a tanh activation in the encoder's output layer. Secondly, using a discriminator in the latent space that is trained adversarially, we ensure that encoded representations of in-class examples resemble uniform random samples drawn from the same bounded space. Thirdly, using a second adversarial discriminator in the input space, we ensure all randomly drawn latent samples generate examples that look real. Finally, we introduce a gradient-descent based sampling technique that explores points in the latent space that generate potential out-of-class examples, which are fed back to the network to further train it to generate in-class examples from those points. The effectiveness of the proposed method is measured across four publicly available datasets using two one-class novelty detection protocols where we achieve state-of-the-art results.",2019,"Pramuditha Perera,Ramesh Nallapati,Bing Xiang",Computer Science,415,30
70349920,Deep Transfer Learning for Multiple Class Novelty Detection,"We propose a transfer learning-based solution for the problem of multiple class novelty detection. In particular, we propose an end-to-end deep-learning based approach in which we investigate how the knowledge contained in an external, out-of-distributional dataset can be used to improve the performance of a deep network for visual novelty detection. Our solution differs from the standard deep classification networks on two accounts. First, we use a novel loss function, membership loss, in addition to the classical cross-entropy loss for training networks. Secondly, we use the knowledge from the external dataset more effectively to learn globally negative filters, filters that respond to generic objects outside the known class set. We show that thresholding the maximal activation of the proposed network can be used to identify novel objects effectively. Extensive experiments on four publicly available novelty detection datasets show that the proposed method achieves significant improvements over the state-of-the-art methods.",2019,"Pramuditha Perera,Vishal M. Patel",Computer Science,85,30
53734379,Are pre-trained CNNs good feature extractors for anomaly detection in surveillance videos?,"Recently, several techniques have been explored to detect unusual behaviour in surveillance videos. Nevertheless, few studies leverage features from pre-trained CNNs and none of then present a comparison of features generate by different models. Motivated by this gap, we compare features extracted by four state-of-the-art image classification networks as a way of describing patches from security video frames. We carry out experiments on the Ped1 and Ped2 datasets and analyze the usage of different feature normalization techniques. Our results indicate that choosing the appropriate normalization is crucial to improve the anomaly detection performance when working with CNN features. Also, in the Ped2 dataset our approach was able to obtain results comparable to the ones of several state-of-the-art methods. Lastly, as our method only considers the appearance of each frame, we believe that it can be combined with approaches that focus on motion patterns to further improve performance.",2018,"T. S. Nazaré,R. Mello,M. Ponti",Computer Science,39,37
51914939,Informed Democracy: Voting-based Novelty Detection for Action Recognition,"Novelty detection is crucial for real-life applications. While it is common in activity recognition to assume a closed-set setting, i.e. test samples are always of training categories, this assumption is impractical in a real-world scenario. Test samples can be of various categories including those never seen before during training. Thus, being able to know what we know and what we do not know is decisive for the model to avoid what can be catastrophic consequences. We present in this work a novel approach for identifying samples of activity classes that are not previously seen by the classifier. Our model employs a voting-based scheme that leverages the estimated uncertainty of the individual classifiers in their predictions to measure the novelty of a new input sample. Furthermore, the voting is privileged to a subset of informed classifiers that can best estimate whether a sample is novel or not when it is classified to a certain known category. In a thorough evaluation on UCF-101 and HMDB-51, we show that our model consistently outperforms state-of-the-art in novelty detection. Additionally, by combining our model with off-the-shelf zero-shot learning (ZSL) approaches, our model leads to a significant improvement in action classification accuracy for the generalized ZSL setting.",2018,"Alina Roitberg,Ziad Al-Halah,R. Stiefelhagen",Computer Science,27,47
53046534,Do Deep Generative Models Know What They Don't Know?,"A neural network deployed in the wild may be asked to make predictions for inputs that were drawn from a different distribution than that of the training data. A plethora of work has demonstrated that it is easy to find or synthesize inputs for which a neural network is highly confident yet wrong. Generative models are widely viewed to be robust to such mistaken confidence as modeling the density of the input features can be used to detect novel, out-of-distribution inputs. In this paper we challenge this assumption. We find that the density learned by flow-based models, VAEs, and PixelCNNs cannot distinguish images of common objects such as dogs, trucks, and horses (i.e. CIFAR-10) from those of house numbers (i.e. SVHN), assigning a higher likelihood to the latter when the model is trained on the former. Moreover, we find evidence of this phenomenon when pairing several popular image data sets: FashionMNIST vs MNIST, CelebA vs SVHN, ImageNet vs CIFAR-10 / CIFAR-100 / SVHN. To investigate this curious behavior, we focus analysis on flow-based generative models in particular since they are trained and evaluated via the exact marginal likelihood. We find such behavior persists even when we restrict the flows to constant-volume transformations. These transformations admit some theoretical analysis, and we show that the difference in likelihoods can be explained by the location and variances of the data and the model curvature. Our results caution against using the density estimates from deep generative models to identify inputs similar to the training distribution until their behavior for out-of-distribution inputs is better understood.",2018,"Eric T. Nalisnick,Akihiro Matsukawa,Y. Teh,Dilan Görür,Balaji Lakshminarayanan","Computer Science,Mathematics",635,39
213077361,Anomaly Detection Based on Unsupervised Disentangled Representation Learning in Combination with Manifold Learning,"Identifying anomalous samples from highly complex and unstructured data is a crucial but challenging task in a variety of intelligent systems. In this paper, we present a novel deep anomaly detection framework named AnoDM (standing for Anomaly detection based on unsupervised Disentangled representation learning and Manifold learning). The disentanglement learning is currently implemented by β-VAE for automatically discovering interpretable factorized latent representations in a completely unsupervised manner. The manifold learning is realized by t-SNE for projecting the latent representations to a 2D map. We define a new anomaly score function by combining β-VAE’s reconstruction error in the raw feature space and local density estimation in the t-SNE space. AnoDM was evaluated on both image and time-series data and achieved better results than models that use just one of the two measures and other deep learning methods.",2020,"Xiaoyan Li,I. Kiringa,T. Yeap,Xiaodan Zhu,Yifeng Li",Computer Science,5,45
53694083,Image Anomaly Detection with Generative Adversarial Networks,,2018,"Lucas Deecke,Robert A. Vandermeulen,Lukas Ruff,S. Mandt,M. Kloft",Computer Science,182,52
49746491,Are generative deep models for novelty detection truly better?,"Many deep models have been recently proposed for anomaly detection. This paper presents comparison of selected generative deep models and classical anomaly detection methods on an extensive number of non--image benchmark datasets. We provide statistical comparison of the selected models, in many configurations, architectures and hyperparamaters. We arrive to conclusion that performance of the generative models is determined by the process of selection of their hyperparameters. Specifically, performance of the deep generative models deteriorates with decreasing amount of anomalous samples used in hyperparameter selection. In practical scenarios of anomaly detection, none of the deep generative models systematically outperforms the kNN.",2018,"V. Škvára,T. Pevný,V. Šmídl","Computer Science,Mathematics",36,24
49312162,Deep One-Class Classification,"Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objec-tive. In this paper we introduce a new anomaly detection method—Deep Support Vector Data Description—, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GT-SRB stop signs.",2018,"Lukas Ruff,Nico Görnitz,Lucas Deecke,Shoaib Ahmed Siddiqui,Robert A. Vandermeulen,Alexander Binder,Emmanuel Müller,M. Kloft",Computer Science,1418,58
52983782,Exponential Family Restricted Boltzmann Machines and Annealed Importance Sampling,"In this paper, we investigate restricted Boltzmann machines (RBMs) from the exponential family perspective, en-abling the visible units to follow any suitable distributions from the exponential family. We derive a unified view to compute the free energy function for exponential family RBMs (exp-RBMs). Based on that, annealed important sampling (AIS) is generalized to the entire exponential family, allowing for estimating the log-partition function and log-likelihood. Our experiments on a document processing task demonstrate that the generalized free energy functions and AIS estimation perform well in helping capture useful knowledge from the data; the estimated log-partition functions are stable. The appropriate instances of exp-RBMs can generate novel and meaningful samples and can be applied to classification tasks.",2018,"Yifeng Li,Xiao-Dan Zhu",Computer Science,10,18
44108048,Deep Anomaly Detection Using Geometric Transformations,"We consider the problem of anomaly detection in images, and present a new detection technique. Given a sample of images, all known to belong to a ""normal"" class (e.g., dogs), we show how to train a deep neural model that can detect out-of-distribution images (i.e., non-dog objects). The main idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our algorithm improves state-of-the-art methods by a wide margin.",2018,"I. Golan,Ran El-Yaniv","Computer Science,Mathematics",512,45
4588148,Investigating Capsule Networks with Dynamic Routing for Text Classification,"In this study, we explore capsule networks with dynamic routing for text classification. We propose three strategies to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain “background” information or have not been successfully trained. A series of experiments are conducted with capsule networks on six text classification benchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets, which shows the effectiveness of capsule networks for text classification. We additionally show that capsule networks exhibit significant improvement when transfer single-label to multi-label text classification over strong baseline methods. To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for text modeling.",2018,"Wei Zhao,Jianbo Ye,Min Yang,Zeyang Lei,Suofei Zhang,Zhou Zhao",Computer Science,349,30
65203110,Matrix capsules with EM routing,,2018,"Geoffrey E. Hinton,S. Sabour,Nicholas Frosst",Computer Science,931,13
3603485,Dynamic Routing Between Capsules,"A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.",2017,"S. Sabour,Nicholas Frosst,Geoffrey E. Hinton",Computer Science,3949,21
702279,Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms,"We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at this https URL",2017,"Han Xiao,Kashif Rasul,Roland Vollgraf","Computer Science,Mathematics",6591,6
86408273,User allocation‐aware edge cloud placement in mobile edge computing,"Mobile edge computing is emerging as a novel ubiquitous computing platform to overcome the limit resources of mobile devices and bandwidth bottleneck of the core network in mobile cloud computing. In mobile edge computing, it is a significant issue for cost reduction and QoS improvement to place edge clouds at the edge network as a small data center to serve users. In this paper, we study the edge cloud placement problem, which is to place the edge clouds at the candidate locations and allocate the mobile users to the edge clouds. Specifically, we formulate it as a multiobjective optimization problem with objective to balance the workload between edge clouds and minimize the service communication delay of mobile users. To this end, we propose an approximate approach that adopted the K‐means and mixed‐integer quadratic programming. Furthermore, we conduct experiments based on Shanghai Telecom's base station data set and compare our approach with other representative approaches. The results show that our approach performs better to some extent in terms of workload balance and communication delay and validate the proposed approach.",2020,"Yan Guo,Shangguang Wang,Ao Zhou,Jinliang Xu,Jie Yuan,Ching-Hsien Hsu",Computer Science,101,25
156055438,A QoS-aware virtual machine scheduling method for energy conservation in cloud-based cyber-physical systems,,2019,"Lianyong Qi,Yi Chen,Yuan Yuan,Shucun Fu,Xuyun Zhang,Xiaolong Xu",Computer Science,185,38
70290610,Privacy Enhancing Technologies in the Internet of Things: Perspectives and Challenges,"Internet of Things (IoT) devices have brought much efficiency and convenience to our daily life. However, the devices may collect a myriad of data from people without their consent. Controlling the large amount of data generated from the devices from being misused is critical to mitigate privacy risks. Therefore, privacy protection on personal data has become an important factor in the development of the IoT. Historically, privacy enhancing technologies (PETs) can effectively enhance the privacy and protect users’ personally identifiable information. To date, many researchers have stressed the importance of PETs and proposed solutions relevant to different application fields of the IoT. However, to the best of our knowledge, none of the research has analyzed the PETs in IoT from the aspects of privacy threat issues and privacy legislation. As a result, this paper surveys on the solutions of PETs in the field of IoT, which has filtered down from the large number of published academic papers to the 120 primary studies published between 2014 and 2017. After collecting the papers, we categorized them based on the functions and the coverage of privacy protection, and analyzed them from different aspects, ranging from high-level principles of general data protection regulations and ISO/IEC 29100:2011 requirements to the actual resolution of privacy threats in IoT. Thus, we aim to identify the current state of development of the PETs in various fields and examine whether the existing PETs comply with the latest legal principles and privacy standards and reduce the threats to privacy. Finally, recommendations for future research are given based on the results.",2019,"Shi-Cho Cha,T. Hsu,Yang Xiang,Kuo-Hui Yeh",Computer Science,61,200
148572355,IoT Big Data Security and Privacy Versus Innovation,"In this paper, we address the conflict in the collection, use, and management of Big Data at the intersection of security and privacy requirements and the demand of innovative uses of the data. This problem is exaggerated in the context of the Internet of Things (IoT). We propose a three-part decomposition of the design space, in order to clarify requirements and constraints. To reach this final analysis, we begin by clarifying the challenges in the design space: 1) there is a little agreement on what is meant by IoT, and in particular the security and privacy implications of different definitions; 2) we then consider the requirement and constraints on the Big Data that result from various IoT system designs; and 3) in parallel, we examine the intricacies of the demand for innovation from both the legal and economic perspectives. In this context, we then can decompose the set of drivers and objectives for security/privacy of data as well as innovation into: 1) the regulatory and social policy context; 2) economic and business context; and 3) technology and design context. By identifying these distinct objectives for the design of IoT Big Data management, we propose that more effective design and control is possible at the intersection of these forces, through an iterative process of review and redesign.",2019,K. Sollins,Computer Science,54,25
67150864,Lightweight and Privacy-Preserving Two-Factor Authentication Scheme for IoT Devices,"Device authentication is an essential security feature for Internet of Things (IoT). Many IoT devices are deployed in the open and public places, which makes them vulnerable to physical and cloning attacks. Therefore, any authentication protocol designed for IoT devices should be robust even in cases when an IoT device is captured by an adversary. Moreover, many of the IoT devices have limited storage and computational capabilities. Hence, it is desirable that the security solutions for IoT devices should be computationally efficient. To address all these requirements, in this paper, we present a lightweight and privacy-preserving two-factor authentication scheme for IoT devices, where physically uncloneable functions have been considered as one of the authentication factors. Security and performance analysis show that our proposed scheme is not only robust against several attacks, but also very efficient in terms of computational efficiently.",2019,"P. Gope,B. Sikdar",Computer Science,224,24
76658511,Machine Learning Based Resource Allocation of Cloud Computing in Auction,"Resource allocation in auctions is a challenging problem for cloud computing. However, the resource allocation problem is NP-hard and cannot be solved in polynomial time. The existing studies mainly use approximate algorithms such as PTAS or heuristic algorithms to determine a feasible solution; however, these algorithms have the disadvantages of low computational efficiency or low allocate accuracy. In this paper, we use the classification of machine learning to model and analyze the multi-dimensional cloud resource allocation problem and propose two resource allocation prediction algorithms based on linear and logistic regressions. By learning a small-scale training set, the prediction model can guarantee that the social welfare, allocation accuracy, and resource utilization in the feasible solution are very close to those of the optimal allocation solution. The experimental results show that the proposed scheme has good effect on resource allocation in cloud computing.",2018,"Jixian Zhang,Ning Xie,Xuejie Zhang,Kun Yue,Weidong Li,K. Deepesh",Computer Science,65,15
69456575,Towards Green Service Composition Approach in the Cloud,"With the increasing popularity of cloud computing, many notable quality of service (QoS)-aware service composition approaches have been incorporated in service-oriented cloud computing systems. However, these approaches are implemented without considering the energy and network resource consumption of the composite services. The increases in energy and network resource consumption resulting from these compositions can incur a high cost in data centers. In this paper, the trade-off among QoS performance, energy consumption, and network resource consumption in a service composition process is first analyzed. Then, a green service composition approach is proposed. It gives priority to those composite services that are hosted on the same virtual machine, physical server, or edge switch with end-to-end QoS guarantee. It fulfills the green service composition optimization by minimizing the energy and network resource consumption on physical servers and switches in cloud data centers. Experimental results indicate that, with comparisons to other approaches, our approach saves 20-50 percent of energy consumption and 10-50 percent of network resource consumption.",2018,"Shangguang Wang,Ao Zhou,Ruo Bao,Wu Chou,S. Yau",Computer Science,36,57
52096236,Privacy in Internet of Things: From Principles to Technologies,"Ubiquitous deployment of low-cost smart devices and widespread use of high-speed wireless networks have led to the rapid development of the Internet of Things (IoT). IoT embraces countless physical objects that have not been involved in the traditional Internet and enables their interaction and cooperation to provide a wide range of IoT applications. Many services in the IoT may require a comprehensive understanding and analysis of data collected through a large number of physical devices that challenges both personal information privacy and the development of IoT. Information privacy in IoT is a broad and complex concept as its understanding and perception differ among individuals and its enforcement requires efforts from both legislation as well as technologies. In this paper, we review the state-of-the-art principles of privacy laws, the architectures for IoT and the representative privacy enhancing technologies (PETs). We analyze how legal principles can be supported through a careful implementation of PETs at various layers of a layered IoT architecture model to meet the privacy requirements of the individuals interacting with IoT systems. We demonstrate how privacy legislation maps to privacy principles which in turn drives the design of necessary PETs to be employed in the IoT architecture stack.",2018,"C. Li,Balaji Palanisamy",Computer Science,73,180
139905737,Research on trust model in container-based cloud service,"Container virtual technology aims to provide program independence and resource sharing. The container enables flexible cloud service. Compared with traditional virtualization, traditional virtual machines have difficulty in resource and expense requirements. The container technology has the advantages of smaller size, faster migration, lower resource overhead, and higher utilization. Within container-based cloud environment, services can adopt multi-target nodes. This paper reports research results to improve the traditional trust model with consideration of cooperation effects. Cooperation trust means that in a container-based cloud environment, services can be divided into multiple containers for different container nodes. When multiple target nodes work for one service at the same time, these nodes are in a cooperation state.  When multi-target nodes cooperate to complete the service, the target nodes evaluate each other. The calculation of cooperation trust evaluation is used to update the degree of comprehensive trust. Experimental simulation results show that the cooperation trust evaluation can help solving the trust problem in the container-based cloud environment and can improve the success rate of following cooperation.",2018,"X. Xie,Tianwei Yuan,Xiao Zhou,Xiaochun Cheng",Computer Science,44,35
49566175,Cooperative Content Caching in 5G Networks with Mobile Edge Computing,"Along with modern wireless networks being content-centric, the demand for rich multimedia services has been growing at a tremendous pace, which brings significant challenges to mobile networks in terms of the need for massive content delivery. Edge caching has emerged as a promising approach to alleviate the heavy burden on data transmission through caching and forwarding contents at the edge of networks. However, existing studies always treat storage and computing resources separately, and neglect the mobility characteristic of both the content caching nodes and end users. Driven by these issues, in this work, we propose a new cooperative edge caching architecture for 5G networks, where mobile edge computing resources are utilized for enhancing edge caching capability. In the architecture, we focus on mobility-aware hierarchical caching, where smart vehicles are taken as collaborative caching agents for sharing content cache tasks with base stations. To further utilize the caching resource of smart vehicles, we introduce a new vehicular caching cloud concept, and propose a vehicle-aided edge caching scheme, where the caching and computing resources at the wireless network edge are jointly scheduled. Numerical results indicate that the proposed scheme minimizes content access latency and improves caching resource utilization.",2018,"Ke Zhang,S. Leng,Yejun He,Sabita Maharjan,Yan Zhang",Computer Science,182,15
201254794,Stimulus-driven and concept-driven analysis for image caption generation,,2020,"Songtao Ding,Shiru Qu,Yuling Xi,Shaohua Wan",Computer Science,172,47
208099485,Cognitive computing and wireless communications on the edge for healthcare service robots,,2020,"Shaohua Wan,Zonghua Gu,Q. Ni",Computer Science,172,56
199020231,Classifying transportation mode and speed from trajectory data via deep multi-scale learning,,2019,"Rui Zhang,Peng Xie,Chen Wang,Gaoyang Liu,Shaohua Wan",Computer Science,85,37
145937250,Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition,"Human actions are often captured by multiple cameras (or sensors) to overcome the significant variations in viewpoints, background clutter, object speed, and motion patterns in video surveillance, and action recognition systems often benefit from fusing multiple types of cameras (sensors). Therefore, adaptive fusion of the information from multiple domains is mandatory for multiview human action recognition. Two widely applied fusion schemes are feature-level fusion and score-level fusion. We point out that limitations still exist and there is tremendous room for improvement, including the separate computation of feature fusion and action recognition, or the fixed weights for each action and each camera. However, previous fusion methods cannot accomplish them. In this paper, inspired by nature, the above limitations are addressed for multiview action recognition by developing a novel adaptive fusion and category-level dictionary learning model (abbreviated to AFCDL). It can jointly learn the adaptive weight for each camera and optimize the reconstruction of samples toward the action recognition task. To induce the dictionary learning and the reconstruction of query set (or test samples), the induced set for each category is built, and the corresponding induced regularization term is designed for the objective function. Extensive experiments on four public multiview action benchmarks show that AFCDL can significantly outperforms the state-of-the-art methods with 3% to 10% improvement in recognition accuracy.",2019,"Zan Gao,Haizhen Xuan,Hua Zhang,Shaohua Wan,Kim-Kwang Raymond Choo",Computer Science,140,65
183593003,An Optimization and Auction-Based Incentive Mechanism to Maximize Social Welfare for Mobile Crowdsourcing,"Mobile crowdsourcing is an emerging crowdsourcing paradigm, which generates large-scale sensing tasks and sensing data. One of the major issues in mobile crowdsourcing is how to maximize social welfare through selecting appropriate sensing tasks for crowd workers and selecting appropriate workers for sensing tasks such that it can improve the effectiveness and efficiency of mobile crowdsourcing. This paper proposes an incentive mechanism to maximize social welfare for mobile crowdsourcing and, respectively, investigates worker-centric task selection and platform-centric worker selection. This paper applies an optimization algorithm in task selection for mobile crowdsourcing systems. A discrete particle swarm optimization (DPSO) algorithm for worker-centric task selection is designed to maximize the utilities of workers. In addition, a platform-centric worker selection method, which integrates multiattribute auction and two-stage auction, is proposed to maximize the utility of the platform. The performance of the proposed incentive mechanism is evaluated through experiments. The experimental results show that the proposed incentive mechanism can improve the efficiency and truthfulness of mobile crowdsourcing effectively.",2019,"Yingjie Wang,Zhipeng Cai,Zhi-hui Zhan,Yue-jiao Gong,Xiangrong Tong",Computer Science,95,57
67791217,Time-aware distributed service recommendation with privacy-preservation,,2019,"Lianyong Qi,Ruili Wang,Chunhua Hu,Shancang Li,Qiang He,Xiaolong Xu",Computer Science,135,51
59222332,Domain-wise approaches for updating approximations with multi-dimensional variation of ordered information systems,,2019,"Shu Wang,Tianrui Li,Chuan Luo,Hongmei Chen,H. Fujita",Computer Science,31,47
73467781,Task Allocation Model Based on Worker Friend Relationship for Mobile Crowdsourcing,"With the rapid development of mobile devices, mobile crowdsourcing has become an important research focus. According to the task allocation, scholars have proposed many methods. However, few works discuss combining social networks and mobile crowdsourcing. To maximize the utilities of mobile crowdsourcing system, this paper proposes a task allocation model considering the attributes of social networks for mobile crowdsourcing system. Starting from the homogeneity of human beings, the relationship between friends in social networks is applied to mobile crowdsourcing system. A task allocation algorithm based on the friend relationships is proposed. The GeoHash coding mechanism is adopted in the process of calculating the strength of worker relationship, which effectively protects the location privacy of workers. Utilizing synthetic dataset and the real-world Yelp dataset, the performance of the proposed task allocation model was evaluated. Through comparison experiments, the effectiveness and applicability of the proposed allocation mechanism were verified.",2019,"Bingxu Zhao,Yingjie Wang,Yingshu Li,Yang Gao,Xiangrong Tong","Computer Science,Medicine",25,40
53711162,Updating three-way decisions in incomplete multi-scale information systems,,2019,"Chuan Luo,Tianrui Li,Yanyong Huang,H. Fujita",Computer Science,123,50
49329806,Multi-Dimensional QoS Prediction for Service Recommendations,"Advances in mobile Internet technology have enabled the clients of Web services to be able to keep their service sessions alive while they are on the move. Since the services consumed by a mobile client may be different over time due to client location changes, a multi-dimensional spatiotemporal model is necessary for analyzing the service consumption relations. Moreover, competitive Web service recommenders for the mobile clients must be able to predict unknown quality-of-service (QoS) values well by taking into account the target client's service requesting time and location, e.g., performing the prediction via a set of multi-dimensional QoS measures. Most contemporary QoS prediction methods exploit the QoS characteristics for one specific dimension, e.g., time or location, and do not exploit the structural relationships among the multi-dimensional QoS data. This paper proposes an integrated QoS prediction approach which unifies the modeling of multi-dimensional QoS data via multi-linear-algebra based concepts of tensor and enables efficient Web service recommendation for mobile clients via tensor decomposition and reconstruction optimization algorithms. In light of the unavailability of measured multi-dimensional QoS datasets in the public domain, this paper also presents a transformational approach to creating a credible multi-dimensional QoS dataset from a measured taxi usage dataset which contains high dimensional time and space information. Comparative experimental evaluation results show that the proposed QoS prediction approach can result in much better accuracy in recommending Web services than several other representative ones.",2019,"Shangguang Wang,You Ma,Bo Cheng,Fangchun Yang,Rong N. Chang",Computer Science,80,35
47016965,A Tunable Measure for Information Leakage,"A tunable measure for information leakage called maximal a-leakage is introduced. This measure quantifies the maximal gain of an adversary in refining a tilted version of its prior belief of any (potentially random) function of a dataset conditioning on a disclosed dataset. The choice of $\alpha$ determines the specific adversarial action ranging from refining a belief for $\alpha=1$ to guessing the best posterior for $\alpha=\infty$, and for these extremal values this measure simplifies to mutual information (MI) and maximal leakage (MaxL), respectively. For all other $\alpha$ this measure is shown to be the Arimoto channel capacity. Several properties of this measure are proven including: (i) quasi-convexity in the mapping between the original and disclosed datasets; (ii) data processing inequalities; and (iii) a composition property. A full version of this paper is in [1].",2018,"Jiachun Liao,O. Kosut,L. Sankar,F. Calmon","Computer Science,Mathematics",49,15
1217359,Optimal Utility-Privacy Trade-off with the Total Variation Distance as the Privacy Measure,"The total variation distance is proposed as a privacy measure in an information disclosure scenario when the goal is to reveal some information about available data in return of utility, while retaining the privacy of certain sensitive latent variables from the legitimate receiver. The total variation distance is introduced as a measure of privacy-leakage by showing that: i) it satisfies the post-processing and linkage inequalities, which makes it consistent with an intuitive notion of a privacy measure; ii) the optimal utility-privacy trade-off can be solved through a standard linear program when total variation distance is employed as the privacy measure; iii) it provides a bound on the privacy-leakage measured by mutual information, maximal leakage, or the improvement in an inference attack with a bounded cost function.",2018,"Borzoo Rassouli,Deniz Gündüz","Computer Science,Mathematics",72,29
9672301,Privacy-Utility Tradeoffs under Constrained Data Release Mechanisms,"Privacy-preserving data release mechanisms aim to simultaneously minimize information-leakage with respect to sensitive data and distortion with respect to useful data. Dependencies between sensitive and useful data results in a privacy-utility tradeoff that has strong connections to generalized rate-distortion problems. In this work, we study how the optimal privacy-utility tradeoff region is affected by constraints on the data that is directly available as input to the release mechanism. In particular, we consider the availability of only sensitive data, only useful data, and both (full data). We show that a general hierarchy holds: the tradeoff region given only the sensitive data is no larger than the region given only the useful data, which in turn is clearly no larger than the region given both sensitive and useful data. In addition, we determine conditions under which the tradeoff region given only the useful data coincides with that given full data. These are based on the common information between the sensitive and useful data. We establish these results for general families of privacy and utility measures that satisfy certain natural properties required of any reasonable measure of privacy or utility. We also uncover a new, subtler aspect of the data processing inequality for general non-symmetric privacy measures and discuss its operational relevance and implications. Finally, we derive exact closed-analytic-form expressions for the privacy-utility tradeoffs for symmetrically dependent sensitive and useful data under mutual information and Hamming distortion as the respective privacy and utility measures.",2017,"Ye Wang,Y. O. Basciftci,P. Ishwar","Computer Science,Mathematics",30,25
5769,Estimation Efficiency Under Privacy Constraints,"We investigate the problem of estimating a random variable <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> under a privacy constraint dictated by another correlated random variable <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula>. When <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> are discrete, we express the underlying privacy-utility tradeoff in terms of the privacy-constrained guessing probability <inline-formula> <tex-math notation=""LaTeX"">${\mathcal {h}}(P_{XY}, \varepsilon)$ </tex-math></inline-formula>, and the maximum probability <inline-formula> <tex-math notation=""LaTeX"">$\mathsf {P}_{\mathsf {c}}(Y|Z)$ </tex-math></inline-formula> of correctly guessing <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> given an auxiliary random variable <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula>, where the maximization is taken over all <inline-formula> <tex-math notation=""LaTeX"">$P_{Z|Y}$ </tex-math></inline-formula> ensuring that <inline-formula> <tex-math notation=""LaTeX"">$\mathsf {P}_{\mathsf {c}}(X|Z)\leq \varepsilon $ </tex-math></inline-formula> for a given privacy threshold <inline-formula> <tex-math notation=""LaTeX"">$\varepsilon \geq 0$ </tex-math></inline-formula>. We prove that <inline-formula> <tex-math notation=""LaTeX"">${\mathcal {h}}(P_{XY}, \cdot)$ </tex-math></inline-formula> is concave and piecewise linear, which allows us to derive its expression in closed form for any <inline-formula> <tex-math notation=""LaTeX"">$\varepsilon $ </tex-math></inline-formula> when <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> are binary. In the non-binary case, we derive <inline-formula> <tex-math notation=""LaTeX"">${\mathcal {h}}(P_{XY}, \varepsilon)$ </tex-math></inline-formula> in the high-utility regime (i.e., for sufficiently large, but nontrivial, values of <inline-formula> <tex-math notation=""LaTeX"">$\varepsilon $ </tex-math></inline-formula>) under the assumption that <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula> have the same alphabets. We also analyze the privacy-constrained guessing probability for two scenarios in which <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula>, <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula>, and <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula> are binary vectors. When <inline-formula> <tex-math notation=""LaTeX"">$X$ </tex-math></inline-formula> and <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> are continuous random variables, we formulate the corresponding privacy-utility tradeoff in terms of <inline-formula> <tex-math notation=""LaTeX"">${\mathsf {sENSR}}(P_{XY}, \varepsilon)$ </tex-math></inline-formula>, the smallest normalized minimum mean squared-error (mmse) incurred in estimating <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> from a Gaussian perturbation <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula>. Here, the minimization is taken over a family of Gaussian perturbations <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula> for which the mmse of <inline-formula> <tex-math notation=""LaTeX"">$f(X)$ </tex-math></inline-formula> given <inline-formula> <tex-math notation=""LaTeX"">$Z$ </tex-math></inline-formula> is within a factor <inline-formula> <tex-math notation=""LaTeX"">$1- \varepsilon $ </tex-math></inline-formula> from the variance of <inline-formula> <tex-math notation=""LaTeX"">$f(X)$ </tex-math></inline-formula> for any non-constant real-valued function <inline-formula> <tex-math notation=""LaTeX"">$f$ </tex-math></inline-formula>. We derive tight upper and lower bounds for <inline-formula> <tex-math notation=""LaTeX"">${\mathsf {sENSR}}$ </tex-math></inline-formula> when <inline-formula> <tex-math notation=""LaTeX"">$Y$ </tex-math></inline-formula> is Gaussian. For general absolutely continuous random variables, we obtain a tight lower bound for <inline-formula> <tex-math notation=""LaTeX"">${\mathsf {sENSR}}(P_{XY}, \varepsilon)$ </tex-math></inline-formula> in the high privacy regime, i.e., for small <inline-formula> <tex-math notation=""LaTeX"">$\varepsilon $ </tex-math></inline-formula>.",2017,"S. Asoodeh,Mario Díaz,F. Alajaji,T. Linder","Computer Science,Mathematics",69,44
28822100,Guessing with limited memory,"Suppose that we wish to guess the realization x of a discrete random variable X taking values in a finite set, by asking sequential questions of the form “Is X is equal to x?” exhausting the elements of X until the answer is Yes. [1, 2]. If the distribution of X is known to the guesser, and the guesser has memory of his previous has memory of his previous queries then the best strategy is to guess in decreasing order of probabilities. In this paper, we consider the problem of a memoryless guesser, namely, each new guess is independent of the previous guesses. We consider also the scenario of a guesser with a bounded number of guesses. For both cases we derive the optimal guessing strategies, and show new connections to Rényi entropy.",2017,"Wasim Huleihel,Salman Salamatian,M. Médard","Mathematics,Computer Science",21,15
129999,Measuring Real-World Accuracies and Biases in Modeling Password Guessability,"Parameterized password guessability--how many guesses a particular cracking algorithm with particular training data would take to guess a password--has become a common metric of password security. Unlike statistical metrics, it aims to model real-world attackers and to provide per-password strength estimates. We investigate how cracking approaches often used by researchers compare to real-world cracking by professionals, as well as how the choice of approach biases research conclusions. 
 
We find that semi-automated cracking by professionals outperforms popular fully automated approaches, but can be approximated by combining multiple such approaches. These approaches are only effective, however, with careful configuration and tuning; in commonly used default configurations, they underestimate the real-world guessability of passwords. We find that analyses of large password sets are often robust to the algorithm used for guessing as long as it is configured effectively. However, cracking algorithms differ systematically in their effectiveness guessing passwords with certain common features (e.g., character substitutions). This has important implications for analyzing the security of specific password characteristics or of individual passwords (e.g., in a password meter or security audit). Our results highlight the danger of relying only on a single cracking algorithm as a measure of password strength and constitute the first scientific evidence that automated guessing can often approximate guessing by professionals.",2015,"Blase Ur,Sean M. Segreti,Lujo Bauer,Nicolas Christin,L. Cranor,Saranga Komanduri,Darya Kurilova,Michelle L. Mazurek,William Melicher,Richard Shay",Computer Science,166,66
2109423,"Quantifying computational security subject to source constraints, guesswork and inscrutability","Guesswork forms the mathematical framework for quantifying computational security subject to brute-force determination by query. In this paper, we consider guesswork subject to a per-symbol Shannon entropy budget. We introduce inscrutability rate as the asymptotic rate of increase in the exponential number of guesses required of an adversary to determine one or more secret strings. We prove that the inscrutability rate of any string-source supported on a finite alphabet χ, if it exists, lies between the per-symbol Shannon entropy constraint and log |χ|. We further prove that the inscrutability rate of any finite-order Markov string-source with hidden statistics remains the same as the unhidden case, i.e., the asymptotic value of hiding the statistics per each symbol is vanishing. On the other hand, we show that there exists a string-source that achieves the upper limit on the inscrutability rate, i.e., log |χ|, under the same Shannon entropy budget.",2015,"Ahmad Beirami,Robert Calderbank,K. Duffy,M. Médard","Mathematics,Computer Science",22,20
9649679,Multi-User Guesswork and Brute Force Security,"The guesswork problem was originally motivated by a desire to quantify computational security for single user systems. Leveraging recent results from its analysis, we extend the remit and utility of the framework to the quantification of the computational security of multi-user systems. In particular, assume that V users independently select strings stochastically from a finite, but potentially large, list. An inquisitor who does not know which strings have been selected wishes to identify U of them. The inquisitor knows the selection probabilities of each user and is equipped with a method that enables the testing of each (user, string) pair, one at a time, for whether that string had been selected by that user. Here, we establish that, unless U=V, there is no general strategy that minimizes the distribution of the number of guesses, but in the asymptote as the strings become long we prove the following: by construction, there is an asymptotically optimal class of strategies; the number of guesses required in an asymptotically optimal strategy satisfies a large deviation principle with a rate function, which is not necessarily convex, that can be determined from the rate functions of optimally guessing individual users' strings; if all users' selection statistics are identical, the exponential growth rate of the average guesswork as the string-length increases is determined by the specific Rényi entropy of the string-source with parameter (V-U+1)/(V-U+2), generalizing the known V=U=1 case; and that the Shannon entropy of the source is a lower bound on the average guesswork growth rate for all U and V, thus providing a bound on computational security for multi-user systems. Examples are presented to illustrate these results and their ramifications for systems design.",2014,"Mark M. Christiansen,K. Duffy,F. Calmon,M. Médard","Computer Science,Mathematics",30,33
7619208,From the Information Bottleneck to the Privacy Funnel,"We focus on the privacy-utility trade-off encountered by users who wish to disclose some information to an analyst, that is correlated with their private data, in the hope of receiving some utility. We rely on a general privacy statistical inference framework, under which data is transformed before it is disclosed, according to a probabilistic privacy mapping. We show that when the log-loss is introduced in this framework in both the privacy metric and the distortion metric, the privacy leakage and the utility constraint can be reduced to the mutual information between private data and disclosed data, and between non-private data and disclosed data respectively. We justify the relevance and generality of the privacy metric under the log-loss by proving that the inference threat under any bounded cost function can be upperbounded by an explicit function of the mutual information between private data and disclosed data. We then show that the privacy-utility tradeoff under the log-loss can be cast as the non-convex Privacy Funnel optimization, and we leverage its connection to the Information Bottleneck, to provide a greedy algorithm that is locally optimal. We evaluate its performance on the US census dataset. Finally, we characterize the optimal privacy mapping for the Gaussian Privacy Funnel.",2014,"A. Makhdoumi,Salman Salamatian,N. Fawaz,M. Médard","Computer Science,Mathematics",173,24
3974233,Fast Homomorphic Evaluation of Deep Discretized Neural Networks,,2018,"F. Bourse,Michele Minelli,Matthias Minihold,Pascal Paillier",Computer Science,251,52
289366,Privacy-Preserving Deep Learning via Additively Homomorphic Encryption,"We present a privacy-preserving deep learning system in which many learning participants perform neural network-based deep learning over a combined dataset of all, without revealing the participants’ local data to a central server. To that end, we revisit the previous work by Shokri and Shmatikov (ACM CCS 2015) and show that, with their method, local data information may be leaked to an honest-but-curious server. We then fix that problem by building an enhanced system with the following properties: 1) no information is leaked to the server and 2) accuracy is kept intact, compared with that of the ordinary deep learning system also over the combined dataset. Our system bridges deep learning and cryptography: we utilize asynchronous stochastic gradient descent as applied to neural networks, in combination with additively homomorphic encryption. We show that our usage of encryption adds tolerable overhead to the ordinary deep learning system.",2018,"L. T. Phong,Yoshinori Aono,Takuya Hayashi,Lihua Wang,S. Moriai",Computer Science,858,34
58348058,Deep Learning Inferences with Hybrid Homomorphic Encryption,,2018,"A. Meehan,R. Ko,G. Holmes",Computer Science,4,0
4046474,Gazelle: A Low Latency Framework for Secure Neural Network Inference,"The growing popularity of cloud-based machine learning raises a natural question about the privacy guarantees that can be provided in such a setting. Our work tackles this problem in the context where a client wishes to classify private images using a convolutional neural network (CNN) trained by a server. Our goal is to build efficient protocols whereby the client can acquire the classification result without revealing their input to the server, while guaranteeing the privacy of the server's neural network. 
To this end, we design Gazelle, a scalable and low-latency system for secure neural network inference, using an intricate combination of homomorphic encryption and traditional two-party computation techniques (such as garbled circuits). Gazelle makes three contributions. First, we design the Gazelle homomorphic encryption library which provides fast algorithms for basic homomorphic operations such as SIMD (single instruction multiple data) addition, SIMD multiplication and ciphertext permutation. Second, we implement the Gazelle homomorphic linear algebra kernels which map neural network layers to optimized homomorphic matrix-vector multiplication and convolution routines. Third, we design optimized encryption switching protocols which seamlessly convert between homomorphic and garbled circuit encodings to enable implementation of complete neural network inference. 
We evaluate our protocols on benchmark neural networks trained on the MNIST and CIFAR-10 datasets and show that Gazelle outperforms the best existing systems such as MiniONN (ACM CCS 2017) by 20 times and Chameleon (Crypto Eprint 2017/1164) by 30 times in online runtime. Similarly when compared with fully homomorphic approaches like CryptoNets (ICML 2016) we demonstrate three orders of magnitude faster online run-time.",2018,"C. Juvekar,V. Vaikuntanathan,A. Chandrakasan",Computer Science,698,49
3638420,Chameleon: A Hybrid Secure Computation Framework for Machine Learning Applications,"We present Chameleon, a novel hybrid (mixed-protocol) framework for secure function evaluation (SFE) which enables two parties to jointly compute a function without disclosing their private inputs. Chameleon combines the best aspects of generic SFE protocols with the ones that are based upon additive secret sharing. In particular, the framework performs linear operations in the ring $\mathbbZ _2^l $ using additively secret shared values and nonlinear operations using Yao's Garbled Circuits or the Goldreich-Micali-Wigderson protocol. Chameleon departs from the common assumption of additive or linear secret sharing models where three or more parties need to communicate in the online phase: the framework allows two parties with private inputs to communicate in the online phase under the assumption of a third node generating correlated randomness in an offline phase. Almost all of the heavy cryptographic operations are precomputed in an offline phase which substantially reduces the communication overhead. Chameleon is both scalable and significantly more efficient than the ABY framework (NDSS'15) it is based on. Our framework supports signed fixed-point numbers. In particular, Chameleon's vector dot product of signed fixed-point numbers improves the efficiency of mining and classification of encrypted data for algorithms based upon heavy matrix multiplications. Our evaluation of Chameleon on a 5 layer convolutional deep neural network shows 133x and 4.2x faster executions than Microsoft CryptoNets (ICML'16) and MiniONN (CCS'17), respectively.",2018,"M. Riazi,Christian Weinert,Oleksandr Tkachenko,Ebrahim M. Songhori,T. Schneider,F. Koushanfar",Computer Science,394,94
26233593,Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption,"Consider two data providers, each maintaining private records of different feature sets about common entities. They aim to learn a linear model jointly in a federated setting, namely, data is local and a shared model is trained from locally computed updates. In contrast with most work on distributed learning, in this scenario (i) data is split vertically, i.e. by features, (ii) only one data provider knows the target variable and (iii) entities are not linked across the data providers. Hence, to the challenge of private learning, we add the potentially negative consequences of mistakes in entity resolution. Our contribution is twofold. First, we describe a three-party end-to-end solution in two phases ---privacy-preserving entity resolution and federated logistic regression over messages encrypted with an additively homomorphic scheme---, secure against a honest-but-curious adversary. The system allows learning without either exposing data in the clear or sharing which entities the data providers have in common. Our implementation is as accurate as a naive non-private solution that brings all data in one place, and scales to problems with millions of entities with hundreds of features. Second, we provide what is to our knowledge the first formal analysis of the impact of entity resolution's mistakes on learning, with results on how optimal classifiers, empirical losses, margins and generalisation abilities are affected. Our results bring a clear and strong support for federated learning: under reasonable assumptions on the number and magnitude of entity resolution's mistakes, it can be extremely beneficial to carry out federated learning in the setting where each peer's data provides a significant uplift to the other.",2017,"Stephen Hardy,Wilko Henecka,Hamish Ivey-Law,R. Nock,Giorgio Patrini,Guillaume Smith,Brian Thorne",Computer Science,419,40
3617652,Oblivious Neural Network Predictions via MiniONN Transformations,"Machine learning models hosted in a cloud service are increasingly popular but risk privacy: clients sending prediction requests to the service need to disclose potentially sensitive information. In this paper, we explore the problem of privacy-preserving predictions: after each prediction, the server learns nothing about clients' input and clients learn nothing about the model. We present MiniONN, the first approach for transforming an existing neural network to an oblivious neural network supporting privacy-preserving predictions with reasonable efficiency. Unlike prior work, MiniONN requires no change to how models are trained. To this end, we design oblivious protocols for commonly used operations in neural network prediction models. We show that MiniONN outperforms existing work in terms of response latency and message sizes. We demonstrate the wide applicability of MiniONN by transforming several typical neural network models trained from standard datasets.",2017,"Jian Liu,Mika Juuti,Yao Lu,N. Asokan",Computer Science,577,62
4791068,Early Identification of Patients With Acute Decompensated Heart Failure.,,2017,"S. Blecker,D. Sontag,Leora I. Horwitz,G. Kuperman,Hannah Park,A. Reyentovich,S. Katz",Medicine,14,15
2519922,DeepSecure: Scalable Provably-Secure Deep Learning,"This paper presents DeepSecure, the an scalable and provably secure Deep Learning (DL) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. In addition to the optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. Our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.",2017,"B. Rouhani,M. Riazi,F. Koushanfar",Computer Science,330,48
11605311,SecureML: A System for Scalable Privacy-Preserving Machine Learning,"Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",2017,"Payman Mohassel,Yupeng Zhang",Computer Science,1418,42
236396479,Survey on Human Activity Recognition using Smartphone,"The field of Human Activity Recognition (HAR) is an active research field in which methods are being developed to understand human behavior by interpreting features obtained from various sources, these activities can be recognized using interactive sensors that are affected by human movement. Sensor can embed elements within Smartphones or Personal Digital Assistants (PDAs). The great increase in smart phone users and the increase in the sensor ability of these smart phones, and users usually carry their smartphones with them. This fact makes HAR more important and accepted. In this survey, A number of previous studies were studied and analyzed, where we prepared a comparison of the research works conducted over the period 2010-2020 in human activity recognition using Smartphone sensors. Comparison charts highlight their most important aspects such as a type of sensor used, activities, sensor placement, HAR-system type (offline, online), computing device, classifier (type of algorithms) and system accuracy levels .",2021,"Adeeba Kh,L. Ibrahim",Computer Science,9,48
63830117,ELDC: An Artificial Neural Network Based Energy-Efficient and Robust Routing Scheme for Pollution Monitoring in WSNs,"The range of applications of Wireless Sensor Networks (WSNs) is increasing continuously despite of their serious constraints of the sensor nodes’ resources such as storage, processing capacity, communication range and energy. The main issues in WSN are the energy consumption and the delay in relaying data to the Sink node. This becomes extremely important when deploying a big number of nodes, like the case of industry pollution monitoring. We propose an artificial neural network based energy-efficient and robust routing scheme for WSNs called ELDC. In this technique, the network is trained on huge data set containing almost all scenarios to make the network more reliable and adaptive to the environment. Additionally, it uses group based methodology to increase the life-span of the overall network, where groups may have different sizes. An artificial neural network provides an efficient threshold values for the selection of a group's CN and a cluster head based on back propagation technique and allows intelligent, efficient, and robust group organization. Thus, our proposed technique is highly energy-efficient capable to increase sensor nodes’ lifetime. Simulation results show that it outperforms LEACH protocol by 42 percent, and other state-of-the-art protocols by more than 30 percent.",2020,"A. Mehmood,Zhihan Lv,Jaime Lloret,M. Umar",Computer Science,69,42
53308303,Deep Convolutional Neural Networks for Indoor Localization with CSI Images,"With the increasing demand of location-based services, Wi-Fi based localization has attracted great interest because it provides ubiquitous access in indoor environments. In this paper, we propose CiFi, deep convolutional neural networks (DCNN) for indoor localization with commodity 5GHz WiFi. Leveraging a modified device driver, we extract phase data of channel state information (CSI), which is used to estimate the angle of arrival (AoA). We then create estimated AoA images as input to a DCNN, to train the weights in the offline phase. The location of mobile device is predicted based using the trained DCNN and new CSI AoA images. We implement the proposed CiFi system with commodity Wi-Fi devices in the 5GHz band and verify its performance with extensive experiments in two representative indoor environments.",2020,"Xuyu Wang,Xiangyu Wang,S. Mao",Computer Science,165,46
125827950,Channel State Information Prediction for 5G Wireless Communications: A Deep Learning Approach,"Channel state information (CSI) estimation is one of the most fundamental problems in wireless communication systems. Various methods, so far, have been developed to conduct CSI estimation. However, they usually require high computational complexity, which makes them unsuitable for 5G wireless communications due to employing many new techniques (e.g., massive MIMO, OFDM, and millimeter-Wave (mmWave)). In this paper, we propose an efficient online CSI prediction scheme, called OCEAN, for predicting CSI from historical data in 5G wireless communication systems. Specifically, we first identify several important features affecting the CSI of a radio link and a data sample consists of the information of the features and the CSI. We then design a learning framework that is an integration of a CNN (convolutional neural network) and a long short term with memory (LSTM) network. We also further develop an offline-online two-step training mechanism, enabling the prediction results to be more stable when applying it to practical 5G wireless communication systems. To validate OCEAN's efficacy, we consider four typical case studies, and conduct extensive experiments in the four scenarios, i.e., two outdoor and two indoor scenarios. The experiment results show that OCEAN not only obtains the predicted CSI values very quickly but also achieves highly accurate CSI prediction with up to 2.650-3.457 percent average difference ratio (ADR) between the predicted and measured CSI.",2020,"Changqing Luo,Jinlong Ji,Qianlong Wang,Xuhui Chen,Pan Li",Computer Science,275,29
127904314,Machine learning algorithms for wireless sensor networks: A survey,,2019,"Praveen Kumar Donta,Tarachand Amgoth,Chandra Sekhara Rao Annavarapu",Computer Science,441,242
69496687,Deep Learning Based Transmit Power Control in Underlaid Device-to-Device Communication,"In this paper, a means of transmit power control for underlaid device-to-device (D2D) communication is proposed based on deep learning technology. In the proposed scheme, the transmit power of D2D user equipment (DUE) is autonomously learned via a deep neural network such that the weighted sum rate (WSR) of DUEs can be maximized by considering the interference from cellular user equipment. Unlike conventional transmit power control schemes in which complex optimization problems have to be solved in an iterative manner, which possibly requires long computation time, in our proposed scheme the transmit power can be determined with a relatively low computation time. Through simulations, we confirm that the proposed scheme achieves a sufficiently high WSR with a sufficiently low computation time.",2019,"Woongsup Lee,Minhoe Kim,D. Cho",Computer Science,36,20
70135417,Spatio-Temporal Analysis and Prediction of Cellular Traffic in Metropolis,"Understanding and predicting cellular traffic at large-scale and fine-granularity is beneficial and valuable to mobile users, wireless carriers, and city authorities. Predicting cellular traffic in modern metropolis is particularly challenging because of the tremendous temporal and spatial dynamics introduced by diverse user Internet behaviors and frequent user mobility citywide. In this paper, we characterize and investigate the root causes of such dynamics in cellular traffic through a big cellular usage dataset covering 1.5 million users and 5,929 cell towers in a major city of China. We reveal intensive spatio-temporal dependency even among distant cell towers, which is largely overlooked in previous works. To explicitly characterize and effectively model the spatio-temporal dependency of urban cellular traffic, we propose a novel decomposition of in-cell and inter-cell data traffic, and apply a graph-based deep learning approach to accurate cellular traffic prediction. Experimental results demonstrate that our method consistently outperforms the state-of-the-art time-series based approaches and we also show through an example study how the decomposition of cellular traffic can be used for event inference.",2019,"Xu Wang,Zimu Zhou,Fu Xiao,Kai Xing,Zheng Yang,Yunhao Liu,Chunyi Peng",Computer Science,41,48
59599820,Towards Federated Learning at Scale: System Design,"Federated Learning is a distributed machine learning approach which enables model training on a large corpus of decentralized data. We have built a scalable production system for Federated Learning in the domain of mobile devices, based on TensorFlow. In this paper, we describe the resulting high-level design, sketch some of the challenges and their solutions, and touch upon the open problems and future directions.",2019,"Keith Bonawitz,Hubert Eichner,W. Grieskamp,Dzmitry Huba,A. Ingerman,Vladimir Ivanov,Chloé Kiddon,Jakub Konecný,S. Mazzocchi,H. B. McMahan,Timon Van Overveldt,David Petrou,Daniel Ramage,Jason Roselander","Computer Science,Mathematics",1979,26
54457125,"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play","One program to rule them all Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system. Science, this issue p. 1140; see also pp. 1087 and 1118 AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each. The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.",2018,"David Silver,T. Hubert,Julian Schrittwieser,Ioannis Antonoglou,Matthew Lai,A. Guez,Marc Lanctot,L. Sifre,D. Kumaran,T. Graepel,T. Lillicrap,K. Simonyan,D. Hassabis","Computer Science,Medicine",2732,54
71715635,Deep Reinforcement Learning Based QoS-Aware Routing in Knowledge-Defined Networking,,2018,"Pham Tran Anh Quang,Y. H. Aoul,A. Outtagarts",Computer Science,34,20
3302077,Privacy-Preserving Adversarial Networks,"We propose a data-driven framework for optimizing privacy-preserving data release mechanisms to attain the information-theoretically optimal tradeoff between minimizing distortion of useful data and concealing specific sensitive information. Our approach employs adversarially-trained neural networks to implement randomized mechanisms and to perform a variational approximation of mutual information privacy. We validate our Privacy-Preserving Adversarial Networks (PPAN) framework via proof-of-concept experiments on discrete and continuous synthetic data, as well as the MNIST handwritten digits dataset. For synthetic data, our model-agnostic PPAN approach achieves tradeoff points very close to the optimal tradeoffs that are analytically-derived from model knowledge. In experiments with the MNIST data, we visually demonstrate a learned tradeoff between minimizing the pixel-level distortion versus concealing the written digit.",2017,"Ardhendu Shekhar Tripathy,Ye Wang,P. Ishwar","Computer Science,Mathematics",69,38
8029498,Context-Aware Generative Adversarial Privacy,"Preserving the utility of published datasets while simultaneously providing provable privacy guarantees is a well-known challenge. On the one hand, context-free privacy solutions, such as differential privacy, provide strong privacy guarantees, but often lead to a significant reduction in utility. On the other hand, context-aware privacy solutions, such as information theoretic privacy, achieve an improved privacy-utility tradeoff, but assume that the data holder has access to dataset statistics. We circumvent these limitations by introducing a novel context-aware privacy framework called generative adversarial privacy (GAP). GAP leverages recent advancements in generative adversarial networks (GANs) to allow the data holder to learn privatization schemes from the dataset itself. Under GAP, learning the privacy mechanism is formulated as a constrained minimax game between two players: a privatizer that sanitizes the dataset in a way that limits the risk of inference attacks on the individuals' private variables, and an adversary that tries to infer the private variables from the sanitized dataset. To evaluate GAP's performance, we investigate two simple (yet canonical) statistical dataset models: (a) the binary data model, and (b) the binary Gaussian mixture model. For both models, we derive game-theoretically optimal minimax privacy mechanisms, and show that the privacy mechanisms learned from data (in a generative adversarial fashion) match the theoretically optimal ones. This demonstrates that our framework can be easily applied in practice, even in the absence of dataset statistics.",2017,"Chong Huang,P. Kairouz,Xiao Chen,L. Sankar,R. Rajagopal","Computer Science,Mathematics",143,101
3586777,Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis,"An increasing number of sensors on mobile, Internet of things (IoT), and wearable devices generate time-series measurements of physical activities. Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition, a wide range of potentially sensitive information about the individuals can also be discovered through access to sensory data and this cannot easily be protected using traditional privacy approaches. In this paper, we propose a privacy-preserving sensing framework for managing access to time-series data in order to provide utility while protecting individuals' privacy. We introduce Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences, to protect users' privacy. This efficiency is achieved by defining a user-customized objective function for deep autoencoders. Replacement will not only eliminate the possibility of recognition sensitive inferences, it also eliminates the possibility of detecting the occurrence of them, that is the main weakness of other approaches such as filtering or randomization. We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets. We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information. Finally, we utilize the GANs for detecting the occurrence of replacement, after releasing data, and show that this can be done only if the adversarial network is trained on the users' original data.",2017,"M. Malekzadeh,R. Clegg,H. Haddadi","Computer Science,Mathematics",65,46
23808696,Privacy-Preserving Generative Deep Neural Networks Support Clinical Data Sharing,"Background Data sharing accelerates scientific progress but sharing individual level data while preserving patient privacy presents a barrier. Methods and Results Using pairs of deep neural networks, we generated simulated, synthetic “participants” that closely resemble participants of the SPRINT trial. We showed that such paired networks can be trained with differential privacy, a formal privacy framework that limits the likelihood that queries of the synthetic participants’ data could identify a real a participant in the trial. Machine-learning predictors built on the synthetic population generalize to the original dataset. This finding suggests that the synthetic data can be shared with others, enabling them to perform hypothesis-generating analyses as though they had the original trial data. Conclusions Deep neural networks that generate synthetic participants facilitate secondary analyses and reproducible investigation of clinical datasets by enhancing data sharing while preserving participant privacy.",2017,"B. Beaulieu-Jones,Zhiwei Steven Wu,Christopher J. Williams,Ran Lee,S. Bhavnani,James Brian Byrd,C. Greene","Medicine,Computer Science,Biology",340,48
29681354,Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs,"Generative Adversarial Networks (GANs) have shown remarkable success as a framework for training models to produce realistic-looking data. In this work, we propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to produce realistic real-valued multi-dimensional time series, with an emphasis on their application to medical data. RGANs make use of recurrent neural networks (RNNs) in the generator and the discriminator. In the case of RCGANs, both of these RNNs are conditioned on auxiliary information. We demonstrate our models in a set of toy datasets, where we show visually and quantitatively (using sample likelihood and maximum mean discrepancy) that they can successfully generate realistic time-series. We also describe novel evaluation methods for GANs, where we generate a synthetic labelled training dataset, and evaluate on a real test set the performance of a model trained on the synthetic data, and vice-versa. We illustrate with these metrics that RCGANs can generate time-series data useful for supervised training, with only minor degradation in performance on real test data. This is demonstrated on digit classification from ‘serialised’ MNIST and by training an early warning system on a medical dataset of 17,000 patients from an intensive care unit. We further discuss and analyse the privacy concerns that may arise when using RCGANs to generate realistic synthetic medical time series data, and demonstrate results from differentially private training of the RCGAN.",2017,"Cristóbal Esteban,Stephanie L. Hyland,G. Rätsch","Mathematics,Computer Science",610,33
2873210,Generating Multi-label Discrete Electronic Health Records using Generative Adversarial Networks,"Access to electronic health records (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk. In this paper, we propose a new approach, medical Generative Adversarial Network (medGAN), to generate realistic synthetic EHRs. Based on an input EHR dataset, medGAN can generate high-dimensional discrete variables (e.g., binary and count features) via a combination of an autoencoder and generative adversarial networks. We also propose minibatch averaging to efficiently avoid mode collapse, and increase the learning efficiency with batch normalization and shortcut connections. To demonstrate feasibility, we showed that medGAN generates synthetic EHR datasets that achieve comparable performance to real data on many experiments including distribution statistics, predictive modeling tasks and medical expert review.",2017,"E. Choi,Siddharth Biswal,B. Malin,J. Duke,W. Stewart,Jimeng Sun",Computer Science,70,45
7739761,Generating Multi-label Discrete Patient Records using Generative Adversarial Networks,"Access to electronic health record (EHR) data has motivated computational advances in medical research. However, various concerns, particularly over privacy, can limit access to and collaborative use of EHR data. Sharing synthetic EHR data could mitigate risk. In this paper, we propose a new approach, medical Generative Adversarial Network (medGAN), to generate realistic synthetic patient records. Based on input real patient records, medGAN can generate high-dimensional discrete variables (e.g., binary and count features) via a combination of an autoencoder and generative adversarial networks. We also propose minibatch averaging to efficiently avoid mode collapse, and increase the learning efficiency with batch normalization and shortcut connections. To demonstrate feasibility, we showed that medGAN generates synthetic patient records that achieve comparable performance to real data on many experiments including distribution statistics, predictive modeling tasks and a medical expert review. We also empirically observe a limited privacy risk in both identity and attribute disclosure using medGAN.",2017,"E. Choi,Siddharth Biswal,B. Malin,J. Duke,W. Stewart,Jimeng Sun","Computer Science,Mathematics",426,54
36911378,The MobiAct Dataset: Recognition of Activities of Daily Living using Smartphones,,2016,"George Vavoulas,Charikleia Chatzaki,Thodoris Malliotakis,M. Pediaditis,M. Tsiknakis",Computer Science,201,10
13191305,The great time series classification bake off: a review and experimental evaluation of recent algorithmic advances,,2016,"A. Bagnall,Jason Lines,A. Bostrom,J. Large,Eamonn J. Keogh","Medicine,Computer Science",1093,52
14006978,mSieve: differential behavioral privacy in time series of mobile sensor data,"Differential privacy concepts have been successfully used to protect anonymity of individuals in population-scale analysis. Sharing of mobile sensor data, especially physiological data, raise different privacy challenges, that of protecting private behaviors that can be revealed from time series of sensor data. Existing privacy mechanisms rely on noise addition and data perturbation. But the accuracy requirement on inferences drawn from physiological data, together with well-established limits within which these data values occur, render traditional privacy mechanisms inapplicable. In this work, we define a new behavioral privacy metric based on differential privacy and propose a novel data substitution mechanism to protect behavioral privacy. We evaluate the efficacy of our scheme using 660 hours of ECG, respiration, and activity data collected from 43 participants and demonstrate that it is possible to retain meaningful utility, in terms of inference accuracy (90%), while simultaneously preserving the privacy of sensitive behaviors.",2016,"Nazir Saleheen,Supriyo Chakraborty,Nasir Ali,Md. Mahbubur Rahman,Syed Monowar Hossain,Rummana Bari,E. Buder,M. Srivastava,Santosh Kumar","Computer Science,Medicine",44,44
44069023,Private and Scalable Personal Data Analytics Using Hybrid Edge-to-Cloud Deep Learning,"Although the ability to collect, collate, and analyze the vast amount of data generated from cyber-physical systems and Internet of Things devices can be beneficial to both users and industry, this process has led to a number of challenges, including privacy and scalability issues. The authors present a hybrid framework where user-centered edge devices and resources can complement the cloud for providing privacy-aware, accurate, and efficient analytics.",2018,"S. A. Ossia,A. Shamsabadi,A. Taheri,H. Rabiee,H. Haddadi",Computer Science,44,16
226953312,Comments on “Dropping Activation Outputs with Localized First-Layer Deep Network for Enhancing User Privacy and Data Security”,"Inference based on deep learning models is usually implemented by exposing sensitive user data to the outside models, which of course gives rise to acute privacy concerns. To deal with these concerns, Dong et al. recently proposed an approach, namely the dropping-activation-outputs (DAO) first layer. This approach was claimed to be a non-invertible transformation, such that the privacy of user data could not be compromised. However, In this paper, we prove that the DAO first layer, in fact, can generally be inverted, and hence fails to preserve privacy. We also provide a countermeasure against the privacy vulnerabilities that we examined.",2018,"Xinrui Tan,Hongjia Li,Liming Wang,Zhen Xu",Computer Science,6,27
4046474,Gazelle: A Low Latency Framework for Secure Neural Network Inference,"The growing popularity of cloud-based machine learning raises a natural question about the privacy guarantees that can be provided in such a setting. Our work tackles this problem in the context where a client wishes to classify private images using a convolutional neural network (CNN) trained by a server. Our goal is to build efficient protocols whereby the client can acquire the classification result without revealing their input to the server, while guaranteeing the privacy of the server's neural network. 
To this end, we design Gazelle, a scalable and low-latency system for secure neural network inference, using an intricate combination of homomorphic encryption and traditional two-party computation techniques (such as garbled circuits). Gazelle makes three contributions. First, we design the Gazelle homomorphic encryption library which provides fast algorithms for basic homomorphic operations such as SIMD (single instruction multiple data) addition, SIMD multiplication and ciphertext permutation. Second, we implement the Gazelle homomorphic linear algebra kernels which map neural network layers to optimized homomorphic matrix-vector multiplication and convolution routines. Third, we design optimized encryption switching protocols which seamlessly convert between homomorphic and garbled circuit encodings to enable implementation of complete neural network inference. 
We evaluate our protocols on benchmark neural networks trained on the MNIST and CIFAR-10 datasets and show that Gazelle outperforms the best existing systems such as MiniONN (ACM CCS 2017) by 20 times and Chameleon (Crypto Eprint 2017/1164) by 30 times in online runtime. Similarly when compared with fully homomorphic approaches like CryptoNets (ICML 2016) we demonstrate three orders of magnitude faster online run-time.",2018,"C. Juvekar,V. Vaikuntanathan,A. Chandrakasan",Computer Science,698,49
4860036,Dropping Activation Outputs With Localized First-Layer Deep Network for Enhancing User Privacy and Data Security,"Deep learning methods can play a crucial role in anomaly detection, prediction, and supporting decision making for applications like personal health-care, pervasive body sensing, and so on. However, current architecture of deep networks suffers the privacy issue that users need to give out their data to the model (typically hosted in a server or a cluster on Cloud) for training or prediction. This problem is getting more severe for those sensitive health-care or medical data (e.g., fMRI or body sensors measures like EEG signals). In addition to this, there is also a security risk of leaking these data during the data transmission from user to the model (especially when it is through the Internet). Targeting at these issues, in this paper, we proposed a new architecture for deep network in which users do not reveal their original data to the model. In our method, feed-forward propagation and data encryption are combined into one process: we migrate the first layer of deep network to users’ local devices and apply the activation functions locally, and then use the “dropping activation output” method to make the output non-invertible. The resulting approach is able to make model prediction without accessing users’ sensitive raw data. The experiment conducted in this paper showed that our approach achieves the desirable privacy protection requirement and demonstrated several advantages over the traditional approach with encryption/decryption.",2017,"Hao Dong,Chao Wu,Zhen Wei,Yike Guo",Computer Science,27,29
3586777,Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis,"An increasing number of sensors on mobile, Internet of things (IoT), and wearable devices generate time-series measurements of physical activities. Though access to the sensory data is critical to the success of many beneficial applications such as health monitoring or activity recognition, a wide range of potentially sensitive information about the individuals can also be discovered through access to sensory data and this cannot easily be protected using traditional privacy approaches. In this paper, we propose a privacy-preserving sensing framework for managing access to time-series data in order to provide utility while protecting individuals' privacy. We introduce Replacement AutoEncoder, a novel feature-learning algorithm which learns how to transform discriminative features of multi-variate time-series that correspond to sensitive inferences, into some features that have been more observed in non-sensitive inferences, to protect users' privacy. This efficiency is achieved by defining a user-customized objective function for deep autoencoders. Replacement will not only eliminate the possibility of recognition sensitive inferences, it also eliminates the possibility of detecting the occurrence of them, that is the main weakness of other approaches such as filtering or randomization. We evaluate the efficacy of the algorithm with an activity recognition task in a multi-sensing environment using extensive experiments on three benchmark datasets. We show that it can retain the recognition accuracy of state-of-the-art techniques while simultaneously preserving the privacy of sensitive information. Finally, we utilize the GANs for detecting the occurrence of replacement, after releasing data, and show that this can be done only if the adversarial network is trained on the users' original data.",2017,"M. Malekzadeh,R. Clegg,H. Haddadi","Computer Science,Mathematics",65,46
11886712,Privacy-Preserving Deep Inference for Rich User Data on The Cloud,"Deep neural networks are increasingly being used in a variety of machine learning applications applied to rich user data on the cloud. However, this approach introduces a number of privacy and efficiency challenges, as the cloud operator can perform secondary inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger, and more complicated models. In this paper, we present a hybrid approach for breaking down large, complex deep models for cooperative, privacy-preserving analytics. We do this by breaking down the popular deep architectures and fine-tune them in a particular way. We then evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also asses the local inference cost of different layers on a modern handset for mobile applications. Our evaluations show that by using certain kind of fine-tuning and embedding techniques and at a small processing costs, we can greatly reduce the level of information available to unintended tasks applied to the data feature on the cloud, and hence achieving the desired tradeoff between privacy and performance.",2017,"S. A. Ossia,A. Shamsabadi,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,14,58
2519922,DeepSecure: Scalable Provably-Secure Deep Learning,"This paper presents DeepSecure, the an scalable and provably secure Deep Learning (DL) framework that is built upon automated design, efficient logic synthesis, and optimization methodologies. DeepSecure targets scenarios in which neither of the involved parties including the cloud servers that hold the DL model parameters or the delegating clients who own the data is willing to reveal their information. Our framework is the first to empower accurate and scalable DL analysis of data generated by distributed clients without sacrificing the security to maintain efficiency. The secure DL computation in DeepSecure is performed using Yao's Garbled Circuit (GC) protocol. We devise GC-optimized realization of various components used in DL. Our optimized implementation achieves up to 58-fold higher throughput per sample compared with the best prior solution. In addition to the optimized GC realization, we introduce a set of novel low-overhead pre-processing techniques which further reduce the GC overall runtime in the context of DL. Our extensive evaluations demonstrate up to two orders-of-magnitude additional runtime improvement achieved as a result of our pre-processing methodology.",2017,"B. Rouhani,M. Riazi,F. Koushanfar",Computer Science,330,48
11605311,SecureML: A System for Scalable Privacy-Preserving Machine Learning,"Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",2017,"Payman Mohassel,Yupeng Zhang",Computer Science,1418,42
4909695,A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics,"Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user’s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.",2017,"Seyed Ali Osia,Ali Shahin Shamsabadi,Sina Sajadmanesh,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,204,70
6788781,Opening the Black Box of Deep Neural Networks via Information,"Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work proposed to analyze DNNs in the \textit{Information Plane}; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on {\emph compression} of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer.",2017,"Ravid Shwartz-Ziv,Naftali Tishby",Computer Science,1198,25
13713980,Self-Normalizing Neural Networks,"Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are ""scaled exponential linear units"" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: this http URL.",2017,"G. Klambauer,Thomas Unterthiner,Andreas Mayr,S. Hochreiter","Computer Science,Mathematics",1927,42
39361148,CTS-DP: Publishing correlated time-series data via differential privacy,,2017,"Hao Wang,Zhengquan Xu",Computer Science,58,38
4909695,A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics,"Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user’s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.",2017,"Seyed Ali Osia,Ali Shahin Shamsabadi,Sina Sajadmanesh,A. Taheri,Kleomenis Katevas,H. Rabiee,N. Lane,H. Haddadi",Computer Science,204,70
6366297,A Collaborative Privacy-Preserving Deep Learning System in Distributed Mobile Environment,"In the last couple years, deep learning gained great popularity in health and medical science. For analyzing personal health data, privacy of patients and their data is one of the biggest concerns. Traditional methods have the possibility of leaking data because of transferring raw data and storing all data in centralized houseware. Therefore, we proposed a collaborative privacy-preserving learning system based on deep neural network, which does not share local raw data. The system is implemented on an XMPP server and several mobile devices. In the experiments, reconstructed rate is proposed to evaluate the performance of distributed system compared with centralized training. The rate is over 90% in different scenarios. Furthermore, the network traffic while collaborative learning is also measured.",2016,"Menghan Liu,Haotian Jiang,Jia Chen,Alaa Badokhon,Xuetao Wei,Ming-chun Huang",Computer Science,31,16
14006978,mSieve: differential behavioral privacy in time series of mobile sensor data,"Differential privacy concepts have been successfully used to protect anonymity of individuals in population-scale analysis. Sharing of mobile sensor data, especially physiological data, raise different privacy challenges, that of protecting private behaviors that can be revealed from time series of sensor data. Existing privacy mechanisms rely on noise addition and data perturbation. But the accuracy requirement on inferences drawn from physiological data, together with well-established limits within which these data values occur, render traditional privacy mechanisms inapplicable. In this work, we define a new behavioral privacy metric based on differential privacy and propose a novel data substitution mechanism to protect behavioral privacy. We evaluate the efficacy of our scheme using 660 hours of ECG, respiration, and activity data collected from 43 participants and demonstrate that it is possible to retain meaningful utility, in terms of inference accuracy (90%), while simultaneously preserving the privacy of sensitive behaviors.",2016,"Nazir Saleheen,Supriyo Chakraborty,Nasir Ali,Md. Mahbubur Rahman,Syed Monowar Hossain,Rummana Bari,E. Buder,M. Srivastava,Santosh Kumar","Computer Science,Medicine",44,44
207241585,Deep Learning with Differential Privacy,"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",2016,"Martín Abadi,Andy Chu,I. Goodfellow,H. B. McMahan,Ilya Mironov,Kunal Talwar,Li Zhang","Computer Science,Mathematics",4409,63
616233,I am a Smartwatch and I can Track my User's Arm,"This paper aims to track the 3D posture of the entire arm - both wrist and elbow - using the motion and magnetic sensors on smartwatches. We do not intend to employ machine learning to train the system on a specific set of gestures. Instead, we aim to trace the geometric motion of the arm, which can then be used as a generic platform for gesture-based applications. The problem is challenging because the arm posture is a function of both elbow and shoulder motions, whereas the watch is only a single point of (noisy) measurement from the wrist. Moreover, while other tracking systems (like indoor/outdoor localization) often benefit from maps or landmarks to occasionally reset their estimates, such opportunities are almost absent here. While this appears to be an under-constrained problem, we find that the pointing direction of the forearm is strongly coupled to the arm's posture. If the gyroscope and compass on the watch can be made to estimate this direction, the 3D search space can become smaller; the IMU sensors can then be applied to mitigate the remaining uncertainty. We leverage this observation to design ArmTrak, a system that fuses the IMU sensors and the anatomy of arm joints into a modified hidden Markov model (HMM) to continuously estimate state variables. Using Kinect 2.0 as ground truth, we achieve around 9.2 cm of median error for free-form postures; the errors increase to 13.3 cm for a real time version. We believe this is a step forward in posture tracking, and with some additional work, could become a generic underlay to various practical applications.",2016,"Sheng Shen,He Wang,Romit Roy Choudhury",Computer Science,182,40
7651407,Sleep Monitoring Based on a Tri-Axial Accelerometer and a Pressure Sensor,"Sleep disorders are a common affliction for many people even though sleep is one of the most important factors in maintaining good physiological and emotional health. Numerous researchers have proposed various approaches to monitor sleep, such as polysomnography and actigraphy. However, such approaches are costly and often require overnight treatment in clinics. With this in mind, the research presented here has emerged from the question: “Can data be easily collected and analyzed without causing discomfort to patients?” Therefore, the aim of this study is to provide a novel monitoring system for quantifying sleep quality. The data acquisition system is equipped with multimodal sensors, including a three-axis accelerometer and a pressure sensor. To identify sleep quality based on measured data, a novel algorithm, which uses numerous physiological parameters, was proposed. Such parameters include non-REM sleep time, the number of apneic episodes, and sleep durations for dominant poses. To assess the effectiveness of the proposed system, three participants were enrolled in this experimental study for a duration of 20 days. From the experimental results, it can be seen that the proposed monitoring system is effective for quantifying sleep quality.",2016,"Yunyoung Nam,Yeesock Kim,Jinseok Lee","Computer Science,Medicine",87,30
6056831,Differential Privacy Preservation for Deep Auto-Encoders: an Application of Human Behavior Prediction,"
 
 In recent years, deep learning has spread beyond both academia and industry with many exciting real-world applications. The development of deep learning has presented obvious privacy issues. However, there has been lack of scientific study about privacy preservation in deep learning. In this paper, we concentrate on the auto-encoder, a fundamental component in deep learning, and propose the deep private auto-encoder (dPA). Our main idea is to enforce ε-differential privacy by perturbing the objective functions of the traditional deep auto-encoder, rather than its results. We apply the dPA to human behavior prediction in a health social network. Theoretical analysis and thorough experimental evaluations show that the dPA is highly effective and efficient, and it significantly outperforms existing solutions.
 
",2016,"Nhathai Phan,Yue Wang,Xintao Wu,D. Dou",Computer Science,212,27
3617652,Oblivious Neural Network Predictions via MiniONN Transformations,"Machine learning models hosted in a cloud service are increasingly popular but risk privacy: clients sending prediction requests to the service need to disclose potentially sensitive information. In this paper, we explore the problem of privacy-preserving predictions: after each prediction, the server learns nothing about clients' input and clients learn nothing about the model. We present MiniONN, the first approach for transforming an existing neural network to an oblivious neural network supporting privacy-preserving predictions with reasonable efficiency. Unlike prior work, MiniONN requires no change to how models are trained. To this end, we design oblivious protocols for commonly used operations in neural network prediction models. We show that MiniONN outperforms existing work in terms of response latency and message sizes. We demonstrate the wide applicability of MiniONN by transforming several typical neural network models trained from standard datasets.",2017,"Jian Liu,Mika Juuti,Yao Lu,N. Asokan",Computer Science,577,62
23428046,Deep3: Leveraging three levels of parallelism for efficient Deep Learning,"This paper proposes Deep3, an automated platform-aware Deep Learning (DL) framework that brings orders of magnitude performance improvement to DL training and execution. Deep3 is the first to simultaneously leverage three levels of parallelism for performing DL: data, network, and hardware. It uses platform profiling to abstract physical characterizations of the target platform. The core of Deep3 is a new extensible methodology that enables incorporation of platform characteristics into the higher-level data and neural network transformation. We provide accompanying libraries to ensure automated customization and adaptation to different datasets and platforms. Proof-of-concept evaluations demonstrate 10-100 fold physical performance improvement compared to the state-of-the-art DL frameworks, e.g., TensorFlow.",2017,"B. Rouhani,Azalia Mirhoseini,F. Koushanfar",Computer Science,23,17
11605311,SecureML: A System for Scalable Privacy-Preserving Machine Learning,"Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.",2017,"Payman Mohassel,Yupeng Zhang",Computer Science,1418,42
22010134,TinyDL: Just-in-time deep learning solution for constrained embedded systems,"This work proposes TinyDL, an automated end-to-end framework that aims to integrate the state-of-the-art Deep Learning (DL) models into embedded systems. TinyDL enables efficient training and execution of DL models as data is collected over time while adhering to the underlying physical resources and constraints. The constraints can be characterized in terms of memory bandwidth, energy resources (e.g., battery life), and/or real-time requirement. TinyDL takes advantage of platform profiling to abstract the physical characteristics of the target embedded device. We introduce a platform-aware signal transformation methodology to enable DL training and execution within the confine of the available resources. Our approach balances the trade-off between data movements and computations to improve the performance of costly iterative DL training/execution. Proof-of-concept implementation on NVIDIA Jetson TK1 embedded platform demonstrates up to two orders of magnitude energy improvement over the previous DL solutions, none of which had been amenable to constrained devices.",2017,"B. Rouhani,Azalia Mirhoseini,F. Koushanfar",Computer Science,7,10
5968842,Customizing Neural Networks for Efficient FPGA Implementation,"We propose a novel end-to-end framework to customize execution of deep neural networks on FPGA platforms. Our framework employs a reconfigurable clustering approach that encodes the parameters of deep neural networks in accordance with the application's accuracy requirement and the underlying platform constraints. The throughput of FPGA-based realizations of neural networks is often bounded by the memory access bandwidth. The use of encoded parameters reduces both the required memory bandwidth and the computational complexity of neural networks, increasing the effective throughput. Our framework enables systematic customization of encoded deep neural networks for different FPGA platforms. Proof-of-concept evaluations on four different applications demonstrate up to 9-fold reduction in memory footprint and 15-fold improvement in the operational throughput while the drop in accuracy remains below 0.1%.",2017,"Mohammad Samragh,M. Ghasemzadeh,F. Koushanfar",Computer Science,43,27
2056019,Learning Structured Sparsity in Deep Neural Networks,"High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNNs evaluation. Experimental results show that SSL achieves on average 5.1x and 3.1x speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth can reduce 20 layers of a Deep Residual Network (ResNet) to 18 layers while improve the accuracy from 91.25% to 92.60%, which is still slightly higher than that of original ResNet with 32 layers. For AlexNet, structure regularization by SSL also reduces the error by around ~1%. Open source code is in this https URL",2016,"W. Wen,Chunpeng Wu,Yandan Wang,Yiran Chen,Hai Helen Li","Computer Science,Mathematics",2051,22
26270376,DeLight: Adding Energy Dimension To Deep Neural Networks,"Physical viability, in particular energy efficiency, is a key challenge in realizing the true potential of Deep Neural Networks (DNNs). In this paper, we aim to incorporate the energy dimension as a design parameter in the higher-level hierarchy of DNN training and execution to optimize for the energy resources and constraints. We use energy characterization to bound the network size in accordance to the pertinent physical resources. An automated customization methodology is proposed to adaptively conform the DNN configurations to the underlying hardware characteristics while minimally affecting the inference accuracy. The key to our approach is a new context and resource aware projection of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data projection to enable the training of different DNN architectures which can be aggregated together to further boost the inference accuracy. Accompanying APIs are provided to facilitate rapid prototyping of an arbitrary DNN application customized to the underlying platform. Proof-of-concept evaluations for deployment of different visual, audio, and smart-sensing benchmarks demonstrate up to 100-fold energy improvement compared to the prior-art DL solutions.",2016,"B. Rouhani,Azalia Mirhoseini,F. Koushanfar","Computer Science,Engineering",48,15
207241585,Deep Learning with Differential Privacy,"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",2016,"Martín Abadi,Andy Chu,I. Goodfellow,H. B. McMahan,Ilya Mironov,Kunal Talwar,Li Zhang","Computer Science,Mathematics",4409,63
217485587,CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy,"Applying machine learning to a problem which involves medical, financial, or other types of sensitive data, not only requires accurate predictions but also careful attention to maintaining data privacy and security. Legal and ethical requirements may prevent the use of cloud-based machine learning solutions for such tasks. In this work, we will present a method to convert learned neural networks to CryptoNets, neural networks that can be applied to encrypted data. This allows a data owner to send their data in an encrypted form to a cloud service that hosts the network. The encryption ensures that the data remains confidential since the cloud does not have access to the keys needed to decrypt it. Nevertheless, we will show that the cloud service is capable of applying the neural network to the encrypted data to make encrypted predictions, and also return them in encrypted form. These encrypted predictions can be sent back to the owner of the secret key who can decrypt them. Therefore, the cloud service does not gain any information about the raw data nor about the prediction it made. We demonstrate CryptoNets on the MNIST optical character recognition tasks. CryptoNets achieve 99% accuracy and can make around 59000 predictions per hour on a single PC. Therefore, they allow high throughput, accurate, and private predictions.",2016,"Nathan Dowlin,Ran Gilad-Bachrach,Kim Laine,K. Lauter,M. Naehrig,J. Wernsing",Computer Science,1324,32
17495366,Secure Data Exchange: A Marketplace in the Cloud,"A vast amount of data belonging to companies and individuals is currently stored in the cloud in encrypted form by trustworthy service providers such as Microsoft, Amazon, and Google. Unfortunately, the only way for the cloud to use the data in computations is to first decrypt it, then compute on it, and finally re-encrypt it, resulting in a problematic trade-off between value/utility and security. At a high level, our goal in this paper is to present a general and practical cryptographic solution to this dilemma. More precisely, we describe a scenario that we call Secure Data Exchange (SDE), where several data owners are storing private encrypted data in a semi-honest non-colluding cloud, and an evaluator (a third party) wishes to engage in a secure function evaluation on the data belonging to some subset of the data owners. We require that none of the parties involved learns anything beyond what they already know and what is revealed by the function, even when the parties (except the cloud) are active malicious. We also recognize the ubiquity of scenarios where the lack of an efficient SDE protocol prevents for example business transactions, research collaborations, or mutually beneficial computations on aggregated private data from taking place, and discuss several such scenarios in detail. Our main result is an efficient and practical protocol for enabling SDE using Secure Multi-Party Computation (MPC) in a novel adaptation of the server-aided setting. We also present the details of an implementation along with performance numbers.",2019,"Ran Gilad-Bachrach,Kim Laine,K. Lauter,Peter Rindal,Mike Rosulek",Computer Science,24,39
657888,Privacy Preserving Data Mining,,2016,"J. Vaidya,Yu Zhu,C. Clifton",Computer Science,3553,27
207241585,Deep Learning with Differential Privacy,"Machine learning techniques based on neural networks are achieving remarkable results in a wide variety of domains. Often, the training of models requires large, representative datasets, which may be crowdsourced and contain sensitive information. The models should not expose private information in these datasets. Addressing this goal, we develop new algorithmic techniques for learning and a refined analysis of privacy costs within the framework of differential privacy. Our implementation and experiments demonstrate that we can train deep neural networks with non-convex objectives, under a modest privacy budget, and at a manageable cost in software complexity, training efficiency, and model quality.",2016,"Martín Abadi,Andy Chu,I. Goodfellow,H. B. McMahan,Ilya Mironov,Kunal Talwar,Li Zhang","Computer Science,Mathematics",4409,63
217485587,CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy,"Applying machine learning to a problem which involves medical, financial, or other types of sensitive data, not only requires accurate predictions but also careful attention to maintaining data privacy and security. Legal and ethical requirements may prevent the use of cloud-based machine learning solutions for such tasks. In this work, we will present a method to convert learned neural networks to CryptoNets, neural networks that can be applied to encrypted data. This allows a data owner to send their data in an encrypted form to a cloud service that hosts the network. The encryption ensures that the data remains confidential since the cloud does not have access to the keys needed to decrypt it. Nevertheless, we will show that the cloud service is capable of applying the neural network to the encrypted data to make encrypted predictions, and also return them in encrypted form. These encrypted predictions can be sent back to the owner of the secret key who can decrypt them. Therefore, the cloud service does not gain any information about the raw data nor about the prediction it made. We demonstrate CryptoNets on the MNIST optical character recognition tasks. CryptoNets achieve 99% accuracy and can make around 59000 predictions per hour on a single PC. Therefore, they allow high throughput, accurate, and private predictions.",2016,"Nathan Dowlin,Ran Gilad-Bachrach,Kim Laine,K. Lauter,M. Naehrig,J. Wernsing",Computer Science,1324,32
207233895,Scalable and Secure Logistic Regression via Homomorphic Encryption,"Logistic regression is a powerful machine learning tool to classify data. When dealing with sensitive data such as private or medical information, cares are necessary. In this paper, we propose a secure system for protecting the training data in logistic regression via homomorphic encryption. Perhaps surprisingly, despite the non-polynomial tasks of training in logistic regression, we show that only additively homomorphic encryption is needed to build our system. Our system is secure and scalable with the dataset size.",2016,"Yoshinori Aono,Takuya Hayashi,L. T. Phong,Lihua Wang",Computer Science,162,26
20714,Privacy-preserving deep learning,"Deep learning based on artificial neural networks is a very popular approach to modeling, classifying, and recognizing complex data such as images, speech, and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal, highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it, nor restrict the purposes for which it is used. Furthermore, centrally kept data is subject to legal subpoenas and extrajudicial surveillance. Many data owners-for example, medical institutions that may want to apply deep learning methods to clinical records-are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning. In this paper, we present a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.",2015,"R. Shokri,Vitaly Shmatikov",Computer Science,1906,60
7010644,GraphSC: Parallel Secure Computation Made Easy,"We propose introducing modern parallel programming paradigms to secure computation, enabling their secure execution on large datasets. To address this challenge, we present Graph SC, a framework that (i) provides a programming paradigm that allows non-cryptography experts to write secure code, (ii) brings parallelism to such secure implementations, and (iii) meets the need for obliviousness, thereby not leaking any private information. Using Graph SC, developers can efficiently implement an oblivious version of graph-based algorithms (including sophisticated data mining and machine learning algorithms) that execute in parallel with minimal communication overhead. Importantly, our secure version of graph-based algorithms incurs a small logarithmic overhead in comparison with the non-secure parallel version. We build Graph SC and demonstrate, using several algorithms as examples, that secure computation can be brought into the realm of practicality for big data analysis. Our secure matrix factorization implementation can process 1 million ratings in 13 hours, which is a multiple order-of-magnitude improvement over the only other existing attempt, which requires 3 hours to process 16K ratings.",2015,"Kartik Nayak,X. Wang,Stratis Ioannidis,Udi Weinsberg,N. Taft,E. Shi",Computer Science,150,81
14639818,ABY - A Framework for Efficient Mixed-Protocol Secure Two-Party Computation,from details of underlying secure computation protocol Use only fast symmetric key crypto Code is available on GitHub: http://encrypto.de/code/ABY,2015,"Daniel Demmler,T. Schneider,Michael Zohner",Computer Science,677,80
2133959,On the Computational Efficiency of Training Neural Networks,"It is well-known that neural networks are computationally hard to train. On the other hand, in practice, modern day neural networks are trained efficiently using SGD and a variety of tricks that include different activation functions (e.g. ReLU), over-specification (i.e., train networks which are larger than needed), and regularization. In this paper we revisit the computational complexity of training neural networks from a modern perspective. We provide both positive and negative results, some of them yield new provably efficient and practical algorithms for training certain types of neural networks.",2014,"Roi Livni,S. Shalev-Shwartz,O. Shamir","Mathematics,Computer Science",445,25
8085841,Stochastic gradient descent with differentially private updates,"Differential privacy is a recent framework for computation on sensitive data, which has shown considerable promise in the regime of large datasets. Stochastic gradient methods are a popular approach for learning in the data-rich regime because they are computationally tractable and scalable. In this paper, we derive differentially private versions of stochastic gradient descent, and test them empirically. Our results show that standard SGD experiences high variability due to differential privacy, but a moderate increase in the batch size can improve performance significantly.",2013,"Shuang Song,Kamalika Chaudhuri,A. Sarwate",Computer Science,559,27
16837768,Crowd motion monitoring using tracklet-based commotion measure,"Abnormal detection in crowd is a challenging vision task due to the scarcity of real-world training examples and the lack of a clear definition of abnormality. To tackle these challenges, we propose a novel measure to capture the commotion of a crowd motion for the task of abnormality detection in crowd. The unsupervised nature of the proposed measure allows to detect abnormality adaptively (i.e. context dependent) with no training cost. The extensive experiments on three different levels (e.g. pixel, frame and video) show the superiority of the proposed approach compared to the state of the arts.",2015,"Hossein Mousavi,Moin Nabi,Hamed Kiani Galoogahi,A. Perina,Vittorio Murino",Computer Science,40,21
18021059,Analyzing Tracklets for the Detection of Abnormal Crowd Behavior,"This paper presents a novel video descriptor, referred to as Histogram of Oriented Tracklets, for recognizing abnormal situation in crowded scenes. Unlike standard approaches that use optical flow, which estimates motion vectors only from two successive frames, we built our descriptor over long-range motion trajectories which is called tracklets in the literature. Following the standard procedure, we divided video sequences in spatio-temporal cuboids within which we collected statistics on the tracklets passing through them. In particular, we quantized orientation and magnitude in a 2-dimensional histogram which encodes the motion patterns expected in each cuboid. We classify frames as normal and abnormal by using Latent Dirichlet Allocation and Support Vector Machines. We evaluated the effectiveness of the proposed descriptors on three datasets: UCSD, Violence in Crowds and UMN. The experiments demonstrated (i) very promising results in abnormality detection, (ii) setting new state-of-the-art on two of them, and (iii) outperforming former descriptors based on the optical flow, dense trajectories and the social force model.",2015,"Hossein Mousavi,Sadegh Mohammadi,A. Perina,R. Chellali,Vittorio Murino",Computer Science,116,27
13471908,Abnormal behavior detection using dominant sets,,2014,"M. Alvar,A. Torsello,Á. S. Miralles,J. M. Armingol",Computer Science,30,54
3052515,Violent flows: Real-time detection of violent crowd behavior,"Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.",2012,"Tal Hassner,Yossi Itcher,Orit Kliper-Gross",Computer Science,417,34
7861505,"Improved anomaly detection in crowded scenes via cell-based analysis of foreground speed, size and texture","A robust and efficient anomaly detection technique is proposed, capable of dealing with crowded scenes where traditional tracking based approaches tend to fail. Initial foreground segmentation of the input frames confines the analysis to foreground objects and effectively ignores irrelevant background dynamics. Input frames are split into non-overlapping cells, followed by extracting features based on motion, size and texture from each cell. Each feature type is independently analysed for the presence of an anomaly. Unlike most methods, a refined estimate of object motion is achieved by computing the optical flow of only the foreground pixels. The motion and size features are modelled by an approximated version of kernel density estimation, which is computationally efficient even for large training datasets. Texture features are modelled by an adaptively grown code-book, with the number of entries in the codebook selected in an online fashion. Experiments on the recently published UCSD Anomaly Detection dataset show that the proposed method obtains considerably better results than three recent approaches: MPPCA, social force, and mixture of dynamic textures (MDT). The proposed method is also several orders of magnitude faster than MDT, the next best performing method.",2011,"Vikas Reddy,Conrad Sanderson,B. Lovell",Computer Science,192,33
4231589,Random field topic model for semantic region analysis in crowded scenes from tracklets,"In this paper, a Random Field Topic (RFT) model is proposed for semantic region analysis from motions of objects in crowded scenes. Different from existing approaches of learning semantic regions either from optical flows or from complete trajectories, our model assumes that fragments of trajectories (called tracklets) are observed in crowded scenes. It advances the existing Latent Dirichlet Allocation topic model, by integrating the Markov random fields (MR-F) as prior to enforce the spatial and temporal coherence between tracklets during the learning process. Two kinds of MRF, pairwise MRF and the forest of randomly spanning trees, are defined. Another contribution of this model is to include sources and sinks as high-level semantic prior, which effectively improves the learning of semantic regions and the clustering of tracklets. Experiments on a large scale data set, which includes 40, 000+ tracklets collected from the crowded New York Grand Central station, show that our model outperforms state-of-the-art methods both on qualitative results of learning semantic regions and on quantitative results of clustering tracklets.",2011,"Bolei Zhou,Xiaogang Wang,Xiaoou Tang",Computer Science,153,32
7490062,Sparse reconstruction cost for abnormal event detection,"We propose to detect abnormal events via a sparse reconstruction over the normal bases. Given an over-complete normal basis set (e.g., an image sequence or a collection of local spatio-temporal patches), we introduce the sparse reconstruction cost (SRC) over the normal dictionary to measure the normalness of the testing sample. To condense the size of the dictionary, a novel dictionary selection method is designed with sparsity consistency constraint. By introducing the prior weight of each basis during sparse reconstruction, the proposed SRC is more robust compared to other outlier detection criteria. Our method provides a unified solution to detect both local abnormal events (LAE) and global abnormal events (GAE). We further extend it to support online abnormal event detection by updating the dictionary incrementally. Experiments on three benchmark datasets and the comparison to the state-of-the-art methods validate the advantages of our algorithm.",2011,"Yang Cong,Junsong Yuan,Ji Liu",Computer Science,778,28
9271136,Abnormal detection using interaction energy potentials,"A new method is proposed to detect abnormal behaviors in human group activities. This approach effectively models group activities based on social behavior analysis. Different from previous work that uses independent local features, our method explores the relationships between the current behavior state of a subject and its actions. An interaction energy potential function is proposed to represent the current behavior state of a subject, and velocity is used as its actions. Our method does not depend on human detection or segmentation, so it is robust to detection errors. Instead, tracked spatio-temporal interest points are able to provide a good estimation of modeling group interaction. SVM is used to find abnormal events. We evaluate our algorithm in two datasets: UMN and BEHAVE. Experimental results show its promising performance against the state-of-art methods.",2011,"Xinyi Cui,Qingshan Liu,Mingchen Gao,Dimitris N. Metaxas",Computer Science,238,32
206485682,Crowd Analysis Using Computer Vision Techniques,"This article presents a survey on crowd analysis using computer vision techniques, covering different aspects such as people tracking, crowd density estimation, event detection, validation, and simulation. It also reports how related the areas of computer vision and computer graphics should be to deal with current challenges in crowd analysis.",2010,"Julio C. S. Jacques Junior,S. Musse,C. Jung",Computer Science,380,46
13401588,Panic-driven event detection from surveillance video stream without track and motion features,"Modern surveillance systems are becoming highly automated in terms of scene understanding and event detection capabilities, and most existing methods rely on track-and motion-based features for event classification and anomaly detection. However, trajectory-based methods fail in public scenarios due to frequently loosing the object tracks, while the capabilities of motion-based methods are limited in detection of direction and velocity related anomalies. In this paper, a novel feature extraction and event detection method is presented without using any track and motion features where event discriminating characteristics are discovered from the dynamics of multiple temporal features extracted from foreground blobs and then confined in support vector machine based models for real-time event detection. Experimental results on benchmark datasets show that the proposed method can successfully discriminate panic-driven events like sudden split, runaway, and fighting from usual events.",2010,"Mahfuzul Haque,M. Murshed",Computer Science,24,16
14715398,Abnormality Detection with Improved Histogram of Oriented Tracklets,,2015,"Hossein Mousavi,Moin Nabi,Hamed Kiani Galoogahi,A. Perina,Vittorio Murino",Computer Science,43,29
18021059,Analyzing Tracklets for the Detection of Abnormal Crowd Behavior,"This paper presents a novel video descriptor, referred to as Histogram of Oriented Tracklets, for recognizing abnormal situation in crowded scenes. Unlike standard approaches that use optical flow, which estimates motion vectors only from two successive frames, we built our descriptor over long-range motion trajectories which is called tracklets in the literature. Following the standard procedure, we divided video sequences in spatio-temporal cuboids within which we collected statistics on the tracklets passing through them. In particular, we quantized orientation and magnitude in a 2-dimensional histogram which encodes the motion patterns expected in each cuboid. We classify frames as normal and abnormal by using Latent Dirichlet Allocation and Support Vector Machines. We evaluated the effectiveness of the proposed descriptors on three datasets: UCSD, Violence in Crowds and UMN. The experiments demonstrated (i) very promising results in abnormality detection, (ii) setting new state-of-the-art on two of them, and (iii) outperforming former descriptors based on the optical flow, dense trajectories and the social force model.",2015,"Hossein Mousavi,Sadegh Mohammadi,A. Perina,R. Chellali,Vittorio Murino",Computer Science,116,27
5675557,Temporal Poselets for Collective Activity Detection and Recognition,"Detection and recognition of collective human activities are important modules of any system devoted to high level social behavior analysis. In this paper, we present a novel semantic-based spatio-temporal descriptor which can cope with several interacting people at different scales and multiple activities in a video. Our descriptor is suitable for modelling the human motion interaction in crowded environments - the scenario most difficult to analyse because of occlusions. In particular, we extend the Pose let detector approach by defining a descriptor based on Pose let activation patterns over time, named TPOS. We will show that this descriptor can effectively tackle complex real scenarios allowing to detect humans in the scene, to localize (in space-time) human activities, and perform collective group activity recognition in a joint manner, reaching state-of-the-art results.",2013,"Moin Nabi,A. D. Bue,Vittorio Murino",Computer Science,24,24
15466712,A Review of Anomaly Detection in Automated Surveillance,"As surveillance becomes ubiquitous, the amount of data to be processed grows along with the demand for manpower to interpret the data. A key goal of surveillance is to detect behaviors that can be considered anomalous. As a result, an extensive body of research in automated surveillance has been developed, often with the goal of automatic detection of anomalies. Research into anomaly detection in automated surveillance covers a wide range of domains, employing a vast array of techniques. This review presents an overview of recent research approaches on the topic of anomaly detection in automated surveillance. The reviewed studies are analyzed across five aspects: surveillance target, anomaly definitions and assumptions, types of sensors used and the feature extraction processes, learning methods, and modeling algorithms.",2012,"Angela A. Sodemann,Matthew P. Ross,B. Borghetti",Computer Science,224,105
9604604,Histograms of Optical Flow Orientation for Visual Abnormal Events Detection,"In this paper, we propose an algorithm to detect abnormal events based on video streams. The algorithm is based on histograms of the orientation of optical flow descriptor and one-class SVM classifier. We introduce grids of Histograms of the Orientation of Optical Flow (HOFs) as the descriptors for motion information of the monolithic video frame. The one-class SVM, after a learning period characterizing normal behaviors, detects the abnormal events in the current frame. Extensive testing on benchmark dataset corroborates the effectiveness of the proposed detection method.",2012,"Tian Wang,H. Snoussi",Computer Science,63,20
3052515,Violent flows: Real-time detection of violent crowd behavior,"Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.",2012,"Tal Hassner,Yossi Itcher,Orit Kliper-Gross",Computer Science,417,34
41840831,An energy model approach to people counting for abnormal crowd behavior detection,,2012,"Guogang Xiong,Jun Cheng,Xinyu Wu,Yen-Lun Chen,Y. Ou,Yangsheng Xu",Computer Science,74,46
13537104,Action recognition by dense trajectories,"Feature trajectories have shown to be efficient for representing videos. Typically, they are extracted using the KLT tracker or matching SIFT descriptors between frames. However, the quality as well as quantity of these trajectories is often not sufficient. Inspired by the recent success of dense sampling in image classification, we propose an approach to describe videos by dense trajectories. We sample dense points from each frame and track them based on displacement information from a dense optical flow field. Given a state-of-the-art optical flow algorithm, our trajectories are robust to fast irregular motions as well as shot boundaries. Additionally, dense trajectories cover the motion information in videos well. We, also, investigate how to design descriptors to encode the trajectory information. We introduce a novel descriptor based on motion boundary histograms, which is robust to camera motion. This descriptor consistently outperforms other state-of-the-art descriptors, in particular in uncontrolled realistic videos. We evaluate our video description in the context of action classification with a bag-of-features approach. Experimental results show a significant improvement over the state of the art on four datasets of varying difficulty, i.e. KTH, YouTube, Hollywood2 and UCF sports.",2011,"Heng Wang,Alexander Kläser,C. Schmid,Cheng-Lin Liu","Computer Science,Mathematics",2340,37
7490062,Sparse reconstruction cost for abnormal event detection,"We propose to detect abnormal events via a sparse reconstruction over the normal bases. Given an over-complete normal basis set (e.g., an image sequence or a collection of local spatio-temporal patches), we introduce the sparse reconstruction cost (SRC) over the normal dictionary to measure the normalness of the testing sample. To condense the size of the dictionary, a novel dictionary selection method is designed with sparsity consistency constraint. By introducing the prior weight of each basis during sparse reconstruction, the proposed SRC is more robust compared to other outlier detection criteria. Our method provides a unified solution to detect both local abnormal events (LAE) and global abnormal events (GAE). We further extend it to support online abnormal event detection by updating the dictionary incrementally. Experiments on three benchmark datasets and the comparison to the state-of-the-art methods validate the advantages of our algorithm.",2011,"Yang Cong,Junsong Yuan,Ji Liu",Computer Science,778,28
2743814,"Anomalous Behaviour Detection Using Spatiotemporal Oriented Energies, Subset Inclusion Histogram Comparison and Event-Driven Processing",,2010,"Andrei Zaharescu,Richard P. Wildes",Computer Science,93,37
9604604,Histograms of Optical Flow Orientation for Visual Abnormal Events Detection,"In this paper, we propose an algorithm to detect abnormal events based on video streams. The algorithm is based on histograms of the orientation of optical flow descriptor and one-class SVM classifier. We introduce grids of Histograms of the Orientation of Optical Flow (HOFs) as the descriptors for motion information of the monolithic video frame. The one-class SVM, after a learning period characterizing normal behaviors, detects the abnormal events in the current frame. Extensive testing on benchmark dataset corroborates the effectiveness of the proposed detection method.",2012,"Tian Wang,H. Snoussi",Computer Science,63,20
3052515,Violent flows: Real-time detection of violent crowd behavior,"Although surveillance video cameras are now widely used, their effectiveness is questionable. Here, we focus on the challenging task of monitoring crowded events for outbreaks of violence. Such scenes require a human surveyor to monitor multiple video screens, presenting crowds of people in a constantly changing sea of activity, and to identify signs of breaking violence early enough to alert help. With this in mind, we propose the following contributions: (1) We describe a novel approach to real-time detection of breaking violence in crowded scenes. Our method considers statistics of how flow-vector magnitudes change over time. These statistics, collected for short frame sequences, are represented using the VIolent Flows (ViF) descriptor. ViF descriptors are then classified as either violent or non-violent using linear SVM. (2) We present a unique data set of real-world surveillance videos, along with standard benchmarks designed to test both violent/non-violent classification, as well as real-time detection accuracy. Finally, (3) we provide empirical tests, comparing our method to state-of-the-art techniques, and demonstrating its effectiveness.",2012,"Tal Hassner,Yossi Itcher,Orit Kliper-Gross",Computer Science,417,34
3085328,Understanding collective crowd behaviors: Learning a Mixture model of Dynamic pedestrian-Agents,"In this paper, a new Mixture model of Dynamic pedestrian-Agents (MDA) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes. Collective behaviors characterize the intrinsic dynamics of the crowd. From the agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with its initial and termination states reflecting a pedestrian's belief of the starting point and the destination. Then the whole crowd is modeled as a mixture of dynamic pedestrian-agents. Once the model is unsupervisedly learned from real data, MDA can simulate the crowd behaviors. Furthermore, MDA can well infer the past behaviors and predict the future behaviors of pedestrians given their trajectories only partially observed, and classify different pedestrian behaviors in the scene. The effectiveness of MDA and its applications are demonstrated by qualitative and quantitative experiments on the video surveillance dataset collected from the New York Grand Central Station.",2012,"Bolei Zhou,Xiaogang Wang,Xiaoou Tang",Computer Science,343,28
20249873,Loveparade 2010: Automatic video analysis of a crowd disaster,,2012,"B. Krausz,C. Bauckhage","Mathematics,Computer Science",175,30
14119368,Abnormal Crowd Behavior Detection by Social Force Optimization,,2011,"Ramachandra Raghavendra,A. D. Bue,M. Cristani,Vittorio Murino",Computer Science,53,20
7509559,Analyzing pedestrian behavior in crowds for automatic detection of congestions,"Congestions in pedestrian traffic typically occur when the number of pedestrians exceeds the capacity of pedestrian facilities. In some cases, the pedestrian density reaches a critical level which may lead to a crowd stampede as happens rather frequently at mass gatherings, in stadiums or at train stations. In the past, research has focused on improving simulations of crowd motion in order to identify potentially dangerous locations and to direct pedestrian streams. Recently, works towards the automatic real-time detection of critical mass behavior based on optical flow computations have been proposed. In this paper, we verify these approaches by analyzing mircoscopic pedestrian behavior in congestions and conducting experiments on synthetic as well as on real datasets.",2011,"B. Krausz,C. Bauckhage",Computer Science,28,26
16102573,Optimizing interaction force for global anomaly detection in crowded scenes,"This paper presents a novel method for global anomaly detection in crowded scenes. The proposed method introduces the Particle Swarm Optimization (PSO) method as a robust algorithm for optimizing the interaction force computed using the Social Force Model (SFM). The main objective of the proposed method is to drift the population of particles towards the areas of the main image motion. Such displacement is driven by the PSO fitness function aimed at minimizing the interaction force, so as to model the most diffused and typical crowd behavior. Experiments are extensively conducted on public available datasets, namely, UMN and PETS 2009, and also on a challenging dataset of videos taken from Internet. The experimental results revealed that the proposed scheme outperforms all the available state-of-the-art algorithms for global anomaly detection.",2011,"Ramachandra Raghavendra,A. D. Bue,M. Cristani,Vittorio Murino",Computer Science,84,14
13537104,Action recognition by dense trajectories,"Feature trajectories have shown to be efficient for representing videos. Typically, they are extracted using the KLT tracker or matching SIFT descriptors between frames. However, the quality as well as quantity of these trajectories is often not sufficient. Inspired by the recent success of dense sampling in image classification, we propose an approach to describe videos by dense trajectories. We sample dense points from each frame and track them based on displacement information from a dense optical flow field. Given a state-of-the-art optical flow algorithm, our trajectories are robust to fast irregular motions as well as shot boundaries. Additionally, dense trajectories cover the motion information in videos well. We, also, investigate how to design descriptors to encode the trajectory information. We introduce a novel descriptor based on motion boundary histograms, which is robust to camera motion. This descriptor consistently outperforms other state-of-the-art descriptors, in particular in uncontrolled realistic videos. We evaluate our video description in the context of action classification with a bag-of-features approach. Experimental results show a significant improvement over the state of the art on four datasets of varying difficulty, i.e. KTH, YouTube, Hollywood2 and UCF sports.",2011,"Heng Wang,Alexander Kläser,C. Schmid,Cheng-Lin Liu","Computer Science,Mathematics",2340,37
4231589,Random field topic model for semantic region analysis in crowded scenes from tracklets,"In this paper, a Random Field Topic (RFT) model is proposed for semantic region analysis from motions of objects in crowded scenes. Different from existing approaches of learning semantic regions either from optical flows or from complete trajectories, our model assumes that fragments of trajectories (called tracklets) are observed in crowded scenes. It advances the existing Latent Dirichlet Allocation topic model, by integrating the Markov random fields (MR-F) as prior to enforce the spatial and temporal coherence between tracklets during the learning process. Two kinds of MRF, pairwise MRF and the forest of randomly spanning trees, are defined. Another contribution of this model is to include sources and sinks as high-level semantic prior, which effectively improves the learning of semantic regions and the clustering of tracklets. Experiments on a large scale data set, which includes 40, 000+ tracklets collected from the crowded New York Grand Central station, show that our model outperforms state-of-the-art methods both on qualitative results of learning semantic regions and on quantitative results of clustering tracklets.",2011,"Bolei Zhou,Xiaogang Wang,Xiaoou Tang",Computer Science,153,32
317279,Tracklet Descriptors for Action Modeling and Video Analysis,,2010,"Michalis Raptis,Stefano Soatto","Computer Science,Mathematics",167,46
1471813,Poselet Key-Framing: A Model for Human Activity Recognition,"In this paper, we develop a new model for recognizing human actions. An action is modeled as a very sparse sequence of temporally local discriminative key frames - collections of partial key-poses of the actor(s), depicting key states in the action sequence. We cast the learning of key frames in a max-margin discriminative framework, where we treat key frames as latent variables. This allows us to (jointly) learn a set of most discriminative key frames while also learning the local temporal context between them. Key frames are encoded using a spatially-localizable pose let-like representation with HoG and BoW components learned from weak annotations, we rely on structured SVM formulation to align our components and mine for hard negatives to boost localization performance. This results in a model that supports spatio-temporal localization and is insensitive to dropped frames or partial observations. We show classification performance that is competitive with the state of the art on the benchmark UT-Interaction dataset and illustrate that our model outperforms prior methods in an on-line streaming setting.",2013,"Michalis Raptis,L. Sigal",Computer Science,238,39
2327119,A Unified Framework for Multi-target Tracking and Collective Activity Recognition,,2012,"Wongun Choi,S. Savarese","Computer Science,Mathematics",342,37
6010741,Combining Per-frame and Per-track Cues for Multi-person Action Recognition,,2012,"S. Khamis,Vlad I. Morariu,L. Davis",Computer Science,49,32
66952,Discriminative Latent Models for Recognizing Contextual Group Activities,"In this paper, we go beyond recognizing the actions of individuals and focus on group activities. This is motivated from the observation that human actions are rarely performed in isolation; the contextual information of what other people in the scene are doing provides a useful cue for understanding high-level activities. We propose a novel framework for recognizing group activities which jointly captures the group activity, the individual person actions, and the interactions among them. Two types of contextual information, group-person interaction and person-person interaction, are explored in a latent variable framework. In particular, we propose three different approaches to model the person-person interaction. One approach is to explore the structures of person-person interaction. Differently from most of the previous latent structured models, which assume a predefined structure for the hidden layer, e.g., a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. The second approach explores person-person interaction in the feature level. We introduce a new feature representation called the action context (AC) descriptor. The AC descriptor encodes information about not only the action of an individual person in the video, but also the behavior of other people nearby. The third approach combines the above two. Our experimental results demonstrate the benefit of using contextual information for disambiguating group activities.",2012,"Tian Lan,Yang Wang,Weilong Yang,S. Robinovitch,Greg Mori","Computer Science,Medicine",296,51
9208396,Action bank: A high-level representation of activity in video,"Activity recognition in video is dominated by low- and mid-level features, and while demonstrably capable, by nature, these features carry little semantic meaning. Inspired by the recent object bank approach to image representation, we present Action Bank, a new high-level representation of video. Action bank is comprised of many individual action detectors sampled broadly in semantic space as well as viewpoint space. Our representation is constructed to be semantically rich and even when paired with simple linear SVM classifiers is capable of highly discriminative performance. We have tested action bank on four major activity recognition benchmarks. In all cases, our performance is better than the state of the art, namely 98.2% on KTH (better by 3.3%), 95.0% on UCF Sports (better by 3.7%), 57.9% on UCF50 (baseline is 47.9%), and 26.9% on HMDB51 (baseline is 23.2%). Furthermore, when we analyze the classifiers, we find strong transfer of semantics from the constituent action detectors to the bank classifier.",2012,"S. Sadanand,Jason J. Corso",Computer Science,793,39
13622862,A flow model for joint action recognition and identity maintenance,"We propose a framework that performs action recognition and identity maintenance of multiple targets simultaneously. Instead of first establishing tracks using an appearance model and then performing action recognition, we construct a network flow-based model that links detected bounding boxes across video frames while inferring activities, thus integrating identity maintenance and action recognition. Inference in our model reduces to a constrained minimum cost flow problem, which we solve exactly and efficiently. By leveraging both appearance similarity and action transition likelihoods, our model improves on state-of-the-art results on action recognition for two datasets.",2012,"S. Khamis,Vlad I. Morariu,L. Davis",Computer Science,40,32
13537104,Action recognition by dense trajectories,"Feature trajectories have shown to be efficient for representing videos. Typically, they are extracted using the KLT tracker or matching SIFT descriptors between frames. However, the quality as well as quantity of these trajectories is often not sufficient. Inspired by the recent success of dense sampling in image classification, we propose an approach to describe videos by dense trajectories. We sample dense points from each frame and track them based on displacement information from a dense optical flow field. Given a state-of-the-art optical flow algorithm, our trajectories are robust to fast irregular motions as well as shot boundaries. Additionally, dense trajectories cover the motion information in videos well. We, also, investigate how to design descriptors to encode the trajectory information. We introduce a novel descriptor based on motion boundary histograms, which is robust to camera motion. This descriptor consistently outperforms other state-of-the-art descriptors, in particular in uncontrolled realistic videos. We evaluate our video description in the context of action classification with a bag-of-features approach. Experimental results show a significant improvement over the state of the art on four datasets of varying difficulty, i.e. KTH, YouTube, Hollywood2 and UCF sports.",2011,"Heng Wang,Alexander Kläser,C. Schmid,Cheng-Lin Liu","Computer Science,Mathematics",2340,37
2493017,Action recognition from a distributed representation of pose and appearance,"We present a distributed representation of pose and appearance of people called the “poselet activation vector”. First we show that this representation can be used to estimate the pose of people defined by the 3D orientations of the head and torso in the challenging PASCAL VOC 2010 person detection dataset. Our method is robust to clutter, aspect and viewpoint variation and works even when body parts like faces and limbs are occluded or hard to localize. We combine this representation with other sources of information like interaction with objects and other people in the image and use it for action recognition. We report competitive results on the PASCAL VOC 2010 static image action classification challenge.",2011,"Subhransu Maji,Lubomir D. Bourdev,Jitendra Malik","Mathematics,Computer Science",330,26
6006618,Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis,"Previous work on action recognition has focused on adapting hand-designed local features, such as SIFT or HOG, from static images to the video domain. In this paper, we propose using unsupervised feature learning as a way to learn features directly from video data. More specifically, we present an extension of the Independent Subspace Analysis algorithm to learn invariant spatio-temporal features from unlabeled video data. We discovered that, despite its simplicity, this method performs surprisingly well when combined with deep learning techniques such as stacking and convolution to learn hierarchical representations. By replacing hand-designed features with our learned features, we achieve classification results superior to all previous published results on the Hollywood2, UCF, KTH and YouTube action recognition datasets. On the challenging Hollywood2 and YouTube action datasets we obtain 53.3% and 75.8% respectively, which are approximately 5% better than the current best published results. Further benefits of this method, such as the ease of training and the efficiency of training and prediction, will also be discussed. You can download our code and learned spatio-temporal features here: http://ai.stanford.edu/∼wzou/",2011,"Quoc V. Le,Will Y. Zou,Serena Yeung,A. Ng",Computer Science,1100,45
17814249,Learning context for collective activity recognition,"In this paper we present a framework for the recognition of collective human activities. A collective activity is defined or reinforced by the existence of coherent behavior of individuals in time and space. We call such coherent behavior ‘Crowd Context’. Examples of collective activities are “queuing in a line” or “talking”. Following [7], we propose to recognize collective activities using the crowd context and introduce a new scheme for learning it automatically. Our scheme is constructed upon a Random Forest structure which randomly samples variable volume spatio-temporal regions to pick the most discriminating attributes for classification. Unlike previous approaches, our algorithm automatically finds the optimal configuration of spatio-temporal bins, over which to sample the evidence, by randomization. This enables a methodology for modeling crowd context. We employ a 3D Markov Random Field to regularize the classification and localize collective activities in the scene. We demonstrate the flexibility and scalability of the proposed framework in a number of experiments and show that our method outperforms state-of-the art action classification techniques [7, 19].",2011,"Wongun Choi,Khuram Shahid,S. Savarese",Computer Science,258,31
24837317,Crowd Event Perception Based on Spatio-temporal Viscous Fluid Field,"Over the past decades, a wide attention has been paid to crowd control and management in intelligent video surveillance area. In this paper, the authors propose a novel spatiotemporal viscous fluid field to recognize large-scale crowd event with respect to both appearance and driven factor of crowd behavior. Firstly, a spatiotemporal variation matrix is proposed to exploit motion property of a crowd. In particular, the paper exploits characteristics of the matrix with eigenvalue decomposition algorithm and constructs an abstract fluid field to model the crowd motion pattern, which is denoted by spatiotemporal fluid field. Secondly, the paper proposes a spatiotemporal force field to exploit the interaction force between the pedestrians. Furthermore, the fluid and force field constructs a spatiotemporal viscous fluid field. Thirdly, after generating feature with bag of word model, the authors utilize latent Dirichlet allocation model to recognize crowd behavior. The experiments on PETS2009 and UMN datasets show that the proposed method has a better performance for large-scale crowd behavior perception in both robustness and effectiveness comparing with the conventional methods.",2012,"Hang Su,Hua Yang,Shibao Zheng,Yawen Fan,Sha Wei",Computer Science,17,13
3085328,Understanding collective crowd behaviors: Learning a Mixture model of Dynamic pedestrian-Agents,"In this paper, a new Mixture model of Dynamic pedestrian-Agents (MDA) is proposed to learn the collective behavior patterns of pedestrians in crowded scenes. Collective behaviors characterize the intrinsic dynamics of the crowd. From the agent-based modeling, each pedestrian in the crowd is driven by a dynamic pedestrian-agent, which is a linear dynamic system with its initial and termination states reflecting a pedestrian's belief of the starting point and the destination. Then the whole crowd is modeled as a mixture of dynamic pedestrian-agents. Once the model is unsupervisedly learned from real data, MDA can simulate the crowd behaviors. Furthermore, MDA can well infer the past behaviors and predict the future behaviors of pedestrians given their trajectories only partially observed, and classify different pedestrian behaviors in the scene. The effectiveness of MDA and its applications are demonstrated by qualitative and quantitative experiments on the video surveillance dataset collected from the New York Grand Central Station.",2012,"Bolei Zhou,Xiaogang Wang,Xiaoou Tang",Computer Science,343,28
2296945,Tracking Pedestrians Using Local Spatio-Temporal Motion Patterns in Extremely Crowded Scenes,"Tracking pedestrians is a vital component of many computer vision applications, including surveillance, scene understanding, and behavior analysis. Videos of crowded scenes present significant challenges to tracking due to the large number of pedestrians and the frequent partial occlusions that they produce. The movement of each pedestrian, however, contributes to the overall crowd motion (i.e., the collective motions of the scene's constituents over the entire video) that exhibits an underlying spatially and temporally varying structured pattern. In this paper, we present a novel Bayesian framework for tracking pedestrians in videos of crowded scenes using a space-time model of the crowd motion. We represent the crowd motion with a collection of hidden Markov models trained on local spatio-temporal motion patterns, i.e., the motion patterns exhibited by pedestrians as they move through local space-time regions of the video. Using this unique representation, we predict the next local spatio-temporal motion pattern a tracked pedestrian will exhibit based on the observed frames of the video. We then use this prediction as a prior for tracking the movement of an individual in videos of extremely crowded scenes. We show that our approach of leveraging the crowd motion enables tracking in videos of complex scenes that present unique difficulty to other approaches.",2012,"L. Kratz,K. Nishino","Medicine,Computer Science",141,30
363733,Vision-Based Analysis of Small Groups in Pedestrian Crowds,"Building upon state-of-the-art algorithms for pedestrian detection and multi-object tracking, and inspired by sociological models of human collective behavior, we automatically detect small groups of individuals who are traveling together. These groups are discovered by bottom-up hierarchical clustering using a generalized, symmetric Hausdorff distance defined with respect to pairwise proximity and velocity. We validate our results quantitatively and qualitatively on videos of real-world pedestrian scenes. Where human-coded ground truth is available, we find substantial statistical agreement between our results and the human-perceived small group structure of the crowd. Results from our automated crowd analysis also reveal interesting patterns governing the shape of pedestrian groups. These discoveries complement current research in crowd dynamics, and may provide insights to improve evacuation planning and real-time situation awareness during public disturbances.",2012,"Weina Ge,R. Collins,Barry Ruback","Computer Science,Medicine",366,75
16102573,Optimizing interaction force for global anomaly detection in crowded scenes,"This paper presents a novel method for global anomaly detection in crowded scenes. The proposed method introduces the Particle Swarm Optimization (PSO) method as a robust algorithm for optimizing the interaction force computed using the Social Force Model (SFM). The main objective of the proposed method is to drift the population of particles towards the areas of the main image motion. Such displacement is driven by the PSO fitness function aimed at minimizing the interaction force, so as to model the most diffused and typical crowd behavior. Experiments are extensively conducted on public available datasets, namely, UMN and PETS 2009, and also on a challenging dataset of videos taken from Internet. The experimental results revealed that the proposed scheme outperforms all the available state-of-the-art algorithms for global anomaly detection.",2011,"Ramachandra Raghavendra,A. D. Bue,M. Cristani,Vittorio Murino",Computer Science,84,14
215754778,Data-driven crowd analysis in videos,"In this work we present a new crowd analysis algorithm powered by behavior priors that are learned on a large database of crowd videos gathered from the Internet. The algorithm works by first learning a set of crowd behavior priors off-line. During testing, crowd patches are matched to the database and behavior priors are transferred. We adhere to the insight that despite the fact that the entire space of possible crowd behaviors is infinite, the space of distinguishable crowd motion patterns may not be all that large. For many individuals in a crowd, we are able to find analogous crowd patches in our database which contain similar patterns of behavior that can effectively act as priors to constrain the difficult task of tracking an individual in a crowd. Our algorithm is data-driven and, unlike some crowd characterization methods, does not require us to have seen the test video beforehand. It performs like state-of-the-art methods for tracking people having common crowd behaviors and outperforms the methods when the tracked individual behaves in an unusual way.",2011,"Mikel D. Rodriguez,Josef Sivic,I. Laptev,Jean-Yves Audibert",Computer Science,228,33
4231589,Random field topic model for semantic region analysis in crowded scenes from tracklets,"In this paper, a Random Field Topic (RFT) model is proposed for semantic region analysis from motions of objects in crowded scenes. Different from existing approaches of learning semantic regions either from optical flows or from complete trajectories, our model assumes that fragments of trajectories (called tracklets) are observed in crowded scenes. It advances the existing Latent Dirichlet Allocation topic model, by integrating the Markov random fields (MR-F) as prior to enforce the spatial and temporal coherence between tracklets during the learning process. Two kinds of MRF, pairwise MRF and the forest of randomly spanning trees, are defined. Another contribution of this model is to include sources and sinks as high-level semantic prior, which effectively improves the learning of semantic regions and the clustering of tracklets. Experiments on a large scale data set, which includes 40, 000+ tracklets collected from the crowded New York Grand Central station, show that our model outperforms state-of-the-art methods both on qualitative results of learning semantic regions and on quantitative results of clustering tracklets.",2011,"Bolei Zhou,Xiaogang Wang,Xiaoou Tang",Computer Science,153,32
117084501,Numerical Methods for Large Eigenvalue Problems,Preface to the Classics Edition Preface 1. Background in matrix theory and linear algebra 2. Sparse matrices 3. Perturbation theory and error analysis 4. The tools of spectral approximation 5. Subspace iteration 6. Krylov subspace methods 7. Filtering and restarting techniques 8. Preconditioning techniques 9. Non-standard eigenvalue problems 10. Origins of matrix eigenvalue problems References Index.,2011,Y. Saad,Mathematics,612,0
7325832,Group motion segmentation using a Spatio-Temporal Driving Force Model,"We consider the ‘group motion segmentation’ problem and provide a solution for it. The group motion segmentation problem aims at analyzing motion trajectories of multiple objects in video and finding among them the ones involved in a ‘group motion pattern’. This problem is motivated by and serves as the basis for the ‘multi-object activity recognition’ problem, which is currently an active research topic in event analysis and activity recognition. Specifically, we learn a Spatio-Temporal Driving Force Model to characterize a group motion pattern and design an approach for segmenting the group motion. We illustrate the approach using videos of American football plays, where we identify the offensive players, who follow an offensive motion pattern, from motions of all players in the field. Experiments using GaTech Football Play Dataset validate the effectiveness of the segmentation algorithm.",2010,"Ruonan Li,R. Chellappa",Computer Science,57,38
14411054,Chaotic invariants of Lagrangian particle trajectories for anomaly detection in crowded scenes,"A novel method for crowd flow modeling and anomaly detection is proposed for both coherent and incoherent scenes. The novelty is revealed in three aspects. First, it is a unique utilization of particle trajectories for modeling crowded scenes, in which we propose new and efficient representative trajectories for modeling arbitrarily complicated crowd flows. Second, chaotic dynamics are introduced into the crowd context to characterize complicated crowd motions by regulating a set of chaotic invariant features, which are reliably computed and used for detecting anomalies. Third, a probabilistic framework for anomaly detection and localization is formulated. The overall work-flow begins with particle advection based on optical flow. Then particle trajectories are clustered to obtain representative trajectories for a crowd flow. Next, the chaotic dynamics of all representative trajectories are extracted and quantified using chaotic invariants known as maximal Lyapunov exponent and correlation dimension. Probabilistic model is learned from these chaotic feature set, and finally, a maximum likelihood estimation criterion is adopted to identify a query video of a scene as normal or abnormal. Furthermore, an effective anomaly localization algorithm is designed to locate the position and size of an anomaly. Experiments are conducted on known crowd data set, and results show that our method achieves higher accuracy in anomaly detection and can effectively localize anomalies.",2010,"Shandong Wu,Brian E. Moore,M. Shah","Computer Science,Mathematics",538,24
1086900,Recognizing Gestures by Learning Local Motion Signatures of HOG Descriptors,"We introduce a new gesture recognition framework based on learning local motion signatures (LMSs) of HOG descriptors introduced by [1]. Our main contribution is to propose a new probabilistic learning-classification scheme based on a reliable tracking of local features. After the generation of these LMSs computed on one individual by tracking Histograms of Oriented Gradient (HOG) [2] descriptor, we learn a codebook of video-words (i.e., clusters of LMSs) using k-means algorithm on a learning gesture video database. Then, the video-words are compacted to a code-book of codewords by the Maximization of Mutual Information (MMI) algorithm. At the final step, we compare the LMSs generated for a new gesture w.r.t. the learned code-book via the k-nearest neighbors (k-NN) algorithm and a novel voting strategy. Our main contribution is the handling of the N to N mapping between codewords and gesture labels within the proposed voting strategy. Experiments have been carried out on two public gesture databases: KTH [3] and IXMAS [4]. Results show that the proposed method outperforms recent state-of-the-art methods.",2012,"M. Kaâniche,F. Brémond","Computer Science,Medicine",44,34
7069813,The Action Similarity Labeling Challenge,"Recognizing actions in videos is rapidly becoming a topic of much research. To facilitate the development of methods for action recognition, several video collections, along with benchmark protocols, have previously been proposed. In this paper, we present a novel video database, the “Action Similarity LAbeliNg” (ASLAN) database, along with benchmark protocols. The ASLAN set includes thousands of videos collected from the web, in over 400 complex action classes. Our benchmark protocols focus on action similarity (same/not-same), rather than action classification, and testing is performed on never-before-seen actions. We propose this data set and benchmark as a means for gaining a more principled understanding of what makes actions different or similar, rather than learning the properties of particular action classes. We present baseline results on our benchmark, and compare them to human performance. To promote further study of action similarity techniques, we make the ASLAN database, benchmarks, and descriptor encodings publicly available to the research community.",2012,"Orit Kliper-Gross,Tal Hassner,Lior Wolf","Computer Science,Medicine",122,51
