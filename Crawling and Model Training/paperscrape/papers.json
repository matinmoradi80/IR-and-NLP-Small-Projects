{"Title": "The Eighth Visual Object Tracking VOT2020 Challenge Results", "ID": "231732518", "Abstract": "A significant novelty is introduction of a new VOT short-term tracking evaluation methodology, and introduction of segmentation ground truth in the VOT-ST2020 challenge – bounding boxes will no longer be used in theVDT challenges. The Visual Object Tracking challenge VOT2020 is the eighth annual tracker benchmarking activity organized by the VOT initiative. Results of 58 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The VOT2020 challenge was composed of five sub-challenges focusing on different tracking domains: (i) VOT-ST2020 challenge focused on short-term tracking in RGB, (ii) VOT-RT2020 challenge focused on “real-time” short-term tracking in RGB, (iii) VOT-LT2020 focused on long-term tracking namely coping with target disappearance and reappearance, (iv) VOT-RGBT2020 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2020 challenge focused on long-term tracking in RGB and depth imagery. Only the VOT-ST2020 datasets were refreshed. A significant novelty is introduction of a new VOT short-term tracking evaluation methodology, and introduction of segmentation ground truth in the VOT-ST2020 challenge – bounding boxes will no longer be used in the VOT-ST challenges. A The Eighth Visual Object Tracking VOT2020 Challenge Results 3 new VOT Python toolkit that implements all these novelites was introduced. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.", "Publication Year": 2020, "Authors": "M. Kristan, A. Leonardis, Jiri Matas, M. Felsberg, R. Pflugfelder, Joni-Kristian Kämäräinen, Martin Danelljan, L. Č. Zajc, A. Lukežič, O. Drbohlav, Linbo He, Yushan Zhang, Song Yan, Jinyu Yang, G. Fernandez, A. Hauptmann, Alireza Memarmoghadam, Álvaro García-Martín, Andreas Robinson, A. Varfolomieiev, Awet Haileslassie Gebrehiwot, Bedirhan Uzun, Bin Yan, Bing Li, C. Qian, Chi-Yi Tsai, C. Micheloni, Dong Wang, Fei Wang, Fei Xie, Felix Järemo Lawin, F. Gustafsson, G. Foresti, Goutam Bhat, Guang-Gui Chen, Haibin Ling, Haitao Zhang, Hakan Cevikalp, Haojie Zhao, Haoran Bai, Hari Chandana Kuchibhotla, Hasan Saribas, Heng Fan, Hossein Ghanei-Yakhdan, Houqiang Li, Houwen Peng, Huchuan Lu, Hui Li, Javad Khaghani, Jesús Bescós, Jianhua Li, Jianlong Fu, Jiaqian Yu, Jingtao Xu, J. Kittler, Jun Yin, Junhyun Lee, Kaicheng Yu, Kaiwen Liu, Kang Yang, Kenan Dai, Li Cheng, Li Zhang, Lijun Wang, Linyuan Wang, L. Gool, Luca Bertinetto, Matteo Dunnhofer, Miao Cheng, Mohana Murali Dasari, Ning Wang, Pengyu Zhang, Philip H. S. Torr, Qiang Wang, R. Timofte, Rama Krishna Sai Subrahmanyam Gorthi, Seokeon Choi, S. M. Marvasti-Zadeh, Shaochuan Zhao, S. Kasaei, Shoumeng Qiu, Shuhao Chen, Thomas Bo Schön, Tianyang Xu, W. Lu, Weiming Hu, Wen-gang Zhou, Xi Qiu, Xiao Ke, Xiaojun Wu, Xiaolin Zhang, Xiaoyun Yang, Xuefeng Zhu, Yingjie Jiang, Yingming Wang, Yiwei Chen, Yu Ye, Yuezhou Li, Yuncon Yao, Yunsung Lee, Yuzhang Gu, Zezhou Wang, Zhangyong Tang, Zhenhua Feng, Zhijun Mai, Zhipeng Zhang, Zhirong Wu, Ziang Ma", "Related Topics": "VOT2020, Accurate Tracking By Overlap Maximization, Visual Object Tracking, Short-term Tracking, Alpha-Refine, GlobalTrack, Meta-Updater, DiMP, Reappearance, SuperDiMP", "Citation Count": 187, "Reference Count": 87, "References": "786577081e00d69eeac8e9612eaf2dad59765e73, 219e9a4527110baf1feb3df20db12064eeafdfb7, 3c74b636c0f74c1a0cbbd6e165c2760264044971, 15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d, 6179ac06f1a8fd1ac6b693b02824948dff438d54, c6dc55afe9fbe46f4f4dd48ae620ad455bfa5508, dd45fe910a0200d43aaa77362f658542f6e175ff, ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7, 45512d44f1205bc92775f2e880858b3f23c9f5fd, 320d05db95ab42ade69294abe46cd1aca6aca602"}
{"Title": "Benign and malignant breast tumors classification based on region growing and CNN segmentation", "ID": "39119547", "Abstract": "Semantic Scholar extracted view of \"Benign and malignant breast tumors classification based on region growing and CNN segmentation\" by R. Rouhi et al.", "Publication Year": 2015, "Authors": "R. Rouhi, M. Jafari, S. Kasaei, P. Keshavarzian", "Related Topics": "Cellular Neural Networks, Mammograms, Malignant, Convolutional Neural Network, Mammographic Image Analysis Society, Approximate Nearest Neighbor, Support Vector Machines, Random Forests, Digital Database For Screening Mammography, Classification", "Citation Count": 352, "Reference Count": 58, "References": "3c948ca247c6f55ef994400e713412b5f845dd40, 9b5d0a48b0feb156a1270da54d90d0963a3f0404, 76389ebb7c1496239e66fd663b0e7e43d391bca9, d0059280e3f69b8fd07ce036e7d2407e3ebcff9e, 2dfb1fd3adfa58a3448251e03b1a5a78239958b3, 46c409dd878e643271ef63f1817ded8b57abc01e, 342da5d8633aebf27d914a8618e523579a130289, fe83150bc326fd62d352cb2993ac91344f195e10, 483f0f12feb8ac1c396349e5526a7552b6b067cd, a9d0b3485f3091e832f87edb469c350c90cabae1"}
{"Title": "Classification of benign and malignant masses based on Zernike moments", "ID": "5670140", "Abstract": "Semantic Scholar extracted view of \"Classification of benign and malignant masses based on Zernike moments\" by Amir Tahmasbi et al.", "Publication Year": 2011, "Authors": "Amir Tahmasbi, Fatemeh Saki, S. B. Shokouhi", "Related Topics": "Computer Aided Detection ( Cade ) And Diagnosis, Zernike Moments, Multi-layer Perceptron, Malignant, Classification, Receiver Operating Characteristics, Region Of Interest, Fuzzy Preference Relations, Opposition-Based Learning", "Citation Count": 247, "Reference Count": 54, "References": "63a83600a73ffbfd6a58e315a247aa4f3da90a9b, 474ae46626676d01c7b38328c107b1531b181b46, 3e63f9f1323de17e96c4eaffda77b701d138c1f8, ce1e33c037689acbfd19d4dcfc53021bc59dee2b, 40bbb7667b260bad22b0e2cb34562f57735d67f8, d98b3a493bdf327f3447e75b4814339e1b436d05, ea7685f5ee65c4c152478111b5bfcb23a446d358, 802c5bf4c93b795f9f509a3b90efabc501e21c01, 9bf32a68edfea8b8c072bcd3ee0d696687bab403, 603b2f00c9948e63514bdefa4ac2d3357cc2a1dc"}
{"Title": "Breast mass contour segmentation algorithm in digital mammograms", "ID": "17223461", "Abstract": "Semantic Scholar extracted view of \"Breast mass contour segmentation algorithm in digital mammograms\" by Tolga Berber et al.", "Publication Year": 2013, "Authors": "Tolga Berber, A. Alpkocak, P. Balcı, O. Dicle", "Related Topics": "Balanced Accuracy, Radiologist, Mass Detection, Cylindrical Algebraic Decomposition", "Citation Count": 70, "Reference Count": 31, "References": "6c4aac0941b002d74264b7f702881e85f2eb47a2, 1c26e62c7d9719dcdd652932345090534d661629, 81b568a5899f22f6d8ea7dd2fc31f31f6d423e1a, 728d5be150b5ef7e2b22586f61b7a905b33ee7e6, 103a9fc043d9fcccec9d545a53a76e22dcfe9c3f, c83e00120d7adcda72ac01b95234134c47cba76a, 07a94891c522d59a1343e6292234aa9d43e89d89, dda0dc40bc5cb79d5638d8cac955337362e6473e, 2d78c76f2696918bb9457d30e2b9b62c10ccae45, e71d328440738b2ad8a1937ad6f5c0786c6cc315"}
{"Title": "Classification of Breast Masses based on Cognitive Resonance", "ID": "61475691", "Abstract": "A trustable mammography Computer Aided-Diagnosis (CADx) system utilizing a new cognitive classifier that primes a knowledge-base developed according to a mammography expert using a special kind of linguistics and grammar formalism. In this pape r, a novel approach has been proposed for mass diagnosis in mammography images. The objective is developing a trustable mammography Computer Aided-Diagnosis (CADx) system utilizing a new cognitive classifier. The input Region of Interest (ROI) is subjected to some preprocessing stages; then, a group of features describing the shape, margin and density characteristics of masses have been extracted. The proposed features are consistent with the evaluations that an expert radiologist takes into account in diagnosis process. The most effective features are selected in the feature selection stage and mapped from the set of real numbers to a set of linguistic terms. The proposed classifier primes a knowledge-base which is developed according to a mammography expert; its rules have been written using a special kind of linguistics and grammar formalism. The semantic comparison of features of the image to the expectations of the knowledge base, called cognitive resonance, leads to the final assessment. Since the output of this system comes with reason, the system is trustable. The best achieved Accuracy and False Positive Rate (FPR) are 87.93% and 10.52%, respectively. More numerical results are reported in the paper.", "Publication Year": 2012, "Authors": "Amir Tahmasbi, Fatemeh Saki, A. Amirkhani, Seyed Mohammad Seyedzade, Shariar B. Shokouhi", "Related Topics": "Linguistic Term, Margin, Grammar Formalism, Classification, Region Of Interest, Computer Aided Detection ( Cade ) And Diagnosis, Fuzzy Preference Relations", "Citation Count": 5, "Reference Count": 14, "References": "474ae46626676d01c7b38328c107b1531b181b46, 46c409dd878e643271ef63f1817ded8b57abc01e, 63a83600a73ffbfd6a58e315a247aa4f3da90a9b, ce1e33c037689acbfd19d4dcfc53021bc59dee2b, 802c5bf4c93b795f9f509a3b90efabc501e21c01, 34c44883a6152c5298f2c452670c1127072400e6, 6a6c0294803a5a31944d98588f482f7cc11f922e, 0937d51456ccf1dff869bc7540b8ace314488400, c6fbf1dd5f0b48ff01eede7149bb7d5da89d47c9, 2aaa0202c1dfb96d1e946d78b97b81fb18477207"}
{"Title": "A novel cognitive interpretation of breast cancer thermography with complementary learning fuzzy neural memory structure", "ID": "28690978", "Abstract": "Semantic Scholar extracted view of \"A novel cognitive interpretation of breast cancer thermography with complementary learning fuzzy neural memory structure\" by T. Z. Tan et al.", "Publication Year": 2006, "Authors": "T. Z. Tan, Hiok Chai Quek, G. Ng, E. Ng", "Related Topics": "Complementary Learning Fuzzy Neural Network, Breast Thermography, Confluence", "Citation Count": 122, "Reference Count": 119, "References": "cf56f94145af0ffb9484ba320677357a8a6822cf, 47a563783e0e25a0f2bddc9c806409f87261abc6, 0d2dc248254d1bd4fac973b3af2920983a8b5280, 2004b092de7809e5d3e46f5ac628986707399468, 72eecc47ab699d81b8350607eeb9c9ddbc6d01c0, 3a13396220d416a44b17ad5739e0f6b6a11fbbe2, c27f077e3ef069c153ae5157c041a78ab85f8f95, ea575ec28556d7162a8b9ccd8ea8191d34425483, f4c7e5d95e22521aa9eca342a0fa10b0ea32931e, 46da4d9a1a6ee66908bb37f0c2e4c50f481a632b"}
{"Title": "Innovation approach to cognitive medical image interpretation", "ID": "17163175", "Abstract": "This publication presents selected aspects of modelling cognitive processes designed for the in-depth interpretation of image data, and a proposal for employing UBIAS cognitive information systems to cognitively interpret and analyze image-type data. This publication presents selected aspects of modelling cognitive processes designed for the in-depth interpretation of image data. This type of cognitive processes can be observed when executing complex data analysis and interpretation. This publication will also present a proposal for employing UBIAS cognitive information systems (Understanding Based Image Analysis Systems) to cognitively interpret and analyze image-type data. This type of analysis will be done based on human cognitive processes occurring in a person's brain. The application of this type of cognitive processes to the automatic, computer analysis of data will be illustrated with the example of a cognitive analysis of medical data showing various types of foot deformities. The process of analyzing, interpreting and reasoning on the basis of the semantic contents of a given image has led to rolling out a new class of cognitive systems designed for the in-depth image data analysis. And it is this type of processes that will be presented here.", "Publication Year": 2008, "Authors": "L. Ogiela", "Related Topics": "Understanding Based Image Analysis Systems", "Citation Count": 10, "Reference Count": 16, "References": "444fc72280b76fff14eb22f500745b24645e36be, 9c2c1a52caf3ce621f9d579969cac3252191d822, 058db23492fe2c221c1bce6912af43ccd3639a18, 959ad6161c2e0bf050bc6ebd3691cc37a662e319, 8ef4b9945d411bc0afaef22a56898e5456f92c43, 100a531ad1544b6f033bb79b5c839f0ca9d7e382, 8fa67aaebfe72a02533bdb91bdc04a5f117d26d1, a1e255d23b2f350996fa288f5e0df3638bf37ad9, 50230e99367068a49f5acdd750b03da223685910, 61da428682f8c146aa9773a2fc2d427001ce4f81"}
{"Title": "Cognitive Systems for Medical Pattern Understanding and Diagnosis", "ID": "32660109", "Abstract": "The approach presented will show the possibilities of automatic and intelligent disease detection and its classification based on cognitive resonance processes and a new way of intelligent cognitive systems and pattern analysis using cognitive categorization. In the paper will be presented a new way of intelligent cognitive systems and pattern analysis using cognitive categorization. Such an understanding will be based on the linguistic and cognitive mechanisms of pattern recognition and classification. The goal is making computer analysis of the meaning for some selected classes of medical patterns. The approach presented will show the possibilities of automatic and intelligent disease detection and its classification based on cognitive resonance processes. Cognitive categorisation systems operate by executing a particular type of thought, cognitive and reasoning processes which take place in the human mind and which ultimately lead to making an in-depth description of the analysis and reasoning process.", "Publication Year": 2008, "Authors": "L. Ogiela", "Related Topics": "Classification, Pattern-recognition, Reasoning Process", "Citation Count": 30, "Reference Count": 9, "References": "5b5413962e80f03ceb1c13d6465655e6729b43e4, abb65ac0e763ab39661f0601378772ed9f69f13e, 903b8b19c548088a2c91c32548d81d861d353b79, f728e23d15051fb6575656bc48994e83aa11b8f8, 30dcd9579fc23d0cfb9ec4e8553f285f2987277a, 50230e99367068a49f5acdd750b03da223685910, 8edeef06411aa1ddb3bd01fae2b9da76d2a7c8cd, 206dbdaf705fa794c0d0e8e1658953469fc2d2c5, 0232da500137526a7ef5b1d8d9785a56d97bb699"}
{"Title": "Cognitive Informatics Foundations of Nature and Machine Intelligence", "ID": "14998819", "Abstract": "The compatibility of nature and machine intelligence is revealed, which forms a theoretical foundation for rigorous study in machine intelligence, AI, and intelligent systems. Intelligence is a driving force or an ability to acquire and use knowledge and skills, or to inference in problem solving. This keynote lecture describes the taxonomy and nature of intelligence. It analyzes roles of information in the evolution of human intelligence, and the needs for logical abstraction in modeling the brain and natural intelligence. A formal model of intelligence is developed known as the generic intelligence mode (GIM), which provides a foundation to explain the mechanisms of advanced natural intelligence such as thinking, learning, and inferences. A measurement framework of intelligent capability of humans and systems is presented in the forms of intelligent quotient, intelligent equivalence, and intelligent metrics. On the basis of GIM model and theories, the compatibility of nature and machine intelligence is revealed, which forms a theoretical foundation for rigorous study in machine intelligence, AI, and intelligent systems.", "Publication Year": 2007, "Authors": "Yingxu Wang", "Related Topics": "Natural Intelligence, Inference, Global Ionospheric Maps, Cognitive Informatics", "Citation Count": 11, "Reference Count": 32, "References": "ad2d95fffd34d69a7c190a46412a9ee761f756d1, 9a380592d6a341bf5793f4216d6e1e98c94f9255, 06620c3d5ee00cff3589d0204fce329da894b992, 2c5f9930e77d9be190c28b7b85aeceb8769c0179, 211e0ff9a6e3f464e932245707e3aaa068aec5eb, 414f7b53810bf19f539306be0fea9b56a7078dc8, 265f4e915754c26bea4bf37aa28e11c9fb1f9444, 31a585d645c422539bf00963f16234a4d858f3dd, 248d19d9b971a2cc44fbe7ee48f10ac2920f70c1, c0f5c2c609375ff8bb90e367ef4b507c5e49db9b"}
{"Title": "Cognitive informatics models of the brain", "ID": "62068787", "Abstract": "A memory-based approach is adopted to explore the brain and to demonstrate that memory is the foundation for any kind of natural or artificial intelligence. The human brain is the most complicated organ in the universe and a new frontier yet to be explored by an interdisciplinary approach. This paper attempts to develop logical and cognitive models of the brain by using cognitive informatics and formal methodologies. This paper adopts a memory-based approach to explore the brain and to demonstrate that memory is the foundation for any kind of natural or artificial intelligence. Logical structures of memories are explored, and cognitive models of the brain are proposed. Cognitive mechanisms of the brain, including hypotheses and theories on the thinking engine of the brain, long-term memory establishment, and roles of perceptive eye movement, and sleep in long-term memory development, are investigated. The models and theories can be applied to explain a wide range of fundamental phenomena in psychology, cognitive science, physiology, computing, and neural science.", "Publication Year": 2006, "Authors": "Yingxu Wang, Y. Wang", "Related Topics": "Cognitive Informatics, Artificial Intelligence, Memory-based Approaches", "Citation Count": 97, "Reference Count": 8, "References": "f35fa49a633ca16fab3155d6724a829028d6cb23, 33050bea00d4b41091d0ba669413317be8547ea6, 37434f07e43a3dfc36551deeaeb07a8ab5bf79a7, 11a5f7bf0ec911c337a2e57d540dcfcb5ae42caf, b51761ba8bac1419373dbc0b791c137953e9566b, 27c218fe2a65d077c3e4ef354c54a1a2d9ca0142, a15174ed603bae1b101c4655111bb511787b95b4, b4538feb07ee11009e9dad4e6a6c24a975ef3a28"}
{"Title": "Formal Description of the Mechanisms and Cognitive Process of Memorization", "ID": "14622320", "Abstract": "The mechanisms of memorization as a cognitive process is investigated that explains how and when memory is created in long-term memory and is rigorously described using real-time process algebra (RTPA). Memorization is a key cognitive process of the brain because almost all human intelligence is functioning based on it. This paper presents the theory of memory and the cognitive process of memorization. Neural informatics foundations and functional models of memory and memorization are explored toward the development of the mathematical models of memory. The mechanisms of memorization as a cognitive process is investigated that explains how and when memory is created in long-term memory. On the basis of the formalized memory and memorization models, the cognitive process of memorization is rigorously described using real-time process algebra (RTPA). This work forms one of the core enquiries for formally explaining the mechanisms of the brain and the natural intelligence according to the layered reference model of the brain (LRMB) developed in cognitive informatics.", "Publication Year": 2007, "Authors": "Yingxu Wang", "Related Topics": "Memorization, Real-Time Process Algebra, Layered Reference Model Of The Brain, Natural Intelligence, Cognitive Informatics, Neural Informatics", "Citation Count": 10, "Reference Count": 40, "References": "d636cb05eae1d06eb9534ac81e5293a8bc937688, 3fec5c566c42241a54e4bd56bae641a18da7149b, 211e0ff9a6e3f464e932245707e3aaa068aec5eb, 9a380592d6a341bf5793f4216d6e1e98c94f9255, ad2d95fffd34d69a7c190a46412a9ee761f756d1, b3bbc120acb34cffafae2c4e6ea24330bddb8189, 06620c3d5ee00cff3589d0204fce329da894b992, 263e3e9630c453a7a55ee18ff7f96017c59e4b8c, 33050bea00d4b41091d0ba669413317be8547ea6, 3c730da61f1dc2fdd4a320a2a387eda6f5e66c55"}
{"Title": "The Seventh Visual Object Tracking VOT2019 Challenge Results", "ID": "207925044", "Abstract": "The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative; results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The Visual Object Tracking challenge VOT2019 is the seventh annual tracker benchmarking activity organized by the VOT initiative. Results of 81 trackers are presented; many are state-of-the-art trackers published at major computer vision conferences or in journals in the recent years. The evaluation included the standard VOT and other popular methodologies for short-term tracking analysis as well as the standard VOT methodology for long-term tracking analysis. The VOT2019 challenge was composed of five challenges focusing on different tracking domains: (i) VOTST2019 challenge focused on short-term tracking in RGB, (ii) VOT-RT2019 challenge focused on \"real-time\" shortterm tracking in RGB, (iii) VOT-LT2019 focused on longterm tracking namely coping with target disappearance and reappearance. Two new challenges have been introduced: (iv) VOT-RGBT2019 challenge focused on short-term tracking in RGB and thermal imagery and (v) VOT-RGBD2019 challenge focused on long-term tracking in RGB and depth imagery. The VOT-ST2019, VOT-RT2019 and VOT-LT2019 datasets were refreshed while new datasets were introduced for VOT-RGBT2019 and VOT-RGBD2019. The VOT toolkit has been updated to support both standard shortterm, long-term tracking and tracking with multi-channel imagery. Performance of the tested trackers typically by far exceeds standard baselines. The source code for most of the trackers is publicly available from the VOT page. The dataset, the evaluation kit and the results are publicly available at the challenge website.", "Publication Year": 2019, "Authors": "M. Kristan, Jiri Matas, A. Leonardis, M. Felsberg, R. Pflugfelder, Joni-Kristian, Kämäräinen, L. Č. Zajc, O. Drbohlav, A. Lukežič, Amanda Berg, Abdelrahman, Eldesokey, Jani Käpylä, G. Fernandez, Abel Gonzalez-Garcia, Alireza, Memarmoghadam, Andong Lu, Anfeng He, A. Varfolomieiev, Antoni B. Chan, Ardhendu Shekhar, Tripathi, A. Smeulders, Bala Suraj Pedasingu, B. Chen, Baopeng Zhang, Baoyuan Wu, Bi, Li, Bin He, Bin Yan, Bing Bai, Bing Li, Bo Li, B. Kim, Chao Ma, Chen Fang, Chen, Qian, Cheng Chen, Chenglong Li, Chengquan Zhang, Chi-Yi Tsai, Chong Luo, Christian, Micheloni, Chunhui Zhang, D. Tao, Deepak Gupta, Dejia Song, Dong Wang, Efstratios, Gavves, Eunu Yi, F. Khan, Fangyi Zhang, Fei Wang, Fei Zhao, George De, Ath, Goutam Bhat, Guang-Gui Chen, Guangting Wang, Guoxuan Li, Hakan Çevikalp, Hao Du, Haojie, Zhao, Hasan Saribas, Ho Min Jung, Hongliang Bai, Hongyuan Yu, Houwen Peng, Huchuan, Lǔ, Hui Li, Jia-Ke Li, Jianhua Li, Jianlong Fu, Jie Chen, Jie Gao, Jie Zhao, Jin Tang, Jing, Jingjing Wu, Jingtuo Liu, Jinqiao Wang, Jinqing Qi, Jinyue Zhang, John Tsotsos, J. Hyuk, Lee, Joost van de Weijer, J. Kittler, Jun Ha Lee, Junfei Zhuang, Kangkai Zhang, Kangkang, Wang, Kenan Dai, Lei Chen, Lei Liu, Leida Guo, Li Zhang, Liang Wang, Liang Wang, Lichao, Zhang, Lijun Wang, Lijun Zhou, Linyu Zheng, Litu Rout, L. Gool, Luca Bertinetto, Martin, Danelljan, Matteo Dunnhofer, Meng Ni, M. Y. Kim, Ming Tang, Ming-Hsuan Yang, Naveen, Paluru, N. Martinel, Pengfei Xu, Pengfei Zhang, Pengkun Zheng, Pengyu Zhang, S. PhilipH., Torr, Q. Wang, Qing Guo, R. Timofte, Rama Krishna Sai Subrahmanyam Gorthi, Richard, Everson, Ruize Han, Ruohan Zhang, Shan You, Shaochuan Zhao, Shengwei Zhao, Shihu, Shikun Li, Shiming Ge, Shuai Bai, Shuosen Guan, Tengfei Xing, Tianyang Xu, Tianyu, Yang, Ting Zhang, Tomás Vojír, Wei Feng, Wei Hu, Weizhao Wang, Wenjie Tang, Wenjun, Zeng, Wenyu Liu, Xi Chen, Xi Qiu, Xiang Bai, Xiaojun Wu, Xiaoyun Yang, Xier, Xin Li, Xingyuan Sun, Xingyu Chen, Xinmei Tian, Xuwen Tang, Xuefeng Zhu, Yan-ping Huang, Yanan, Yanchao Lian, Yang Gu, Y. Liu, Yanjie Chen, Yi Zhang, Yinda Xu, Yingming, Yingping Li, Yu Zhou, Yuan Dong, Yufei Xu, Yunhua Zhang, Yunkun Li, Zeyu Zhao, Luo, Zhaoliang Zhang, Zhenhua Feng, Zhenyu He, Zhichao Song, Zhihao Chen, Zhipeng, Zhirong Wu, Zhiwei Xiong, Zhongjian Huang, Zhu Teng, Zihan Ni", "Related Topics": "VOT2019, VOT-RGBT2019, Visual Object Tracking, ATOM Tracker, FuCoLoT, DCFST, VOT-RGBT2019 Dataset, A3CTD, RGB Tracking, SPM-Tracker", "Citation Count": 366, "Reference Count": 114, "References": "3c74b636c0f74c1a0cbbd6e165c2760264044971, 53329e5c79c1128c7b252a12b182c472a3413bfa, 6179ac06f1a8fd1ac6b693b02824948dff438d54, 15c3d43d1e7ca086bb8ea7f3958b6d4d6abb7a3d, 4338f00c11224f1b4056125561927777ab610c9d, 6767812e114c426d45ea83894b156f7906e525cd, 19d6b9725a59f4b624205829d5f03ac893ca1367, 23f8927f996d56f3b5076d8993a70bcfc70182a1, dd45fe910a0200d43aaa77362f658542f6e175ff, ed0bab800e5e8fcf1b4e05024b2bcd1c2b1632f7"}
{"Title": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics", "ID": "4909695", "Abstract": "This article presents a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics, and shows that by using Siamese fine-tuning and at a small processing cost, this approach can greatly reduce the level of unnecessary, potentially sensitive information in the personal data. Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user’s device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.", "Publication Year": 2017, "Authors": "Seyed Ali Osia, Ali Shahin Shamsabadi, Sina Sajadmanesh, A. Taheri, Kleomenis Katevas, H. Rabiee, N. Lane, H. Haddadi", "Related Topics": "Face Recognition, Privacy Guarantees, Inference Attacks, Mobile Analytics, Photo-editing, Object Detection, Siamese Networks, Architecture, Computer Vision, Gender Classification", "Citation Count": 204, "Reference Count": 70, "References": "65c8a794830f9a11aa0b9ab682f3b6256be67185, 6c20cd584e7258056840eb88437d69731000bb0f, 60951974d24dd83e288117b0cd217af6a5d34178, f2f8f7a2ec1b2ede48cbcd189b376ab9fa0735ef, 8a5d0579590465494c9aba58a857af43b190b6a6, 2b7f9117eb6608a58be4c078ca3d69c0e5ccb875, 187a78ebfe654e9c1d3e8d070c8845a49c1d1a42, 5a7a7dfea3674d4e0474f7fdd596951da44babe4, 7fcb90f68529cbfab49f471b54719ded7528d0ef, 405006da005398279bdf7c3423d47aa0951c5391"}
{"Title": "Multiresolution Knowledge Distillation for Anomaly Detection", "ID": "227126845", "Abstract": "This work proposes to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle anomaly detection and localization. Unsupervised representation learning has proved to be a critical component of anomaly detection/localization in images. The challenges to learn such a representation are two-fold. Firstly, the sample size is not often large enough to learn a rich generalizable representation through conventional techniques. Secondly, while only normal samples are available at training, the learned features should be discriminative of normal and anomalous samples. Here, we propose to use the \"distillation\" of features at various layers of an expert network, which is pre-trained on ImageNet, into a simpler cloner network to tackle both issues. We detect and localize anomalies using the discrepancy between the expert and cloner networks’ intermediate activation values given an input sample. We show that considering multiple intermediate hints in distillation leads to better exploitation of the expert’s knowledge and a more distinctive discrepancy between the two networks, compared to utilizing only the last layer activation values. Notably, previous methods either fail in precise anomaly localization or need expensive region-based training. In contrast, with no need for any special or intensive training procedure, we incorporate interpretability algorithms in our novel framework to localize anomalous regions. Despite the striking difference between some test datasets and ImageNet, we achieve competitive or significantly superior results compared to SOTA on MNIST, F-MNIST, CIFAR-10, MVTecAD, Retinal-OCT, and two other medical datasets on both anomaly detection and localization.", "Publication Year": 2020, "Authors": "Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, M. Rohban, H. Rabiee", "Related Topics": "Multiresolution Knowledge Distillation, Anomaly Localization, One-class Setting, Uninformed Students, f-AnoGAN, Anomalous Regions, Anomalous Images, Anomaly Detection, ImageNet, Region-based Training", "Citation Count": 217, "Reference Count": 62, "References": "4c1abd8969fc1c360f50373f6552bcfb3cc408b7, 5db790198b9acf4e5efe350acdd814238fcacaa7, 0535625be630c6a67f4c244ebf3aa61ad088fc70, 3aa681914a7da79f7d7293f51a058eefe61c8bb7, 41747cbdbed84762dfbfc305254c97021279dc6e, dbc7401e3e75c40d3c720e7db3c906d48bd742d7, 2b75ba7f75170b73d913c515cc0deefef6c88f5f, 8381157eae4fbf8908d0312a9642f8e69e944449, d9d7ab13ce305ccee309c989a2341d72b1252070, 211b7caa1d47f22dc1f1b2f90b7710fc74e32d5d"}
